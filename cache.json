{"2025-01-17T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2501.10328v1","updated":"2025-01-17T17:57:49Z","published":"2025-01-17T17:57:49Z","title":"BoK: Introducing Bag-of-Keywords Loss for Interpretable Dialogue\n  Response Generation","summary":"  The standard language modeling (LM) loss by itself has been shown to be\ninadequate for effective dialogue modeling. As a result, various training\napproaches, such as auxiliary loss functions and leveraging human feedback, are\nbeing adopted to enrich open-domain dialogue systems. One such auxiliary loss\nfunction is Bag-of-Words (BoW) loss, defined as the cross-entropy loss for\npredicting all the words/tokens of the next utterance. In this work, we propose\na novel auxiliary loss named Bag-of-Keywords (BoK) loss to capture the central\nthought of the response through keyword prediction and leverage it to enhance\nthe generation of meaningful and interpretable responses in open-domain\ndialogue systems. BoK loss upgrades the BoW loss by predicting only the\nkeywords or critical words/tokens of the next utterance, intending to estimate\nthe core idea rather than the entire response. We incorporate BoK loss in both\nencoder-decoder (T5) and decoder-only (DialoGPT) architecture and train the\nmodels to minimize the weighted sum of BoK and LM (BoK-LM) loss. We perform our\nexperiments on two popular open-domain dialogue datasets, DailyDialog and\nPersona-Chat. We show that the inclusion of BoK loss improves the dialogue\ngeneration of backbone models while also enabling post-hoc interpretability. We\nalso study the effectiveness of BoK-LM loss as a reference-free metric and\nobserve comparable performance to the state-of-the-art metrics on various\ndialogue evaluation datasets.\n","authors":["Suvodip Dey","Maunendra Sankar Desarkar"],"pdf_url":"https://arxiv.org/pdf/2501.10328v1.pdf","comment":"Accepted at SIGDIAL 2024"},{"id":"http://arxiv.org/abs/2501.10326v1","updated":"2025-01-17T17:56:58Z","published":"2025-01-17T17:56:58Z","title":"Large language models for automated scholarly paper review: A survey","summary":"  Large language models (LLMs) have significantly impacted human society,\ninfluencing various domains. Among them, academia is not simply a domain\naffected by LLMs, but it is also the pivotal force in the development of LLMs.\nIn academic publications, this phenomenon is represented during the\nincorporation of LLMs into the peer review mechanism for reviewing manuscripts.\nWe proposed the concept of automated scholarly paper review (ASPR) in our\nprevious paper. As the incorporation grows, it now enters the coexistence phase\nof ASPR and peer review, which is described in that paper. LLMs hold\ntransformative potential for the full-scale implementation of ASPR, but they\nalso pose new issues and challenges that need to be addressed. In this survey\npaper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin\nwith a survey to find out which LLMs are used to conduct ASPR. Then, we review\nwhat ASPR-related technological bottlenecks have been solved with the\nincorporation of LLM technology. After that, we move on to explore new methods,\nnew datasets, new source code, and new online systems that come with LLMs for\nASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and\ninvestigate the attitudes and reactions of publishers and academia to ASPR.\nLastly, we discuss the challenges associated with the development of LLMs for\nASPR. We hope this survey can serve as an inspirational reference for the\nresearchers and promote the progress of ASPR for its actual implementation.\n","authors":["Zhenzhen Zhuang","Jiandong Chen","Hongfeng Xu","Yuwen Jiang","Jialiang Lin"],"pdf_url":"https://arxiv.org/pdf/2501.10326v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2501.07329v2","updated":"2025-01-17T17:53:27Z","published":"2025-01-13T13:43:46Z","title":"Joint Automatic Speech Recognition And Structure Learning For Better\n  Speech Understanding","summary":"  Spoken language understanding (SLU) is a structure prediction task in the\nfield of speech. Recently, many works on SLU that treat it as a\nsequence-to-sequence task have achieved great success. However, This method is\nnot suitable for simultaneous speech recognition and understanding. In this\npaper, we propose a joint speech recognition and structure learning framework\n(JSRSL), an end-to-end SLU model based on span, which can accurately transcribe\nspeech and extract structured content simultaneously. We conduct experiments on\nname entity recognition and intent classification using the Chinese dataset\nAISHELL-NER and the English dataset SLURP. The results show that our proposed\nmethod not only outperforms the traditional sequence-to-sequence method in both\ntranscription and extraction capabilities but also achieves state-of-the-art\nperformance on the two datasets.\n","authors":["Jiliang Hu","Zuchao Li","Mengjia Shen","Haojun Ai","Sheng Li","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.07329v2.pdf","comment":"5 pages, 2 figures, accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.10322v1","updated":"2025-01-17T17:51:53Z","published":"2025-01-17T17:51:53Z","title":"Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level\n  Processing for Robust, Adaptable Language Models","summary":"  Tokenization is a fundamental step in natural language processing, breaking\ntext into units that computational models can process. While learned subword\ntokenizers have become the de-facto standard, they present challenges such as\nlarge vocabularies, limited adaptability to new domains or languages, and\nsensitivity to spelling errors and variations. To overcome these limitations,\nwe investigate a hierarchical architecture for autoregressive language\nmodelling that combines character-level and word-level processing. It employs a\nlightweight character-level encoder to convert character sequences into word\nembeddings, which are then processed by a word-level backbone model and decoded\nback into characters via a compact character-level decoder. This method retains\nthe sequence compression benefits of word-level tokenization without relying on\na rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion\nparameters, that hierarchical transformers match the downstream task\nperformance of subword-tokenizer-based models while exhibiting significantly\ngreater robustness to input perturbations. Additionally, during continued\npretraining on an out-of-domain language, our model trains almost twice as\nfast, achieves superior performance on the target language, and retains more of\nits previously learned knowledge. Hierarchical transformers pave the way for\nNLP systems that are more robust, flexible, and generalizable across languages\nand domains.\n","authors":["Pit Neitemeier","Björn Deiseroth","Constantin Eichenberg","Lukas Balles"],"pdf_url":"https://arxiv.org/pdf/2501.10322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03545v2","updated":"2025-01-17T17:47:24Z","published":"2025-01-07T05:43:23Z","title":"Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual\n  Information in Long-form Text Generation","summary":"  This paper presents ICAT, an evaluation framework for measuring coverage of\ndiverse factual information in long-form text generation. ICAT breaks down a\nlong output text into a list of atomic claims and not only verifies each claim\nthrough retrieval from a (reliable) knowledge source, but also computes the\nalignment between the atomic factual claims and various aspects expected to be\npresented in the output. We study three implementations of the ICAT framework,\neach with a different assumption on the availability of aspects and alignment\nmethod. By adopting data from the diversification task in the TREC Web Track\nand the ClueWeb corpus, we evaluate the ICAT framework. We demonstrate strong\ncorrelation with human judgments and provide comprehensive evaluation across\nmultiple state-of-the-art LLMs. Our framework further offers interpretable and\nfine-grained analysis of diversity and coverage. Its modular design allows for\neasy adaptation to different domains and datasets, making it a valuable tool\nfor evaluating the qualitative aspects of long-form responses produced by LLMs.\n","authors":["Chris Samarinas","Alexander Krubner","Alireza Salemi","Youngwoo Kim","Hamed Zamani"],"pdf_url":"https://arxiv.org/pdf/2501.03545v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10319v1","updated":"2025-01-17T17:47:15Z","published":"2025-01-17T17:47:15Z","title":"Natural Language Processing of Privacy Policies: A Survey","summary":"  Natural Language Processing (NLP) is an essential subset of artificial\nintelligence. It has become effective in several domains, such as healthcare,\nfinance, and media, to identify perceptions, opinions, and misuse, among\nothers. Privacy is no exception, and initiatives have been taken to address the\nchallenges of usable privacy notifications to users with the help of NLP. To\nthis aid, we conduct a literature review by analyzing 109 papers at the\nintersection of NLP and privacy policies. First, we provide a brief\nintroduction to privacy policies and discuss various facets of associated\nproblems, which necessitate the application of NLP to elevate the current state\nof privacy notices and disclosures to users. Subsequently, we a) provide an\noverview of the implementation and effectiveness of NLP approaches for better\nprivacy policy communication; b) identify the methodologies that can be further\nenhanced to provide robust privacy policies; and c) identify the gaps in the\ncurrent state-of-the-art research. Our systematic analysis reveals that several\nresearch papers focus on annotating and classifying privacy texts for analysis\nbut need to adequately dwell on other aspects of NLP applications, such as\nsummarization. More specifically, ample research opportunities exist in this\ndomain, covering aspects such as corpus generation, summarization vectors,\ncontextualized word embedding, identification of privacy-relevant statement\ncategories, fine-grained classification, and domain-specific model tuning.\n","authors":["Andrick Adhikari","Sanchari Das","Rinku Dewri"],"pdf_url":"https://arxiv.org/pdf/2501.10319v1.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2501.10316v1","updated":"2025-01-17T17:40:12Z","published":"2025-01-17T17:40:12Z","title":"Towards Preventing Overreliance on Task-Oriented Conversational AI\n  Through Accountability Modeling","summary":"  Recent LLMs have enabled significant advancements for conversational agents.\nHowever, they are also well-known to hallucinate, i.e., they often produce\nresponses that seem plausible but are not factually correct. On the other hand,\nusers tend to over-rely on LLM-based AI agents; they accept the AI's suggestion\neven when it is wrong. Adding good friction, such as explanations or getting\nuser confirmations, has been proposed as a mitigation in AI-supported\ndecision-making systems. In this paper, we propose an accountability model for\nLLM-based task-oriented dialogue agents to address user overreliance via\nfriction turns in cases of model uncertainty and errors associated with\ndialogue state tracking (DST). The accountability model is an augmented LLM\nwith an additional accountability head, which functions as a binary classifier\nto predict the slots of the dialogue states. We perform our experiments with\nthree backbone LLMs (Llama, Mistral, Gemma) on two established task-oriented\ndatasets (MultiWOZ and Snips). Our empirical findings demonstrate that this\napproach not only enables reliable estimation of AI agent errors but also\nguides the LLM decoder in generating more accurate actions. We observe around\n3% absolute improvement in joint goal accuracy by incorporating accountability\nheads in modern LLMs for the MultiWOZ dataset. We also show that this method\nenables the agent to self-correct its actions, further boosting its performance\nby 3%. Finally, we discuss the application of accountability modeling to\nprevent user overreliance by introducing friction.\n","authors":["Suvodip Dey","Yi-Jyun Sun","Gokhan Tur","Dilek Hakkani-Tur"],"pdf_url":"https://arxiv.org/pdf/2501.10316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.10021v3","updated":"2025-01-17T17:37:42Z","published":"2021-07-21T11:31:57Z","title":"Neuradicon: operational representation learning of neuroimaging reports","summary":"  Radiological reports typically summarize the content and interpretation of\nimaging studies in unstructured form that precludes quantitative analysis. This\nlimits the monitoring of radiological services to throughput undifferentiated\nby content, impeding specific, targeted operational optimization. Here we\npresent Neuradicon, a natural language processing (NLP) framework for\nquantitative analysis of neuroradiological reports. Our framework is a hybrid\nof rule-based and artificial intelligence models to represent neurological\nreports in succinct, quantitative form optimally suited to operational\nguidance. We demonstrate the application of Neuradicon to operational\nphenotyping of a corpus of 336,569 reports, and report excellent\ngeneralizability across time and two independent healthcare institutions.\n","authors":["Henry Watkins","Robert Gray","Adam Julius","Yee-Haur Mah","Walter H. L. Pinaya","Paul Wright","Ashwani Jha","Holger Engleitner","Jorge Cardoso","Sebastien Ourselin","Geraint Rees","Rolf Jaeger","Parashkev Nachev"],"pdf_url":"https://arxiv.org/pdf/2107.10021v3.pdf","comment":"26 pages, 11 figures"},{"id":"http://arxiv.org/abs/2404.08938v2","updated":"2025-01-17T17:05:41Z","published":"2024-04-13T09:24:32Z","title":"Improved Paraphrase Generation via Controllable Latent Diffusion","summary":"  Paraphrase generation strives to generate high-quality and diverse\nexpressions of a given text, a domain where diffusion models excel. Though SOTA\ndiffusion generation reconciles generation quality and diversity, textual\ndiffusion suffers from a truncation issue that hinders efficiency and quality\ncontrol. In this work, we propose \\textit{L}atent \\textit{D}iffusion\n\\textit{P}araphraser~(LDP), a novel paraphrase generation by modeling a\ncontrollable diffusion process given a learned latent space. LDP achieves\nsuperior generation efficiency compared to its diffusion counterparts. It can\nfacilitate only input segments to ensure paraphrase semantics, improving the\nresults without external features. Experiments show that LDP better reconciles\nparaphrase generation quality and diversity than baselines. Further analysis\nshows that our method is also helpful to other similar text generations and\ndomain adaptations\n","authors":["Wei Zou","Ziyuan Zhuang","Xiang Geng","Shujian Huang","Jia Liu","Jiajun Chen"],"pdf_url":"https://arxiv.org/pdf/2404.08938v2.pdf","comment":"The article has been accepted by Frontiers of Computer Science (FCS)"},{"id":"http://arxiv.org/abs/2501.10282v1","updated":"2025-01-17T16:21:18Z","published":"2025-01-17T16:21:18Z","title":"Computational Protein Science in the Era of Large Language Models (LLMs)","summary":"  Considering the significance of proteins, computational protein science has\nalways been a critical scientific field, dedicated to revealing knowledge and\ndeveloping applications within the protein sequence-structure-function\nparadigm. In the last few decades, Artificial Intelligence (AI) has made\nsignificant impacts in computational protein science, leading to notable\nsuccesses in specific protein modeling tasks. However, those previous AI models\nstill meet limitations, such as the difficulty in comprehending the semantics\nof protein sequences, and the inability to generalize across a wide range of\nprotein modeling tasks. Recently, LLMs have emerged as a milestone in AI due to\ntheir unprecedented language processing & generalization capability. They can\npromote comprehensive progress in fields rather than solving individual tasks.\nAs a result, researchers have actively introduced LLM techniques in\ncomputational protein science, developing protein Language Models (pLMs) that\nskillfully grasp the foundational knowledge of proteins and can be effectively\ngeneralized to solve a diversity of sequence-structure-function reasoning\nproblems. While witnessing prosperous developments, it's necessary to present a\nsystematic overview of computational protein science empowered by LLM\ntechniques. First, we summarize existing pLMs into categories based on their\nmastered protein knowledge, i.e., underlying sequence patterns, explicit\nstructural and functional information, and external scientific languages.\nSecond, we introduce the utilization and adaptation of pLMs, highlighting their\nremarkable achievements in promoting protein structure prediction, protein\nfunction prediction, and protein design studies. Then, we describe the\npractical application of pLMs in antibody design, enzyme design, and drug\ndiscovery. Finally, we specifically discuss the promising future directions in\nthis fast-growing field.\n","authors":["Wenqi Fan","Yi Zhou","Shijie Wang","Yuyao Yan","Hui Liu","Qian Zhao","Le Song","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2501.10282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09686v2","updated":"2025-01-17T15:24:53Z","published":"2025-01-16T17:37:58Z","title":"Towards Large Reasoning Models: A Survey on Scaling LLM Reasoning\n  Capabilities","summary":"  Language has long been conceived as an essential tool for human reasoning.\nThe breakthrough of Large Language Models (LLMs) has sparked significant\nresearch interest in leveraging these models to tackle complex reasoning tasks.\nResearchers have moved beyond simple autoregressive token generation by\nintroducing the concept of \"thought\" -- a sequence of tokens representing\nintermediate steps in the reasoning process. This innovative paradigm enables\nLLMs' to mimic complex human reasoning processes, such as tree search and\nreflective thinking. Recently, an emerging trend of learning to reason has\napplied reinforcement learning (RL) to train LLMs to master reasoning\nprocesses. This approach enables the automatic generation of high-quality\nreasoning trajectories through trial-and-error search algorithms, significantly\nexpanding LLMs' reasoning capacity by providing substantially more training\ndata. Furthermore, recent studies demonstrate that encouraging LLMs to \"think\"\nwith more tokens during test-time inference can further significantly boost\nreasoning accuracy. Therefore, the train-time and test-time scaling combined to\nshow a new research frontier -- a path toward Large Reasoning Model. The\nintroduction of OpenAI's o1 series marks a significant milestone in this\nresearch direction. In this survey, we present a comprehensive review of recent\nprogress in LLM reasoning. We begin by introducing the foundational background\nof LLMs and then explore the key technical components driving the development\nof large reasoning models, with a focus on automated data construction,\nlearning-to-reason techniques, and test-time scaling. We also analyze popular\nopen-source projects at building large reasoning models, and conclude with open\nchallenges and future research directions.\n","authors":["Fengli Xu","Qianyue Hao","Zefang Zong","Jingwei Wang","Yunke Zhang","Jingyi Wang","Xiaochong Lan","Jiahui Gong","Tianjian Ouyang","Fanjin Meng","Chenyang Shao","Yuwei Yan","Qinglong Yang","Yiwen Song","Sijian Ren","Xinyuan Hu","Yu Li","Jie Feng","Chen Gao","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2501.09686v2.pdf","comment":"36 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.03814v5","updated":"2025-01-17T15:02:08Z","published":"2024-06-06T07:39:17Z","title":"Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and\n  Gated Monolingual Datastores","summary":"  The kNN-CTC model has proven to be effective for monolingual automatic speech\nrecognition (ASR). However, its direct application to multilingual scenarios\nlike code-switching, presents challenges. Although there is potential for\nperformance improvement, a kNN-CTC model utilizing a single bilingual datastore\ncan inadvertently introduce undesirable noise from the alternative language. To\naddress this, we propose a novel kNN-CTC-based code-switching ASR (CS-ASR)\nframework that employs dual monolingual datastores and a gated datastore\nselection mechanism to reduce noise interference. Our method selects the\nappropriate datastore for decoding each frame, ensuring the injection of\nlanguage-specific information into the ASR process. We apply this framework to\ncutting-edge CTC-based models, developing an advanced CS-ASR system. Extensive\nexperiments demonstrate the remarkable effectiveness of our gated datastore\nmechanism in enhancing the performance of zero-shot Chinese-English CS-ASR.\n","authors":["Jiaming Zhou","Shiwan Zhao","Hui Wang","Tian-Hao Zhang","Haoqin Sun","Xuechen Wang","Yong Qin"],"pdf_url":"https://arxiv.org/pdf/2406.03814v5.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2410.13780v2","updated":"2025-01-17T14:26:37Z","published":"2024-10-17T17:19:48Z","title":"Optimal Quantization for Matrix Multiplication","summary":"  Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|\\bar{A}\\|_F, \\|\\bar{B}\\|_F$ and\n$\\|\\bar{A}^\\top \\bar{B}\\|_F$, where $\\bar{A},\\bar{B}$ are versions of $A,B$\nwith zero-centered columns, respectively. For iid Gaussian matrices our\nquantizer achieves the lower bound and is, thus, asymptotically optimal. A\npractical low-complexity version of our quantizer achieves performance quite\nclose to optimal. In addition, we derive rate-distortion function for matrix\nmultiplication of iid Gaussian matrices, which exhibits an interesting\nphase-transition at $R\\approx 0.906$ bit/entry.\n","authors":["Or Ordentlich","Yury Polyanskiy"],"pdf_url":"https://arxiv.org/pdf/2410.13780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01477v2","updated":"2025-01-17T14:10:15Z","published":"2024-11-03T08:30:29Z","title":"DPCL-Diff: The Temporal Knowledge Graph Reasoning Based on Graph Node\n  Diffusion Model with Dual-Domain Periodic Contrastive Learning","summary":"  Temporal knowledge graph (TKG) reasoning that infers future missing facts is\nan essential and challenging task. Predicting future events typically relies on\nclosely related historical facts, yielding more accurate results for repetitive\nor periodic events. However, for future events with sparse historical\ninteractions, the effectiveness of this method, which focuses on leveraging\nhigh-frequency historical information, diminishes. Recently, the capabilities\nof diffusion models in image generation have opened new opportunities for TKG\nreasoning. Therefore, we propose a graph node diffusion model with dual-domain\nperiodic contrastive learning (DPCL-Diff). Graph node diffusion model (GNDiff)\nintroduces noise into sparsely related events to simulate new events,\ngenerating high-quality data that better conforms to the actual distribution.\nThis generative mechanism significantly enhances the model's ability to reason\nabout new events. Additionally, the dual-domain periodic contrastive learning\n(DPCL) maps periodic and non-periodic event entities to Poincar\\'e and\nEuclidean spaces, leveraging their characteristics to distinguish similar\nperiodic events effectively. Experimental results on four public datasets\ndemonstrate that DPCL-Diff significantly outperforms state-of-the-art TKG\nmodels in event prediction, demonstrating our approach's effectiveness. This\nstudy also investigates the combined effectiveness of GNDiff and DPCL in TKG\ntasks.\n","authors":["Yukun Cao","Lisheng Wang","Luobin Huang"],"pdf_url":"https://arxiv.org/pdf/2411.01477v2.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2406.14393v4","updated":"2025-01-17T13:56:50Z","published":"2024-06-20T15:12:27Z","title":"Jailbreaking as a Reward Misspecification Problem","summary":"  The widespread adoption of large language models (LLMs) has raised concerns\nabout their safety and reliability, particularly regarding their vulnerability\nto adversarial attacks. In this paper, we propose a novel perspective that\nattributes this vulnerability to reward misspecification during the alignment\nprocess. This misspecification occurs when the reward function fails to\naccurately capture the intended behavior, leading to misaligned model outputs.\nWe introduce a metric ReGap to quantify the extent of reward misspecification\nand demonstrate its effectiveness and robustness in detecting harmful backdoor\nprompts. Building upon these insights, we present ReMiss, a system for\nautomated red teaming that generates adversarial prompts in a\nreward-misspecified space. ReMiss achieves state-of-the-art attack success\nrates on the AdvBench benchmark against various target aligned LLMs while\npreserving the human readability of the generated prompts. Furthermore, these\nattacks on open-source models demonstrate high transferability to closed-source\nmodels like GPT-4o and out-of-distribution tasks from HarmBench. Detailed\nanalysis highlights the unique advantages of the proposed reward\nmisspecification objective compared to previous methods, offering new insights\nfor improving LLM safety and robustness.\n","authors":["Zhihui Xie","Jiahui Gao","Lei Li","Zhenguo Li","Qi Liu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2406.14393v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.11960v3","updated":"2025-01-17T13:34:49Z","published":"2023-04-24T09:53:33Z","title":"Bandit on the Hunt: Dynamic Crawling for Cyber Threat Intelligence","summary":"  Public information contains valuable Cyber Threat Intelligence (CTI) that is\nused to prevent attacks in the future. Ideally, the learnings from previous\nattacks help to mitigate all those that follow. While there are standards for\nsharing this information, much of it is shared in non-standardized news\narticles or blog posts. It is a time-consuming task to monitor online sources\nfor threats and even then, one can never be sure, to use the right sources.\nCurrent research propose extractors of Indicators of Compromise from known\nsources, while the identification of new sources is rarely considered. This\npaper proposes a focused crawler focused on the CTI domain based on multi-armed\nbandit ( MAB) and different crawling strategies. It uses SBERT to identify\nrelevant documents, while dynamically adapt its crawling path. We propose a\nsystem called ThreatCrawl, which achieve a harvest rate of over 25% and is able\nto expand its used seed by over 300%, while retaining focus on the topic at\nhand. In addition, this crawler identified previously unknown but highly\nrelevant overview pages, datasets, and domains.\n","authors":["Philipp Kuehn","Dilara Nadermahmoodi","Markus Bayer","Christian Reuter"],"pdf_url":"https://arxiv.org/pdf/2304.11960v3.pdf","comment":"6 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2501.10179v1","updated":"2025-01-17T13:24:13Z","published":"2025-01-17T13:24:13Z","title":"A Simple but Effective Closed-form Solution for Extreme Multi-label\n  Learning","summary":"  Extreme multi-label learning (XML) is a task of assigning multiple labels\nfrom an extremely large set of labels to each data instance. Many current\nhigh-performance XML models are composed of a lot of hyperparameters, which\ncomplicates the tuning process. Additionally, the models themselves are adapted\nspecifically to XML, which complicates their reimplementation. To remedy this\nproblem, we propose a simple method based on ridge regression for XML. The\nproposed method not only has a closed-form solution but also is composed of a\nsingle hyperparameter. Since there are no precedents on applying ridge\nregression to XML, this paper verified the performance of the method by using\nvarious XML benchmark datasets. Furthermore, we enhanced the prediction of\nlow-frequency labels in XML, which hold informative content. This prediction is\nessential yet challenging because of the limited amount of data. Here, we\nemployed a simple frequency-based weighting. This approach greatly simplifies\nthe process compared with existing techniques. Experimental results revealed\nthat it can achieve levels of performance comparable to, or even exceeding,\nthose of models with numerous hyperparameters. Additionally, we found that the\nfrequency-based weighting significantly improved the predictive performance for\nlow-frequency labels, while requiring almost no changes in implementation. The\nsource code for the proposed method is available on github at\nhttps://github.com/cars1015/XML-ridge.\n","authors":["Kazuma Onishi","Katsuhiko Hayashi"],"pdf_url":"https://arxiv.org/pdf/2501.10179v1.pdf","comment":"10pages, Accepted at ECIR25"},{"id":"http://arxiv.org/abs/2501.10175v1","updated":"2025-01-17T13:17:42Z","published":"2025-01-17T13:17:42Z","title":"Multi-stage Training of Bilingual Islamic LLM for Neural Passage\n  Retrieval","summary":"  This study examines the use of Natural Language Processing (NLP) technology\nwithin the Islamic domain, focusing on developing an Islamic neural retrieval\nmodel. By leveraging the robust XLM-R model, the research employs a language\nreduction technique to create a lightweight bilingual large language model\n(LLM). Our approach for domain adaptation addresses the unique challenges faced\nin the Islamic domain, where substantial in-domain corpora exist only in Arabic\nwhile limited in other languages, including English.\n  The work utilizes a multi-stage training process for retrieval models,\nincorporating large retrieval datasets, such as MS MARCO, and smaller,\nin-domain datasets to improve retrieval performance. Additionally, we have\ncurated an in-domain retrieval dataset in English by employing data\naugmentation techniques and involving a reliable Islamic source. This approach\nenhances the domain-specific dataset for retrieval, leading to further\nperformance gains.\n  The findings suggest that combining domain adaptation and a multi-stage\ntraining method for the bilingual Islamic neural retrieval model enables it to\noutperform monolingual models on downstream retrieval tasks.\n","authors":["Vera Pavlova"],"pdf_url":"https://arxiv.org/pdf/2501.10175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16302v2","updated":"2025-01-17T12:27:40Z","published":"2024-09-10T11:00:24Z","title":"How Redundant Is the Transformer Stack in Speech Representation Models?","summary":"  Self-supervised speech representation models, particularly those leveraging\ntransformer architectures, have demonstrated remarkable performance across\nvarious tasks such as speech recognition, speaker identification, and emotion\ndetection. Recent studies on transformer models revealed a high redundancy\nbetween layers and the potential for significant pruning, which we will\ninvestigate here for transformer-based speech representation models. We perform\na detailed analysis of layer similarity in speech representation models using\nthree similarity metrics: cosine similarity, centered kernel alignment, and\nmutual nearest-neighbor alignment. Our findings reveal a block-like structure\nof high similarity, suggesting two main processing steps and significant\nredundancy of layers. We demonstrate the effectiveness of pruning\ntransformer-based speech representation models without the need for\npost-training, achieving up to 40% reduction in transformer layers while\nmaintaining over 95% of the model's predictive capacity. Furthermore, we employ\na knowledge distillation method to substitute the entire transformer stack with\nmimicking layers, reducing the network size 95-98% and the inference time by up\nto 94%. This substantial decrease in computational load occurs without\nconsiderable performance loss, suggesting that the transformer stack is almost\ncompletely redundant for downstream applications of speech representation\nmodels.\n","authors":["Teresa Dorszewski","Albert Kjøller Jacobsen","Lenka Tětková","Lars Kai Hansen"],"pdf_url":"https://arxiv.org/pdf/2409.16302v2.pdf","comment":"To appear at ICASSP 2025 (excluding appendix)"},{"id":"http://arxiv.org/abs/2501.10150v1","updated":"2025-01-17T12:23:30Z","published":"2025-01-17T12:23:30Z","title":"Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair\n  Language Modeling and Translation","summary":"  Mitigation of biases, such as language models' reliance on gender\nstereotypes, is a crucial endeavor required for the creation of reliable and\nuseful language technology. The crucial aspect of debiasing is to ensure that\nthe models preserve their versatile capabilities, including their ability to\nsolve language tasks and equitably represent various genders. To address this\nissue, we introduce a streamlined Dual Dabiasing Algorithm through Model\nAdaptation (2DAMA). Novel Dual Debiasing enables robust reduction of\nstereotypical bias while preserving desired factual gender information encoded\nby language models. We show that 2DAMA effectively reduces gender bias in\nEnglish and is one of the first approaches facilitating the mitigation of\nstereotypical tendencies in translation. The proposed method's key advantage is\nthe preservation of factual gender cues, which are useful in a wide range of\nnatural language processing tasks.\n","authors":["Tomasz Limisiewicz","David Mareček","Tomáš Musil"],"pdf_url":"https://arxiv.org/pdf/2501.10150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10132v1","updated":"2025-01-17T11:41:53Z","published":"2025-01-17T11:41:53Z","title":"ComplexFuncBench: Exploring Multi-Step and Constrained Function Calling\n  under Long-Context Scenario","summary":"  Enhancing large language models (LLMs) with real-time APIs can help generate\nmore accurate and up-to-date responses. However, evaluating the function\ncalling abilities of LLMs in real-world scenarios remains under-explored due to\nthe complexity of data collection and evaluation. In this work, we introduce\nComplexFuncBench, a benchmark for complex function calling across five\nreal-world scenarios. Compared to existing benchmarks, ComplexFuncBench\nencompasses multi-step and constrained function calling, which requires\nlong-parameter filing, parameter value reasoning, and 128k long context.\nAdditionally, we propose an automatic framework, ComplexEval, for\nquantitatively evaluating complex function calling tasks. Through comprehensive\nexperiments, we demonstrate the deficiencies of state-of-the-art LLMs in\nfunction calling and suggest future directions for optimizing these\ncapabilities. The data and code are available at\n\\url{https://github.com/THUDM/ComplexFuncBench}.\n","authors":["Lucen Zhong","Zhengxiao Du","Xiaohan Zhang","Haiyi Hu","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2501.10132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07629v3","updated":"2025-01-17T11:37:04Z","published":"2024-12-10T16:08:14Z","title":"Piece of Table: A Divide-and-Conquer Approach for Selecting Sub-Tables\n  in Table Question Answering","summary":"  Applying language models (LMs) to tables is challenging due to the inherent\nstructural differences between two-dimensional tables and one-dimensional text\nfor which the LMs were originally designed. Furthermore, when applying\nlinearized tables to LMs, the maximum token lengths often imposed in\nself-attention calculations make it difficult to comprehensively understand the\ncontext spread across large tables. To address these challenges, we present\nPieTa (Piece of Table), a new framework for sub-table-based question answering\n(QA). PieTa operates through an iterative process of dividing tables into\nsmaller windows, using LMs to select relevant cells within each window, and\nmerging these cells into a sub-table. This multi-resolution approach captures\ndependencies across multiple rows and columns while avoiding the limitations\ncaused by long context inputs. Instantiated as a simple iterative sub-table\nunion algorithm, PieTa demonstrates improved performance over previous\nsub-table-based QA approaches.\n","authors":["Wonjin Lee","Kyumin Kim","Sungjae Lee","Jihun Lee","Kwang In Kim"],"pdf_url":"https://arxiv.org/pdf/2412.07629v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10107v1","updated":"2025-01-17T10:50:22Z","published":"2025-01-17T10:50:22Z","title":"BBPOS: BERT-based Part-of-Speech Tagging for Uzbek","summary":"  This paper advances NLP research for the low-resource Uzbek language by\nevaluating two previously untested monolingual Uzbek BERT models on the\npart-of-speech (POS) tagging task and introducing the first publicly available\nUPOS-tagged benchmark dataset for Uzbek. Our fine-tuned models achieve 91%\naverage accuracy, outperforming the baseline multi-lingual BERT as well as the\nrule-based tagger. Notably, these models capture intermediate POS changes\nthrough affixes and demonstrate context sensitivity, unlike existing rule-based\ntaggers.\n","authors":["Latofat Bobojonova","Arofat Akhundjanova","Phil Ostheimer","Sophie Fellenz"],"pdf_url":"https://arxiv.org/pdf/2501.10107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12997v2","updated":"2025-01-17T10:02:38Z","published":"2024-12-17T15:21:28Z","title":"Enabling Low-Resource Language Retrieval: Establishing Baselines for\n  Urdu MS MARCO","summary":"  As the Information Retrieval (IR) field increasingly recognizes the\nimportance of inclusivity, addressing the needs of low-resource languages\nremains a significant challenge. This paper introduces the first large-scale\nUrdu IR dataset, created by translating the MS MARCO dataset through machine\ntranslation. We establish baseline results through zero-shot learning for IR in\nUrdu and subsequently apply the mMARCO multilingual IR methodology to this\nnewly translated dataset. Our findings demonstrate that the fine-tuned model\n(Urdu-mT5-mMARCO) achieves a Mean Reciprocal Rank (MRR@10) of 0.247 and a\nRecall@10 of 0.439, representing significant improvements over zero-shot\nresults and showing the potential for expanding IR access for Urdu speakers. By\nbridging access gaps for speakers of low-resource languages, this work not only\nadvances multilingual IR research but also emphasizes the ethical and societal\nimportance of inclusive IR technologies. This work provides valuable insights\ninto the challenges and solutions for improving language representation and\nlays the groundwork for future research, especially in South Asian languages,\nwhich can benefit from the adaptable methods used in this study.\n","authors":["Umer Butt","Stalin Veranasi","Günter Neumann"],"pdf_url":"https://arxiv.org/pdf/2412.12997v2.pdf","comment":"7 pages, ECIR 2025, conference camera-ready version"},{"id":"http://arxiv.org/abs/2411.19939v2","updated":"2025-01-17T09:50:55Z","published":"2024-11-29T18:56:37Z","title":"VLSBench: Unveiling Visual Leakage in Multimodal Safety","summary":"  Safety concerns of Multimodal large language models (MLLMs) have gradually\nbecome an important problem in various applications. Surprisingly, previous\nworks indicate a counter-intuitive phenomenon that using textual unlearning to\nalign MLLMs achieves comparable safety performances with MLLMs trained with\nimage-text pairs. To explain such a counter-intuitive phenomenon, we discover a\nvisual safety information leakage (VSIL) problem in existing multimodal safety\nbenchmarks, i.e., the potentially risky and sensitive content in the image has\nbeen revealed in the textual query. In this way, MLLMs can easily refuse these\nsensitive text-image queries according to textual queries. However, image-text\npairs without VSIL are common in real-world scenarios and are overlooked by\nexisting multimodal safety benchmarks. To this end, we construct multimodal\nvisual leakless safety benchmark (VLSBench) preventing visual safety leakage\nfrom image to textual query with 2.4k image-text pairs. Experimental results\nindicate that VLSBench poses a significant challenge to both open-source and\nclose-source MLLMs, including LLaVA, Qwen2-VL, Llama3.2-Vision, and GPT-4o.\nThis study demonstrates that textual alignment is enough for multimodal safety\nscenarios with VSIL, while multimodal alignment is a more promising solution\nfor multimodal safety scenarios without VSIL. Please see our code and data at:\nhttps://hxhcreate.github.io/vlsbench.github.io/\n","authors":["Xuhao Hu","Dongrui Liu","Hao Li","Xuanjing Huang","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2411.19939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10072v1","updated":"2025-01-17T09:43:49Z","published":"2025-01-17T09:43:49Z","title":"Author-Specific Linguistic Patterns Unveiled: A Deep Learning Study on\n  Word Class Distributions","summary":"  Deep learning methods have been increasingly applied to computational\nlinguistics to uncover patterns in text data. This study investigates\nauthor-specific word class distributions using part-of-speech (POS) tagging and\nbigram analysis. By leveraging deep neural networks, we classify literary\nauthors based on POS tag vectors and bigram frequency matrices derived from\ntheir works. We employ fully connected and convolutional neural network\narchitectures to explore the efficacy of unigram and bigram-based\nrepresentations. Our results demonstrate that while unigram features achieve\nmoderate classification accuracy, bigram-based models significantly improve\nperformance, suggesting that sequential word class patterns are more\ndistinctive of authorial style. Multi-dimensional scaling (MDS) visualizations\nreveal meaningful clustering of authors' works, supporting the hypothesis that\nstylistic nuances can be captured through computational methods. These findings\nhighlight the potential of deep learning and linguistic feature analysis for\nauthor profiling and literary studies.\n","authors":["Patrick Krauss","Achim Schilling"],"pdf_url":"https://arxiv.org/pdf/2501.10072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03594v2","updated":"2025-01-17T09:37:36Z","published":"2024-11-29T05:57:37Z","title":"BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix\n  Sharing and Throughput-oriented Token Batching","summary":"  Large language models (LLMs) increasingly play an important role in a wide\nrange of information processing and management tasks. Many of these tasks are\nperformed in large batches or even offline, and the performance indictor for\nwhich is throughput. These tasks usually show the characteristic of prefix\nsharing, where different prompt input can partially show the common prefix.\nHowever, the existing LLM inference engines tend to optimize the streaming\nrequests and show limitations of supporting the large batched tasks with the\nprefix sharing characteristic. The existing solutions use the LRU-based cache\nto reuse the KV context of common prefix between requests. The KV context that\nare about to be reused may prematurely evicted with the implicit cache\nmanagement. Besides, the streaming oriented systems do not leverage the\nrequest-batch information and can not mix the decoding tokens with the prefill\nchunks to the best for the batched scenarios, and thus fails to saturate the\nGPU. We propose BatchLLM to address the above problems. BatchLLM explicitly\nidentifies the common prefixes globally. The requests sharing the same prefix\nwill be scheduled together to reuse the KV context the best. BatchLLM reorders\nthe requests and schedules the requests with larger ratio of decoding first to\nbetter mix the decoding tokens with the latter prefill chunks, and applies\nmemory-centric token batching to enlarge the token-batch sizes, which helps to\nincrease the GPU utilization. Finally, BatchLLM optimizes the prefix-shared\nAttention kernel with horizontal fusion to reduce tail effect and kernel launch\noverhead. Extensive evaluation shows that BatchLLM outperforms vLLM and SGLang\nby 1.3$\\times$ to 10.8$\\times$ on a set of microbenchmarks and a typical\nindustry workload under different hardware environments.\n","authors":["Zhen Zheng","Xin Ji","Taosong Fang","Fanghao Zhou","Chuanjie Liu","Gang Peng"],"pdf_url":"https://arxiv.org/pdf/2412.03594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.20262v3","updated":"2025-01-17T09:32:54Z","published":"2024-03-29T16:13:31Z","title":"ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language\n  Models","summary":"  Research on Large Language Models (LLMs) has recently witnessed an increasing\ninterest in extending the models' context size to better capture dependencies\nwithin long documents. While benchmarks have been proposed to assess long-range\nabilities, existing efforts primarily considered generic tasks that are not\nnecessarily aligned with real-world applications. In contrast, we propose a new\nbenchmark for long-context LLMs focused on a practical meeting assistant\nscenario in which the long contexts consist of transcripts obtained by\nautomatic speech recognition, presenting unique challenges for LLMs due to the\ninherent noisiness and oral nature of such data. Our benchmark, ELITR-Bench,\naugments the existing ELITR corpus by adding 271 manually crafted questions\nwith their ground-truth answers, as well as noisy versions of meeting\ntranscripts altered to target different Word Error Rate levels. Our experiments\nwith 12 long-context LLMs on ELITR-Bench confirm the progress made across\nsuccessive generations of both proprietary and open models, and point out their\ndiscrepancies in terms of robustness to transcript noise. We also provide a\nthorough analysis of our GPT-4-based evaluation, including insights from a\ncrowdsourcing study. Our findings indicate that while GPT-4's scores align with\nhuman judges, its ability to distinguish beyond three score levels may be\nlimited.\n","authors":["Thibaut Thonet","Jos Rozen","Laurent Besacier"],"pdf_url":"https://arxiv.org/pdf/2403.20262v3.pdf","comment":"Published in COLING 2025"},{"id":"http://arxiv.org/abs/2312.17296v8","updated":"2025-01-17T09:28:45Z","published":"2023-12-28T16:25:52Z","title":"Structured Packing in LLM Training Improves Long Context Utilization","summary":"  Recent advancements in long-context large language models have attracted\nsignificant attention, yet their practical applications often suffer from\nsuboptimal context utilization. This study investigates structuring training\ndata to enhance semantic interdependence, demonstrating that this approach\neffectively improves context utilization. To this end, we introduce the\nStructured Packing for Long Context (SPLiCe) method, which utilizes retrieval\nto collate mutually relevant documents into long and coherent training\nexamples. We validate SPLiCe empirically across models of varying sizes -- 3B,\n7B, and 13B -- achieving improved performance in long-context tasks, such as\nQasper and HotpotQA. Remarkably, even brief fine-tuning with SPLiCe is\nsufficient to realize these benefits. Additionally, SPLiCe effectively\nmitigates the lost-in-middle phenomenon often observed in large models. Our\ncomprehensive analysis of SPLiCe explores its design choices and reveals\nintriguing transfer effects; for instance, training on programming code\nenhances performance on natural language tasks.\n","authors":["Konrad Staniszewski","Szymon Tworkowski","Sebastian Jaszczur","Yu Zhao","Henryk Michalewski","Łukasz Kuciński","Piotr Miłoś"],"pdf_url":"https://arxiv.org/pdf/2312.17296v8.pdf","comment":"AAAI'25"},{"id":"http://arxiv.org/abs/2501.10062v1","updated":"2025-01-17T09:27:08Z","published":"2025-01-17T09:27:08Z","title":"OMoE: Diversifying Mixture of Low-Rank Adaptation by Orthogonal\n  Finetuning","summary":"  Building mixture-of-experts (MoE) architecture for Low-rank adaptation (LoRA)\nis emerging as a potential direction in parameter-efficient fine-tuning (PEFT)\nfor its modular design and remarkable performance. However, simply stacking the\nnumber of experts cannot guarantee significant improvement. In this work, we\nfirst conduct qualitative analysis to indicate that experts collapse to similar\nrepresentations in vanilla MoE, limiting the capacity of modular design and\ncomputational efficiency. Ulteriorly, Our analysis reveals that the performance\nof previous MoE variants maybe limited by a lack of diversity among experts.\nMotivated by these findings, we propose Orthogonal Mixture-of-Experts (OMoE), a\nresource-efficient MoE variant that trains experts in an orthogonal manner to\npromote diversity. In OMoE, a Gram-Schmidt process is leveraged to enforce that\nthe experts' representations lie within the Stiefel manifold. By applying\northogonal constraints directly to the architecture, OMoE keeps the learning\nobjective unchanged, without compromising optimality. Our method is simple and\nalleviates memory bottlenecks, as it incurs minimal experts compared to vanilla\nMoE models. Experiments on diverse commonsense reasoning benchmarks demonstrate\nthat OMoE can consistently achieve stable and efficient performance improvement\nwhen compared with the state-of-the-art methods while significantly reducing\nthe number of required experts.\n","authors":["Jinyuan Feng","Zhiqiang Pu","Tianyi Hu","Dongmin Li","Xiaolin Ai","Huimu Wang"],"pdf_url":"https://arxiv.org/pdf/2501.10062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10057v1","updated":"2025-01-17T09:22:35Z","published":"2025-01-17T09:22:35Z","title":"MSTS: A Multimodal Safety Test Suite for Vision-Language Models","summary":"  Vision-language models (VLMs), which process image and text inputs, are\nincreasingly integrated into chat assistants and other consumer AI\napplications. Without proper safeguards, however, VLMs may give harmful advice\n(e.g. how to self-harm) or encourage unsafe behaviours (e.g. to consume drugs).\nDespite these clear hazards, little work so far has evaluated VLM safety and\nthe novel risks created by multimodal inputs. To address this gap, we introduce\nMSTS, a Multimodal Safety Test Suite for VLMs. MSTS comprises 400 test prompts\nacross 40 fine-grained hazard categories. Each test prompt consists of a text\nand an image that only in combination reveal their full unsafe meaning. With\nMSTS, we find clear safety issues in several open VLMs. We also find some VLMs\nto be safe by accident, meaning that they are safe because they fail to\nunderstand even simple test prompts. We translate MSTS into ten languages,\nshowing non-English prompts to increase the rate of unsafe model responses. We\nalso show models to be safer when tested with text only rather than multimodal\nprompts. Finally, we explore the automation of VLM safety assessments, finding\neven the best safety classifiers to be lacking.\n","authors":["Paul Röttger","Giuseppe Attanasio","Felix Friedrich","Janis Goldzycher","Alicia Parrish","Rishabh Bhardwaj","Chiara Di Bonaventura","Roman Eng","Gaia El Khoury Geagea","Sujata Goswami","Jieun Han","Dirk Hovy","Seogyeong Jeong","Paloma Jeretič","Flor Miriam Plaza-del-Arco","Donya Rooein","Patrick Schramowski","Anastassia Shaitarova","Xudong Shen","Richard Willats","Andrea Zugarini","Bertie Vidgen"],"pdf_url":"https://arxiv.org/pdf/2501.10057v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2407.17482v2","updated":"2025-01-17T09:17:30Z","published":"2024-07-02T08:07:27Z","title":"Reinforcement Learning from Human Feedback: Whose Culture, Whose Values,\n  Whose Perspectives?","summary":"  We argue for the epistemic and ethical advantages of pluralism in\nReinforcement Learning from Human Feedback (RLHF) in the context of Large\nLanguage Models (LLM). Drawing on social epistemology and pluralist philosophy\nof science, we suggest ways in which RHLF can be made more responsive to human\nneeds and how we can address challenges along the way. The paper concludes with\nan agenda for change, i.e. concrete, actionable steps to improve LLM\ndevelopment.\n","authors":["Kristian González Barman","Simon Lohse","Henk de Regt"],"pdf_url":"https://arxiv.org/pdf/2407.17482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07678v3","updated":"2025-01-17T08:54:50Z","published":"2024-12-10T17:06:33Z","title":"Can linguists better understand DNA?","summary":"  Multilingual transfer ability, which reflects how well models fine-tuned on\none source language can be applied to other languages, has been well studied in\nmultilingual pre-trained models. However, the existence of such capability\ntransfer between natural language and gene sequences/languages remains under\nexplored.This study addresses this gap by drawing inspiration from the\nsentence-pair classification task used for evaluating sentence similarity in\nnatural language. We constructed two analogous tasks: DNA-pair\nclassification(DNA sequence similarity) and DNA-protein-pair\nclassification(gene coding determination). These tasks were designed to\nvalidate the transferability of capabilities from natural language to gene\nsequences. Even a small-scale pre-trained model like GPT-2-small, which was\npre-trained on English, achieved an accuracy of 78% on the DNA-pair\nclassification task after being fine-tuned on English sentence-pair\nclassification data(XTREME PAWS-X). While training a BERT model on multilingual\ntext, the precision reached 89%. On the more complex DNA-protein-pair\nclassification task, however, the model's output was barely distinguishable\nfrom random output.Experimental validation has confirmed that the transfer of\ncapabilities from natural language to biological language is unequivocally\npresent. Building on this foundation, we have also investigated the impact of\nmodel parameter scale and pre-training on this capability transfer. We provide\nrecommendations for facilitating the transfer of capabilities from natural\nlanguage to genetic language,as well as new approaches for conducting\nbiological research based on this capability.This study offers an intriguing\nnew perspective on exploring the relationship between natural language and\ngenetic language.\n","authors":["Wang Liang"],"pdf_url":"https://arxiv.org/pdf/2412.07678v3.pdf","comment":"20 pages,8 figures"},{"id":"http://arxiv.org/abs/2307.09059v4","updated":"2025-01-17T08:32:40Z","published":"2023-07-18T08:23:46Z","title":"Text-guided Image Restoration and Semantic Enhancement for Text-to-Image\n  Person Retrieval","summary":"  The goal of Text-to-Image Person Retrieval (TIPR) is to retrieve specific\nperson images according to the given textual descriptions. A primary challenge\nin this task is bridging the substantial representational gap between visual\nand textual modalities. The prevailing methods map texts and images into\nunified embedding space for matching, while the intricate semantic\ncorrespondences between texts and images are still not effectively constructed.\nTo address this issue, we propose a novel TIPR framework to build fine-grained\ninteractions and alignment between person images and the corresponding texts.\nSpecifically, via fine-tuning the Contrastive Language-Image Pre-training\n(CLIP) model, a visual-textual dual encoder is firstly constructed, to\npreliminarily align the image and text features. Secondly, a Text-guided Image\nRestoration (TIR) auxiliary task is proposed to map abstract textual entities\nto specific image regions, improving the alignment between local textual and\nvisual embeddings. Additionally, a cross-modal triplet loss is presented to\nhandle hard samples, and further enhance the model's discriminability for minor\ndifferences. Moreover, a pruning-based text data augmentation approach is\nproposed to enhance focus on essential elements in descriptions, thereby\navoiding excessive model attention to less significant information. The\nexperimental results show our proposed method outperforms state-of-the-art\nmethods on three popular benchmark datasets, and the code will be made publicly\navailable at https://github.com/Delong-liu-bupt/SEN.\n","authors":["Delong Liu","Haiwen Li","Zhicheng Zhao","Yuan Dong"],"pdf_url":"https://arxiv.org/pdf/2307.09059v4.pdf","comment":"The paper was withdrawn due to a dispute among the authors regarding\n  the content of the article"},{"id":"http://arxiv.org/abs/2501.10024v1","updated":"2025-01-17T08:20:32Z","published":"2025-01-17T08:20:32Z","title":"Automatic Speech Recognition for Sanskrit with Transfer Learning","summary":"  Sanskrit, one of humanity's most ancient languages, has a vast collection of\nbooks and manuscripts on diverse topics that have been accumulated over\nmillennia. However, its digital content (audio and text), which is vital for\nthe training of AI systems, is profoundly limited. Furthermore, its intricate\nlinguistics make it hard to develop robust NLP tools for wider accessibility.\nGiven these constraints, we have developed an automatic speech recognition\nmodel for Sanskrit by employing transfer learning mechanism on OpenAI's Whisper\nmodel. After carefully optimising the hyper-parameters, we obtained promising\nresults with our transfer-learned model achieving a word error rate of 15.42%\non Vaksancayah dataset. An online demo of our model is made available for the\nuse of public and to evaluate its performance firsthand thereby paving the way\nfor improved accessibility and technological support for Sanskrit learning in\nthe modern era.\n","authors":["Bidit Sadhukhan","Swami Punyeshwarananda"],"pdf_url":"https://arxiv.org/pdf/2501.10024v1.pdf","comment":"Paper has been accepted at the 4th International Conference on\n  Computer, Communication, Control & Information Technology (C3IT), Hooghly,\n  India, 2024, pp. 1-5"},{"id":"http://arxiv.org/abs/2501.09997v1","updated":"2025-01-17T07:30:01Z","published":"2025-01-17T07:30:01Z","title":"Attention-guided Self-reflection for Zero-shot Hallucination Detection\n  in Large Language Models","summary":"  Hallucination has emerged as a significant barrier to the effective\napplication of Large Language Models (LLMs). In this work, we introduce a novel\nAttention-Guided SElf-Reflection (AGSER) approach for zero-shot hallucination\ndetection in LLMs. The AGSER method utilizes attention contributions to\ncategorize the input query into attentive and non-attentive queries. Each query\nis then processed separately through the LLMs, allowing us to compute\nconsistency scores between the generated responses and the original answer. The\ndifference between the two consistency scores serves as a hallucination\nestimator. In addition to its efficacy in detecting hallucinations, AGSER\nnotably reduces computational complexity, requiring only three passes through\nthe LLM and utilizing two sets of tokens. We have conducted extensive\nexperiments with four widely-used LLMs across three different hallucination\nbenchmarks, demonstrating that our approach significantly outperforms existing\nmethods in zero-shot hallucination detection.\n","authors":["Qiang Liu","Xinlong Chen","Yue Ding","Shizhen Xu","Shu Wu","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2501.09997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09993v1","updated":"2025-01-17T07:23:06Z","published":"2025-01-17T07:23:06Z","title":"Agent-as-Judge for Factual Summarization of Long Narratives","summary":"  Large Language Models (LLMs) have demonstrated near-human performance in\nsummarization tasks based on traditional metrics such as ROUGE and BERTScore.\nHowever, these metrics do not adequately capture critical aspects of\nsummarization quality, such as factual accuracy, particularly for long\nnarratives (>100K tokens). Recent advances, such as LLM-as-a-Judge, address the\nlimitations of metrics based on lexical similarity but still exhibit factual\ninconsistencies, especially in understanding character relationships and\nstates. In this work, we introduce NarrativeFactScore, a novel\n\"Agent-as-a-Judge\" framework for evaluating and refining summaries. By\nleveraging a Character Knowledge Graph (CKG) extracted from input and generated\nsummaries, NarrativeFactScore assesses the factual consistency and provides\nactionable guidance for refinement, such as identifying missing or erroneous\nfacts. We demonstrate the effectiveness of NarrativeFactScore through a\ndetailed workflow illustration and extensive validation on widely adopted\nbenchmarks, achieving superior performance compared to competitive methods. Our\nresults highlight the potential of agent-driven evaluation systems to improve\nthe factual reliability of LLM-generated summaries.\n","authors":["Yeonseok Jeong","Minsoo Kim","Seung-won Hwang","Byung-Hak Kim"],"pdf_url":"https://arxiv.org/pdf/2501.09993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15084v2","updated":"2025-01-17T07:12:55Z","published":"2024-12-19T17:29:44Z","title":"AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward\n  Modeling","summary":"  In this paper, we introduce AceMath, a suite of frontier math models that\nexcel in solving complex math problems, along with highly effective reward\nmodels capable of evaluating generated solutions and reliably identifying the\ncorrect ones. To develop the instruction-tuned math models, we propose a\nsupervised fine-tuning (SFT) process that first achieves competitive\nperformance across general domains, followed by targeted fine-tuning for the\nmath domain using a carefully curated set of prompts and synthetically\ngenerated responses. The resulting model, AceMath-72B-Instruct greatly\noutperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop\nmath-specialized reward model, we first construct AceMath-RewardBench, a\ncomprehensive and robust benchmark for evaluating math reward models across\ndiverse problems and difficulty levels. After that, we present a systematic\napproach to build our math reward models. The resulting model, AceMath-72B-RM,\nconsistently outperforms state-of-the-art reward models. Furthermore, when\ncombining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest\naverage rm@8 score across the math reasoning benchmarks. We release model\nweights, training data, and evaluation benchmarks at:\nhttps://research.nvidia.com/labs/adlr/acemath\n","authors":["Zihan Liu","Yang Chen","Mohammad Shoeybi","Bryan Catanzaro","Wei Ping"],"pdf_url":"https://arxiv.org/pdf/2412.15084v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09982v1","updated":"2025-01-17T06:46:10Z","published":"2025-01-17T06:46:10Z","title":"RichSpace: Enriching Text-to-Video Prompt Space via Text Embedding\n  Interpolation","summary":"  Text-to-video generation models have made impressive progress, but they still\nstruggle with generating videos with complex features. This limitation often\narises from the inability of the text encoder to produce accurate embeddings,\nwhich hinders the video generation model. In this work, we propose a novel\napproach to overcome this challenge by selecting the optimal text embedding\nthrough interpolation in the embedding space. We demonstrate that this method\nenables the video generation model to produce the desired videos. Additionally,\nwe introduce a simple algorithm using perpendicular foot embeddings and cosine\nsimilarity to identify the optimal interpolation embedding. Our findings\nhighlight the importance of accurate text embeddings and offer a pathway for\nimproving text-to-video generation performance.\n","authors":["Yuefan Cao","Chengyue Gong","Xiaoyu Li","Yingyu Liang","Zhizhou Sha","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2501.09982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05844v2","updated":"2025-01-17T05:33:54Z","published":"2024-11-06T15:32:28Z","title":"LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation\n  for Design Space Exploration","summary":"  GraphRAG integrates (knowledge) graphs with large language models (LLMs) to\nimprove reasoning accuracy and contextual relevance. Despite its promising\napplications and strong relevance to multiple research communities, such as\ndatabases and natural language processing, GraphRAG currently lacks modular\nworkflow analysis, systematic solution frameworks, and insightful empirical\nstudies. To bridge these gaps, we propose LEGO-GraphRAG, a modular framework\nthat enables: 1) fine-grained decomposition of the GraphRAG workflow, 2)\nsystematic classification of existing techniques and implemented GraphRAG\ninstances, and 3) creation of new GraphRAG instances. Our framework facilitates\ncomprehensive empirical studies of GraphRAG on large-scale real-world graphs\nand diverse query sets, revealing insights into balancing reasoning quality,\nruntime efficiency, and token or GPU cost, that are essential for building\nadvanced GraphRAG systems.\n","authors":["Yukun Cao","Zengyi Gao","Zhiyang Li","Xike Xie","Kevin Zhou","Jianliang Xu"],"pdf_url":"https://arxiv.org/pdf/2411.05844v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09959v1","updated":"2025-01-17T05:21:49Z","published":"2025-01-17T05:21:49Z","title":"A Survey on Multi-Turn Interaction Capabilities of Large Language Models","summary":"  Multi-turn interaction in the dialogue system research refers to a system's\nability to maintain context across multiple dialogue turns, enabling it to\ngenerate coherent and contextually relevant responses. Recent advancements in\nlarge language models (LLMs) have significantly expanded the scope of\nmulti-turn interaction, moving beyond chatbots to enable more dynamic agentic\ninteractions with users or environments. In this paper, we provide a focused\nreview of the multi-turn capabilities of LLMs, which are critical for a wide\nrange of downstream applications, including conversational search and\nrecommendation, consultation services, and interactive tutoring. This survey\nexplores four key aspects: (1) the core model capabilities that contribute to\neffective multi-turn interaction, (2) how multi-turn interaction is evaluated\nin current practice, (3) the general algorithms used to enhance multi-turn\ninteraction, and (4) potential future directions for research in this field.\n","authors":["Chen Zhang","Xinyi Dai","Yaxiong Wu","Qu Yang","Yasheng Wang","Ruiming Tang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2501.09959v1.pdf","comment":"Draft Version, 14 pages, Ongoing refinement over time"},{"id":"http://arxiv.org/abs/2501.09957v1","updated":"2025-01-17T05:19:14Z","published":"2025-01-17T05:19:14Z","title":"FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation\n  based on Knowledge Graphs","summary":"  To mitigate the hallucination and knowledge deficiency in large language\nmodels (LLMs), Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG)\nhas shown promising potential by utilizing KGs as external resource to enhance\nLLMs reasoning.However, existing KG-RAG approaches struggle with a trade-off\nbetween flexibility and retrieval quality.Modular methods prioritize\nflexibility by avoiding the use of KG-fine-tuned models during retrieval,\nleading to fixed retrieval strategies and suboptimal retrieval\nquality.Conversely, coupled methods embed KG information within models to\nimprove retrieval quality, but at the expense of flexibility.In this paper, we\npropose a novel flexible modular KG-RAG framework, termed FRAG, which\nsynergizes the advantages of both approaches.FRAG estimates the hop range of\nreasoning paths based solely on the query and classify it as either simple or\ncomplex.To match the complexity of the query, tailored pipelines are applied to\nensure efficient and accurate reasoning path retrieval, thus fostering the\nfinal reasoning process.By using the query text instead of the KG to infer the\nstructural information of reasoning paths and employing adaptable retrieval\nstrategies, FRAG improves retrieval quality while maintaining\nflexibility.Moreover, FRAG does not require extra LLMs fine-tuning or calls,\nsignificantly boosting efficiency and conserving resources.Extensive\nexperiments show that FRAG achieves state-of-the-art performance with high\nefficiency and low resource consumption.\n","authors":["Zengyi Gao","Yukun Cao","Hairu Wang","Ao Ke","Yuan Feng","Xike Xie","S Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.09957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00771v2","updated":"2025-01-17T04:47:11Z","published":"2024-10-01T15:07:07Z","title":"Empowering Large Language Model for Continual Video Question Answering\n  with Collaborative Prompting","summary":"  In recent years, the rapid increase in online video content has underscored\nthe limitations of static Video Question Answering (VideoQA) models trained on\nfixed datasets, as they struggle to adapt to new questions or tasks posed by\nnewly available content. In this paper, we explore the novel challenge of\nVideoQA within a continual learning framework, and empirically identify a\ncritical issue: fine-tuning a large language model (LLM) for a sequence of\ntasks often results in catastrophic forgetting. To address this, we propose\nCollaborative Prompting (ColPro), which integrates specific question constraint\nprompting, knowledge acquisition prompting, and visual temporal awareness\nprompting. These prompts aim to capture textual question context, visual\ncontent, and video temporal dynamics in VideoQA, a perspective underexplored in\nprior research. Experimental results on the NExT-QA and DramaQA datasets show\nthat ColPro achieves superior performance compared to existing approaches,\nachieving 55.14\\% accuracy on NExT-QA and 71.24\\% accuracy on DramaQA,\nhighlighting its practical relevance and effectiveness.\n","authors":["Chen Cai","Zheng Wang","Jianjun Gao","Wenyang Liu","Ye Lu","Runzhong Zhang","Kim-Hui Yap"],"pdf_url":"https://arxiv.org/pdf/2410.00771v2.pdf","comment":"Accepted by main EMNLP 2024"},{"id":"http://arxiv.org/abs/2309.10444v5","updated":"2025-01-17T04:45:45Z","published":"2023-09-19T09:04:15Z","title":"Exploring Iterative Enhancement for Improving Learnersourced\n  Multiple-Choice Question Explanations with Large Language Models","summary":"  Large language models exhibit superior capabilities in processing and\nunderstanding language, yet their applications in educational contexts remain\nunderexplored. Learnersourcing enhances learning by engaging students in\ncreating their own educational content. When learnersourcing multiple-choice\nquestions, creating explanations for the solution of a question is a crucial\nstep; it helps other students understand the solution and promotes a deeper\nunderstanding of related concepts. However, it is often difficult for students\nto craft effective solution explanations, due to limited subject understanding.\nTo help scaffold the task of automated explanation generation, we present and\nevaluate a framework called \"ILearner-LLM\", that iteratively enhances the\ngenerated explanations for the given questions with large language models.\nComprising an explanation generation model and an explanation evaluation model,\nthe framework generates high-quality student-aligned explanations by\niteratively feeding the quality rating score from the evaluation model back\ninto the instruction prompt of the explanation generation model. Experimental\nresults demonstrate the effectiveness of our ILearner-LLM on LLaMA2-13B and\nGPT-4 to generate higher quality explanations that are closer to those written\nby students on five PeerWise datasets. Our findings represent a promising path\nto enrich the learnersourcing experience for students and to enhance the\ncapabilities of large language models for educational applications.\n","authors":["Qiming Bao","Juho Leinonen","Alex Yuxuan Peng","Wanjun Zhong","Gaël Gendron","Timothy Pistotti","Alice Huang","Paul Denny","Michael Witbrock","Jiamou Liu"],"pdf_url":"https://arxiv.org/pdf/2309.10444v5.pdf","comment":"The short version (v4) has been accepted as a non-archival workshop\n  paper at AGI@ICLR 2024, and the full version has been accepted by the main\n  track of AAAI/EAAI 2025"},{"id":"http://arxiv.org/abs/2310.09430v5","updated":"2025-01-17T04:39:38Z","published":"2023-10-13T22:29:15Z","title":"Assessing and Enhancing the Robustness of Large Language Models with\n  Task Structure Variations for Logical Reasoning","summary":"  Large language models (LLMs), such as LLaMA, Alpaca, Vicuna, GPT-3.5 and\nGPT-4, have advanced the performance of AI systems on various natural language\nprocessing tasks to human-like levels. However, their generalisation and\nrobustness when performing logical reasoning has not been sufficiently\nassessed. To comprehensively evaluate this ability, we develop three new\nlogical reasoning datasets named \"ReClor-plus\", \"LogiQA-plus\" and\n\"LogiQAv2-plus\" that extend standard logical reasoning datasets to evaluate the\nrobustness of the LLM's reasoning. For each, we create three subsets: the first\nwith randomly shuffled options, the second with the correct choices replaced by\n\"none of the other options is correct\", and the third with a combination of\nshuffling and substitution. Experiments on these datasets show that these\nsimple augmentations greatly hinder the models' performance. Despite their high\nperformance on the original publicly available datasets, we find that all\nmodels perform poorly on these newly constructed datasets. We also demonstrate\nthat introducing task variations into the training set can markedly improve the\nmodel's performance on both the original and our developed datasets. Finally,\nwe show that applying logic-driven data augmentation for fine-tuning and\nprompting can enhance generalisation in both discriminative and generative\nmodels, offering a path to improving their robustness for tasks involving\nlogical reasoning. Source code and data are made publicly available at\nhttps://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning.\n","authors":["Qiming Bao","Gael Gendron","Alex Yuxuan Peng","Wanjun Zhong","Neset Tan","Yang Chen","Michael Witbrock","Jiamou Liu"],"pdf_url":"https://arxiv.org/pdf/2310.09430v5.pdf","comment":"The short version (v3) was accepted for oral presentation at the\n  first LLM@IJCAI 2023 non-archival symposium, and the full version was\n  accepted by ICONIP 2024"},{"id":"http://arxiv.org/abs/2407.01892v2","updated":"2025-01-17T04:29:47Z","published":"2024-07-02T02:27:46Z","title":"GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial\n  Reasoning","summary":"  Spatial reasoning, an important faculty of human cognition with many\npractical applications, is one of the core commonsense skills that is not\npurely language-based and, for satisfying (as opposed to optimal) solutions,\nrequires some minimum degree of planning. Existing benchmarks of Commonsense\nSpatial Reasoning (CSR) tend to evaluate how Large Language Models (LLMs)\ninterpret text-based spatial $\\textit{descriptions}$ rather than directly\nevaluate a plan produced by the LLM in response to a $\\textit{specific}$\nspatial reasoning problem. In this paper, we construct a large-scale benchmark\ncalled GRASP, which consists of 16,000 grid-based environments where the agent\nis tasked with an energy collection problem. These environments include 100\ngrid instances instantiated using each of the 160 different grid settings,\ninvolving five different energy distributions, two modes of agent starting\nposition, and two distinct obstacle configurations, as well as three kinds of\nagent constraints. Using GRASP, we compare classic baseline approaches, such as\nrandom walk and greedy search methods, with advanced LLMs like GPT-3.5-Turbo,\nGPT-4o, and GPT-o1-mini. The experimental results indicate that even these\nadvanced LLMs struggle to consistently achieve satisfactory solutions.\n","authors":["Zhisheng Tang","Mayank Kejriwal"],"pdf_url":"https://arxiv.org/pdf/2407.01892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17640v2","updated":"2025-01-17T04:26:44Z","published":"2024-09-26T08:44:38Z","title":"T3: A Novel Zero-shot Transfer Learning Framework Iteratively Training\n  on an Assistant Task for a Target Task","summary":"  Long text summarization, gradually being essential for efficiently processing\nlarge volumes of information, stays challenging for Large Language Models\n(LLMs) such as GPT and LLaMA families because of the insufficient open-sourced\ntraining datasets and the high requirement of contextual details dealing. To\naddress the issue, we design a novel zero-shot transfer learning framework,\nabbreviated as T3, to iteratively training a baseline LLM on an assistant task\nfor the target task, where the former should own richer data resources and\nshare structural or semantic similarity with the latter. In practice, T3 is\napproached to deal with the long text summarization task by utilizing question\nanswering as the assistant task, and further validated its effectiveness on the\nBBC summary, NarraSum, FairytaleQA, and NLQuAD datasets, with up to nearly 14%\nimprovement in ROUGE, 35% improvement in BLEU, and 16% improvement in Factscore\ncompared to three baseline LLMs, demonstrating its potential for more\nassistant-target task combinations.\n","authors":["Xindi Tong","Yujin Zhu","Shijian Fan","Liang Xu"],"pdf_url":"https://arxiv.org/pdf/2409.17640v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09950v1","updated":"2025-01-17T04:26:13Z","published":"2025-01-17T04:26:13Z","title":"Sympathy over Polarization: A Computational Discourse Analysis of Social\n  Media Posts about the July 2024 Trump Assassination Attempt","summary":"  On July 13, 2024, at the Trump rally in Pennsylvania, someone attempted to\nassassinate Republican Presidential Candidate Donald Trump. This attempt\nsparked a large-scale discussion on social media. We collected posts from X\n(formerly known as Twitter) one week before and after the assassination attempt\nand aimed to model the short-term effects of such a ``shock'' on public\nopinions and discussion topics. Specifically, our study addresses three key\nquestions: first, we investigate how public sentiment toward Donald Trump\nshifts over time and across regions (RQ1) and examine whether the assassination\nattempt itself significantly affects public attitudes, independent of the\nexisting political alignments (RQ2). Finally, we explore the major themes in\nonline conversations before and after the crisis, illustrating how discussion\ntopics evolved in response to this politically charged event (RQ3). By\nintegrating large language model-based sentiment analysis,\ndifference-in-differences modeling, and topic modeling techniques, we find that\nfollowing the attempt the public response was broadly sympathetic to Trump\nrather than polarizing, despite baseline ideological and regional disparities.\n","authors":["Qingcheng Zeng","Guanhong Liu","Zhaoqian Xue","Diego Ford","Rob Voigt","Loni Hagen","Lingyao Li"],"pdf_url":"https://arxiv.org/pdf/2501.09950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.11156v4","updated":"2025-01-17T04:21:47Z","published":"2023-03-17T17:53:19Z","title":"Can AI-Generated Text be Reliably Detected?","summary":"  Large Language Models (LLMs) perform impressively well in various\napplications. However, the potential for misuse of these models in activities\nsuch as plagiarism, generating fake news, and spamming has raised concern about\ntheir responsible use. Consequently, the reliable detection of AI-generated\ntext has become a critical area of research. AI text detectors have shown to be\neffective under their specific settings. In this paper, we stress-test the\nrobustness of these AI text detectors in the presence of an attacker. We\nintroduce recursive paraphrasing attack to stress test a wide range of\ndetection schemes, including the ones using the watermarking as well as neural\nnetwork-based detectors, zero shot classifiers, and retrieval-based detectors.\nOur experiments conducted on passages, each approximately 300 tokens long,\nreveal the varying sensitivities of these detectors to our attacks. Our\nfindings indicate that while our recursive paraphrasing method can\nsignificantly reduce detection rates, it only slightly degrades text quality in\nmany cases, highlighting potential vulnerabilities in current detection systems\nin the presence of an attacker. Additionally, we investigate the susceptibility\nof watermarked LLMs to spoofing attacks aimed at misclassifying human-written\ntext as AI-generated. We demonstrate that an attacker can infer hidden AI text\nsignatures without white-box access to the detection method, potentially\nleading to reputational risks for LLM developers. Finally, we provide a\ntheoretical framework connecting the AUROC of the best possible detector to the\nTotal Variation distance between human and AI text distributions. This analysis\noffers insights into the fundamental challenges of reliable detection as\nlanguage models continue to advance. Our code is publicly available at\nhttps://github.com/vinusankars/Reliability-of-AI-text-detectors.\n","authors":["Vinu Sankar Sadasivan","Aounon Kumar","Sriram Balasubramanian","Wenxiao Wang","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2303.11156v4.pdf","comment":"Published in Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2501.09943v1","updated":"2025-01-17T03:47:19Z","published":"2025-01-17T03:47:19Z","title":"Indigenous Languages Spoken in Argentina: A Survey of NLP and Speech\n  Resources","summary":"  Argentina has a diverse, yet little-known, Indigenous language heritage. Most\nof these languages are at risk of disappearing, resulting in a significant loss\nof world heritage and cultural knowledge. Currently, no unified information on\nspeakers and computational tools is available for these languages. In this\nwork, we present a systematization of the Indigenous languages spoken in\nArgentina, along with national demographic data on the country's Indigenous\npopulation. The languages are classified into seven families: Mapuche,\nTup\\'i-Guaran\\'i, Guaycur\\'u, Quechua, Mataco-Mataguaya, Aymara, and Chon. We\nalso provide an introductory survey of the computational resources available\nfor these languages, whether or not they are specifically developed for\nArgentine varieties.\n","authors":["Belu Ticona","Fernando Carranza","Viviana Cotik"],"pdf_url":"https://arxiv.org/pdf/2501.09943v1.pdf","comment":"Accepted to COLING Main 2025"},{"id":"http://arxiv.org/abs/2403.16950v5","updated":"2025-01-17T03:43:53Z","published":"2024-03-25T17:11:28Z","title":"Aligning with Human Judgement: The Role of Pairwise Preference in Large\n  Language Model Evaluators","summary":"  Large Language Models (LLMs) have demonstrated promising capabilities as\nautomatic evaluators in assessing the quality of generated natural language.\nHowever, LLMs still exhibit biases in evaluation and often struggle to generate\ncoherent evaluations that align with human assessments. In this work, we first\nconduct a systematic study of the misalignment between LLM evaluators and human\nevaluation, revealing that existing calibration methods aimed at mitigating\nbiases of LLMs are insufficient for effectively aligning LLM evaluators.\nInspired by the use of preference data in RLHF, we formulate the evaluation as\na ranking problem and introduce Pairwise-preference Search (PAIRS), an\nuncertainty-guided search-based rank aggregation method that employs LLMs to\nconduct pairwise comparisons locally and efficiently ranks candidate texts\nglobally. PAIRS achieves state-of-the-art performance on representative\nevaluation tasks in long-form generations and demonstrates significant\nimprovements over direct scoring. Furthermore, we provide insights into the\nrole of pairwise preference in quantifying the transitivity of LLMs and\ndemonstrate how PAIRS benefits from calibration using debiased pairwise\nevaluations.\n","authors":["Yinhong Liu","Han Zhou","Zhijiang Guo","Ehsan Shareghi","Ivan Vulić","Anna Korhonen","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2403.16950v5.pdf","comment":"This paper has been accepted by COLM 2024"},{"id":"http://arxiv.org/abs/2501.09940v1","updated":"2025-01-17T03:42:18Z","published":"2025-01-17T03:42:18Z","title":"Passage Segmentation of Documents for Extractive Question Answering","summary":"  Retrieval-Augmented Generation (RAG) has proven effective in open-domain\nquestion answering. However, the chunking process, which is essential to this\npipeline, often receives insufficient attention relative to retrieval and\nsynthesis components. This study emphasizes the critical role of chunking in\nimproving the performance of both dense passage retrieval and the end-to-end\nRAG pipeline. We then introduce the Logits-Guided Multi-Granular Chunker\n(LGMGC), a novel framework that splits long documents into contextualized,\nself-contained chunks of varied granularity. Our experimental results,\nevaluated on two benchmark datasets, demonstrate that LGMGC not only improves\nthe retrieval step but also outperforms existing chunking methods when\nintegrated into a RAG pipeline.\n","authors":["Zuhong Liu","Charles-Elie Simon","Fabien Caspani"],"pdf_url":"https://arxiv.org/pdf/2501.09940v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.02933v4","updated":"2025-01-17T03:19:16Z","published":"2024-04-03T01:09:41Z","title":"NL2KQL: From Natural Language to Kusto Query","summary":"  Data is growing rapidly in volume and complexity. Proficiency in database\nquery languages is pivotal for crafting effective queries. As coding assistants\nbecome more prevalent, there is significant opportunity to enhance database\nquery languages. The Kusto Query Language (KQL) is a widely used query language\nfor large semi-structured data such as logs, telemetries, and time-series for\nbig data analytics platforms. This paper introduces NL2KQL an innovative\nframework that uses large language models (LLMs) to convert natural language\nqueries (NLQs) to KQL queries. The proposed NL2KQL framework includes several\nkey components: Schema Refiner which narrows down the schema to its most\npertinent elements; the Few-shot Selector which dynamically selects relevant\nexamples from a few-shot dataset; and the Query Refiner which repairs syntactic\nand semantic errors in KQL queries. Additionally, this study outlines a method\nfor generating large datasets of synthetic NLQ-KQL pairs which are valid within\na specific database contexts. To validate NL2KQL's performance, we utilize an\narray of online (based on query execution) and offline (based on query parsing)\nmetrics. Through ablation studies, the significance of each framework component\nis examined, and the datasets used for benchmarking are made publicly\navailable. This work is the first of its kind and is compared with available\nbaselines to demonstrate its effectiveness.\n","authors":["Xinye Tang","Amir H. Abdi","Jeremias Eichelbaum","Mahan Das","Alex Klein","Nihal Irmak Pakis","William Blum","Daniel L Mace","Tanvi Raja","Namrata Padmanabhan","Ye Xing"],"pdf_url":"https://arxiv.org/pdf/2404.02933v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10960v4","updated":"2025-01-17T03:09:24Z","published":"2024-07-15T17:55:42Z","title":"Fast Matrix Multiplications for Lookup Table-Quantized LLMs","summary":"  The deployment of large language models (LLMs) is often constrained by memory\nbandwidth, where the primary bottleneck is the cost of transferring model\nparameters from the GPU's global memory to its registers. When coupled with\ncustom kernels that fuse the dequantization and matmul operations, weight-only\nquantization can thus enable faster inference by reducing the amount of memory\nmovement. However, developing high-performance kernels for weight-quantized\nLLMs presents substantial challenges, especially when the weights are\ncompressed to non-evenly-divisible bit widths (e.g., 3 bits) with non-uniform,\nlookup table (LUT) quantization. This paper describes FLUTE, a flexible lookup\ntable engine for LUT-quantized LLMs, which uses offline restructuring of the\nquantized weight matrix to minimize bit manipulations associated with\nunpacking, and vectorization and duplication of the lookup table to mitigate\nshared memory bandwidth constraints. At batch sizes < 32 and quantization group\nsize of 128 (typical in LLM inference), the FLUTE kernel can be 2-4x faster\nthan existing GEMM kernels. As an application of FLUTE, we explore a simple\nextension to lookup table-based NormalFloat quantization and apply it to\nquantize LLaMA3 to various configurations, obtaining competitive quantization\nperformance against strong baselines while obtaining an end-to-end throughput\nincrease of 1.5 to 2 times.\n","authors":["Han Guo","William Brandon","Radostin Cholakov","Jonathan Ragan-Kelley","Eric P. Xing","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2407.10960v4.pdf","comment":"EMNLP 2024 (Findings)"},{"id":"http://arxiv.org/abs/2501.09929v1","updated":"2025-01-17T02:55:23Z","published":"2025-01-17T02:55:23Z","title":"Steering Large Language Models with Feature Guided Activation Additions","summary":"  Effective and reliable control over large language model (LLM) behavior is a\nsignificant challenge. While activation steering methods, which add steering\nvectors to a model's hidden states, are a promising approach, existing\ntechniques often lack precision and interpretability in how they influence\nmodel outputs. We introduce Feature Guided Activation Additions (FGAA), a novel\nactivation steering method that leverages insights from Contrastive Activation\nAddition (CAA) and Sparse Autoencoder-Targeted Steering (SAE-TS). By operating\nin the latent space of a Sparse Autoencoder (SAE) and employing optimization\ntechniques to select desired SAE features, FGAA constructs precise steering\nvectors that provide better steering effects while maintaining coherence of\nsteered model outputs. In this regard, evaluations on Gemma-2-2B and Gemma-2-9B\nmodels across various steering tasks demonstrate that FGAA outperforms existing\nsteering methods of CAA, SAE decoder steering, and SAE-TS. Our results also\nhighlight important trade-offs between steering scale and general model\ncapabilities that are consistent across all tested steering methods.\n","authors":["Samuel Soo","Wesley Teng","Chandrasekaran Balaganesh"],"pdf_url":"https://arxiv.org/pdf/2501.09929v1.pdf","comment":"7 maintext pages, 14 appendix pages"},{"id":"http://arxiv.org/abs/2501.09928v1","updated":"2025-01-17T02:48:29Z","published":"2025-01-17T02:48:29Z","title":"Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective\n  Retrieval-Augmented LLMs","summary":"  Dialogue benchmarks are crucial in training and evaluating chatbots engaging\nin domain-specific conversations. Knowledge graphs (KGs) represent semantically\nrich and well-organized data spanning various domains, such as DBLP, DBpedia,\nand YAGO. Traditionally, dialogue benchmarks have been manually created from\ndocuments, neglecting the potential of KGs in automating this process. Some\nquestion-answering benchmarks are automatically generated using extensive\npreprocessing from KGs, but they do not support dialogue generation. This paper\nintroduces Chatty-Gen, a novel multi-stage retrieval-augmented generation\nplatform for automatically generating high-quality dialogue benchmarks tailored\nto a specific domain using a KG. Chatty-Gen decomposes the generation process\ninto manageable stages and uses assertion rules for automatic validation\nbetween stages. Our approach enables control over intermediate results to\nprevent time-consuming restarts due to hallucinations. It also reduces reliance\non costly and more powerful commercial LLMs. Chatty-Gen eliminates upfront\nprocessing of the entire KG using efficient query-based retrieval to find\nrepresentative subgraphs based on the dialogue context. Our experiments with\nseveral real and large KGs demonstrate that Chatty-Gen significantly\noutperforms state-of-the-art systems and ensures consistent model and system\nperformance across multiple LLMs of diverse capabilities, such as GPT-4o,\nGemini 1.5, Llama 3, and Mistral.\n","authors":["Reham Omar","Omij Mangukiya","Essam Mansour"],"pdf_url":"https://arxiv.org/pdf/2501.09928v1.pdf","comment":"The paper is publsihed in SIGMOD 2025"},{"id":"http://arxiv.org/abs/2501.09538v2","updated":"2025-01-17T02:35:08Z","published":"2025-01-16T13:42:09Z","title":"Analyzing Continuous Semantic Shifts with Diachronic Word Similarity\n  Matrices","summary":"  The meanings and relationships of words shift over time. This phenomenon is\nreferred to as semantic shift. Research focused on understanding how semantic\nshifts occur over multiple time periods is essential for gaining a detailed\nunderstanding of semantic shifts. However, detecting change points only between\nadjacent time periods is insufficient for analyzing detailed semantic shifts,\nand using BERT-based methods to examine word sense proportions incurs a high\ncomputational cost. To address those issues, we propose a simple yet intuitive\nframework for how semantic shifts occur over multiple time periods by\nleveraging a similarity matrix between the embeddings of the same word through\ntime. We compute a diachronic word similarity matrix using fast and lightweight\nword embeddings across arbitrary time periods, making it deeper to analyze\ncontinuous semantic shifts. Additionally, by clustering the similarity matrices\nfor different words, we can categorize words that exhibit similar behavior of\nsemantic shift in an unsupervised manner.\n","authors":["Hajime Kiyama","Taichi Aida","Mamoru Komachi","Toshinobu Ogiso","Hiroya Takamura","Daichi Mochihashi"],"pdf_url":"https://arxiv.org/pdf/2501.09538v2.pdf","comment":"COLING2025"},{"id":"http://arxiv.org/abs/2408.07832v8","updated":"2025-01-17T02:18:00Z","published":"2024-07-31T14:49:35Z","title":"LADDER: Language Driven Slice Discovery and Error Rectification","summary":"  Error slice discovery is crucial to diagnose and mitigate model errors.\nCurrent clustering or discrete attribute-based slice discovery methods face key\nlimitations: 1) clustering results in incoherent slices, while assigning\ndiscrete attributes to slices leads to incomplete coverage of error patterns\ndue to missing or insufficient attributes; 2) these methods lack complex\nreasoning, preventing them from fully explaining model biases; 3) they fail to\nintegrate \\textit{domain knowledge}, limiting their usage in specialized fields\n\\eg radiology. We propose\\ladder (\\underline{La}nguage-\\underline{D}riven\n\\underline{D}iscovery and \\underline{E}rror \\underline{R}ectification), to\naddress the limitations by: (1) leveraging the flexibility of natural language\nto address incompleteness, (2) employing LLM's latent \\textit{domain knowledge}\nand advanced reasoning to analyze sentences and derive testable hypotheses\ndirectly, identifying biased attributes, and form coherent error slices without\nclustering. Existing mitigation methods typically address only the\nworst-performing group, often amplifying errors in other subgroups. In\ncontrast,\\ladder generates pseudo attributes from the discovered hypotheses to\nmitigate errors across all biases without explicit attribute annotations or\nprior knowledge of bias. Rigorous evaluations on 6 datasets spanning natural\nand medical images -- comparing 200+ classifiers with diverse architectures,\npretraining strategies, and LLMs -- show that\\ladder consistently outperforms\nexisting baselines in discovering and mitigating biases.\n","authors":["Shantanu Ghosh","Rayan Syed","Chenyu Wang","Clare B. Poynton","Shyam Visweswaran","Kayhan Batmanghelich"],"pdf_url":"https://arxiv.org/pdf/2408.07832v8.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.20550v2","updated":"2025-01-17T01:44:44Z","published":"2024-09-30T17:51:15Z","title":"LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism,\n  and Mitigation","summary":"  Code generation aims to automatically generate code from input requirements,\nsignificantly enhancing development efficiency. Recent large language models\n(LLMs) based approaches have shown promising results and revolutionized code\ngeneration task. Despite the promising performance, LLMs often generate\ncontents with hallucinations, especially for the code generation scenario\nrequiring the handling of complex contextual dependencies in practical\ndevelopment process. Although previous study has analyzed hallucinations in\nLLM-powered code generation, the study is limited to standalone function\ngeneration. In this paper, we conduct an empirical study to study the\nphenomena, mechanism, and mitigation of LLM hallucinations within more\npractical and complex development contexts in repository-level generation\nscenario. First, we manually examine the code generation results from six\nmainstream LLMs to establish a hallucination taxonomy of LLM-generated code.\nNext, we elaborate on the phenomenon of hallucinations, analyze their\ndistribution across different models. We then analyze causes of hallucinations\nand identify four potential factors contributing to hallucinations. Finally, we\npropose an RAG-based mitigation method, which demonstrates consistent\neffectiveness in all studied LLMs. The replication package including code,\ndata, and experimental results is available at\nhttps://github.com/DeepSoftwareAnalytics/LLMCodingHallucination\n","authors":["Ziyao Zhang","Yanlin Wang","Chong Wang","Jiachi Chen","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2409.20550v2.pdf","comment":"Accepted by ISSTA 2025"},{"id":"http://arxiv.org/abs/2402.18540v2","updated":"2025-01-17T01:43:21Z","published":"2024-02-28T18:23:49Z","title":"Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt\n  Templates","summary":"  Public LLMs such as the Llama 2-Chat underwent alignment training and were\nconsidered safe. Recently Qi et al. [2024] reported that even benign\nfine-tuning on seemingly safe datasets can give rise to unsafe behaviors in the\nmodels. The current paper is about methods and best practices to mitigate such\nloss of alignment. We focus on the setting where a public model is fine-tuned\nbefore serving users for specific usage, where the model should improve on the\ndownstream task while maintaining alignment. Through extensive experiments on\nseveral chat models (Meta's Llama 2-Chat, Mistral AI's Mistral 7B Instruct\nv0.2, and OpenAI's GPT-3.5 Turbo), this paper uncovers that the prompt\ntemplates used during fine-tuning and inference play a crucial role in\npreserving safety alignment, and proposes the ``Pure Tuning, Safe Testing''\n(PTST) strategy -- fine-tune models without a safety prompt, but include it at\ntest time. This seemingly counterintuitive strategy incorporates an intended\ndistribution shift to encourage alignment preservation. Fine-tuning experiments\non GSM8K, ChatDoctor, and OpenOrca show that PTST significantly reduces the\nrise of unsafe behaviors.\n","authors":["Kaifeng Lyu","Haoyu Zhao","Xinran Gu","Dingli Yu","Anirudh Goyal","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2402.18540v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.04421v2","updated":"2025-01-17T01:11:16Z","published":"2024-09-06T17:30:45Z","title":"RLPF: Reinforcement Learning from Prediction Feedback for User\n  Summarization with LLMs","summary":"  LLM-powered personalization agent systems employ Large Language Models (LLMs)\nto predict users' behavior from their past activities. However, their\neffectiveness often hinges on the ability to effectively leverage extensive,\nlong user historical data due to its inherent noise and length of such data.\nExisting pretrained LLMs may generate summaries that are concise but lack the\nnecessary context for downstream tasks, hindering their utility in\npersonalization systems. To address these challenges, we introduce\nReinforcement Learning from Prediction Feedback (RLPF). RLPF fine-tunes LLMs to\ngenerate concise, human-readable user summaries that are optimized for\ndownstream task performance. By maximizing the usefulness of the generated\nsummaries, RLPF effectively distills extensive user history data while\npreserving essential information for downstream tasks. Our empirical evaluation\ndemonstrates significant improvements in both extrinsic downstream task utility\nand intrinsic summary quality, surpassing baseline methods by up to 22% on\ndownstream task performance and achieving an up to 84.59% win rate on\nFactuality, Abstractiveness, and Readability. RLPF also achieves a remarkable\n74% reduction in context length while improving performance on 16 out of 19\nunseen tasks and/or datasets, showcasing its generalizability. This approach\noffers a promising solution for enhancing LLM personalization by effectively\ntransforming long, noisy user histories into informative and human-readable\nrepresentations.\n","authors":["Jiaxing Wu","Lin Ning","Luyang Liu","Harrison Lee","Neo Wu","Chao Wang","Sushant Prakash","Shawn O'Banion","Bradley Green","Jun Xie"],"pdf_url":"https://arxiv.org/pdf/2409.04421v2.pdf","comment":"AAAI 2025"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2501.10343v1","updated":"2025-01-17T18:34:47Z","published":"2025-01-17T18:34:47Z","title":"3rd Workshop on Maritime Computer Vision (MaCVi) 2025: Challenge Results","summary":"  The 3rd Workshop on Maritime Computer Vision (MaCVi) 2025 addresses maritime\ncomputer vision for Unmanned Surface Vehicles (USV) and underwater. This report\noffers a comprehensive overview of the findings from the challenges. We provide\nboth statistical and qualitative analyses, evaluating trends from over 700\nsubmissions. All datasets, evaluation code, and the leaderboard are available\nto the public at https://macvi.org/workshop/macvi25.\n","authors":["Benjamin Kiefer","Lojze Žust","Jon Muhovič","Matej Kristan","Janez Perš","Matija Teršek","Uma Mudenagudi Chaitra Desai","Arnold Wiliem","Marten Kreis","Nikhil Akalwadi","Yitong Quan","Zhiqiang Zhong","Zhe Zhang","Sujie Liu","Xuran Chen","Yang Yang","Matej Fabijanić","Fausto Ferreira","Seongju Lee","Junseok Lee","Kyoobin Lee","Shanliang Yao","Runwei Guan","Xiaoyu Huang","Yi Ni","Himanshu Kumar","Yuan Feng","Yi-Ching Cheng","Tzu-Yu Lin","Chia-Ming Lee","Chih-Chung Hsu","Jannik Sheikh","Andreas Michel","Wolfgang Gross","Martin Weinmann","Josip Šarić","Yipeng Lin","Xiang Yang","Nan Jiang","Yutang Lu","Fei Feng","Ali Awad","Evan Lucas","Ashraf Saleem","Ching-Heng Cheng","Yu-Fan Lin","Tzu-Yu Lin","Chih-Chung Hsu"],"pdf_url":"https://arxiv.org/pdf/2501.10343v1.pdf","comment":"Part of the MaCVi 2025 workshop"},{"id":"http://arxiv.org/abs/2501.09327v2","updated":"2025-01-17T18:30:04Z","published":"2025-01-16T06:52:58Z","title":"On Learning Informative Trajectory Embeddings for Imitation,\n  Classification and Regression","summary":"  In real-world sequential decision making tasks like autonomous driving,\nrobotics, and healthcare, learning from observed state-action trajectories is\ncritical for tasks like imitation, classification, and clustering. For example,\nself-driving cars must replicate human driving behaviors, while robots and\nhealthcare systems benefit from modeling decision sequences, whether or not\nthey come from expert data. Existing trajectory encoding methods often focus on\nspecific tasks or rely on reward signals, limiting their ability to generalize\nacross domains and tasks. Inspired by the success of embedding models like CLIP\nand BERT in static domains, we propose a novel method for embedding\nstate-action trajectories into a latent space that captures the skills and\ncompetencies in the dynamic underlying decision-making processes. This method\noperates without the need for reward labels, enabling better generalization\nacross diverse domains and tasks. Our contributions are threefold: (1) We\nintroduce a trajectory embedding approach that captures multiple abilities from\nstate-action data. (2) The learned embeddings exhibit strong representational\npower across downstream tasks, including imitation, classification, clustering,\nand regression. (3) The embeddings demonstrate unique properties, such as\ncontrolling agent behaviors in IQ-Learn and an additive structure in the latent\nspace. Experimental results confirm that our method outperforms traditional\napproaches, offering more flexible and powerful trajectory representations for\nvarious applications. Our code is available at\nhttps://github.com/Erasmo1015/vte.\n","authors":["Zichang Ge","Changyu Chen","Arunesh Sinha","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2501.09327v2.pdf","comment":"AAMAS 2025"},{"id":"http://arxiv.org/abs/2501.10332v1","updated":"2025-01-17T18:05:04Z","published":"2025-01-17T18:05:04Z","title":"Agent4Edu: Generating Learner Response Data by Generative Agents for\n  Intelligent Education Systems","summary":"  Personalized learning represents a promising educational strategy within\nintelligent educational systems, aiming to enhance learners' practice\nefficiency. However, the discrepancy between offline metrics and online\nperformance significantly impedes their progress. To address this challenge, we\nintroduce Agent4Edu, a novel personalized learning simulator leveraging recent\nadvancements in human intelligence through large language models (LLMs).\nAgent4Edu features LLM-powered generative agents equipped with learner profile,\nmemory, and action modules tailored to personalized learning algorithms. The\nlearner profiles are initialized using real-world response data, capturing\npractice styles and cognitive factors. Inspired by human psychology theory, the\nmemory module records practice facts and high-level summaries, integrating\nreflection mechanisms. The action module supports various behaviors, including\nexercise understanding, analysis, and response generation. Each agent can\ninteract with personalized learning algorithms, such as computerized adaptive\ntesting, enabling a multifaceted evaluation and enhancement of customized\nservices. Through a comprehensive assessment, we explore the strengths and\nweaknesses of Agent4Edu, emphasizing the consistency and discrepancies in\nresponses between agents and human learners. The code, data, and appendix are\npublicly available at https://github.com/bigdata-ustc/Agent4Edu.\n","authors":["Weibo Gao","Qi Liu","Linan Yue","Fangzhou Yao","Rui Lv","Zheng Zhang","Hao Wang","Zhenya Huang"],"pdf_url":"https://arxiv.org/pdf/2501.10332v1.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2501.10326v1","updated":"2025-01-17T17:56:58Z","published":"2025-01-17T17:56:58Z","title":"Large language models for automated scholarly paper review: A survey","summary":"  Large language models (LLMs) have significantly impacted human society,\ninfluencing various domains. Among them, academia is not simply a domain\naffected by LLMs, but it is also the pivotal force in the development of LLMs.\nIn academic publications, this phenomenon is represented during the\nincorporation of LLMs into the peer review mechanism for reviewing manuscripts.\nWe proposed the concept of automated scholarly paper review (ASPR) in our\nprevious paper. As the incorporation grows, it now enters the coexistence phase\nof ASPR and peer review, which is described in that paper. LLMs hold\ntransformative potential for the full-scale implementation of ASPR, but they\nalso pose new issues and challenges that need to be addressed. In this survey\npaper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin\nwith a survey to find out which LLMs are used to conduct ASPR. Then, we review\nwhat ASPR-related technological bottlenecks have been solved with the\nincorporation of LLM technology. After that, we move on to explore new methods,\nnew datasets, new source code, and new online systems that come with LLMs for\nASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and\ninvestigate the attitudes and reactions of publishers and academia to ASPR.\nLastly, we discuss the challenges associated with the development of LLMs for\nASPR. We hope this survey can serve as an inspirational reference for the\nresearchers and promote the progress of ASPR for its actual implementation.\n","authors":["Zhenzhen Zhuang","Jiandong Chen","Hongfeng Xu","Yuwen Jiang","Jialiang Lin"],"pdf_url":"https://arxiv.org/pdf/2501.10326v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2501.10322v1","updated":"2025-01-17T17:51:53Z","published":"2025-01-17T17:51:53Z","title":"Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level\n  Processing for Robust, Adaptable Language Models","summary":"  Tokenization is a fundamental step in natural language processing, breaking\ntext into units that computational models can process. While learned subword\ntokenizers have become the de-facto standard, they present challenges such as\nlarge vocabularies, limited adaptability to new domains or languages, and\nsensitivity to spelling errors and variations. To overcome these limitations,\nwe investigate a hierarchical architecture for autoregressive language\nmodelling that combines character-level and word-level processing. It employs a\nlightweight character-level encoder to convert character sequences into word\nembeddings, which are then processed by a word-level backbone model and decoded\nback into characters via a compact character-level decoder. This method retains\nthe sequence compression benefits of word-level tokenization without relying on\na rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion\nparameters, that hierarchical transformers match the downstream task\nperformance of subword-tokenizer-based models while exhibiting significantly\ngreater robustness to input perturbations. Additionally, during continued\npretraining on an out-of-domain language, our model trains almost twice as\nfast, achieves superior performance on the target language, and retains more of\nits previously learned knowledge. Hierarchical transformers pave the way for\nNLP systems that are more robust, flexible, and generalizable across languages\nand domains.\n","authors":["Pit Neitemeier","Björn Deiseroth","Constantin Eichenberg","Lukas Balles"],"pdf_url":"https://arxiv.org/pdf/2501.10322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.10021v3","updated":"2025-01-17T17:37:42Z","published":"2021-07-21T11:31:57Z","title":"Neuradicon: operational representation learning of neuroimaging reports","summary":"  Radiological reports typically summarize the content and interpretation of\nimaging studies in unstructured form that precludes quantitative analysis. This\nlimits the monitoring of radiological services to throughput undifferentiated\nby content, impeding specific, targeted operational optimization. Here we\npresent Neuradicon, a natural language processing (NLP) framework for\nquantitative analysis of neuroradiological reports. Our framework is a hybrid\nof rule-based and artificial intelligence models to represent neurological\nreports in succinct, quantitative form optimally suited to operational\nguidance. We demonstrate the application of Neuradicon to operational\nphenotyping of a corpus of 336,569 reports, and report excellent\ngeneralizability across time and two independent healthcare institutions.\n","authors":["Henry Watkins","Robert Gray","Adam Julius","Yee-Haur Mah","Walter H. L. Pinaya","Paul Wright","Ashwani Jha","Holger Engleitner","Jorge Cardoso","Sebastien Ourselin","Geraint Rees","Rolf Jaeger","Parashkev Nachev"],"pdf_url":"https://arxiv.org/pdf/2107.10021v3.pdf","comment":"26 pages, 11 figures"},{"id":"http://arxiv.org/abs/2501.10300v1","updated":"2025-01-17T16:51:03Z","published":"2025-01-17T16:51:03Z","title":"An Ontology for Social Determinants of Education (SDoEd) based on\n  Human-AI Collaborative Approach","summary":"  The use of computational ontologies is well-established in the field of\nMedical Informatics. The topic of Social Determinants of Health (SDoH) has also\nreceived extensive attention. Work at the intersection of ontologies and SDoH\nhas been published. However, a standardized framework for Social Determinants\nof Education (SDoEd) is lacking. In this paper, we are closing the gap by\nintroducing an SDoEd ontology for creating a precise conceptualization of the\ninterplay between life circumstances of students and their possible educational\nachievements. The ontology was developed utilizing suggestions from\nChatGPT-3.5-010422 and validated using peer-reviewed research articles. The\nfirst version of developed ontology was evaluated by human experts in the field\nof education and validated using standard ontology evaluation software. This\nversion of the SDoEd ontology contains 231 domain concepts, 10 object\nproperties, and 24 data properties\n","authors":["Navya Martin Kollapally","James Geller","Patricia Morreale","Daehan Kwak"],"pdf_url":"https://arxiv.org/pdf/2501.10300v1.pdf","comment":"Accepted in CONSORTIUM FOR COMPUTING SCIENCES IN COLLEGES"},{"id":"http://arxiv.org/abs/2408.09594v2","updated":"2025-01-17T16:44:35Z","published":"2024-08-18T20:59:59Z","title":"Moonshine: Distilling Game Content Generators into Steerable Generative\n  Models","summary":"  Procedural Content Generation via Machine Learning (PCGML) has enhanced game\ncontent creation, yet challenges in controllability and limited training data\npersist. This study addresses these issues by distilling a constructive PCG\nalgorithm into a controllable PCGML model. We first generate a large amount of\ncontent with a constructive algorithm and label it using a Large Language Model\n(LLM). We use these synthetic labels to condition two PCGML models for\ncontent-specific generation, a diffusion model and the five-dollar model. This\nneural network distillation process ensures that the generation aligns with the\noriginal algorithm while introducing controllability through plain text. We\ndefine this text-conditioned PCGML as a Text-to-game-Map (T2M) task, offering\nan alternative to prevalent text-to-image multi-modal tasks. We compare our\ndistilled models with the baseline constructive algorithm. Our analysis of the\nvariety, accuracy, and quality of our generation demonstrates the efficacy of\ndistilling constructive methods into controllable text-conditioned PCGML\nmodels.\n","authors":["Yuhe Nie","Michael Middleton","Tim Merino","Nidhushan Kanagaraja","Ashutosh Kumar","Zhan Zhuang","Julian Togelius"],"pdf_url":"https://arxiv.org/pdf/2408.09594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07836v3","updated":"2025-01-17T16:35:27Z","published":"2024-01-15T17:06:02Z","title":"Two Types of AI Existential Risk: Decisive and Accumulative","summary":"  The conventional discourse on existential risks (x-risks) from AI typically\nfocuses on abrupt, dire events caused by advanced AI systems, particularly\nthose that might achieve or surpass human-level intelligence. These events have\nsevere consequences that either lead to human extinction or irreversibly\ncripple human civilization to a point beyond recovery. This discourse, however,\noften neglects the serious possibility of AI x-risks manifesting incrementally\nthrough a series of smaller yet interconnected disruptions, gradually crossing\ncritical thresholds over time. This paper contrasts the conventional \"decisive\nAI x-risk hypothesis\" with an \"accumulative AI x-risk hypothesis.\" While the\nformer envisions an overt AI takeover pathway, characterized by scenarios like\nuncontrollable superintelligence, the latter suggests a different causal\npathway to existential catastrophes. This involves a gradual accumulation of\ncritical AI-induced threats such as severe vulnerabilities and systemic erosion\nof economic and political structures. The accumulative hypothesis suggests a\nboiling frog scenario where incremental AI risks slowly converge, undermining\nsocietal resilience until a triggering event results in irreversible collapse.\nThrough systems analysis, this paper examines the distinct assumptions\ndifferentiating these two hypotheses. It is then argued that the accumulative\nview can reconcile seemingly incompatible perspectives on AI risks. The\nimplications of differentiating between these causal pathways -- the decisive\nand the accumulative -- for the governance of AI as well as long-term AI safety\nare discussed.\n","authors":["Atoosa Kasirzadeh"],"pdf_url":"https://arxiv.org/pdf/2401.07836v3.pdf","comment":"Journal article for Philosophical Studies"},{"id":"http://arxiv.org/abs/2306.12215v2","updated":"2025-01-17T16:04:05Z","published":"2023-06-21T12:15:57Z","title":"Automated Machine Learning for Remaining Useful Life Predictions","summary":"  Being able to predict the remaining useful life (RUL) of an engineering\nsystem is an important task in prognostics and health management. Recently,\ndata-driven approaches to RUL predictions are becoming prevalent over\nmodel-based approaches since no underlying physical knowledge of the\nengineering system is required. Yet, this just replaces required expertise of\nthe underlying physics with machine learning (ML) expertise, which is often\nalso not available. Automated machine learning (AutoML) promises to build\nend-to-end ML pipelines automatically enabling domain experts without ML\nexpertise to create their own models. This paper introduces AutoRUL, an\nAutoML-driven end-to-end approach for automatic RUL predictions. AutoRUL\ncombines fine-tuned standard regression methods to an ensemble with high\npredictive power. By evaluating the proposed method on eight real-world and\nsynthetic datasets against state-of-the-art hand-crafted models, we show that\nAutoML provides a viable alternative to hand-crafted data-driven RUL\npredictions. Consequently, creating RUL predictions can be made more accessible\nfor domain experts using AutoML by eliminating ML expertise from data-driven\nmodel construction.\n","authors":["Marc-André Zöller","Fabian Mauthe","Peter Zeiler","Marius Lindauer","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2306.12215v2.pdf","comment":"Manuscript accepted at IEEE SMC 2023"},{"id":"http://arxiv.org/abs/2501.10273v1","updated":"2025-01-17T16:01:05Z","published":"2025-01-17T16:01:05Z","title":"SEANN: A Domain-Informed Neural Network for Epidemiological Insights","summary":"  In epidemiology, traditional statistical methods such as logistic regression,\nlinear regression, and other parametric models are commonly employed to\ninvestigate associations between predictors and health outcomes. However,\nnon-parametric machine learning techniques, such as deep neural networks\n(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for\nthis task. Despite their potential, these methods face challenges due to the\nlimited availability of high-quality, high-quantity data in this field. To\naddress these challenges, we introduce SEANN, a novel approach for informed\nDNNs that leverages a prevalent form of domain-specific knowledge: Pooled\nEffect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,\nin different forms, and represent a quantitative form of a scientific\nconsensus. By direct integration within the learning procedure using a custom\nloss, we experimentally demonstrate significant improvements in the\ngeneralizability of predictive performances and the scientific plausibility of\nextracted relationships compared to a domain-knowledge agnostic neural network\nin a scarce and noisy data setting.\n","authors":["Jean-Baptiste Guimbaud","Marc Plantevit","Léa Maître","Rémy Cazabet"],"pdf_url":"https://arxiv.org/pdf/2501.10273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10256v1","updated":"2025-01-17T15:39:21Z","published":"2025-01-17T15:39:21Z","title":"Unsupervised Rhythm and Voice Conversion of Dysarthric to Healthy Speech\n  for ASR","summary":"  Automatic speech recognition (ASR) systems are well known to perform poorly\non dysarthric speech. Previous works have addressed this by speaking rate\nmodification to reduce the mismatch with typical speech. Unfortunately, these\napproaches rely on transcribed speech data to estimate speaking rates and\nphoneme durations, which might not be available for unseen speakers. Therefore,\nwe combine unsupervised rhythm and voice conversion methods based on\nself-supervised speech representations to map dysarthric to typical speech. We\nevaluate the outputs with a large ASR model pre-trained on healthy speech\nwithout further fine-tuning and find that the proposed rhythm conversion\nespecially improves performance for speakers of the Torgo corpus with more\nsevere cases of dysarthria. Code and audio samples are available at\nhttps://idiap.github.io/RnV .\n","authors":["Karl El Hajal","Enno Hermann","Ajinkya Kulkarni","Mathew Magimai. -Doss"],"pdf_url":"https://arxiv.org/pdf/2501.10256v1.pdf","comment":"Accepted at ICASSP 2025 Satellite Workshop: Workshop on Speech\n  Pathology Analysis and DEtection (SPADE)"},{"id":"http://arxiv.org/abs/2501.09686v2","updated":"2025-01-17T15:24:53Z","published":"2025-01-16T17:37:58Z","title":"Towards Large Reasoning Models: A Survey on Scaling LLM Reasoning\n  Capabilities","summary":"  Language has long been conceived as an essential tool for human reasoning.\nThe breakthrough of Large Language Models (LLMs) has sparked significant\nresearch interest in leveraging these models to tackle complex reasoning tasks.\nResearchers have moved beyond simple autoregressive token generation by\nintroducing the concept of \"thought\" -- a sequence of tokens representing\nintermediate steps in the reasoning process. This innovative paradigm enables\nLLMs' to mimic complex human reasoning processes, such as tree search and\nreflective thinking. Recently, an emerging trend of learning to reason has\napplied reinforcement learning (RL) to train LLMs to master reasoning\nprocesses. This approach enables the automatic generation of high-quality\nreasoning trajectories through trial-and-error search algorithms, significantly\nexpanding LLMs' reasoning capacity by providing substantially more training\ndata. Furthermore, recent studies demonstrate that encouraging LLMs to \"think\"\nwith more tokens during test-time inference can further significantly boost\nreasoning accuracy. Therefore, the train-time and test-time scaling combined to\nshow a new research frontier -- a path toward Large Reasoning Model. The\nintroduction of OpenAI's o1 series marks a significant milestone in this\nresearch direction. In this survey, we present a comprehensive review of recent\nprogress in LLM reasoning. We begin by introducing the foundational background\nof LLMs and then explore the key technical components driving the development\nof large reasoning models, with a focus on automated data construction,\nlearning-to-reason techniques, and test-time scaling. We also analyze popular\nopen-source projects at building large reasoning models, and conclude with open\nchallenges and future research directions.\n","authors":["Fengli Xu","Qianyue Hao","Zefang Zong","Jingwei Wang","Yunke Zhang","Jingyi Wang","Xiaochong Lan","Jiahui Gong","Tianjian Ouyang","Fanjin Meng","Chenyang Shao","Yuwei Yan","Qinglong Yang","Yiwen Song","Sijian Ren","Xinyuan Hu","Yu Li","Jie Feng","Chen Gao","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2501.09686v2.pdf","comment":"36 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.09274v2","updated":"2025-01-17T15:22:00Z","published":"2025-01-16T03:44:16Z","title":"Large Language Model is Secretly a Protein Sequence Optimizer","summary":"  We consider the protein sequence engineering problem, which aims to find\nprotein sequences with high fitness levels, starting from a given wild-type\nsequence. Directed evolution has been a dominating paradigm in this field which\nhas an iterative process to generate variants and select via experimental\nfeedback. We demonstrate large language models (LLMs), despite being trained on\nmassive texts, are secretly protein sequence optimizers. With a directed\nevolutionary method, LLM can perform protein engineering through Pareto and\nexperiment-budget constrained optimization, demonstrating success on both\nsynthetic and experimental fitness landscapes.\n","authors":["Yinkai Wang","Jiaxing He","Yuanqi Du","Xiaohui Chen","Jianan Canal Li","Li-Ping Liu","Xiaolin Xu","Soha Hassoun"],"pdf_url":"https://arxiv.org/pdf/2501.09274v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2403.03728v2","updated":"2025-01-17T15:15:15Z","published":"2024-03-06T14:18:24Z","title":"Bridging Diversity and Uncertainty in Active learning with\n  Self-Supervised Pre-Training","summary":"  This study addresses the integration of diversity-based and uncertainty-based\nsampling strategies in active learning, particularly within the context of\nself-supervised pre-trained models. We introduce a straightforward heuristic\ncalled TCM that mitigates the cold start problem while maintaining strong\nperformance across various data levels. By initially applying TypiClust for\ndiversity sampling and subsequently transitioning to uncertainty sampling with\nMargin, our approach effectively combines the strengths of both strategies. Our\nexperiments demonstrate that TCM consistently outperforms existing methods\nacross various datasets in both low and high data regimes.\n","authors":["Paul Doucet","Benjamin Estermann","Till Aczel","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2403.03728v2.pdf","comment":"Accepted at ICLR 2024 Workshop on Practical Machine Learning for Low\n  Resource Settings (PML4LRS)"},{"id":"http://arxiv.org/abs/2501.10243v1","updated":"2025-01-17T15:11:30Z","published":"2025-01-17T15:11:30Z","title":"Random-Key Algorithms for Optimizing Integrated Operating Room\n  Scheduling","summary":"  Efficient surgery room scheduling is essential for hospital efficiency,\npatient satisfaction, and resource utilization. This study addresses this\nchallenge by introducing a novel concept of Random-Key Optimizer (RKO),\nrigorously tested on literature and new, real-world inspired instances. Our\ncombinatorial optimization problem incorporates multi-room scheduling,\nequipment scheduling, and complex availability constraints for rooms, patients,\nand surgeons, facilitating rescheduling and enhancing operational flexibility.\nThe RKO approach represents solutions as points in a continuous space, which\nare then mapped in the problem solution space via a deterministic function\nknown as a decoder. The core idea is to operate metaheuristics and heuristics\nin the random-key space, unaware of the original solution space. We design the\nBiased Random-Key Genetic Algorithm with $Q$-Learning, Simulated Annealing, and\nIterated Local Search for use within an RKO framework, employing a single\ndecoder function. The proposed metaheuristics are complemented by lower-bound\nformulations, providing optimal gaps for evaluating the effectiveness of the\nheuristic results. Our results demonstrate significant lower and upper bounds\nimprovements for the literature instances, notably proving one optimal result.\nFurthermore, the best-proposed metaheuristic efficiently generates schedules\nfor the newly introduced instances, even in highly constrained scenarios. This\nresearch offers valuable insights and practical solutions for improving surgery\nscheduling processes, offering tangible benefits to hospitals by optimising\nresource allocation, reducing patient wait times, and enhancing overall\noperational efficiency.\n","authors":["Bruno Salezze Vieira","Eduardo Machado Silva","Antonio Augusto Chaves"],"pdf_url":"https://arxiv.org/pdf/2501.10243v1.pdf","comment":"38 pages, Preprint submitted to Applied Soft Computing"},{"id":"http://arxiv.org/abs/2501.10240v1","updated":"2025-01-17T15:09:57Z","published":"2025-01-17T15:09:57Z","title":"Challenges and recommendations for Electronic Health Records data\n  extraction and preparation for dynamic prediction modelling in hospitalized\n  patients -- a practical guide","summary":"  Dynamic predictive modeling using electronic health record (EHR) data has\ngained significant attention in recent years. The reliability and\ntrustworthiness of such models depend heavily on the quality of the underlying\ndata, which is largely determined by the stages preceding the model\ndevelopment: data extraction from EHR systems and data preparation. We list\nover forty challenges encountered during these stages and provide actionable\nrecommendations for addressing them. These challenges are organized into four\ncategories: cohort definition, outcome definition, feature engineering, and\ndata cleaning. This list is designed to serve as a practical guide for data\nextraction engineers and researchers, supporting better practices and improving\nthe quality and real-world applicability of dynamic prediction models in\nclinical settings.\n","authors":["Elena Albu","Shan Gao","Pieter Stijnen","Frank E. Rademakers","Bas C T van Bussel","Taya Collyer","Tina Hernandez-Boussard","Laure Wynants","Ben Van Calster"],"pdf_url":"https://arxiv.org/pdf/2501.10240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.11414v3","updated":"2025-01-17T15:08:47Z","published":"2023-12-18T18:18:10Z","title":"The Animal-AI Environment: A Virtual Laboratory For Comparative\n  Cognition and Artificial Intelligence Research","summary":"  The Animal-AI Environment is a unique game-based research platform designed\nto facilitate collaboration between the artificial intelligence and comparative\ncognition research communities. In this paper, we present the latest version of\nthe Animal-AI Environment, outlining several major features that make the game\nmore engaging for humans and more complex for AI systems. These features\ninclude interactive buttons, reward dispensers, and player notifications, as\nwell as an overhaul of the environment's graphics and processing for\nsignificant improvements in agent training time and quality of the human player\nexperience. We provide detailed guidance on how to build computational and\nbehavioural experiments with the Animal-AI Environment. We present results from\na series of agents, including the state-of-the-art deep reinforcement learning\nagent Dreamer-v3, on newly designed tests and the Animal-AI Testbed of 900\ntasks inspired by research in the field of comparative cognition. The Animal-AI\nEnvironment offers a new approach for modelling cognition in humans and\nnon-human animals, and for building biologically inspired artificial\nintelligence.\n","authors":["Konstantinos Voudouris","Ibrahim Alhas","Wout Schellaert","Matteo G. Mecattaf","Ben Slater","Matthew Crosby","Joel Holmes","John Burden","Niharika Chaubey","Niall Donnelly","Matishalin Patel","Marta Halina","José Hernández-Orallo","Lucy G. Cheke"],"pdf_url":"https://arxiv.org/pdf/2312.11414v3.pdf","comment":"37 pages, 16 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.13780v2","updated":"2025-01-17T14:26:37Z","published":"2024-10-17T17:19:48Z","title":"Optimal Quantization for Matrix Multiplication","summary":"  Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|\\bar{A}\\|_F, \\|\\bar{B}\\|_F$ and\n$\\|\\bar{A}^\\top \\bar{B}\\|_F$, where $\\bar{A},\\bar{B}$ are versions of $A,B$\nwith zero-centered columns, respectively. For iid Gaussian matrices our\nquantizer achieves the lower bound and is, thus, asymptotically optimal. A\npractical low-complexity version of our quantizer achieves performance quite\nclose to optimal. In addition, we derive rate-distortion function for matrix\nmultiplication of iid Gaussian matrices, which exhibits an interesting\nphase-transition at $R\\approx 0.906$ bit/entry.\n","authors":["Or Ordentlich","Yury Polyanskiy"],"pdf_url":"https://arxiv.org/pdf/2410.13780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10733v5","updated":"2025-01-17T14:22:06Z","published":"2024-10-14T17:15:07Z","title":"Deep Compression Autoencoder for Efficient High-Resolution Diffusion\n  Models","summary":"  We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder\nmodels for accelerating high-resolution diffusion models. Existing autoencoder\nmodels have demonstrated impressive results at a moderate spatial compression\nratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for\nhigh spatial compression ratios (e.g., 64x). We address this challenge by\nintroducing two key techniques: (1) Residual Autoencoding, where we design our\nmodels to learn residuals based on the space-to-channel transformed features to\nalleviate the optimization difficulty of high spatial-compression autoencoders;\n(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases\ntraining strategy for mitigating the generalization penalty of high\nspatial-compression autoencoders. With these designs, we improve the\nautoencoder's spatial compression ratio up to 128 while maintaining the\nreconstruction quality. Applying our DC-AE to latent diffusion models, we\nachieve significant speedup without accuracy drop. For example, on ImageNet\n512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup\non H100 GPU for UViT-H while achieving a better FID, compared with the widely\nused SD-VAE-f8 autoencoder. Our code is available at\nhttps://github.com/mit-han-lab/efficientvit.\n","authors":["Junyu Chen","Han Cai","Junsong Chen","Enze Xie","Shang Yang","Haotian Tang","Muyang Li","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2410.10733v5.pdf","comment":"Preprint. First two authors contributed equally to this work. Update:\n  fix typo"},{"id":"http://arxiv.org/abs/2501.10190v1","updated":"2025-01-17T13:37:58Z","published":"2025-01-17T13:37:58Z","title":"Temporal Causal Reasoning with (Non-Recursive) Structural Equation\n  Models","summary":"  Structural Equation Models (SEM) are the standard approach to representing\ncausal dependencies between variables in causal models. In this paper we\npropose a new interpretation of SEMs when reasoning about Actual Causality, in\nwhich SEMs are viewed as mechanisms transforming the dynamics of exogenous\nvariables into the dynamics of endogenous variables. This allows us to combine\ncounterfactual causal reasoning with existing temporal logic formalisms, and to\nintroduce a temporal logic, CPLTL, for causal reasoning about such structures.\nWe show that the standard restriction to so-called \\textit{recursive} models\n(with no cycles in the dependency graph) is not necessary in our approach,\nallowing us to reason about mutually dependent processes and feedback loops.\nFinally, we introduce new notions of model equivalence for temporal causal\nmodels, and show that CPLTL has an efficient model-checking procedure.\n","authors":["Maksim Gladyshev","Natasha Alechina","Mehdi Dastani","Dragan Doder","Brian Logan"],"pdf_url":"https://arxiv.org/pdf/2501.10190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10187v1","updated":"2025-01-17T13:32:28Z","published":"2025-01-17T13:32:28Z","title":"Good things come in small packages: Should we adopt Lite-GPUs in AI\n  infrastructure?","summary":"  To match the blooming demand of generative AI workloads, GPU designers have\nso far been trying to pack more and more compute and memory into single complex\nand expensive packages. However, there is growing uncertainty about the\nscalability of individual GPUs and thus AI clusters, as state-of-the-art GPUs\nare already displaying packaging, yield, and cooling limitations. We propose to\nrethink the design and scaling of AI clusters through efficiently-connected\nlarge clusters of Lite-GPUs, GPUs with single, small dies and a fraction of the\ncapabilities of larger GPUs. We think recent advances in co-packaged optics can\nbe key in overcoming the communication challenges of distributing AI workloads\nonto more Lite-GPUs. In this paper, we present the key benefits of Lite-GPUs on\nmanufacturing cost, blast radius, yield, and power efficiency; and discuss\nsystems opportunities and challenges around resource, workload, memory, and\nnetwork management.\n","authors":["Burcu Canakci","Junyi Liu","Xingbo Wu","Nathanaël Cheriere","Paolo Costa","Sergey Legtchenko","Dushyanth Narayanan","Ant Rowstron"],"pdf_url":"https://arxiv.org/pdf/2501.10187v1.pdf","comment":"5+ pages, 4 figures"},{"id":"http://arxiv.org/abs/2501.10186v1","updated":"2025-01-17T13:32:19Z","published":"2025-01-17T13:32:19Z","title":"Generative Artificial Intelligence: Implications for Biomedical and\n  Health Professions Education","summary":"  Generative AI has had a profound impact on biomedicine and health, both in\nprofessional work and in education. Based on large language models (LLMs),\ngenerative AI has been found to perform as well as humans in simulated\nsituations taking medical board exams, answering clinical questions, solving\nclinical cases, applying clinical reasoning, and summarizing information.\nGenerative AI is also being used widely in education, performing well in\nacademic courses and their assessments. This review summarizes the successes of\nLLMs and highlights some of their challenges in the context of education, most\nnotably aspects that may undermines the acquisition of knowledge and skills for\nprofessional work. It then provides recommendations for best practices\novercoming shortcomings for LLM use in education. Although there are challenges\nfor use of generative AI in education, all students and faculty, in biomedicine\nand health and beyond, must have understanding and be competent in its use.\n","authors":["William Hersh"],"pdf_url":"https://arxiv.org/pdf/2501.10186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.13309v2","updated":"2025-01-17T13:28:01Z","published":"2023-12-20T04:35:00Z","title":"Generate E-commerce Product Background by Integrating Category\n  Commonality and Personalized Style","summary":"  The state-of-the-art methods for e-commerce product background generation\nsuffer from the inefficiency of designing product-wise prompts when scaling up\nthe production, as well as the ineffectiveness of describing fine-grained\nstyles when customizing personalized backgrounds for some specific brands. To\naddress these obstacles, we integrate the category commonality and personalized\nstyle into diffusion models. Concretely, we propose a Category-Wise Generator\nto enable large-scale background generation with only one model for the first\ntime. A unique identifier in the prompt is assigned to each category, whose\nattention is located on the background by a mask-guided cross attention layer\nto learn the category-wise style. Furthermore, for products with specific and\nfine-grained requirements in layout, elements, etc, a Personality-Wise\nGenerator is devised to learn such personalized style directly from a reference\nimage to resolve textual ambiguities, and is trained in a self-supervised\nmanner for more efficient training data usage. To advance research in this\nfield, the first large-scale e-commerce product background generation dataset\nBG60k is constructed, which covers more than 60k product images from over 2k\ncategories. Experiments demonstrate that our method could generate high-quality\nbackgrounds for different categories, and maintain the personalized background\nstyle of reference images. BG60k will be available at\n\\url{https://github.com/Whileherham/BG60k}.\n","authors":["Haohan Wang","Wei Feng","Yaoyu Li","Zheng Zhang","Jingjing Lv","Junjie Shen","Zhangang Lin","Jingping Shao"],"pdf_url":"https://arxiv.org/pdf/2312.13309v2.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.10179v1","updated":"2025-01-17T13:24:13Z","published":"2025-01-17T13:24:13Z","title":"A Simple but Effective Closed-form Solution for Extreme Multi-label\n  Learning","summary":"  Extreme multi-label learning (XML) is a task of assigning multiple labels\nfrom an extremely large set of labels to each data instance. Many current\nhigh-performance XML models are composed of a lot of hyperparameters, which\ncomplicates the tuning process. Additionally, the models themselves are adapted\nspecifically to XML, which complicates their reimplementation. To remedy this\nproblem, we propose a simple method based on ridge regression for XML. The\nproposed method not only has a closed-form solution but also is composed of a\nsingle hyperparameter. Since there are no precedents on applying ridge\nregression to XML, this paper verified the performance of the method by using\nvarious XML benchmark datasets. Furthermore, we enhanced the prediction of\nlow-frequency labels in XML, which hold informative content. This prediction is\nessential yet challenging because of the limited amount of data. Here, we\nemployed a simple frequency-based weighting. This approach greatly simplifies\nthe process compared with existing techniques. Experimental results revealed\nthat it can achieve levels of performance comparable to, or even exceeding,\nthose of models with numerous hyperparameters. Additionally, we found that the\nfrequency-based weighting significantly improved the predictive performance for\nlow-frequency labels, while requiring almost no changes in implementation. The\nsource code for the proposed method is available on github at\nhttps://github.com/cars1015/XML-ridge.\n","authors":["Kazuma Onishi","Katsuhiko Hayashi"],"pdf_url":"https://arxiv.org/pdf/2501.10179v1.pdf","comment":"10pages, Accepted at ECIR25"},{"id":"http://arxiv.org/abs/2501.10160v1","updated":"2025-01-17T12:48:48Z","published":"2025-01-17T12:48:48Z","title":"CSSDM Ontology to Enable Continuity of Care Data Interoperability","summary":"  The rapid advancement of digital technologies and recent global pandemic\nscenarios have led to a growing focus on how these technologies can enhance\nhealthcare service delivery and workflow to address crises. Action plans that\nconsolidate existing digital transformation programs are being reviewed to\nestablish core infrastructure and foundations for sustainable healthcare\nsolutions. Reforming health and social care to personalize home care, for\nexample, can help avoid treatment in overcrowded acute hospital settings and\nimprove the experiences and outcomes for both healthcare professionals and\nservice users. In this information-intensive domain, addressing the\ninteroperability challenge through standards-based roadmaps is crucial for\nenabling effective connections between health and social care services. This\napproach facilitates safe and trustworthy data workflows between different\nhealthcare system providers. In this paper, we present a methodology for\nextracting, transforming, and loading data through a semi-automated process\nusing a Common Semantic Standardized Data Model (CSSDM) to create personalized\nhealthcare knowledge graph (KG). The CSSDM is grounded in the formal ontology\nof ISO 13940 ContSys and incorporates FHIR-based specifications to support\nstructural attributes for generating KGs. We propose that the CSSDM facilitates\ndata harmonization and linking, offering an alternative approach to\ninteroperability. This approach promotes a novel form of collaboration between\ncompanies developing health information systems and cloud-enabled health\nservices. Consequently, it provides multiple stakeholders with access to\nhigh-quality data and information sharing.\n","authors":["Subhashis Das","Debashis Naskar","Sara Rodriguez Gonzalez","Pamela Hussey"],"pdf_url":"https://arxiv.org/pdf/2501.10160v1.pdf","comment":"6 pages, 5 figures, Published in: 2024 IEEE International Conference\n  on Bioinformatics and Biomedicine (BIBM)"},{"id":"http://arxiv.org/abs/2501.10153v1","updated":"2025-01-17T12:24:28Z","published":"2025-01-17T12:24:28Z","title":"Region-wise stacking ensembles for estimating brain-age using MRI","summary":"  Predictive modeling using structural magnetic resonance imaging (MRI) data is\na prominent approach to study brain-aging. Machine learning algorithms and\nfeature extraction methods have been employed to improve predictions and\nexplore healthy and accelerated aging e.g. neurodegenerative and psychiatric\ndisorders. The high-dimensional MRI data pose challenges to building\ngeneralizable and interpretable models as well as for data privacy. Common\npractices are resampling or averaging voxels within predefined parcels, which\nreduces anatomical specificity and biological interpretability as voxels within\na region may differently relate to aging. Effectively, naive fusion by\naveraging can result in information loss and reduced accuracy. We present a\nconceptually novel two-level stacking ensemble (SE) approach. The first level\ncomprises regional models for predicting individuals' age based on voxel-wise\ninformation, fused by a second-level model yielding final predictions. Eight\ndata fusion scenarios were explored using as input Gray matter volume (GMV)\nestimates from four datasets covering the adult lifespan. Performance, measured\nusing mean absolute error (MAE), R2, correlation and prediction bias, showed\nthat SE outperformed the region-wise averages. The best performance was\nobtained when first-level regional predictions were obtained as out-of-sample\npredictions on the application site with second-level models trained on\nindependent and site-specific data (MAE=4.75 vs baseline regional mean GMV\nMAE=5.68). Performance improved as more datasets were used for training.\nFirst-level predictions showed improved and more robust aging signal providing\nnew biological insights and enhanced data privacy. Overall, the SE improves\naccuracy compared to the baseline while preserving or enhancing data privacy.\n","authors":["Georgios Antonopoulos","Shammi More","Simon B. Eickhoff","Federico Raimondo","Kaustubh R. Patil"],"pdf_url":"https://arxiv.org/pdf/2501.10153v1.pdf","comment":"version1"},{"id":"http://arxiv.org/abs/2501.10151v1","updated":"2025-01-17T12:23:42Z","published":"2025-01-17T12:23:42Z","title":"Topology-Driven Attribute Recovery for Attribute Missing Graph Learning\n  in Social Internet of Things","summary":"  With the advancement of information technology, the Social Internet of Things\n(SIoT) has fostered the integration of physical devices and social networks,\ndeepening the study of complex interaction patterns. Text Attribute Graphs\n(TAGs) capture both topological structures and semantic attributes, enhancing\nthe analysis of complex interactions within the SIoT. However, existing graph\nlearning methods are typically designed for complete attributed graphs, and the\ncommon issue of missing attributes in Attribute Missing Graphs (AMGs) increases\nthe difficulty of analysis tasks. To address this, we propose the\nTopology-Driven Attribute Recovery (TDAR) framework, which leverages\ntopological data for AMG learning. TDAR introduces an improved pre-filling\nmethod for initial attribute recovery using native graph topology.\nAdditionally, it dynamically adjusts propagation weights and incorporates\nhomogeneity strategies within the embedding space to suit AMGs' unique\ntopological structures, effectively reducing noise during information\npropagation. Extensive experiments on public datasets demonstrate that TDAR\nsignificantly outperforms state-of-the-art methods in attribute reconstruction\nand downstream tasks, offering a robust solution to the challenges posed by\nAMGs. The code is available at https://github.com/limengran98/TDAR.\n","authors":["Mengran Li","Junzhou Chen","Chenyun Yu","Guanying Jiang","Ronghui Zhang","Yanming Shen","Houbing Herbert Song"],"pdf_url":"https://arxiv.org/pdf/2501.10151v1.pdf","comment":"Accepted by IEEE Internet of Things Journal"},{"id":"http://arxiv.org/abs/2501.10150v1","updated":"2025-01-17T12:23:30Z","published":"2025-01-17T12:23:30Z","title":"Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair\n  Language Modeling and Translation","summary":"  Mitigation of biases, such as language models' reliance on gender\nstereotypes, is a crucial endeavor required for the creation of reliable and\nuseful language technology. The crucial aspect of debiasing is to ensure that\nthe models preserve their versatile capabilities, including their ability to\nsolve language tasks and equitably represent various genders. To address this\nissue, we introduce a streamlined Dual Dabiasing Algorithm through Model\nAdaptation (2DAMA). Novel Dual Debiasing enables robust reduction of\nstereotypical bias while preserving desired factual gender information encoded\nby language models. We show that 2DAMA effectively reduces gender bias in\nEnglish and is one of the first approaches facilitating the mitigation of\nstereotypical tendencies in translation. The proposed method's key advantage is\nthe preservation of factual gender cues, which are useful in a wide range of\nnatural language processing tasks.\n","authors":["Tomasz Limisiewicz","David Mareček","Tomáš Musil"],"pdf_url":"https://arxiv.org/pdf/2501.10150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12634v2","updated":"2025-01-17T12:19:05Z","published":"2024-06-18T14:01:53Z","title":"News Without Borders: Domain Adaptation of Multilingual Sentence\n  Embeddings for Cross-lingual News Recommendation","summary":"  Rapidly growing numbers of multilingual news consumers pose an increasing\nchallenge to news recommender systems in terms of providing customized\nrecommendations. First, existing neural news recommenders, even when powered by\nmultilingual language models (LMs), suffer substantial performance losses in\nzero-shot cross-lingual transfer (ZS-XLT). Second, the current paradigm of\nfine-tuning the backbone LM of a neural recommender on task-specific data is\ncomputationally expensive and infeasible in few-shot recommendation and\ncold-start setups, where data is scarce or completely unavailable. In this\nwork, we propose a news-adapted sentence encoder (NaSE), domain-specialized\nfrom a pretrained massively multilingual sentence encoder (SE). To this end, we\nconstruct and leverage PolyNews and PolyNewsParallel, two multilingual\nnews-specific corpora. With the news-adapted multilingual SE in place, we test\nthe effectiveness of (i.e., question the need for) supervised fine-tuning for\nnews recommendation, and propose a simple and strong baseline based on (i)\nfrozen NaSE embeddings and (ii) late click-behavior fusion. We show that NaSE\nachieves state-of-the-art performance in ZS-XLT in true cold-start and few-shot\nnews recommendation.\n","authors":["Andreea Iana","Fabian David Schmidt","Goran Glavaš","Heiko Paulheim"],"pdf_url":"https://arxiv.org/pdf/2406.12634v2.pdf","comment":"Accepted at the 47th European Conference on Information Retrieval\n  (ECIR 2025) Appendix A is provided only in the arXiv version"},{"id":"http://arxiv.org/abs/2412.18836v2","updated":"2025-01-17T12:18:44Z","published":"2024-12-25T08:49:43Z","title":"MRI2Speech: Speech Synthesis from Articulatory Movements Recorded by\n  Real-time MRI","summary":"  Previous real-time MRI (rtMRI)-based speech synthesis models depend heavily\non noisy ground-truth speech. Applying loss directly over ground truth\nmel-spectrograms entangles speech content with MRI noise, resulting in poor\nintelligibility. We introduce a novel approach that adapts the multi-modal\nself-supervised AV-HuBERT model for text prediction from rtMRI and incorporates\na new flow-based duration predictor for speaker-specific alignment. The\npredicted text and durations are then used by a speech decoder to synthesize\naligned speech in any novel voice. We conduct thorough experiments on two\ndatasets and demonstrate our method's generalization ability to unseen\nspeakers. We assess our framework's performance by masking parts of the rtMRI\nvideo to evaluate the impact of different articulators on text prediction. Our\nmethod achieves a $15.18\\%$ Word Error Rate (WER) on the USC-TIMIT MRI corpus,\nmarking a huge improvement over the current state-of-the-art. Speech samples\nare available at https://mri2speech.github.io/MRI2Speech/\n","authors":["Neil Shah","Ayan Kashyap","Shirish Karande","Vineet Gandhi"],"pdf_url":"https://arxiv.org/pdf/2412.18836v2.pdf","comment":"Accepted at IEEE ICASSP 2025"},{"id":"http://arxiv.org/abs/2409.10048v2","updated":"2025-01-17T12:12:28Z","published":"2024-09-16T07:20:33Z","title":"Audio-Driven Reinforcement Learning for Head-Orientation in Naturalistic\n  Environments","summary":"  Although deep reinforcement learning (DRL) approaches in audio signal\nprocessing have seen substantial progress in recent years, audio-driven DRL for\ntasks such as navigation, gaze control and head-orientation control in the\ncontext of human-robot interaction have received little attention. Here, we\npropose an audio-driven DRL framework in which we utilise deep Q-learning to\ndevelop an autonomous agent that orients towards a talker in the acoustic\nenvironment based on stereo speech recordings. Our results show that the agent\nlearned to perform the task at a near perfect level when trained on speech\nsegments in anechoic environments (that is, without reverberation). The\npresence of reverberation in naturalistic acoustic environments affected the\nagent's performance, although the agent still substantially outperformed a\nbaseline, randomly acting agent. Finally, we quantified the degree of\ngeneralization of the proposed DRL approach across naturalistic acoustic\nenvironments. Our experiments revealed that policies learned by agents trained\non medium or high reverb environments generalized to low reverb environments,\nbut policies learned by agents trained on anechoic or low reverb environments\ndid not generalize to medium or high reverb environments. Taken together, this\nstudy demonstrates the potential of audio-driven DRL for tasks such as\nhead-orientation control and highlights the need for training strategies that\nenable robust generalization across environments for real-world audio-driven\nDRL applications.\n","authors":["Wessel Ledder","Yuzhen Qin","Kiki van der Heijden"],"pdf_url":"https://arxiv.org/pdf/2409.10048v2.pdf","comment":"Accepted at ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.10141v1","updated":"2025-01-17T12:05:24Z","published":"2025-01-17T12:05:24Z","title":"Enhancing UAV Path Planning Efficiency Through Accelerated Learning","summary":"  Unmanned Aerial Vehicles (UAVs) are increasingly essential in various fields\nsuch as surveillance, reconnaissance, and telecommunications. This study aims\nto develop a learning algorithm for the path planning of UAV wireless\ncommunication relays, which can reduce storage requirements and accelerate Deep\nReinforcement Learning (DRL) convergence. Assuming the system possesses terrain\nmaps of the area and can estimate user locations using localization algorithms\nor direct GPS reporting, it can input these parameters into the learning\nalgorithms to achieve optimized path planning performance. However, higher\nresolution terrain maps are necessary to extract topological information such\nas terrain height, object distances, and signal blockages. This requirement\nincreases memory and storage demands on UAVs while also lengthening convergence\ntimes in DRL algorithms. Similarly, defining the telecommunication coverage map\nin UAV wireless communication relays using these terrain maps and user position\nestimations demands higher memory and storage utilization for the learning path\nplanning algorithms. Our approach reduces path planning training time by\napplying a dimensionality reduction technique based on Principal Component\nAnalysis (PCA), sample combination, Prioritized Experience Replay (PER), and\nthe combination of Mean Squared Error (MSE) and Mean Absolute Error (MAE) loss\ncalculations in the coverage map estimates, thereby enhancing a Twin Delayed\nDeep Deterministic Policy Gradient (TD3) algorithm. The proposed solution\nreduces the convergence episodes needed for basic training by approximately\nfour times compared to the traditional TD3.\n","authors":["Joseanne Viana","Boris Galkin","Lester Ho","Holger Claussen"],"pdf_url":"https://arxiv.org/pdf/2501.10141v1.pdf","comment":"This paper was accepted in https://camad2024.ieee-camad.org/\n  conference but it is not available from the conference yet"},{"id":"http://arxiv.org/abs/2501.10139v1","updated":"2025-01-17T12:01:56Z","published":"2025-01-17T12:01:56Z","title":"Conformal Prediction Sets with Improved Conditional Coverage using Trust\n  Scores","summary":"  Standard conformal prediction offers a marginal guarantee on coverage, but\nfor prediction sets to be truly useful, they should ideally ensure coverage\nconditional on each test point. Unfortunately, it is impossible to achieve\nexact, distribution-free conditional coverage in finite samples. In this work,\nwe propose an alternative conformal prediction algorithm that targets coverage\nwhere it matters most--in instances where a classifier is overconfident in its\nincorrect predictions. We start by dissecting miscoverage events in\nmarginally-valid conformal prediction, and show that miscoverage rates vary\nbased on the classifier's confidence and its deviation from the Bayes optimal\nclassifier. Motivated by this insight, we develop a variant of conformal\nprediction that targets coverage conditional on a reduced set of two variables:\nthe classifier's confidence in a prediction and a nonparametric trust score\nthat measures its deviation from the Bayes classifier. Empirical evaluation on\nmultiple image datasets shows that our method generally improves conditional\ncoverage properties compared to standard conformal prediction, including\nclass-conditional coverage, coverage over arbitrary subgroups, and coverage\nover demographic groups.\n","authors":["Jivat Neet Kaur","Michael I. Jordan","Ahmed Alaa"],"pdf_url":"https://arxiv.org/pdf/2501.10139v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02957v3","updated":"2025-01-17T11:59:23Z","published":"2024-05-05T14:53:51Z","title":"Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents","summary":"  The recent rapid development of large language models (LLMs) has sparked a\nnew wave of technological revolution in medical artificial intelligence (AI).\nWhile LLMs are designed to understand and generate text like a human,\nautonomous agents that utilize LLMs as their \"brain\" have exhibited\ncapabilities beyond text processing such as planning, reflection, and using\ntools by enabling their \"bodies\" to interact with the environment. We introduce\na simulacrum of hospital called Agent Hospital that simulates the entire\nprocess of treating illness, in which all patients, nurses, and doctors are\nLLM-powered autonomous agents. Within the simulacrum, doctor agents are able to\nevolve by treating a large number of patient agents without the need to label\ntraining data manually. After treating tens of thousands of patient agents in\nthe simulacrum (human doctors may take several years in the real world), the\nevolved doctor agents outperform state-of-the-art medical agent methods on the\nMedQA benchmark comprising US Medical Licensing Examination (USMLE) test\nquestions. Our methods of simulacrum construction and agent evolution have the\npotential in benefiting a broad range of applications beyond medical AI.\n","authors":["Junkai Li","Yunghwei Lai","Weitao Li","Jingyi Ren","Meng Zhang","Xinhui Kang","Siyu Wang","Peng Li","Ya-Qin Zhang","Weizhi Ma","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2405.02957v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10134v1","updated":"2025-01-17T11:49:49Z","published":"2025-01-17T11:49:49Z","title":"Exploring the Impact of Generative Artificial Intelligence in Education:\n  A Thematic Analysis","summary":"  The recent advancements in Generative Artificial intelligence (GenAI)\ntechnology have been transformative for the field of education. Large Language\nModels (LLMs) such as ChatGPT and Bard can be leveraged to automate boilerplate\ntasks, create content for personalised teaching, and handle repetitive tasks to\nallow more time for creative thinking. However, it is important to develop\nguidelines, policies, and assessment methods in the education sector to ensure\nthe responsible integration of these tools. In this article, thematic analysis\nhas been performed on seven essays obtained from professionals in the education\nsector to understand the advantages and pitfalls of using GenAI models such as\nChatGPT and Bard in education. Exploratory Data Analysis (EDA) has been\nperformed on the essays to extract further insights from the text. The study\nfound several themes which highlight benefits and drawbacks of GenAI tools, as\nwell as suggestions to overcome these limitations and ensure that students are\nusing these tools in a responsible and ethical manner.\n","authors":["Abhishek Kaushik","Sargam Yadav","Andrew Browne","David Lillis","David Williams","Jack Mc Donnell","Peadar Grant","Siobhan Connolly Kernan","Shubham Sharma","Mansi Arora"],"pdf_url":"https://arxiv.org/pdf/2501.10134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07629v3","updated":"2025-01-17T11:37:04Z","published":"2024-12-10T16:08:14Z","title":"Piece of Table: A Divide-and-Conquer Approach for Selecting Sub-Tables\n  in Table Question Answering","summary":"  Applying language models (LMs) to tables is challenging due to the inherent\nstructural differences between two-dimensional tables and one-dimensional text\nfor which the LMs were originally designed. Furthermore, when applying\nlinearized tables to LMs, the maximum token lengths often imposed in\nself-attention calculations make it difficult to comprehensively understand the\ncontext spread across large tables. To address these challenges, we present\nPieTa (Piece of Table), a new framework for sub-table-based question answering\n(QA). PieTa operates through an iterative process of dividing tables into\nsmaller windows, using LMs to select relevant cells within each window, and\nmerging these cells into a sub-table. This multi-resolution approach captures\ndependencies across multiple rows and columns while avoiding the limitations\ncaused by long context inputs. Instantiated as a simple iterative sub-table\nunion algorithm, PieTa demonstrates improved performance over previous\nsub-table-based QA approaches.\n","authors":["Wonjin Lee","Kyumin Kim","Sungjae Lee","Jihun Lee","Kwang In Kim"],"pdf_url":"https://arxiv.org/pdf/2412.07629v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10129v1","updated":"2025-01-17T11:36:38Z","published":"2025-01-17T11:36:38Z","title":"Spatio-temporal Graph Learning on Adaptive Mined Key Frames for\n  High-performance Multi-Object Tracking","summary":"  In the realm of multi-object tracking, the challenge of accurately capturing\nthe spatial and temporal relationships between objects in video sequences\nremains a significant hurdle. This is further complicated by frequent\noccurrences of mutual occlusions among objects, which can lead to tracking\nerrors and reduced performance in existing methods. Motivated by these\nchallenges, we propose a novel adaptive key frame mining strategy that\naddresses the limitations of current tracking approaches. Specifically, we\nintroduce a Key Frame Extraction (KFE) module that leverages reinforcement\nlearning to adaptively segment videos, thereby guiding the tracker to exploit\nthe intrinsic logic of the video content. This approach allows us to capture\nstructured spatial relationships between different objects as well as the\ntemporal relationships of objects across frames. To tackle the issue of object\nocclusions, we have developed an Intra-Frame Feature Fusion (IFF) module.\nUnlike traditional graph-based methods that primarily focus on inter-frame\nfeature fusion, our IFF module uses a Graph Convolutional Network (GCN) to\nfacilitate information exchange between the target and surrounding objects\nwithin a frame. This innovation significantly enhances target\ndistinguishability and mitigates tracking loss and appearance similarity due to\nocclusions. By combining the strengths of both long and short trajectories and\nconsidering the spatial relationships between objects, our proposed tracker\nachieves impressive results on the MOT17 dataset, i.e., 68.6 HOTA, 81.0 IDF1,\n66.6 AssA, and 893 IDS, proving its effectiveness and accuracy.\n","authors":["Futian Wang","Fengxiang Liu","Xiao Wang"],"pdf_url":"https://arxiv.org/pdf/2501.10129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00900v3","updated":"2025-01-17T11:18:37Z","published":"2023-09-02T10:32:53Z","title":"Large Process Models: A Vision for Business Process Management in the\n  Age of Generative AI","summary":"  The continued success of Large Language Models (LLMs) and other generative\nartificial intelligence approaches highlights the advantages that large\ninformation corpora can have over rigidly defined symbolic models, but also\nserves as a proof-point of the challenges that purely statistics-based\napproaches have in terms of safety and trustworthiness. As a framework for\ncontextualizing the potential, as well as the limitations of LLMs and other\nfoundation model-based technologies, we propose the concept of a Large Process\nModel (LPM) that combines the correlation power of LLMs with the analytical\nprecision and reliability of knowledge-based systems and automated reasoning\napproaches. LPMs are envisioned to directly utilize the wealth of process\nmanagement experience that experts have accumulated, as well as process\nperformance data of organizations with diverse characteristics, e.g.,\\\nregarding size, region, or industry. In this vision, the proposed LPM would\nallow organizations to receive context-specific (tailored) process and other\nbusiness models, analytical deep-dives, and improvement recommendations. As\nsuch, they would allow to substantially decrease the time and effort required\nfor business transformation, while also allowing for deeper, more impactful,\nand more actionable insights than previously possible. We argue that\nimplementing an LPM is feasible, but also highlight limitations and research\nchallenges that need to be solved to implement particular aspects of the LPM\nvision.\n","authors":["Timotheus Kampik","Christian Warmuth","Adrian Rebmann","Ron Agam","Lukas N. P. Egger","Andreas Gerber","Johannes Hoffart","Jonas Kolk","Philipp Herzig","Gero Decker","Han van der Aa","Artem Polyvyanyy","Stefanie Rinderle-Ma","Ingo Weber","Matthias Weidlich"],"pdf_url":"https://arxiv.org/pdf/2309.00900v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12750v2","updated":"2025-01-17T11:10:05Z","published":"2024-05-21T13:02:27Z","title":"Generative AI in Cybersecurity: A Comprehensive Review of LLM\n  Applications and Vulnerabilities","summary":"  This paper provides a comprehensive review of the future of cybersecurity\nthrough Generative AI and Large Language Models (LLMs). We explore LLM\napplications across various domains, including hardware design security,\nintrusion detection, software engineering, design verification, cyber threat\nintelligence, malware detection, and phishing detection. We present an overview\nof LLM evolution and its current state, focusing on advancements in models such\nas GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends\nto LLM vulnerabilities, such as prompt injection, insecure output handling,\ndata poisoning, DDoS attacks, and adversarial instructions. We delve into\nmitigation strategies to protect these models, providing a comprehensive look\nat potential attack scenarios and prevention techniques. Furthermore, we\nevaluate the performance of 42 LLM models in cybersecurity knowledge and\nhardware security, highlighting their strengths and weaknesses. We thoroughly\nevaluate cybersecurity datasets for LLM training and testing, covering the\nlifecycle from data creation to usage and identifying gaps for future research.\nIn addition, we review new strategies for leveraging LLMs, including techniques\nlike Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human\nFeedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank\nAdapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim\nto enhance real-time cybersecurity defenses and improve the sophistication of\nLLM applications in threat detection and response. Our paper provides a\nfoundational understanding and strategic direction for integrating LLMs into\nfuture cybersecurity frameworks, emphasizing innovation and robust model\ndeployment to safeguard against evolving cyber threats.\n","authors":["Mohamed Amine Ferrag","Fatima Alwahedi","Ammar Battah","Bilel Cherif","Abdechakour Mechri","Norbert Tihanyi","Tamas Bisztray","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2405.12750v2.pdf","comment":"52 pages, 8 figures"},{"id":"http://arxiv.org/abs/2501.07888v2","updated":"2025-01-17T11:06:34Z","published":"2025-01-14T06:54:39Z","title":"Tarsier2: Advancing Large Vision-Language Models from Detailed Video\n  Description to Comprehensive Video Understanding","summary":"  We introduce Tarsier2, a state-of-the-art large vision-language model (LVLM)\ndesigned for generating detailed and accurate video descriptions, while also\nexhibiting superior general video understanding capabilities. Tarsier2 achieves\nsignificant advancements through three key upgrades: (1) Scaling pre-training\ndata from 11M to 40M video-text pairs, enriching both volume and diversity; (2)\nPerforming fine-grained temporal alignment during supervised fine-tuning; (3)\nUsing model-based sampling to automatically construct preference data and\napplying DPO training for optimization. Extensive experiments show that\nTarsier2-7B consistently outperforms leading proprietary models, including\nGPT-4o and Gemini 1.5 Pro, in detailed video description tasks. On the DREAM-1K\nbenchmark, Tarsier2-7B improves F1 by 2.8\\% over GPT-4o and 5.8\\% over\nGemini-1.5-Pro. In human side-by-side evaluations, Tarsier2-7B shows a +8.6\\%\nperformance advantage over GPT-4o and +24.9\\% over Gemini-1.5-Pro. Tarsier2-7B\nalso sets new state-of-the-art results across 15 public benchmarks, spanning\ntasks such as video question-answering, video grounding, hallucination test,\nand embodied question-answering, demonstrating its versatility as a robust\ngeneralist vision-language model.\n","authors":["Liping Yuan","Jiawei Wang","Haomiao Sun","Yuchen Zhang","Yuan Lin"],"pdf_url":"https://arxiv.org/pdf/2501.07888v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10662v4","updated":"2025-01-17T11:02:03Z","published":"2024-07-15T12:25:49Z","title":"XEQ Scale for Evaluating XAI Experience Quality","summary":"  Explainable Artificial Intelligence (XAI) aims to improve the transparency of\nautonomous decision-making through explanations. Recent literature has\nemphasised users' need for holistic \"multi-shot\" explanations and personalised\nengagement with XAI systems. We refer to this user-centred interaction as an\nXAI Experience. Despite advances in creating XAI experiences, evaluating them\nin a user-centred manner has remained challenging. In response, we developed\nthe XAI Experience Quality (XEQ) Scale. XEQ quantifies the quality of\nexperiences across four dimensions: learning, utility, fulfilment and\nengagement. These contributions extend the state-of-the-art of XAI evaluation,\nmoving beyond the one-dimensional metrics frequently developed to assess\nsingle-shot explanations. This paper presents the XEQ scale development and\nvalidation process, including content validation with XAI experts, and\ndiscriminant and construct validation through a large-scale pilot study. Our\npilot study results offer strong evidence that establishes the XEQ Scale as a\ncomprehensive framework for evaluating user-centred XAI experiences.\n","authors":["Anjana Wijekoon","Nirmalie Wiratunga","David Corsar","Kyle Martin","Ikechukwu Nkisi-Orji","Belen Díaz-Agudo","Derek Bridge"],"pdf_url":"https://arxiv.org/pdf/2407.10662v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10114v1","updated":"2025-01-17T10:58:12Z","published":"2025-01-17T10:58:12Z","title":"Infrastructure for AI Agents","summary":"  Increasingly many AI systems can plan and execute interactions in open-ended\nenvironments, such as making phone calls or buying online goods. As developers\ngrow the space of tasks that such AI agents can accomplish, we will need tools\nboth to unlock their benefits and manage their risks. Current tools are largely\ninsufficient because they are not designed to shape how agents interact with\nexisting institutions (e.g., legal and economic systems) or actors (e.g.,\ndigital service providers, humans, other AI agents). For example, alignment\ntechniques by nature do not assure counterparties that some human will be held\naccountable when a user instructs an agent to perform an illegal action. To\nfill this gap, we propose the concept of agent infrastructure: technical\nsystems and shared protocols external to agents that are designed to mediate\nand influence their interactions with and impacts on their environments. Agent\ninfrastructure comprises both new tools and reconfigurations or extensions of\nexisting tools. For example, to facilitate accountability, protocols that tie\nusers to agents could build upon existing systems for user authentication, such\nas OpenID. Just as the Internet relies on infrastructure like HTTPS, we argue\nthat agent infrastructure will be similarly indispensable to ecosystems of\nagents. We identify three functions for agent infrastructure: 1) attributing\nactions, properties, and other information to specific agents, their users, or\nother actors; 2) shaping agents' interactions; and 3) detecting and remedying\nharmful actions from agents. We propose infrastructure that could help achieve\neach function, explaining use cases, adoption, limitations, and open questions.\nMaking progress on agent infrastructure can prepare society for the adoption of\nmore advanced agents.\n","authors":["Alan Chan","Kevin Wei","Sihao Huang","Nitarshan Rajkumar","Elija Perrier","Seth Lazar","Gillian K. Hadfield","Markus Anderljung"],"pdf_url":"https://arxiv.org/pdf/2501.10114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10107v1","updated":"2025-01-17T10:50:22Z","published":"2025-01-17T10:50:22Z","title":"BBPOS: BERT-based Part-of-Speech Tagging for Uzbek","summary":"  This paper advances NLP research for the low-resource Uzbek language by\nevaluating two previously untested monolingual Uzbek BERT models on the\npart-of-speech (POS) tagging task and introducing the first publicly available\nUPOS-tagged benchmark dataset for Uzbek. Our fine-tuned models achieve 91%\naverage accuracy, outperforming the baseline multi-lingual BERT as well as the\nrule-based tagger. Notably, these models capture intermediate POS changes\nthrough affixes and demonstrate context sensitivity, unlike existing rule-based\ntaggers.\n","authors":["Latofat Bobojonova","Arofat Akhundjanova","Phil Ostheimer","Sophie Fellenz"],"pdf_url":"https://arxiv.org/pdf/2501.10107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10106v1","updated":"2025-01-17T10:47:11Z","published":"2025-01-17T10:47:11Z","title":"LLM Reasoner and Automated Planner: A new NPC approach","summary":"  In domains requiring intelligent agents to emulate plausible human-like\nbehaviour, such as formative simulations, traditional techniques like behaviour\ntrees encounter significant challenges. Large Language Models (LLMs), despite\nnot always yielding optimal solutions, usually offer plausible and human-like\nresponses to a given problem. In this paper, we exploit this capability and\npropose a novel architecture that integrates an LLM for decision-making with a\nclassical automated planner that can generate sound plans for that decision.\nThe combination aims to equip an agent with the ability to make decisions in\nvarious situations, even if they were not anticipated during the design phase.\n","authors":["Israel Puerta-Merino","Jordi Sabater-Mir"],"pdf_url":"https://arxiv.org/pdf/2501.10106v1.pdf","comment":"15 pages, 7 figures, extended version of the homonymous paper\n  submitted to the Catalan Conference on Artificial Intelligent (CCIA) 2025"},{"id":"http://arxiv.org/abs/2501.10105v1","updated":"2025-01-17T10:45:22Z","published":"2025-01-17T10:45:22Z","title":"Universal Actions for Enhanced Embodied Foundation Models","summary":"  Training on diverse, internet-scale data is a key factor in the success of\nrecent large foundation models. Yet, using the same recipe for building\nembodied agents has faced noticeable difficulties. Despite the availability of\nmany crowd-sourced embodied datasets, their action spaces often exhibit\nsignificant heterogeneity due to distinct physical embodiment and control\ninterfaces for different robots, causing substantial challenges in developing\nembodied foundation models using cross-domain data. In this paper, we introduce\nUniAct, a new embodied foundation modeling framework operating in a tokenized\nUniversal Action Space. Our learned universal actions capture the generic\natomic behaviors across diverse robots by exploiting their shared structural\nfeatures, and enable enhanced cross-domain data utilization and\ncross-embodiment generalizations by eliminating the notorious heterogeneity.\nThe universal actions can be efficiently translated back to heterogeneous\nactionable commands by simply adding embodiment-specific details, from which\nfast adaptation to new robots becomes simple and straightforward. Our 0.5B\ninstantiation of UniAct outperforms 14X larger SOTA embodied foundation models\nin extensive evaluations on various real-world and simulation robots,\nshowcasing exceptional cross-embodiment control and adaptation capability,\nhighlighting the crucial benefit of adopting universal actions. Project page:\nhttps://github.com/2toinf/UniAct\n","authors":["Jinliang Zheng","Jianxiong Li","Dongxiu Liu","Yinan Zheng","Zhihao Wang","Zhonghong Ou","Yu Liu","Jingjing Liu","Ya-Qin Zhang","Xianyuan Zhan"],"pdf_url":"https://arxiv.org/pdf/2501.10105v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2501.10100v1","updated":"2025-01-17T10:39:09Z","published":"2025-01-17T10:39:09Z","title":"Robotic World Model: A Neural Network Simulator for Robust Policy\n  Optimization in Robotics","summary":"  Learning robust and generalizable world models is crucial for enabling\nefficient and scalable robotic control in real-world environments. In this\nwork, we introduce a novel framework for learning world models that accurately\ncapture complex, partially observable, and stochastic dynamics. The proposed\nmethod employs a dual-autoregressive mechanism and self-supervised training to\nachieve reliable long-horizon predictions without relying on domain-specific\ninductive biases, ensuring adaptability across diverse robotic tasks. We\nfurther propose a policy optimization framework that leverages world models for\nefficient training in imagined environments and seamless deployment in\nreal-world systems. Through extensive experiments, our approach consistently\noutperforms state-of-the-art methods, demonstrating superior autoregressive\nprediction accuracy, robustness to noise, and generalization across\nmanipulation and locomotion tasks. Notably, policies trained with our method\nare successfully deployed on ANYmal D hardware in a zero-shot transfer,\nachieving robust performance with minimal sim-to-real performance loss. This\nwork advances model-based reinforcement learning by addressing the challenges\nof long-horizon prediction, error accumulation, and sim-to-real transfer. By\nproviding a scalable and robust framework, the introduced methods pave the way\nfor adaptive and efficient robotic systems in real-world applications.\n","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"https://arxiv.org/pdf/2501.10100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10098v1","updated":"2025-01-17T10:35:58Z","published":"2025-01-17T10:35:58Z","title":"landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D\n  Images","summary":"  Anatomical landmark localization in 2D/3D images is a critical task in\nmedical imaging. Although many general-purpose tools exist for landmark\nlocalization in classical computer vision tasks, such as pose estimation, they\nlack the specialized features and modularity necessary for anatomical landmark\nlocalization applications in the medical domain. Therefore, we introduce\nlandmarker, a Python package built on PyTorch. The package provides a\ncomprehensive, flexible toolkit for developing and evaluating landmark\nlocalization algorithms, supporting a range of methodologies, including static\nand adaptive heatmap regression. landmarker enhances the accuracy of landmark\nidentification, streamlines research and development processes, and supports\nvarious image formats and preprocessing pipelines. Its modular design allows\nusers to customize and extend the toolkit for specific datasets and\napplications, accelerating innovation in medical imaging. landmarker addresses\na critical need for precision and customization in landmark localization tasks\nnot adequately met by existing general-purpose pose estimation tools.\n","authors":["Jef Jonkers","Luc Duchateau","Glenn Van Wallendael","Sofie Van Hoecke"],"pdf_url":"https://arxiv.org/pdf/2501.10098v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2501.10091v1","updated":"2025-01-17T10:25:41Z","published":"2025-01-17T10:25:41Z","title":"How Do Programming Students Use Generative AI?","summary":"  Programming students have a widespread access to powerful Generative AI tools\nlike ChatGPT. While this can help understand the learning material and assist\nwith exercises, educators are voicing more and more concerns about an\nover-reliance on generated outputs and lack of critical thinking skills. It is\nthus important to understand how students actually use generative AI and what\nimpact this could have on their learning behavior. To this end, we conducted a\nstudy including an exploratory experiment with 37 programming students, giving\nthem monitored access to ChatGPT while solving a code understanding and\nimproving exercise. While only 23 of the students actually opted to use the\nchatbot, the majority of those eventually prompted it to simply generate a full\nsolution. We observed two prevalent usage strategies: to seek knowledge about\ngeneral concepts and to directly generate solutions. Instead of using the bot\nto comprehend the code and their own mistakes, students often got trapped in a\nvicious cycle of submitting wrong generated code and then asking the bot for a\nfix. Those who self-reported using generative AI regularly were more likely to\nprompt the bot to generate a solution. Our findings indicate that concerns\nabout potential decrease in programmers' agency and productivity with\nGenerative AI are justified. We discuss how researchers and educators can\nrespond to the potential risk of students uncritically over-relying on\ngenerative AI. We also discuss potential modifications to our study design for\nlarge-scale replications.\n","authors":["Christian Rahe","Walid Maalej"],"pdf_url":"https://arxiv.org/pdf/2501.10091v1.pdf","comment":"preprint; accepted to ACM International Conference on the Foundations\n  of Software Engineering (FSE) 2025"},{"id":"http://arxiv.org/abs/2412.12997v2","updated":"2025-01-17T10:02:38Z","published":"2024-12-17T15:21:28Z","title":"Enabling Low-Resource Language Retrieval: Establishing Baselines for\n  Urdu MS MARCO","summary":"  As the Information Retrieval (IR) field increasingly recognizes the\nimportance of inclusivity, addressing the needs of low-resource languages\nremains a significant challenge. This paper introduces the first large-scale\nUrdu IR dataset, created by translating the MS MARCO dataset through machine\ntranslation. We establish baseline results through zero-shot learning for IR in\nUrdu and subsequently apply the mMARCO multilingual IR methodology to this\nnewly translated dataset. Our findings demonstrate that the fine-tuned model\n(Urdu-mT5-mMARCO) achieves a Mean Reciprocal Rank (MRR@10) of 0.247 and a\nRecall@10 of 0.439, representing significant improvements over zero-shot\nresults and showing the potential for expanding IR access for Urdu speakers. By\nbridging access gaps for speakers of low-resource languages, this work not only\nadvances multilingual IR research but also emphasizes the ethical and societal\nimportance of inclusive IR technologies. This work provides valuable insights\ninto the challenges and solutions for improving language representation and\nlays the groundwork for future research, especially in South Asian languages,\nwhich can benefit from the adaptable methods used in this study.\n","authors":["Umer Butt","Stalin Veranasi","Günter Neumann"],"pdf_url":"https://arxiv.org/pdf/2412.12997v2.pdf","comment":"7 pages, ECIR 2025, conference camera-ready version"},{"id":"http://arxiv.org/abs/2411.19939v2","updated":"2025-01-17T09:50:55Z","published":"2024-11-29T18:56:37Z","title":"VLSBench: Unveiling Visual Leakage in Multimodal Safety","summary":"  Safety concerns of Multimodal large language models (MLLMs) have gradually\nbecome an important problem in various applications. Surprisingly, previous\nworks indicate a counter-intuitive phenomenon that using textual unlearning to\nalign MLLMs achieves comparable safety performances with MLLMs trained with\nimage-text pairs. To explain such a counter-intuitive phenomenon, we discover a\nvisual safety information leakage (VSIL) problem in existing multimodal safety\nbenchmarks, i.e., the potentially risky and sensitive content in the image has\nbeen revealed in the textual query. In this way, MLLMs can easily refuse these\nsensitive text-image queries according to textual queries. However, image-text\npairs without VSIL are common in real-world scenarios and are overlooked by\nexisting multimodal safety benchmarks. To this end, we construct multimodal\nvisual leakless safety benchmark (VLSBench) preventing visual safety leakage\nfrom image to textual query with 2.4k image-text pairs. Experimental results\nindicate that VLSBench poses a significant challenge to both open-source and\nclose-source MLLMs, including LLaVA, Qwen2-VL, Llama3.2-Vision, and GPT-4o.\nThis study demonstrates that textual alignment is enough for multimodal safety\nscenarios with VSIL, while multimodal alignment is a more promising solution\nfor multimodal safety scenarios without VSIL. Please see our code and data at:\nhttps://hxhcreate.github.io/vlsbench.github.io/\n","authors":["Xuhao Hu","Dongrui Liu","Hao Li","Xuanjing Huang","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2411.19939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.10156v3","updated":"2025-01-17T09:49:37Z","published":"2024-11-15T12:59:46Z","title":"Mitigating Sycophancy in Decoder-Only Transformer Architectures:\n  Synthetic Data Intervention","summary":"  To address the sycophancy problem caused by reinforcement learning from human\nfeedback in large language models, this research applies synthetic data\nintervention technology to the decoder-only transformer architecture. Based on\nthe research gaps in the existing literature, the researcher designed an\nexperimental process to reduce the tendency of models to cater by generating\ndiversified data, and used GPT4o as an experimental tool for verification. The\nexperiment used 100 true and false questions, and compared the performance of\nthe model trained with synthetic data intervention and the original untrained\nmodel on multiple indicators. The results show that the SDI training model\nsupports the technology in terms of accuracy rate and sycophancy rate and has\nsignificant effectiveness in reducing sycophancy phenomena. Notably, the data\nset, experimental process, code and data results have been uploaded to Github,\nthe link is https://github.com/brucewang123456789/GeniusTrail.git.\n","authors":["Libo Wang"],"pdf_url":"https://arxiv.org/pdf/2411.10156v3.pdf","comment":"This research is also submitted to OpenReview. The main text is 9\n  pages (excluding citations), 7 figures, and 1 table"},{"id":"http://arxiv.org/abs/2501.10075v1","updated":"2025-01-17T09:47:27Z","published":"2025-01-17T09:47:27Z","title":"Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and\n  MModalCC Framework","summary":"  Remote sensing change captioning (RSICC) aims to describe changes between\nbitemporal images in natural language. Existing methods often fail under\nchallenges like illumination differences, viewpoint changes, blur effects,\nleading to inaccuracies, especially in no-change regions. Moreover, the images\nacquired at different spatial resolutions and have registration errors tend to\naffect the captions. To address these issues, we introduce SECOND-CC, a novel\nRSICC dataset featuring high-resolution RGB image pairs, semantic segmentation\nmaps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of\nbitemporal RS images and 30,205 sentences describing the differences between\nimages. Additionally, we propose MModalCC, a multimodal framework that\nintegrates semantic and visual data using advanced attention mechanisms,\nincluding Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross\nAttention (MGCA). Detailed ablation studies and attention visualizations\nfurther demonstrate its effectiveness and ability to address RSICC challenges.\nComprehensive experiments show that MModalCC outperforms state-of-the-art RSICC\nmethods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on\nBLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and\ncodebase publicly available to facilitate future research at\nhttps://github.com/ChangeCapsInRS/SecondCC\n","authors":["Ali Can Karaca","M. Enes Ozelbas","Saadettin Berber","Orkhan Karimli","Turabi Yildirim","M. Fatih Amasyali"],"pdf_url":"https://arxiv.org/pdf/2501.10075v1.pdf","comment":"This work has been submitted to the IEEE Transactions on Geoscience\n  and Remote Sensing journal for possible publication"},{"id":"http://arxiv.org/abs/2501.10074v1","updated":"2025-01-17T09:46:27Z","published":"2025-01-17T09:46:27Z","title":"SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and\n  Chain-of-Thought for Embodied Task Planning","summary":"  Spatial reasoning is an essential problem in embodied AI research. Efforts to\nenhance spatial reasoning abilities through supplementary spatial data and\nfine-tuning have proven limited and ineffective when addressing complex\nembodied tasks, largely due to their dependence on language-based outputs.\nWhile some approaches have introduced a point-based action space to mitigate\nthis issue, they fall short in managing more intricate tasks within complex\nenvironments. This deficiency arises from their failure to fully exploit the\ninherent thinking and reasoning capabilities that are fundamental strengths of\nVision-Language Models (VLMs). To address these limitations, we propose a novel\napproach named SpatialCoT, specifically designed to bolster the spatial\nreasoning capabilities of VLMs. Our approach comprises two stages: spatial\ncoordinate bi-directional alignment, which aligns vision-language inputs with\nspatial coordinates, and chain-of-thought spatial grounding, which harnesses\nthe reasoning capabilities of language models for advanced spatial reasoning.\nWe evaluate SpatialCoT on challenging navigation and manipulation tasks, both\nin simulation and real-world settings. Experimental results demonstrate that\nour method significantly outperforms previous state-of-the-art approaches in\nboth tasks.\n","authors":["Yuecheng Liu","Dafeng Chi","Shiguang Wu","Zhanguang Zhang","Yaochen Hu","Lingfeng Zhang","Yingxue Zhang","Shuang Wu","Tongtong Cao","Guowei Huang","Guangjian Tian","Xingyue Quan","Jianye Hao","Yuzheng Zhuang"],"pdf_url":"https://arxiv.org/pdf/2501.10074v1.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2501.10069v1","updated":"2025-01-17T09:42:48Z","published":"2025-01-17T09:42:48Z","title":"A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling,\n  Search Algorithms, and Relevant Frameworks","summary":"  LLM test-time compute (or LLM inference) via search has emerged as a\npromising research area with rapid developments. However, current frameworks\noften adopt distinct perspectives on three key aspects (task definition, LLM\nprofiling, and search procedures), making direct comparisons challenging.\nMoreover, the search algorithms employed often diverge from standard\nimplementations, and their specific characteristics are not thoroughly\nspecified. In this survey, we provide a comprehensive technical review that\nunifies task definitions and provides modular definitions of LLM profiling and\nsearch procedures. The definitions enable precise comparisons of various LLM\ninference frameworks while highlighting their departures from conventional\nsearch algorithms. We also discuss the applicability, performance, and\nefficiency of these methods. For further details and ongoing updates, please\nrefer to our GitHub repository:\nhttps://github.com/xinzhel/LLM-Agent-Survey/blob/main/search.md\n","authors":["Xinzhe Li"],"pdf_url":"https://arxiv.org/pdf/2501.10069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03594v2","updated":"2025-01-17T09:37:36Z","published":"2024-11-29T05:57:37Z","title":"BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix\n  Sharing and Throughput-oriented Token Batching","summary":"  Large language models (LLMs) increasingly play an important role in a wide\nrange of information processing and management tasks. Many of these tasks are\nperformed in large batches or even offline, and the performance indictor for\nwhich is throughput. These tasks usually show the characteristic of prefix\nsharing, where different prompt input can partially show the common prefix.\nHowever, the existing LLM inference engines tend to optimize the streaming\nrequests and show limitations of supporting the large batched tasks with the\nprefix sharing characteristic. The existing solutions use the LRU-based cache\nto reuse the KV context of common prefix between requests. The KV context that\nare about to be reused may prematurely evicted with the implicit cache\nmanagement. Besides, the streaming oriented systems do not leverage the\nrequest-batch information and can not mix the decoding tokens with the prefill\nchunks to the best for the batched scenarios, and thus fails to saturate the\nGPU. We propose BatchLLM to address the above problems. BatchLLM explicitly\nidentifies the common prefixes globally. The requests sharing the same prefix\nwill be scheduled together to reuse the KV context the best. BatchLLM reorders\nthe requests and schedules the requests with larger ratio of decoding first to\nbetter mix the decoding tokens with the latter prefill chunks, and applies\nmemory-centric token batching to enlarge the token-batch sizes, which helps to\nincrease the GPU utilization. Finally, BatchLLM optimizes the prefix-shared\nAttention kernel with horizontal fusion to reduce tail effect and kernel launch\noverhead. Extensive evaluation shows that BatchLLM outperforms vLLM and SGLang\nby 1.3$\\times$ to 10.8$\\times$ on a set of microbenchmarks and a typical\nindustry workload under different hardware environments.\n","authors":["Zhen Zheng","Xin Ji","Taosong Fang","Fanghao Zhou","Chuanjie Liu","Gang Peng"],"pdf_url":"https://arxiv.org/pdf/2412.03594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.20262v3","updated":"2025-01-17T09:32:54Z","published":"2024-03-29T16:13:31Z","title":"ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language\n  Models","summary":"  Research on Large Language Models (LLMs) has recently witnessed an increasing\ninterest in extending the models' context size to better capture dependencies\nwithin long documents. While benchmarks have been proposed to assess long-range\nabilities, existing efforts primarily considered generic tasks that are not\nnecessarily aligned with real-world applications. In contrast, we propose a new\nbenchmark for long-context LLMs focused on a practical meeting assistant\nscenario in which the long contexts consist of transcripts obtained by\nautomatic speech recognition, presenting unique challenges for LLMs due to the\ninherent noisiness and oral nature of such data. Our benchmark, ELITR-Bench,\naugments the existing ELITR corpus by adding 271 manually crafted questions\nwith their ground-truth answers, as well as noisy versions of meeting\ntranscripts altered to target different Word Error Rate levels. Our experiments\nwith 12 long-context LLMs on ELITR-Bench confirm the progress made across\nsuccessive generations of both proprietary and open models, and point out their\ndiscrepancies in terms of robustness to transcript noise. We also provide a\nthorough analysis of our GPT-4-based evaluation, including insights from a\ncrowdsourcing study. Our findings indicate that while GPT-4's scores align with\nhuman judges, its ability to distinguish beyond three score levels may be\nlimited.\n","authors":["Thibaut Thonet","Jos Rozen","Laurent Besacier"],"pdf_url":"https://arxiv.org/pdf/2403.20262v3.pdf","comment":"Published in COLING 2025"},{"id":"http://arxiv.org/abs/2501.10054v1","updated":"2025-01-17T09:20:56Z","published":"2025-01-17T09:20:56Z","title":"Accelerating Large Language Models through Partially Linear Feed-Forward\n  Network","summary":"  Large language models (LLMs) demonstrate remarkable capabilities but face\ndeployment challenges due to their massive parameter counts. While existing\ncompression techniques like pruning can reduce model size, it leads to\nsignificant accuracy degradation under high compression ratios. We present a\nnovel perspective inspired by constant folding in compiler optimization. Our\napproach enables parameter reduction by treating activation functions in LLMs\nas linear functions.\n  However, recent LLMs use complex non-linear activations like GELU that\nprevent direct application of this technique. We propose TARDIS, which enables\noptimization of LLMs with non-linear activations by partially approximating\nthem with linear functions in frequently occurring input ranges. For outlier\ninputs, TARDIS employs an online predictor to dynamically fall back to original\ncomputations.\n  Our experiments demonstrate that TARDIS achieves 80% parameter reduction in\nfeed-forward networks, while significantly outperforming state-of-the-art\npruning methods Wanda and RIA with up to 65% higher accuracy. In practical\ndeployments for a 7B model, TARDIS achieves 1.6x end-to-end inference speedup\nwhen integrated with the vLLM serving system, and 1.4x speedup with the widely\nadopted HuggingFace implementation, while incurring only a 10.9% accuracy\ntrade-off.\n","authors":["Gansen Hu","Zhaoguo Wang","Jinglin Wei","Wei Huang","Haibo Chen"],"pdf_url":"https://arxiv.org/pdf/2501.10054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17482v2","updated":"2025-01-17T09:17:30Z","published":"2024-07-02T08:07:27Z","title":"Reinforcement Learning from Human Feedback: Whose Culture, Whose Values,\n  Whose Perspectives?","summary":"  We argue for the epistemic and ethical advantages of pluralism in\nReinforcement Learning from Human Feedback (RLHF) in the context of Large\nLanguage Models (LLM). Drawing on social epistemology and pluralist philosophy\nof science, we suggest ways in which RHLF can be made more responsive to human\nneeds and how we can address challenges along the way. The paper concludes with\nan agenda for change, i.e. concrete, actionable steps to improve LLM\ndevelopment.\n","authors":["Kristian González Barman","Simon Lohse","Henk de Regt"],"pdf_url":"https://arxiv.org/pdf/2407.17482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10053v1","updated":"2025-01-17T09:16:13Z","published":"2025-01-17T09:16:13Z","title":"AirRAG: Activating Intrinsic Reasoning for Retrieval Augmented\n  Generation via Tree-based Search","summary":"  Leveraging the autonomous decision-making capabilities of large language\nmodels (LLMs) demonstrates superior performance in reasoning tasks. Despite the\nsuccesses of iterative or recursive retrieval-augmented generation (RAG), they\noften are trapped in a single solution space when confronted with complex\ntasks. In this paper, we propose a novel thinking pattern in RAG which\nintegrates system analysis with efficient reasoning actions, significantly\nactivating intrinsic reasoning capabilities and expanding the solution space of\nspecific tasks via Monte Carlo Tree Search (MCTS), dubbed AirRAG. Specifically,\nour approach designs five fundamental reasoning actions that are expanded to a\nwide tree-based reasoning spaces using MCTS. The extension also uses\nself-consistency verification to explore potential reasoning paths and\nimplement inference scaling. In addition, computationally optimal strategies\nare used to apply more inference computation to key actions to achieve further\nperformance improvements. Experimental results demonstrate the effectiveness of\nAirRAG through considerable performance gains over complex QA datasets.\nFurthermore, AirRAG is flexible and lightweight, making it easy to integrate\nwith other advanced technologies.\n","authors":["Wenfeng Feng","Chuzhan Hao","Yuewei Zhang","Jingyi Song","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2501.10053v1.pdf","comment":"17 pages, 14 figures"},{"id":"http://arxiv.org/abs/2501.10048v1","updated":"2025-01-17T09:09:01Z","published":"2025-01-17T09:09:01Z","title":"Virtual Nodes Improve Long-term Traffic Prediction","summary":"  Effective traffic prediction is a cornerstone of intelligent transportation\nsystems, enabling precise forecasts of traffic flow, speed, and congestion.\nWhile traditional spatio-temporal graph neural networks (ST-GNNs) have achieved\nnotable success in short-term traffic forecasting, their performance in\nlong-term predictions remains limited. This challenge arises from\nover-squashing problem, where bottlenecks and limited receptive fields restrict\ninformation flow and hinder the modeling of global dependencies. To address\nthese challenges, this study introduces a novel framework that incorporates\nvirtual nodes, which are additional nodes added to the graph and connected to\nexisting nodes, in order to aggregate information across the entire graph\nwithin a single GNN layer. Our proposed model incorporates virtual nodes by\nconstructing a semi-adaptive adjacency matrix. This matrix integrates\ndistance-based and adaptive adjacency matrices, allowing the model to leverage\ngeographical information while also learning task-specific features from data.\nExperimental results demonstrate that the inclusion of virtual nodes\nsignificantly enhances long-term prediction accuracy while also improving\nlayer-wise sensitivity to mitigate the over-squashing problem. Virtual nodes\nalso offer enhanced explainability by focusing on key intersections and\nhigh-traffic areas, as shown by the visualization of their adjacency matrix\nweights on road network heat maps. Our advanced approach enhances the\nunderstanding and management of urban traffic systems, making it particularly\nwell-suited for real-world applications.\n","authors":["Xiaoyang Cao","Dingyi Zhuang","Jinhua Zhao","Shenhao Wang"],"pdf_url":"https://arxiv.org/pdf/2501.10048v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03703v3","updated":"2025-01-17T09:03:57Z","published":"2024-04-04T07:49:39Z","title":"Mitigating analytical variability in fMRI results with style transfer","summary":"  We propose a novel approach to improve the reproducibility of neuroimaging\nresults by converting statistic maps across different functional MRI pipelines.\nWe make the assumption that pipelines used to compute fMRI statistic maps can\nbe considered as a style component and we propose to use different generative\nmodels, among which, Generative Adversarial Networks (GAN) and Diffusion Models\n(DM) to convert statistic maps across different pipelines. We explore the\nperformance of multiple GAN frameworks, and design a new DM framework for\nunsupervised multi-domain styletransfer. We constrain the generation of 3D fMRI\nstatistic maps using the latent space of an auxiliary classifier that\ndistinguishes statistic maps from different pipelines and extend traditional\nsampling techniques used in DM to improve the transition performance. Our\nexperiments demonstrate that our proposed methods aresuccessful: pipelines can\nindeed be transferred as a style component, providing animportant source of\ndata augmentation for future medical studies.\n","authors":["Elodie Germani","Camille Maumet","Elisa Fromont"],"pdf_url":"https://arxiv.org/pdf/2404.03703v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10041v1","updated":"2025-01-17T08:56:49Z","published":"2025-01-17T08:56:49Z","title":"Spatiotemporal Prediction of Secondary Crashes by Rebalancing Dynamic\n  and Static Data with Generative Adversarial Networks","summary":"  Data imbalance is a common issue in analyzing and predicting sudden traffic\nevents. Secondary crashes constitute only a small proportion of all crashes.\nThese secondary crashes, triggered by primary crashes, significantly exacerbate\ntraffic congestion and increase the severity of incidents. However, the severe\nimbalance of secondary crash data poses significant challenges for prediction\nmodels, affecting their generalization ability and prediction accuracy.\nExisting methods fail to fully address the complexity of traffic crash data,\nparticularly the coexistence of dynamic and static features, and often struggle\nto effectively handle data samples of varying lengths. Furthermore, most\ncurrent studies predict the occurrence probability and spatiotemporal\ndistribution of secondary crashes separately, lacking an integrated solution.\nTo address these challenges, this study proposes a hybrid model named\nVarFusiGAN-Transformer, aimed at improving the fidelity of secondary crash data\ngeneration and jointly predicting the occurrence and spatiotemporal\ndistribution of secondary crashes. The VarFusiGAN-Transformer model employs\nLong Short-Term Memory (LSTM) networks to enhance the generation of\nmultivariate long-time series data, incorporating a static data generator and\nan auxiliary discriminator to model the joint distribution of dynamic and\nstatic features. In addition, the model's prediction module achieves\nsimultaneous prediction of both the occurrence and spatiotemporal distribution\nof secondary crashes. Compared to existing methods, the proposed model\ndemonstrates superior performance in generating high-fidelity data and\nimproving prediction accuracy.\n","authors":["Junlan Chen","Yiqun Li","Chenyu Ling","Ziyuan Pu","Xiucheng Guo"],"pdf_url":"https://arxiv.org/pdf/2501.10041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17188v2","updated":"2025-01-17T08:38:45Z","published":"2024-06-25T00:02:01Z","title":"Geometric Median (GM) Matching for Robust Data Pruning","summary":"  Large-scale data collections in the wild, are invariably noisy. Thus\ndeveloping data pruning strategies that remain robust even in the presence of\ncorruption is critical in practice. In this work, we propose Geometric Median\n($\\gm$) Matching -- a herding style greedy algorithm that yields a $k$-subset\nsuch that the mean of the subset approximates the geometric median of the\n(potentially) noisy dataset. Theoretically, we show that $\\gm$ Matching enjoys\nan improved $\\gO(1/k)$ scaling over $\\gO(1/\\sqrt{k})$ scaling of uniform\nsampling; while achieving {\\bf optimal breakdown point} of {\\bf 1/2} even under\n{\\bf arbitrary} corruption. Extensive experiments across several popular deep\nlearning benchmarks indicate that $\\gm$ Matching consistently improves over\nprior state-of-the-art; the gains become more profound at high rates of\ncorruption and aggressive pruning rates; making $\\gm$ Matching a strong\nbaseline for future research in robust data pruning.\n","authors":["Anish Acharya","Inderjit S Dhillon","Sujay Sanghavi"],"pdf_url":"https://arxiv.org/pdf/2406.17188v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09059v4","updated":"2025-01-17T08:32:40Z","published":"2023-07-18T08:23:46Z","title":"Text-guided Image Restoration and Semantic Enhancement for Text-to-Image\n  Person Retrieval","summary":"  The goal of Text-to-Image Person Retrieval (TIPR) is to retrieve specific\nperson images according to the given textual descriptions. A primary challenge\nin this task is bridging the substantial representational gap between visual\nand textual modalities. The prevailing methods map texts and images into\nunified embedding space for matching, while the intricate semantic\ncorrespondences between texts and images are still not effectively constructed.\nTo address this issue, we propose a novel TIPR framework to build fine-grained\ninteractions and alignment between person images and the corresponding texts.\nSpecifically, via fine-tuning the Contrastive Language-Image Pre-training\n(CLIP) model, a visual-textual dual encoder is firstly constructed, to\npreliminarily align the image and text features. Secondly, a Text-guided Image\nRestoration (TIR) auxiliary task is proposed to map abstract textual entities\nto specific image regions, improving the alignment between local textual and\nvisual embeddings. Additionally, a cross-modal triplet loss is presented to\nhandle hard samples, and further enhance the model's discriminability for minor\ndifferences. Moreover, a pruning-based text data augmentation approach is\nproposed to enhance focus on essential elements in descriptions, thereby\navoiding excessive model attention to less significant information. The\nexperimental results show our proposed method outperforms state-of-the-art\nmethods on three popular benchmark datasets, and the code will be made publicly\navailable at https://github.com/Delong-liu-bupt/SEN.\n","authors":["Delong Liu","Haiwen Li","Zhicheng Zhao","Yuan Dong"],"pdf_url":"https://arxiv.org/pdf/2307.09059v4.pdf","comment":"The paper was withdrawn due to a dispute among the authors regarding\n  the content of the article"},{"id":"http://arxiv.org/abs/2501.09368v2","updated":"2025-01-17T08:23:03Z","published":"2025-01-16T08:27:40Z","title":"Aligning Instruction Tuning with Pre-training","summary":"  Instruction tuning enhances large language models (LLMs) to follow human\ninstructions across diverse tasks, relying on high-quality datasets to guide\nbehavior. However, these datasets, whether manually curated or synthetically\ngenerated, are often narrowly focused and misaligned with the broad\ndistributions captured during pre-training, limiting LLM generalization and\neffective use of pre-trained knowledge. We propose *Aligning Instruction Tuning\nwith Pre-training* (AITP), a method that bridges this gap by identifying\ncoverage shortfalls in instruction-tuning datasets and rewriting\nunderrepresented pre-training data into high-quality instruction-response\npairs. This approach enriches dataset diversity while preserving task-specific\nobjectives. Evaluations on three fully open LLMs across eight benchmarks\ndemonstrate consistent performance improvements with AITP. Ablations highlight\nthe benefits of adaptive data selection, controlled rewriting, and balanced\nintegration, emphasizing the importance of aligning instruction tuning with\npre-training distributions to unlock the full potential of LLMs.\n","authors":["Yiming Liang","Tianyu Zheng","Xinrun Du","Ge Zhang","Xingwei Qu","Xiang Yue","Chujie Zheng","Jiaheng Liu","Lei Ma","Wenhu Chen","Guoyin Wang","Zhaoxiang Zhang","Wenhao Huang","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.09368v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10024v1","updated":"2025-01-17T08:20:32Z","published":"2025-01-17T08:20:32Z","title":"Automatic Speech Recognition for Sanskrit with Transfer Learning","summary":"  Sanskrit, one of humanity's most ancient languages, has a vast collection of\nbooks and manuscripts on diverse topics that have been accumulated over\nmillennia. However, its digital content (audio and text), which is vital for\nthe training of AI systems, is profoundly limited. Furthermore, its intricate\nlinguistics make it hard to develop robust NLP tools for wider accessibility.\nGiven these constraints, we have developed an automatic speech recognition\nmodel for Sanskrit by employing transfer learning mechanism on OpenAI's Whisper\nmodel. After carefully optimising the hyper-parameters, we obtained promising\nresults with our transfer-learned model achieving a word error rate of 15.42%\non Vaksancayah dataset. An online demo of our model is made available for the\nuse of public and to evaluate its performance firsthand thereby paving the way\nfor improved accessibility and technological support for Sanskrit learning in\nthe modern era.\n","authors":["Bidit Sadhukhan","Swami Punyeshwarananda"],"pdf_url":"https://arxiv.org/pdf/2501.10024v1.pdf","comment":"Paper has been accepted at the 4th International Conference on\n  Computer, Communication, Control & Information Technology (C3IT), Hooghly,\n  India, 2024, pp. 1-5"},{"id":"http://arxiv.org/abs/2501.10017v1","updated":"2025-01-17T07:53:27Z","published":"2025-01-17T07:53:27Z","title":"Enhancing Crash Frequency Modeling Based on Augmented Multi-Type Data by\n  Hybrid VAE-Diffusion-Based Generative Neural Networks","summary":"  Crash frequency modelling analyzes the impact of factors like traffic volume,\nroad geometry, and environmental conditions on crash occurrences. Inaccurate\npredictions can distort our understanding of these factors, leading to\nmisguided policies and wasted resources, which jeopardize traffic safety. A key\nchallenge in crash frequency modelling is the prevalence of excessive zero\nobservations, caused by underreporting, the low probability of crashes, and\nhigh data collection costs. These zero observations often reduce model accuracy\nand introduce bias, complicating safety decision making. While existing\napproaches, such as statistical methods, data aggregation, and resampling,\nattempt to address this issue, they either rely on restrictive assumptions or\nresult in significant information loss, distorting crash data. To overcome\nthese limitations, we propose a hybrid VAE-Diffusion neural network, designed\nto reduce zero observations and handle the complexities of multi-type tabular\ncrash data (count, ordinal, nominal, and real-valued variables). We assess the\nsynthetic data quality generated by this model through metrics like similarity,\naccuracy, diversity, and structural consistency, and compare its predictive\nperformance against traditional statistical models. Our findings demonstrate\nthat the hybrid VAE-Diffusion model outperforms baseline models across all\nmetrics, offering a more effective approach to augmenting crash data and\nimproving the accuracy of crash frequency predictions. This study highlights\nthe potential of synthetic data to enhance traffic safety by improving crash\nfrequency modelling and informing better policy decisions.\n","authors":["Junlan Chen","Qijie He","Pei Liu","Wei Ma","Ziyuan Pu"],"pdf_url":"https://arxiv.org/pdf/2501.10017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10011v1","updated":"2025-01-17T07:48:37Z","published":"2025-01-17T07:48:37Z","title":"Mitigating Hallucinations on Object Attributes using Multiview Images\n  and Negative Instructions","summary":"  Current popular Large Vision-Language Models (LVLMs) are suffering from\nHallucinations on Object Attributes (HoOA), leading to incorrect determination\nof fine-grained attributes in the input images. Leveraging significant\nadvancements in 3D generation from a single image, this paper proposes a novel\nmethod to mitigate HoOA in LVLMs. This method utilizes multiview images sampled\nfrom generated 3D representations as visual prompts for LVLMs, thereby\nproviding more visual information from other viewpoints. Furthermore, we\nobserve the input order of multiple multiview images significantly affects the\nperformance of LVLMs. Consequently, we have devised Multiview Image Augmented\nVLM (MIAVLM), incorporating a Multiview Attributes Perceiver (MAP) submodule\ncapable of simultaneously eliminating the influence of input image order and\naligning visual information from multiview images with Large Language Models\n(LLMs). Besides, we designed and employed negative instructions to mitigate\nLVLMs' bias towards ``Yes\" responses. Comprehensive experiments demonstrate the\neffectiveness of our method.\n","authors":["Zhijie Tan","Yuzhi Li","Shengwei Meng","Xiang Yuan","Weiping Li","Tong Mo","Bingce Wang","Xu Chu"],"pdf_url":"https://arxiv.org/pdf/2501.10011v1.pdf","comment":"2025 IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2025)"},{"id":"http://arxiv.org/abs/2501.10010v1","updated":"2025-01-17T07:48:18Z","published":"2025-01-17T07:48:18Z","title":"Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph\n  Learning","summary":"  Dynamic graph augmentation is used to improve the performance of dynamic\nGNNs. Most methods assume temporal locality, meaning that recent edges are more\ninfluential than earlier edges. However, for temporal changes in edges caused\nby random noise, overemphasizing recent edges while neglecting earlier ones may\nlead to the model capturing noise. To address this issue, we propose STAA\n(SpatioTemporal Activity-Aware Random Walk Diffusion). STAA identifies nodes\nlikely to have noisy edges in spatiotemporal dimensions. Spatially, it analyzes\ncritical topological positions through graph wavelet coefficients. Temporally,\nit analyzes edge evolution through graph wavelet coefficient change rates.\nThen, random walks are used to reduce the weights of noisy edges, deriving a\ndiffusion matrix containing spatiotemporal information as an augmented\nadjacency matrix for dynamic GNN learning. Experiments on multiple datasets\nshow that STAA outperforms other dynamic graph augmentation methods in node\nclassification and link prediction tasks.\n","authors":["Xu Chu","Hanlin Xue","Bingce Wang","Xiaoyang Liu","Weiping Li","Tong Mo","Tuoyu Feng","Zhijie Tan"],"pdf_url":"https://arxiv.org/pdf/2501.10010v1.pdf","comment":"2025 IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2025)"},{"id":"http://arxiv.org/abs/2501.09999v1","updated":"2025-01-17T07:30:16Z","published":"2025-01-17T07:30:16Z","title":"Deep Learning for Early Alzheimer Disease Detection with MRI Scans","summary":"  Alzheimer's Disease is a neurodegenerative condition characterized by\ndementia and impairment in neurological function. The study primarily focuses\non the individuals above age 40, affecting their memory, behavior, and\ncognitive processes of the brain. Alzheimer's disease requires diagnosis by a\ndetailed assessment of MRI scans and neuropsychological tests of the patients.\nThis project compares existing deep learning models in the pursuit of enhancing\nthe accuracy and efficiency of AD diagnosis, specifically focusing on the\nConvolutional Neural Network, Bayesian Convolutional Neural Network, and the\nU-net model with the Open Access Series of Imaging Studies brain MRI dataset.\nBesides, to ensure robustness and reliability in the model evaluations, we\naddress the challenge of imbalance in data. We then perform rigorous evaluation\nto determine strengths and weaknesses for each model by considering\nsensitivity, specificity, and computational efficiency. This comparative\nanalysis would shed light on the future role of AI in revolutionizing AD\ndiagnostics but also paved ways for future innovation in medical imaging and\nthe management of neurodegenerative diseases.\n","authors":["Mohammad Rafsan","Tamer Oraby","Upal Roy","Sanjeev Kumar","Hansapani Rodrigo"],"pdf_url":"https://arxiv.org/pdf/2501.09999v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09997v1","updated":"2025-01-17T07:30:01Z","published":"2025-01-17T07:30:01Z","title":"Attention-guided Self-reflection for Zero-shot Hallucination Detection\n  in Large Language Models","summary":"  Hallucination has emerged as a significant barrier to the effective\napplication of Large Language Models (LLMs). In this work, we introduce a novel\nAttention-Guided SElf-Reflection (AGSER) approach for zero-shot hallucination\ndetection in LLMs. The AGSER method utilizes attention contributions to\ncategorize the input query into attentive and non-attentive queries. Each query\nis then processed separately through the LLMs, allowing us to compute\nconsistency scores between the generated responses and the original answer. The\ndifference between the two consistency scores serves as a hallucination\nestimator. In addition to its efficacy in detecting hallucinations, AGSER\nnotably reduces computational complexity, requiring only three passes through\nthe LLM and utilizing two sets of tokens. We have conducted extensive\nexperiments with four widely-used LLMs across three different hallucination\nbenchmarks, demonstrating that our approach significantly outperforms existing\nmethods in zero-shot hallucination detection.\n","authors":["Qiang Liu","Xinlong Chen","Yue Ding","Shizhen Xu","Shu Wu","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2501.09997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09996v1","updated":"2025-01-17T07:26:28Z","published":"2025-01-17T07:26:28Z","title":"Fast energy-aware OLSR routing in VANETs by means of a parallel\n  evolutionary algorithm","summary":"  This work tackles the problem of reducing the power consumption of the OLSR\nrouting protocol in vehicular networks. Nowadays, energy-aware and green\ncommunication protocols are important research topics, specially when deploying\nwireless mobile networks. This article introduces a fast automatic methodology\nto search for energy-efficient OLSR configurations by using a parallel\nevolutionary algorithm. The experimental analysis demonstrates that significant\nimprovements over the standard configuration can be attained in terms of power\nconsumption, with no noteworthy loss in the QoS.\n","authors":["Jamal Toutouh","Sergio Nesmachnow","Enrique Alba"],"pdf_url":"https://arxiv.org/pdf/2501.09996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09994v1","updated":"2025-01-17T07:24:58Z","published":"2025-01-17T07:24:58Z","title":"Multi-Modal Attention Networks for Enhanced Segmentation and Depth\n  Estimation of Subsurface Defects in Pulse Thermography","summary":"  AI-driven pulse thermography (PT) has become a crucial tool in\nnon-destructive testing (NDT), enabling automatic detection of hidden anomalies\nin various industrial components. Current state-of-the-art techniques feed\nsegmentation and depth estimation networks compressed PT sequences using either\nPrincipal Component Analysis (PCA) or Thermographic Signal Reconstruction\n(TSR). However, treating these two modalities independently constrains the\nperformance of PT inspection models as these representations possess\ncomplementary semantic features. To address this limitation, this work proposes\nPT-Fusion, a multi-modal attention-based fusion network that fuses both PCA and\nTSR modalities for defect segmentation and depth estimation of subsurface\ndefects in PT setups. PT-Fusion introduces novel feature fusion modules,\nEncoder Attention Fusion Gate (EAFG) and Attention Enhanced Decoding Block\n(AEDB), to fuse PCA and TSR features for enhanced segmentation and depth\nestimation of subsurface defects. In addition, a novel data augmentation\ntechnique is proposed based on random data sampling from thermographic\nsequences to alleviate the scarcity of PT datasets. The proposed method is\nbenchmarked against state-of-the-art PT inspection models, including U-Net,\nattention U-Net, and 3D-CNN on the Universit\\'e Laval IRT-PVC dataset. The\nresults demonstrate that PT-Fusion outperforms the aforementioned models in\ndefect segmentation and depth estimation accuracies with a margin of 10%.\n","authors":["Mohammed Salah","Naoufel Werghi","Davor Svetinovic","Yusra Abdulrahman"],"pdf_url":"https://arxiv.org/pdf/2501.09994v1.pdf","comment":"Pulse thermography, infrared thermography, defect segmentation,\n  multi-modal networks, attention mechanism"},{"id":"http://arxiv.org/abs/2404.13733v4","updated":"2025-01-17T07:15:16Z","published":"2024-04-21T18:19:27Z","title":"Elucidating the Design Space of Dataset Condensation","summary":"  Dataset condensation, a concept within data-centric learning, efficiently\ntransfers critical attributes from an original dataset to a synthetic version,\nmaintaining both diversity and realism. This approach significantly improves\nmodel training efficiency and is adaptable across multiple application areas.\nPrevious methods in dataset condensation have faced challenges: some incur high\ncomputational costs which limit scalability to larger datasets (e.g., MTT,\nDREAM, and TESLA), while others are restricted to less optimal design spaces,\nwhich could hinder potential improvements, especially in smaller datasets\n(e.g., SRe2L, G-VBSM, and RDED). To address these limitations, we propose a\ncomprehensive design framework that includes specific, effective strategies\nlike implementing soft category-aware matching and adjusting the learning rate\nschedule. These strategies are grounded in empirical evidence and theoretical\nbacking. Our resulting approach, Elucidate Dataset Condensation (EDC),\nestablishes a benchmark for both small and large-scale dataset condensation. In\nour testing, EDC achieves state-of-the-art accuracy, reaching 48.6% on\nImageNet-1k with a ResNet-18 model at an IPC of 10, which corresponds to a\ncompression ratio of 0.78%. This performance exceeds those of SRe2L, G-VBSM,\nand RDED by margins of 27.3%, 17.2%, and 6.6%, respectively.\n","authors":["Shitong Shao","Zikai Zhou","Huanran Chen","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2404.13733v4.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.15084v2","updated":"2025-01-17T07:12:55Z","published":"2024-12-19T17:29:44Z","title":"AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward\n  Modeling","summary":"  In this paper, we introduce AceMath, a suite of frontier math models that\nexcel in solving complex math problems, along with highly effective reward\nmodels capable of evaluating generated solutions and reliably identifying the\ncorrect ones. To develop the instruction-tuned math models, we propose a\nsupervised fine-tuning (SFT) process that first achieves competitive\nperformance across general domains, followed by targeted fine-tuning for the\nmath domain using a carefully curated set of prompts and synthetically\ngenerated responses. The resulting model, AceMath-72B-Instruct greatly\noutperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop\nmath-specialized reward model, we first construct AceMath-RewardBench, a\ncomprehensive and robust benchmark for evaluating math reward models across\ndiverse problems and difficulty levels. After that, we present a systematic\napproach to build our math reward models. The resulting model, AceMath-72B-RM,\nconsistently outperforms state-of-the-art reward models. Furthermore, when\ncombining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest\naverage rm@8 score across the math reasoning benchmarks. We release model\nweights, training data, and evaluation benchmarks at:\nhttps://research.nvidia.com/labs/adlr/acemath\n","authors":["Zihan Liu","Yang Chen","Mohammad Shoeybi","Bryan Catanzaro","Wei Ping"],"pdf_url":"https://arxiv.org/pdf/2412.15084v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.10725v2","updated":"2025-01-17T07:01:43Z","published":"2023-12-17T14:14:31Z","title":"Harnessing small projectors and multiple views for efficient vision\n  pretraining","summary":"  Recent progress in self-supervised (SSL) visual representation learning has\nled to the development of several different proposed frameworks that rely on\naugmentations of images but use different loss functions. However, there are\nfew theoretically grounded principles to guide practice, so practical\nimplementation of each SSL framework requires several heuristics to achieve\ncompetitive performance. In this work, we build on recent analytical results to\ndesign practical recommendations for competitive and efficient SSL that are\ngrounded in theory. Specifically, recent theory tells us that existing SSL\nframeworks are minimizing the same idealized loss, which is to learn features\nthat best match the data similarity kernel defined by the augmentations used.\nWe show how this idealized loss can be reformulated to a functionally\nequivalent loss that is more efficient to compute. We study the implicit bias\nof using gradient descent to minimize our reformulated loss function and find\nthat using a stronger orthogonalization constraint with a reduced projector\ndimensionality should yield good representations. Furthermore, the theory tells\nus that approximating the reformulated loss should be improved by increasing\nthe number of augmentations, and as such using multiple augmentations should\nlead to improved convergence. We empirically verify our findings on CIFAR, STL\nand Imagenet datasets, wherein we demonstrate an improved linear readout\nperformance when training a ResNet-backbone using our theoretically grounded\nrecommendations. Remarkably, we also demonstrate that by leveraging these\ninsights, we can reduce the pretraining dataset size by up to 2$\\times$ while\nmaintaining downstream accuracy simply by using more data augmentations. Taken\ntogether, our work provides theoretically grounded recommendations that can be\nused to improve SSL convergence and efficiency.\n","authors":["Kumar Krishna Agrawal","Arna Ghosh","Shagun Sodhani","Adam Oberman","Blake Richards"],"pdf_url":"https://arxiv.org/pdf/2312.10725v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.09328v2","updated":"2025-01-17T06:50:23Z","published":"2025-01-16T06:59:20Z","title":"Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against\n  Model Extraction Attacks","summary":"  Developing high-performance deep learning models is resource-intensive,\nleading model owners to utilize Machine Learning as a Service (MLaaS) platforms\ninstead of publicly releasing their models. However, malicious users may\nexploit query interfaces to execute model extraction attacks, reconstructing\nthe target model's functionality locally. While prior research has investigated\ntriggerable watermarking techniques for asserting ownership, existing methods\nface significant challenges: (1) most approaches require additional training,\nresulting in high overhead and limited flexibility, and (2) they often fail to\naccount for advanced attackers, leaving them vulnerable to adaptive attacks.\n  In this paper, we propose Neural Honeytrace, a robust plug-and-play\nwatermarking framework against model extraction attacks. We first formulate a\nwatermark transmission model from an information-theoretic perspective,\nproviding an interpretable account of the principles and limitations of\nexisting triggerable watermarking. Guided by the model, we further introduce:\n(1) a similarity-based training-free watermarking method for plug-and-play and\nflexible watermarking, and (2) a distribution-based multi-step watermark\ninformation transmission strategy for robust watermarking. Comprehensive\nexperiments on four datasets demonstrate that Neural Honeytrace outperforms\nprevious methods in efficiency and resisting adaptive attacks. Neural\nHoneytrace reduces the average number of samples required for a worst-case\nt-Test-based copyright claim from $12,000$ to $200$ with zero training cost.\n","authors":["Yixiao Xu","Binxing Fang","Rui Wang","Yinghai Zhou","Shouling Ji","Yuan Liu","Mohan Li","Zhihong Tian"],"pdf_url":"https://arxiv.org/pdf/2501.09328v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09982v1","updated":"2025-01-17T06:46:10Z","published":"2025-01-17T06:46:10Z","title":"RichSpace: Enriching Text-to-Video Prompt Space via Text Embedding\n  Interpolation","summary":"  Text-to-video generation models have made impressive progress, but they still\nstruggle with generating videos with complex features. This limitation often\narises from the inability of the text encoder to produce accurate embeddings,\nwhich hinders the video generation model. In this work, we propose a novel\napproach to overcome this challenge by selecting the optimal text embedding\nthrough interpolation in the embedding space. We demonstrate that this method\nenables the video generation model to produce the desired videos. Additionally,\nwe introduce a simple algorithm using perpendicular foot embeddings and cosine\nsimilarity to identify the optimal interpolation embedding. Our findings\nhighlight the importance of accurate text embeddings and offer a pathway for\nimproving text-to-video generation performance.\n","authors":["Yuefan Cao","Chengyue Gong","Xiaoyu Li","Yingyu Liang","Zhizhou Sha","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2501.09982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09980v1","updated":"2025-01-17T06:43:03Z","published":"2025-01-17T06:43:03Z","title":"Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm\n  Hemodynamics","summary":"  Intracranial aneurysm (IA) is a common cerebrovascular disease that is\nusually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if\nruptured. Although clinical practice is usually based on individual factors and\nmorphological features of the aneurysm, its pathophysiology and hemodynamic\nmechanisms remain controversial. To address the limitations of current\nresearch, this study constructed a comprehensive hemodynamic dataset of\nintracranial aneurysms. The dataset is based on 466 real aneurysm models, and\n10,000 synthetic models were generated by resection and deformation operations,\nincluding 466 aneurysm-free models and 9,534 deformed aneurysm models. The\ndataset also provides medical image-like segmentation mask files to support\ninsightful analysis. In addition, the dataset contains hemodynamic data\nmeasured at eight steady-state flow rates (0.001 to 0.004 kg/s), including\ncritical parameters such as flow velocity, pressure, and wall shear stress,\nproviding a valuable resource for investigating aneurysm pathogenesis and\nclinical prediction. This dataset will help advance the understanding of the\npathologic features and hemodynamic mechanisms of intracranial aneurysms and\nsupport in-depth research in related fields. Dataset hosted at\nhttps://github.com/Xigui-Li/Aneumo.\n","authors":["Xigui Li","Yuanye Zhou","Feiyang Xiao","Xin Guo","Yichi Zhang","Chen Jiang","Jianchao Ge","Xiansheng Wang","Qimeng Wang","Taiwei Zhang","Chensen Lin","Yuan Cheng","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2501.09980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09972v1","updated":"2025-01-17T06:30:11Z","published":"2025-01-17T06:30:11Z","title":"GVMGen: A General Video-to-Music Generation Model with Hierarchical\n  Attentions","summary":"  Composing music for video is essential yet challenging, leading to a growing\ninterest in automating music generation for video applications. Existing\napproaches often struggle to achieve robust music-video correspondence and\ngenerative diversity, primarily due to inadequate feature alignment methods and\ninsufficient datasets. In this study, we present General Video-to-Music\nGeneration model (GVMGen), designed for generating high-related music to the\nvideo input. Our model employs hierarchical attentions to extract and align\nvideo features with music in both spatial and temporal dimensions, ensuring the\npreservation of pertinent features while minimizing redundancy. Remarkably, our\nmethod is versatile, capable of generating multi-style music from different\nvideo inputs, even in zero-shot scenarios. We also propose an evaluation model\nalong with two novel objective metrics for assessing video-music alignment.\nAdditionally, we have compiled a large-scale dataset comprising diverse types\nof video-music pairs. Experimental results demonstrate that GVMGen surpasses\nprevious models in terms of music-video correspondence, generative diversity,\nand application universality.\n","authors":["Heda Zuo","Weitao You","Junxian Wu","Shihong Ren","Pei Chen","Mingxu Zhou","Yujia Lu","Lingyun Sun"],"pdf_url":"https://arxiv.org/pdf/2501.09972v1.pdf","comment":"Accepted by the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25)"},{"id":"http://arxiv.org/abs/2501.09967v1","updated":"2025-01-17T06:16:57Z","published":"2025-01-17T06:16:57Z","title":"Explainable artificial intelligence (XAI): from inherent explainability\n  to large language models","summary":"  Artificial Intelligence (AI) has continued to achieve tremendous success in\nrecent times. However, the decision logic of these frameworks is often not\ntransparent, making it difficult for stakeholders to understand, interpret or\nexplain their behavior. This limitation hinders trust in machine learning\nsystems and causes a general reluctance towards their adoption in practical\napplications, particularly in mission-critical domains like healthcare and\nautonomous driving. Explainable AI (XAI) techniques facilitate the\nexplainability or interpretability of machine learning models, enabling users\nto discern the basis of the decision and possibly avert undesirable behavior.\nThis comprehensive survey details the advancements of explainable AI methods,\nfrom inherently interpretable models to modern approaches for achieving\ninterpretability of various black box models, including large language models\n(LLMs). Additionally, we review explainable AI techniques that leverage LLM and\nvision-language model (VLM) frameworks to automate or improve the\nexplainability of other machine learning models. The use of LLM and VLM as\ninterpretability methods particularly enables high-level, semantically\nmeaningful explanations of model decisions and behavior. Throughout the paper,\nwe highlight the scientific principles, strengths and weaknesses of\nstate-of-the-art methods and outline different areas of improvement. Where\nappropriate, we also present qualitative and quantitative comparison results of\nvarious methods to show how they compare. Finally, we discuss the key\nchallenges of XAI and directions for future research.\n","authors":["Fuseini Mumuni","Alhassan Mumuni"],"pdf_url":"https://arxiv.org/pdf/2501.09967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.13632v4","updated":"2025-01-17T06:09:13Z","published":"2023-12-21T07:48:54Z","title":"TraceFL: Interpretability-Driven Debugging in Federated Learning via\n  Neuron Provenance","summary":"  In Federated Learning, clients train models on local data and send updates to\na central server, which aggregates them into a global model using a fusion\nalgorithm. This collaborative yet privacy-preserving training comes at a cost.\nFL developers face significant challenges in attributing global model\npredictions to specific clients. Localizing responsible clients is a crucial\nstep towards (a) excluding clients primarily responsible for incorrect\npredictions and (b) encouraging clients who contributed high-quality models to\ncontinue participating in the future. Existing ML debugging approaches are\ninherently inapplicable as they are designed for single-model, centralized\ntraining.\n  We introduce TraceFL, a fine-grained neuron provenance capturing mechanism\nthat identifies clients responsible for a global model's prediction by tracking\nthe flow of information from individual clients to the global model. Since\ninference on different inputs activates a different set of neurons of the\nglobal model, TraceFL dynamically quantifies the significance of the global\nmodel's neurons in a given prediction, identifying the most crucial neurons in\nthe global model. It then maps them to the corresponding neurons in every\nparticipating client to determine each client's contribution, ultimately\nlocalizing the responsible client. We evaluate TraceFL on six datasets,\nincluding two real-world medical imaging datasets and four neural networks,\nincluding advanced models such as GPT. TraceFL achieves 99% accuracy in\nlocalizing the responsible client in FL tasks spanning both image and text\nclassification tasks. At a time when state-of-the-artML debugging approaches\nare mostly domain-specific (e.g., image classification only), TraceFL is the\nfirst technique to enable highly accurate automated reasoning across a wide\nrange of FL applications.\n","authors":["Waris Gill","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2312.13632v4.pdf","comment":"Accepted at 2025 IEEE/ACM 47th International Conference on Software\n  Engineering (ICSE)"},{"id":"http://arxiv.org/abs/2411.05844v2","updated":"2025-01-17T05:33:54Z","published":"2024-11-06T15:32:28Z","title":"LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation\n  for Design Space Exploration","summary":"  GraphRAG integrates (knowledge) graphs with large language models (LLMs) to\nimprove reasoning accuracy and contextual relevance. Despite its promising\napplications and strong relevance to multiple research communities, such as\ndatabases and natural language processing, GraphRAG currently lacks modular\nworkflow analysis, systematic solution frameworks, and insightful empirical\nstudies. To bridge these gaps, we propose LEGO-GraphRAG, a modular framework\nthat enables: 1) fine-grained decomposition of the GraphRAG workflow, 2)\nsystematic classification of existing techniques and implemented GraphRAG\ninstances, and 3) creation of new GraphRAG instances. Our framework facilitates\ncomprehensive empirical studies of GraphRAG on large-scale real-world graphs\nand diverse query sets, revealing insights into balancing reasoning quality,\nruntime efficiency, and token or GPU cost, that are essential for building\nadvanced GraphRAG systems.\n","authors":["Yukun Cao","Zengyi Gao","Zhiyang Li","Xike Xie","Kevin Zhou","Jianliang Xu"],"pdf_url":"https://arxiv.org/pdf/2411.05844v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09284v2","updated":"2025-01-17T04:59:32Z","published":"2025-01-16T04:17:56Z","title":"SEAL: Entangled White-box Watermarks on Low-Rank Adaptation","summary":"  Recently, LoRA and its variants have become the de facto strategy for\ntraining and sharing task-specific versions of large pretrained models, thanks\nto their efficiency and simplicity. However, the issue of copyright protection\nfor LoRA weights, especially through watermark-based techniques, remains\nunderexplored. To address this gap, we propose SEAL (SEcure wAtermarking on\nLoRA weights), the universal whitebox watermarking for LoRA. SEAL embeds a\nsecret, non-trainable matrix between trainable LoRA weights, serving as a\npassport to claim ownership. SEAL then entangles the passport with the LoRA\nweights through training, without extra loss for entanglement, and distributes\nthe finetuned weights after hiding the passport. When applying SEAL, we\nobserved no performance degradation across commonsense reasoning,\ntextual/visual instruction tuning, and text-to-image synthesis tasks. We\ndemonstrate that SEAL is robust against a variety of known attacks: removal,\nobfuscation, and ambiguity attacks.\n","authors":["Giyeong Oh","Saejin Kim","Woohyun Cho","Sangkyu Lee","Jiwan Chung","Dokyung Song","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2501.09284v2.pdf","comment":"Author name corrected"},{"id":"http://arxiv.org/abs/2501.09954v1","updated":"2025-01-17T04:57:42Z","published":"2025-01-17T04:57:42Z","title":"AIRCHITECT v2: Learning the Hardware Accelerator Design Space through\n  Unified Representations","summary":"  Design space exploration (DSE) plays a crucial role in enabling custom\nhardware architectures, particularly for emerging applications like AI, where\noptimized and specialized designs are essential. With the growing complexity of\ndeep neural networks (DNNs) and the introduction of advanced foundational\nmodels (FMs), the design space for DNN accelerators is expanding at an\nexponential rate. Additionally, this space is highly non-uniform and\nnon-convex, making it increasingly difficult to navigate and optimize.\nTraditional DSE techniques rely on search-based methods, which involve\niterative sampling of the design space to find the optimal solution. However,\nthis process is both time-consuming and often fails to converge to the global\noptima for such design spaces. Recently, AIrchitect v1, the first attempt to\naddress the limitations of search-based techniques, transformed DSE into a\nconstant-time classification problem using recommendation networks. In this\nwork, we propose AIrchitect v2, a more accurate and generalizable\nlearning-based DSE technique applicable to large-scale design spaces that\novercomes the shortcomings of earlier approaches. Specifically, we devise an\nencoder-decoder transformer model that (a) encodes the complex design space\ninto a uniform intermediate representation using contrastive learning and (b)\nleverages a novel unified representation blending the advantages of\nclassification and regression to effectively explore the large DSE space\nwithout sacrificing accuracy. Experimental results evaluated on 10^5 real DNN\nworkloads demonstrate that, on average, AIrchitect v2 outperforms existing\ntechniques by 15% in identifying optimal design points. Furthermore, to\ndemonstrate the generalizability of our method, we evaluate performance on\nunseen model workloads (LLMs) and attain a 1.7x improvement in inference\nlatency on the identified hardware architecture.\n","authors":["Jamin Seo","Akshat Ramachandran","Yu-Chuan Chuang","Anirudh Itagi","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2501.09954v1.pdf","comment":"Accepted to DATE 2025"},{"id":"http://arxiv.org/abs/2309.10444v5","updated":"2025-01-17T04:45:45Z","published":"2023-09-19T09:04:15Z","title":"Exploring Iterative Enhancement for Improving Learnersourced\n  Multiple-Choice Question Explanations with Large Language Models","summary":"  Large language models exhibit superior capabilities in processing and\nunderstanding language, yet their applications in educational contexts remain\nunderexplored. Learnersourcing enhances learning by engaging students in\ncreating their own educational content. When learnersourcing multiple-choice\nquestions, creating explanations for the solution of a question is a crucial\nstep; it helps other students understand the solution and promotes a deeper\nunderstanding of related concepts. However, it is often difficult for students\nto craft effective solution explanations, due to limited subject understanding.\nTo help scaffold the task of automated explanation generation, we present and\nevaluate a framework called \"ILearner-LLM\", that iteratively enhances the\ngenerated explanations for the given questions with large language models.\nComprising an explanation generation model and an explanation evaluation model,\nthe framework generates high-quality student-aligned explanations by\niteratively feeding the quality rating score from the evaluation model back\ninto the instruction prompt of the explanation generation model. Experimental\nresults demonstrate the effectiveness of our ILearner-LLM on LLaMA2-13B and\nGPT-4 to generate higher quality explanations that are closer to those written\nby students on five PeerWise datasets. Our findings represent a promising path\nto enrich the learnersourcing experience for students and to enhance the\ncapabilities of large language models for educational applications.\n","authors":["Qiming Bao","Juho Leinonen","Alex Yuxuan Peng","Wanjun Zhong","Gaël Gendron","Timothy Pistotti","Alice Huang","Paul Denny","Michael Witbrock","Jiamou Liu"],"pdf_url":"https://arxiv.org/pdf/2309.10444v5.pdf","comment":"The short version (v4) has been accepted as a non-archival workshop\n  paper at AGI@ICLR 2024, and the full version has been accepted by the main\n  track of AAAI/EAAI 2025"},{"id":"http://arxiv.org/abs/2310.09430v5","updated":"2025-01-17T04:39:38Z","published":"2023-10-13T22:29:15Z","title":"Assessing and Enhancing the Robustness of Large Language Models with\n  Task Structure Variations for Logical Reasoning","summary":"  Large language models (LLMs), such as LLaMA, Alpaca, Vicuna, GPT-3.5 and\nGPT-4, have advanced the performance of AI systems on various natural language\nprocessing tasks to human-like levels. However, their generalisation and\nrobustness when performing logical reasoning has not been sufficiently\nassessed. To comprehensively evaluate this ability, we develop three new\nlogical reasoning datasets named \"ReClor-plus\", \"LogiQA-plus\" and\n\"LogiQAv2-plus\" that extend standard logical reasoning datasets to evaluate the\nrobustness of the LLM's reasoning. For each, we create three subsets: the first\nwith randomly shuffled options, the second with the correct choices replaced by\n\"none of the other options is correct\", and the third with a combination of\nshuffling and substitution. Experiments on these datasets show that these\nsimple augmentations greatly hinder the models' performance. Despite their high\nperformance on the original publicly available datasets, we find that all\nmodels perform poorly on these newly constructed datasets. We also demonstrate\nthat introducing task variations into the training set can markedly improve the\nmodel's performance on both the original and our developed datasets. Finally,\nwe show that applying logic-driven data augmentation for fine-tuning and\nprompting can enhance generalisation in both discriminative and generative\nmodels, offering a path to improving their robustness for tasks involving\nlogical reasoning. Source code and data are made publicly available at\nhttps://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning.\n","authors":["Qiming Bao","Gael Gendron","Alex Yuxuan Peng","Wanjun Zhong","Neset Tan","Yang Chen","Michael Witbrock","Jiamou Liu"],"pdf_url":"https://arxiv.org/pdf/2310.09430v5.pdf","comment":"The short version (v3) was accepted for oral presentation at the\n  first LLM@IJCAI 2023 non-archival symposium, and the full version was\n  accepted by ICONIP 2024"},{"id":"http://arxiv.org/abs/2407.01892v2","updated":"2025-01-17T04:29:47Z","published":"2024-07-02T02:27:46Z","title":"GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial\n  Reasoning","summary":"  Spatial reasoning, an important faculty of human cognition with many\npractical applications, is one of the core commonsense skills that is not\npurely language-based and, for satisfying (as opposed to optimal) solutions,\nrequires some minimum degree of planning. Existing benchmarks of Commonsense\nSpatial Reasoning (CSR) tend to evaluate how Large Language Models (LLMs)\ninterpret text-based spatial $\\textit{descriptions}$ rather than directly\nevaluate a plan produced by the LLM in response to a $\\textit{specific}$\nspatial reasoning problem. In this paper, we construct a large-scale benchmark\ncalled GRASP, which consists of 16,000 grid-based environments where the agent\nis tasked with an energy collection problem. These environments include 100\ngrid instances instantiated using each of the 160 different grid settings,\ninvolving five different energy distributions, two modes of agent starting\nposition, and two distinct obstacle configurations, as well as three kinds of\nagent constraints. Using GRASP, we compare classic baseline approaches, such as\nrandom walk and greedy search methods, with advanced LLMs like GPT-3.5-Turbo,\nGPT-4o, and GPT-o1-mini. The experimental results indicate that even these\nadvanced LLMs struggle to consistently achieve satisfactory solutions.\n","authors":["Zhisheng Tang","Mayank Kejriwal"],"pdf_url":"https://arxiv.org/pdf/2407.01892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17640v2","updated":"2025-01-17T04:26:44Z","published":"2024-09-26T08:44:38Z","title":"T3: A Novel Zero-shot Transfer Learning Framework Iteratively Training\n  on an Assistant Task for a Target Task","summary":"  Long text summarization, gradually being essential for efficiently processing\nlarge volumes of information, stays challenging for Large Language Models\n(LLMs) such as GPT and LLaMA families because of the insufficient open-sourced\ntraining datasets and the high requirement of contextual details dealing. To\naddress the issue, we design a novel zero-shot transfer learning framework,\nabbreviated as T3, to iteratively training a baseline LLM on an assistant task\nfor the target task, where the former should own richer data resources and\nshare structural or semantic similarity with the latter. In practice, T3 is\napproached to deal with the long text summarization task by utilizing question\nanswering as the assistant task, and further validated its effectiveness on the\nBBC summary, NarraSum, FairytaleQA, and NLQuAD datasets, with up to nearly 14%\nimprovement in ROUGE, 35% improvement in BLEU, and 16% improvement in Factscore\ncompared to three baseline LLMs, demonstrating its potential for more\nassistant-target task combinations.\n","authors":["Xindi Tong","Yujin Zhu","Shijian Fan","Liang Xu"],"pdf_url":"https://arxiv.org/pdf/2409.17640v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09949v1","updated":"2025-01-17T04:24:31Z","published":"2025-01-17T04:24:31Z","title":"MultiPruner: Balanced Structure Removal in Foundation Models","summary":"  Recently, state-of-the-art approaches for pruning large pre-trained models\n(LPMs) have demonstrated that the training-free removal of non-critical\nresidual blocks in Transformers is viable for reducing model size, achieving\nresults that outperform previous training-free pruning approaches. Motivated by\nthese findings, we extend BlockPruner (Zhong et al., 2024) and propose\nMultiPruner, a pruning approach that surpasses recent training-free pruning\nmethods by adopting a multidimensional, iterative, fine-grained pruning\nstrategy. In MultiPruner, multidimensional pruning reinstates the structural\nbalance in block-pruned models by sequentially compressing along three\ndimensions: i) residual blocks, ii) channels of multilayer perceptrons (MLP),\nand iii) attention heads. This solution enhances zero-shot accuracy on\ndownstream tasks compared to other techniques while improving model compression\nratios, producing compressed models with fewer computing and memory\nrequirements. Extensive experiments demonstrate the advantages of the proposed\nmethod across various large pre-trained models. The code and pruning\nconfigurations are available at\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.\n","authors":["J. Pablo Muñoz","Jinjie Yuan","Nilesh Jain"],"pdf_url":"https://arxiv.org/pdf/2501.09949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.11156v4","updated":"2025-01-17T04:21:47Z","published":"2023-03-17T17:53:19Z","title":"Can AI-Generated Text be Reliably Detected?","summary":"  Large Language Models (LLMs) perform impressively well in various\napplications. However, the potential for misuse of these models in activities\nsuch as plagiarism, generating fake news, and spamming has raised concern about\ntheir responsible use. Consequently, the reliable detection of AI-generated\ntext has become a critical area of research. AI text detectors have shown to be\neffective under their specific settings. In this paper, we stress-test the\nrobustness of these AI text detectors in the presence of an attacker. We\nintroduce recursive paraphrasing attack to stress test a wide range of\ndetection schemes, including the ones using the watermarking as well as neural\nnetwork-based detectors, zero shot classifiers, and retrieval-based detectors.\nOur experiments conducted on passages, each approximately 300 tokens long,\nreveal the varying sensitivities of these detectors to our attacks. Our\nfindings indicate that while our recursive paraphrasing method can\nsignificantly reduce detection rates, it only slightly degrades text quality in\nmany cases, highlighting potential vulnerabilities in current detection systems\nin the presence of an attacker. Additionally, we investigate the susceptibility\nof watermarked LLMs to spoofing attacks aimed at misclassifying human-written\ntext as AI-generated. We demonstrate that an attacker can infer hidden AI text\nsignatures without white-box access to the detection method, potentially\nleading to reputational risks for LLM developers. Finally, we provide a\ntheoretical framework connecting the AUROC of the best possible detector to the\nTotal Variation distance between human and AI text distributions. This analysis\noffers insights into the fundamental challenges of reliable detection as\nlanguage models continue to advance. Our code is publicly available at\nhttps://github.com/vinusankars/Reliability-of-AI-text-detectors.\n","authors":["Vinu Sankar Sadasivan","Aounon Kumar","Sriram Balasubramanian","Wenxiao Wang","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2303.11156v4.pdf","comment":"Published in Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2501.09948v1","updated":"2025-01-17T04:20:43Z","published":"2025-01-17T04:20:43Z","title":"AI Explainability for Power Electronics: From a Lipschitz Continuity\n  Perspective","summary":"  Lifecycle management of power converters continues to thrive with emerging\nartificial intelligence (AI) solutions, yet AI mathematical explainability\nremains unexplored in power electronics (PE) community. The lack of theoretical\nrigor challenges adoption in mission-critical applications. Therefore, this\nletter proposes a generic framework to evaluate mathematical explainability,\nhighlighting inference stability and training convergence from a Lipschitz\ncontinuity perspective. Inference stability governs consistent outputs under\ninput perturbations, essential for robust real-time control and fault\ndiagnosis. Training convergence guarantees stable learning dynamics,\nfacilitating accurate modeling in PE contexts. Additionally, a Lipschitz-aware\nlearning rate selection strategy is introduced to accelerate convergence while\nmitigating overshoots and oscillations. The feasibility of the proposed\nLipschitz-oriented framework is demonstrated by validating the mathematical\nexplainability of a state-of-the-art physics-in-architecture neural network,\nand substantiated through empirical case studies on dual-active-bridge\nconverters. This letter serves as a clarion call for the PE community to\nembrace mathematical explainability, heralding a transformative era of\ntrustworthy and explainable AI solutions that potentially redefine the future\nof power electronics.\n","authors":["Xinze Li","Fanfan Lin","Homer Alan Mantooth","Juan José Rodríguez-Andina"],"pdf_url":"https://arxiv.org/pdf/2501.09948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09946v1","updated":"2025-01-17T04:00:50Z","published":"2025-01-17T04:00:50Z","title":"Client-Centric Federated Adaptive Optimization","summary":"  Federated Learning (FL) is a distributed learning paradigm where clients\ncollaboratively train a model while keeping their own data private. With an\nincreasing scale of clients and models, FL encounters two key challenges,\nclient drift due to a high degree of statistical/system heterogeneity, and lack\nof adaptivity. However, most existing FL research is based on unrealistic\nassumptions that virtually ignore system heterogeneity. In this paper, we\npropose Client-Centric Federated Adaptive Optimization, which is a class of\nnovel federated adaptive optimization approaches. We enable several features in\nthis framework such as arbitrary client participation, asynchronous server\naggregation, and heterogeneous local computing, which are ubiquitous in\nreal-world FL systems but are missed in most existing works. We provide a\nrigorous convergence analysis of our proposed framework for general nonconvex\nobjectives, which is shown to converge with the best-known rate. Extensive\nexperiments show that our approaches consistently outperform the baseline by a\nlarge margin across benchmarks.\n","authors":["Jianhui Sun","Xidong Wu","Heng Huang","Aidong Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.09946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16950v5","updated":"2025-01-17T03:43:53Z","published":"2024-03-25T17:11:28Z","title":"Aligning with Human Judgement: The Role of Pairwise Preference in Large\n  Language Model Evaluators","summary":"  Large Language Models (LLMs) have demonstrated promising capabilities as\nautomatic evaluators in assessing the quality of generated natural language.\nHowever, LLMs still exhibit biases in evaluation and often struggle to generate\ncoherent evaluations that align with human assessments. In this work, we first\nconduct a systematic study of the misalignment between LLM evaluators and human\nevaluation, revealing that existing calibration methods aimed at mitigating\nbiases of LLMs are insufficient for effectively aligning LLM evaluators.\nInspired by the use of preference data in RLHF, we formulate the evaluation as\na ranking problem and introduce Pairwise-preference Search (PAIRS), an\nuncertainty-guided search-based rank aggregation method that employs LLMs to\nconduct pairwise comparisons locally and efficiently ranks candidate texts\nglobally. PAIRS achieves state-of-the-art performance on representative\nevaluation tasks in long-form generations and demonstrates significant\nimprovements over direct scoring. Furthermore, we provide insights into the\nrole of pairwise preference in quantifying the transitivity of LLMs and\ndemonstrate how PAIRS benefits from calibration using debiased pairwise\nevaluations.\n","authors":["Yinhong Liu","Han Zhou","Zhijiang Guo","Ehsan Shareghi","Ivan Vulić","Anna Korhonen","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2403.16950v5.pdf","comment":"This paper has been accepted by COLM 2024"},{"id":"http://arxiv.org/abs/2404.02933v4","updated":"2025-01-17T03:19:16Z","published":"2024-04-03T01:09:41Z","title":"NL2KQL: From Natural Language to Kusto Query","summary":"  Data is growing rapidly in volume and complexity. Proficiency in database\nquery languages is pivotal for crafting effective queries. As coding assistants\nbecome more prevalent, there is significant opportunity to enhance database\nquery languages. The Kusto Query Language (KQL) is a widely used query language\nfor large semi-structured data such as logs, telemetries, and time-series for\nbig data analytics platforms. This paper introduces NL2KQL an innovative\nframework that uses large language models (LLMs) to convert natural language\nqueries (NLQs) to KQL queries. The proposed NL2KQL framework includes several\nkey components: Schema Refiner which narrows down the schema to its most\npertinent elements; the Few-shot Selector which dynamically selects relevant\nexamples from a few-shot dataset; and the Query Refiner which repairs syntactic\nand semantic errors in KQL queries. Additionally, this study outlines a method\nfor generating large datasets of synthetic NLQ-KQL pairs which are valid within\na specific database contexts. To validate NL2KQL's performance, we utilize an\narray of online (based on query execution) and offline (based on query parsing)\nmetrics. Through ablation studies, the significance of each framework component\nis examined, and the datasets used for benchmarking are made publicly\navailable. This work is the first of its kind and is compared with available\nbaselines to demonstrate its effectiveness.\n","authors":["Xinye Tang","Amir H. Abdi","Jeremias Eichelbaum","Mahan Das","Alex Klein","Nihal Irmak Pakis","William Blum","Daniel L Mace","Tanvi Raja","Namrata Padmanabhan","Ye Xing"],"pdf_url":"https://arxiv.org/pdf/2404.02933v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09934v1","updated":"2025-01-17T03:15:03Z","published":"2025-01-17T03:15:03Z","title":"HEART: Achieving Timely Multi-Model Training for\n  Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning","summary":"  The rapid growth of AI-enabled Internet of Vehicles (IoV) calls for efficient\nmachine learning (ML) solutions that can handle high vehicular mobility and\ndecentralized data. This has motivated the emergence of Hierarchical Federated\nLearning over vehicle-edge-cloud architectures (VEC-HFL). Nevertheless, one\naspect which is underexplored in the literature on VEC-HFL is that vehicles\noften need to execute multiple ML tasks simultaneously, where this multi-model\ntraining environment introduces crucial challenges. First, improper aggregation\nrules can lead to model obsolescence and prolonged training times. Second,\nvehicular mobility may result in inefficient data utilization by preventing the\nvehicles from returning their models to the network edge. Third, achieving a\nbalanced resource allocation across diverse tasks becomes of paramount\nimportance as it majorly affects the effectiveness of collaborative training.\nWe take one of the first steps towards addressing these challenges via\nproposing a framework for multi-model training in dynamic VEC-HFL with the goal\nof minimizing global training latency while ensuring balanced training across\nvarious tasks-a problem that turns out to be NP-hard. To facilitate timely\nmodel training, we introduce a hybrid synchronous-asynchronous aggregation\nrule. Building on this, we present a novel method called Hybrid Evolutionary\nAnd gReedy allocaTion (HEART). The framework operates in two stages: first, it\nachieves balanced task scheduling through a hybrid heuristic approach that\ncombines improved Particle Swarm Optimization (PSO) and Genetic Algorithms\n(GA); second, it employs a low-complexity greedy algorithm to determine the\ntraining priority of assigned tasks on vehicles. Experiments on real-world\ndatasets demonstrate the superiority of HEART over existing methods.\n","authors":["Xiaohong Yang","Minghui Liwang","Xianbin Wang","Zhipeng Cheng","Seyyedali Hosseinalipour","Huaiyu Dai","Zhenzhen Jiao"],"pdf_url":"https://arxiv.org/pdf/2501.09934v1.pdf","comment":"14 pages, 6 figures,"},{"id":"http://arxiv.org/abs/2501.09929v1","updated":"2025-01-17T02:55:23Z","published":"2025-01-17T02:55:23Z","title":"Steering Large Language Models with Feature Guided Activation Additions","summary":"  Effective and reliable control over large language model (LLM) behavior is a\nsignificant challenge. While activation steering methods, which add steering\nvectors to a model's hidden states, are a promising approach, existing\ntechniques often lack precision and interpretability in how they influence\nmodel outputs. We introduce Feature Guided Activation Additions (FGAA), a novel\nactivation steering method that leverages insights from Contrastive Activation\nAddition (CAA) and Sparse Autoencoder-Targeted Steering (SAE-TS). By operating\nin the latent space of a Sparse Autoencoder (SAE) and employing optimization\ntechniques to select desired SAE features, FGAA constructs precise steering\nvectors that provide better steering effects while maintaining coherence of\nsteered model outputs. In this regard, evaluations on Gemma-2-2B and Gemma-2-9B\nmodels across various steering tasks demonstrate that FGAA outperforms existing\nsteering methods of CAA, SAE decoder steering, and SAE-TS. Our results also\nhighlight important trade-offs between steering scale and general model\ncapabilities that are consistent across all tested steering methods.\n","authors":["Samuel Soo","Wesley Teng","Chandrasekaran Balaganesh"],"pdf_url":"https://arxiv.org/pdf/2501.09929v1.pdf","comment":"7 maintext pages, 14 appendix pages"},{"id":"http://arxiv.org/abs/2408.08881v3","updated":"2025-01-17T02:51:41Z","published":"2024-08-03T20:41:35Z","title":"Challenge Summary U-MedSAM: Uncertainty-aware MedSAM for Medical Image\n  Segmentation","summary":"  Medical Image Foundation Models have proven to be powerful tools for mask\nprediction across various datasets. However, accurately assessing the\nuncertainty of their predictions remains a significant challenge. To address\nthis, we propose a new model, U-MedSAM, which integrates the MedSAM model with\nan uncertainty-aware loss function and the Sharpness-Aware Minimization\n(SharpMin) optimizer. The uncertainty-aware loss function automatically\ncombines region-based, distribution-based, and pixel-based loss designs to\nenhance segmentation accuracy and robustness. SharpMin improves generalization\nby finding flat minima in the loss landscape, thereby reducing overfitting. Our\nmethod was evaluated in the CVPR24 MedSAM on Laptop challenge, where U-MedSAM\ndemonstrated promising performance.\n","authors":["Xin Wang","Xiaoyu Liu","Peng Huang","Pu Huang","Shu Hu","Hongtu Zhu"],"pdf_url":"https://arxiv.org/pdf/2408.08881v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2405.17496"},{"id":"http://arxiv.org/abs/2501.09928v1","updated":"2025-01-17T02:48:29Z","published":"2025-01-17T02:48:29Z","title":"Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective\n  Retrieval-Augmented LLMs","summary":"  Dialogue benchmarks are crucial in training and evaluating chatbots engaging\nin domain-specific conversations. Knowledge graphs (KGs) represent semantically\nrich and well-organized data spanning various domains, such as DBLP, DBpedia,\nand YAGO. Traditionally, dialogue benchmarks have been manually created from\ndocuments, neglecting the potential of KGs in automating this process. Some\nquestion-answering benchmarks are automatically generated using extensive\npreprocessing from KGs, but they do not support dialogue generation. This paper\nintroduces Chatty-Gen, a novel multi-stage retrieval-augmented generation\nplatform for automatically generating high-quality dialogue benchmarks tailored\nto a specific domain using a KG. Chatty-Gen decomposes the generation process\ninto manageable stages and uses assertion rules for automatic validation\nbetween stages. Our approach enables control over intermediate results to\nprevent time-consuming restarts due to hallucinations. It also reduces reliance\non costly and more powerful commercial LLMs. Chatty-Gen eliminates upfront\nprocessing of the entire KG using efficient query-based retrieval to find\nrepresentative subgraphs based on the dialogue context. Our experiments with\nseveral real and large KGs demonstrate that Chatty-Gen significantly\noutperforms state-of-the-art systems and ensures consistent model and system\nperformance across multiple LLMs of diverse capabilities, such as GPT-4o,\nGemini 1.5, Llama 3, and Mistral.\n","authors":["Reham Omar","Omij Mangukiya","Essam Mansour"],"pdf_url":"https://arxiv.org/pdf/2501.09928v1.pdf","comment":"The paper is publsihed in SIGMOD 2025"},{"id":"http://arxiv.org/abs/2501.09927v1","updated":"2025-01-17T02:47:25Z","published":"2025-01-17T02:47:25Z","title":"IE-Bench: Advancing the Measurement of Text-Driven Image Editing for\n  Human Perception Alignment","summary":"  Recent advances in text-driven image editing have been significant, yet the\ntask of accurately evaluating these edited images continues to pose a\nconsiderable challenge. Different from the assessment of text-driven image\ngeneration, text-driven image editing is characterized by simultaneously\nconditioning on both text and a source image. The edited images often retain an\nintrinsic connection to the original image, which dynamically change with the\nsemantics of the text. However, previous methods tend to solely focus on\ntext-image alignment or have not aligned with human perception. In this work,\nwe introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to\nenhance the assessment of text-driven edited images. IE-Bench includes a\ndatabase contains diverse source images, various editing prompts and the\ncorresponding results different editing methods, and total 3,010 Mean Opinion\nScores (MOS) provided by 25 human subjects. Furthermore, we introduce IE-QA, a\nmulti-modality source-aware quality assessment method for text-driven image\nediting. To the best of our knowledge, IE-Bench offers the first IQA dataset\nand model tailored for text-driven image editing. Extensive experiments\ndemonstrate IE-QA's superior subjective-alignments on the text-driven image\nediting task compared with previous metrics. We will make all related data and\ncode available to the public.\n","authors":["Shangkun Sun","Bowen Qu","Xiaoyu Liang","Songlin Fan","Wei Gao"],"pdf_url":"https://arxiv.org/pdf/2501.09927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09926v1","updated":"2025-01-17T02:47:14Z","published":"2025-01-17T02:47:14Z","title":"ForestProtector: An IoT Architecture Integrating Machine Vision and Deep\n  Reinforcement Learning for Efficient Wildfire Monitoring","summary":"  Early detection of forest fires is crucial to minimizing the environmental\nand socioeconomic damage they cause. Indeed, a fire's duration directly\ncorrelates with the difficulty and cost of extinguishing it. For instance, a\nfire burning for 1 minute might require 1 liter of water to extinguish, while a\n2-minute fire could demand 100 liters, and a 10-minute fire might necessitate\n1,000 liters. On the other hand, existing fire detection systems based on novel\ntechnologies (e.g., remote sensing, PTZ cameras, UAVs) are often expensive and\nrequire human intervention, making continuous monitoring of large areas\nimpractical. To address this challenge, this work proposes a low-cost forest\nfire detection system that utilizes a central gateway device with computer\nvision capabilities to monitor a 360{\\deg} field of view for smoke at long\ndistances. A deep reinforcement learning agent enhances surveillance by\ndynamically controlling the camera's orientation, leveraging real-time sensor\ndata (smoke levels, ambient temperature, and humidity) from distributed IoT\ndevices. This approach enables automated wildfire monitoring across expansive\nareas while reducing false positives.\n","authors":["Kenneth Bonilla-Ormachea","Horacio Cuizaga","Edwin Salcedo","Sebastian Castro","Sergio Fernandez-Testa","Misael Mamani"],"pdf_url":"https://arxiv.org/pdf/2501.09926v1.pdf","comment":"Accepted for publication in the proceedings of the 11th International\n  Conference on Automation, Robotics, and Applications (ICARA 2025)"},{"id":"http://arxiv.org/abs/2501.09923v1","updated":"2025-01-17T02:40:04Z","published":"2025-01-17T02:40:04Z","title":"Study on a Fast Solver for Combined Field Integral Equations of 3D\n  Conducting Bodies Based on Graph Neural Networks","summary":"  In this paper, we present a graph neural networks (GNNs)-based fast solver\n(GraphSolver) for solving combined field integral equations (CFIEs) of 3D\nconducting bodies. Rao-Wilton-Glisson (RWG) basis functions are employed to\ndiscretely and accurately represent the geometry of 3D conducting bodies. A\nconcise and informative graph representation is then constructed by treating\neach RWG function as a node in the graph, enabling the flow of current between\nnodes. With the transformed graphs, GraphSolver is developed to directly\npredict real and imaginary parts of the x, y and z components of the surface\ncurrent densities at each node (RWG function). Numerical results demonstrate\nthe efficacy of GraphSolver in solving CFIEs for 3D conducting bodies with\nvarying levels of geometric complexity, including basic 3D targets,\nmissile-shaped targets, and airplane-shaped targets.\n","authors":["Tao Shan","Xin Zhang","Di Wu"],"pdf_url":"https://arxiv.org/pdf/2501.09923v1.pdf","comment":"10 pages,11 figures"},{"id":"http://arxiv.org/abs/2501.09918v1","updated":"2025-01-17T02:20:52Z","published":"2025-01-17T02:20:52Z","title":"GenSC-6G: A Prototype Testbed for Integrated Generative AI, Quantum, and\n  Semantic Communication","summary":"  We introduce a prototyping testbed, GenSC-6G, developed to generate a\ncomprehensive dataset that supports the integration of generative artificial\nintelligence (AI), quantum computing, and semantic communication for emerging\nsixth-generation (6G) applications. The GenSC-6G dataset is designed with\nnoise-augmented synthetic data optimized for semantic decoding, classification,\nand localization tasks, significantly enhancing flexibility for diverse\nAI-driven communication applications. This adaptable prototype supports\nseamless modifications across baseline models, communication modules, and\ngoal-oriented decoders. Case studies demonstrate its application in lightweight\nclassification, semantic upsampling, and edge-based language inference under\nnoise conditions. The GenSC-6G dataset serves as a scalable and robust resource\nfor developing goal-oriented communication systems tailored to the growing\ndemands of 6G networks.\n","authors":["Brian E. Arfeto","Shehbaz Tariq","Uman Khalid","Trung Q. Duong","Hyundong Shin"],"pdf_url":"https://arxiv.org/pdf/2501.09918v1.pdf","comment":"SUBMITTED FOR PUBLICATION IN IEEE COMMUNICATIONS MAGAZINE"},{"id":"http://arxiv.org/abs/2501.09913v1","updated":"2025-01-17T02:02:12Z","published":"2025-01-17T02:02:12Z","title":"Towards A Litmus Test for Common Sense","summary":"  This paper is the second in a planned series aimed at envisioning a path to\nsafe and beneficial artificial intelligence. Building on the conceptual\ninsights of \"Common Sense Is All You Need,\" we propose a more formal litmus\ntest for common sense, adopting an axiomatic approach that combines minimal\nprior knowledge (MPK) constraints with diagonal or Godel-style arguments to\ncreate tasks beyond the agent's known concept set. We discuss how this approach\napplies to the Abstraction and Reasoning Corpus (ARC), acknowledging\ntraining/test data constraints, physical or virtual embodiment, and large\nlanguage models (LLMs). We also integrate observations regarding emergent\ndeceptive hallucinations, in which more capable AI systems may intentionally\nfabricate plausible yet misleading outputs to disguise knowledge gaps. The\noverarching theme is that scaling AI without ensuring common sense risks\nintensifying such deceptive tendencies, thereby undermining safety and trust.\nAligning with the broader goal of developing beneficial AI without causing\nharm, our axiomatic litmus test not only diagnoses whether an AI can handle\ntruly novel concepts but also provides a stepping stone toward an ethical,\nreliable foundation for future safe, beneficial, and aligned artificial\nintelligence.\n","authors":["Hugo Latapie"],"pdf_url":"https://arxiv.org/pdf/2501.09913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.20550v2","updated":"2025-01-17T01:44:44Z","published":"2024-09-30T17:51:15Z","title":"LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism,\n  and Mitigation","summary":"  Code generation aims to automatically generate code from input requirements,\nsignificantly enhancing development efficiency. Recent large language models\n(LLMs) based approaches have shown promising results and revolutionized code\ngeneration task. Despite the promising performance, LLMs often generate\ncontents with hallucinations, especially for the code generation scenario\nrequiring the handling of complex contextual dependencies in practical\ndevelopment process. Although previous study has analyzed hallucinations in\nLLM-powered code generation, the study is limited to standalone function\ngeneration. In this paper, we conduct an empirical study to study the\nphenomena, mechanism, and mitigation of LLM hallucinations within more\npractical and complex development contexts in repository-level generation\nscenario. First, we manually examine the code generation results from six\nmainstream LLMs to establish a hallucination taxonomy of LLM-generated code.\nNext, we elaborate on the phenomenon of hallucinations, analyze their\ndistribution across different models. We then analyze causes of hallucinations\nand identify four potential factors contributing to hallucinations. Finally, we\npropose an RAG-based mitigation method, which demonstrates consistent\neffectiveness in all studied LLMs. The replication package including code,\ndata, and experimental results is available at\nhttps://github.com/DeepSoftwareAnalytics/LLMCodingHallucination\n","authors":["Ziyao Zhang","Yanlin Wang","Chong Wang","Jiachi Chen","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2409.20550v2.pdf","comment":"Accepted by ISSTA 2025"},{"id":"http://arxiv.org/abs/2402.18540v2","updated":"2025-01-17T01:43:21Z","published":"2024-02-28T18:23:49Z","title":"Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt\n  Templates","summary":"  Public LLMs such as the Llama 2-Chat underwent alignment training and were\nconsidered safe. Recently Qi et al. [2024] reported that even benign\nfine-tuning on seemingly safe datasets can give rise to unsafe behaviors in the\nmodels. The current paper is about methods and best practices to mitigate such\nloss of alignment. We focus on the setting where a public model is fine-tuned\nbefore serving users for specific usage, where the model should improve on the\ndownstream task while maintaining alignment. Through extensive experiments on\nseveral chat models (Meta's Llama 2-Chat, Mistral AI's Mistral 7B Instruct\nv0.2, and OpenAI's GPT-3.5 Turbo), this paper uncovers that the prompt\ntemplates used during fine-tuning and inference play a crucial role in\npreserving safety alignment, and proposes the ``Pure Tuning, Safe Testing''\n(PTST) strategy -- fine-tune models without a safety prompt, but include it at\ntest time. This seemingly counterintuitive strategy incorporates an intended\ndistribution shift to encourage alignment preservation. Fine-tuning experiments\non GSM8K, ChatDoctor, and OpenOrca show that PTST significantly reduces the\nrise of unsafe behaviors.\n","authors":["Kaifeng Lyu","Haoyu Zhao","Xinran Gu","Dingli Yu","Anirudh Goyal","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2402.18540v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.09905v1","updated":"2025-01-17T01:32:18Z","published":"2025-01-17T01:32:18Z","title":"SLIM: Sim-to-Real Legged Instructive Manipulation via Long-Horizon\n  Visuomotor Learning","summary":"  We present a low-cost quadruped manipulation system that solves long-horizon\nreal-world tasks, trained by reinforcement learning purely in simulation. The\nsystem comprises 1) a hierarchical design of a high-level policy for\nvisual-mobile manipulation following instructions, and a low-level policy for\nquadruped movement and limb-control, 2) a progressive policy expansion approach\nfor solving the long-horizon task together with a teacher-student framework for\nefficient high-level training of the high-level visuomotor policy, and 3) a\nsuite of techniques for minimizing sim-to-real gaps.\n  With budget-friendly but limited reliability and performance hardware, and\njust one wrist-mounted RGB camera, the entire system fully trained in\nsimulation achieves high success rates for long horizon tasks involving search,\nmove, grasp, and drop-into, with fluid sim-to-real transfer in a wide variety\nof indoor and outdoor scenes and lighting conditions.Extensive real-world\nevaluations show that on the long horizon mobile manipulation tasks, our system\nachieves good performance when transferred to real both in terms of task\nsuccess rate and execution efficiency. Finally, we discuss the necessity of our\nsim-to-real techniques for legged mobile manipulation, and show their ablation\nperformance.\n","authors":["Haichao Zhang","Haonan Yu","Le Zhao","Andrew Choi","Qinxun Bai","Yiqing Yang","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2501.09905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06120v5","updated":"2025-01-17T01:18:48Z","published":"2024-11-09T09:03:08Z","title":"Evaluating the Propensity of Generative AI for Producing Harmful\n  Disinformation During an Election Cycle","summary":"  Generative Artificial Intelligence offers a powerful tool for adversaries who\nwish to engage in influence operations, such as the Chinese Spamouflage\noperation and the Russian Internet Research Agency effort that both sought to\ninterfere with recent US election cycles. Therefore, this study seeks to\ninvestigate the propensity of current generative AI models for producing\nharmful disinformation during an election cycle. The probability that different\ngenerative AI models produced disinformation when given adversarial prompts was\nevaluated, in addition the associated harm. This allows for the expected harm\nfor each model to be computed and it was discovered that Copilot and Gemini\ntied for the overall safest performance by realizing the lowest expected harm,\nwhile GPT-4o produced the greatest rates of harmful disinformation, resulting\nin much higher expected harm scores. The impact of disinformation category was\nalso investigated and Gemini was safest within the political category of\ndisinformation due to mitigation attempts made by developers during the\nelection, while Copilot was safest for topics related to health. Moreover,\ncharacteristics of adversarial roles were discovered that led to greater\nexpected harm across all models. Finally, classification models were developed\nthat predicted disinformation production based on the conditions considered in\nthis study, which offers insight into factors important for predicting\ndisinformation production. Based on all of these insights, recommendations are\nprovided that seek to mitigate factors that lead to harmful disinformation\nbeing produced by generative AI models. It is hoped that developers will use\nthese insights to improve future models.\n","authors":["Erik J Schlicht"],"pdf_url":"https://arxiv.org/pdf/2411.06120v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04421v2","updated":"2025-01-17T01:11:16Z","published":"2024-09-06T17:30:45Z","title":"RLPF: Reinforcement Learning from Prediction Feedback for User\n  Summarization with LLMs","summary":"  LLM-powered personalization agent systems employ Large Language Models (LLMs)\nto predict users' behavior from their past activities. However, their\neffectiveness often hinges on the ability to effectively leverage extensive,\nlong user historical data due to its inherent noise and length of such data.\nExisting pretrained LLMs may generate summaries that are concise but lack the\nnecessary context for downstream tasks, hindering their utility in\npersonalization systems. To address these challenges, we introduce\nReinforcement Learning from Prediction Feedback (RLPF). RLPF fine-tunes LLMs to\ngenerate concise, human-readable user summaries that are optimized for\ndownstream task performance. By maximizing the usefulness of the generated\nsummaries, RLPF effectively distills extensive user history data while\npreserving essential information for downstream tasks. Our empirical evaluation\ndemonstrates significant improvements in both extrinsic downstream task utility\nand intrinsic summary quality, surpassing baseline methods by up to 22% on\ndownstream task performance and achieving an up to 84.59% win rate on\nFactuality, Abstractiveness, and Readability. RLPF also achieves a remarkable\n74% reduction in context length while improving performance on 16 out of 19\nunseen tasks and/or datasets, showcasing its generalizability. This approach\noffers a promising solution for enhancing LLM personalization by effectively\ntransforming long, noisy user histories into informative and human-readable\nrepresentations.\n","authors":["Jiaxing Wu","Lin Ning","Luyang Liu","Harrison Lee","Neo Wu","Chao Wang","Sushant Prakash","Shawn O'Banion","Bradley Green","Jun Xie"],"pdf_url":"https://arxiv.org/pdf/2409.04421v2.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2411.14593v2","updated":"2025-01-17T01:00:13Z","published":"2024-11-21T21:23:46Z","title":"A Systematic Study of Multi-Agent Deep Reinforcement Learning for Safe\n  and Robust Autonomous Highway Ramp Entry","summary":"  Vehicles today can drive themselves on highways and driverless robotaxis\noperate in major cities, with more sophisticated levels of autonomous driving\nexpected to be available and become more common in the future. Yet, technically\nspeaking, so-called \"Level 5\" (L5) operation, corresponding to full autonomy,\nhas not been achieved. For that to happen, functions such as fully autonomous\nhighway ramp entry must be available, and provide provably safe, and reliably\nrobust behavior to enable full autonomy. We present a systematic study of a\nhighway ramp function that controls the vehicles forward-moving actions to\nminimize collisions with the stream of highway traffic into which a merging\n(ego) vehicle enters. We take a game-theoretic multi-agent (MA) approach to\nthis problem and study the use of controllers based on deep reinforcement\nlearning (DRL). The virtual environment of the MA DRL uses self-play with\nsimulated data where merging vehicles safely learn to control longitudinal\nposition during a taper-type merge. The work presented in this paper extends\nexisting work by studying the interaction of more than two vehicles (agents)\nand does so by systematically expanding the road scene with additional traffic\nand ego vehicles. While previous work on the two-vehicle setting established\nthat collision-free controllers are theoretically impossible in fully\ndecentralized, non-coordinated environments, we empirically show that\ncontrollers learned using our approach are nearly ideal when measured against\nidealized optimal controllers.\n","authors":["Larry Schester","Luis E. Ortiz"],"pdf_url":"https://arxiv.org/pdf/2411.14593v2.pdf","comment":"9 pages, 9 figures; added support ack"},{"id":"http://arxiv.org/abs/2501.09891v1","updated":"2025-01-17T00:41:44Z","published":"2025-01-17T00:41:44Z","title":"Evolving Deeper LLM Thinking","summary":"  We explore an evolutionary search strategy for scaling inference time compute\nin Large Language Models. The proposed approach, Mind Evolution, uses a\nlanguage model to generate, recombine and refine candidate responses. The\nproposed approach avoids the need to formalize the underlying inference problem\nwhenever a solution evaluator is available. Controlling for inference cost, we\nfind that Mind Evolution significantly outperforms other inference strategies\nsuch as Best-of-N and Sequential Revision in natural language planning tasks.\nIn the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more\nthan 98% of the problem instances using Gemini 1.5 Pro without the use of a\nformal solver.\n","authors":["Kuang-Huei Lee","Ian Fischer","Yueh-Hua Wu","Dave Marwood","Shumeet Baluja","Dale Schuurmans","Xinyun Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09890v1","updated":"2025-01-17T00:40:35Z","published":"2025-01-17T00:40:35Z","title":"Exploring the Implementation of AI in Early Onset Interviews to Help\n  Mitigate Bias","summary":"  This paper investigates the application of artificial intelligence (AI) in\nearly-stage recruitment interviews in order to reduce inherent bias,\nspecifically sentiment bias. Traditional interviewers are often subject to\nseveral biases, including interviewer bias, social desirability effects, and\neven confirmation bias. In turn, this leads to non-inclusive hiring practices,\nand a less diverse workforce. This study further analyzes various AI\ninterventions that are present in the marketplace today such as multimodal\nplatforms and interactive candidate assessment tools in order to gauge the\ncurrent market usage of AI in early-stage recruitment. However, this paper aims\nto use a unique AI system that was developed to transcribe and analyze\ninterview dynamics, which emphasize skill and knowledge over emotional\nsentiments. Results indicate that AI effectively minimizes sentiment-driven\nbiases by 41.2%, suggesting its revolutionizing power in companies' recruitment\nprocesses for improved equity and efficiency.\n","authors":["Nishka Lal","Omar Benkraouda"],"pdf_url":"https://arxiv.org/pdf/2501.09890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09597v2","updated":"2025-01-17T00:25:18Z","published":"2024-10-12T17:23:34Z","title":"A Complete Characterization of Learnability for Stochastic Noisy Bandits","summary":"  We study the stochastic noisy bandit problem with an unknown reward function\n$f^*$ in a known function class $\\mathcal{F}$. Formally, a model $M$ maps arms\n$\\pi$ to a probability distribution $M(\\pi)$ of reward. A model class\n$\\mathcal{M}$ is a collection of models. For each model $M$, define its mean\nreward function $f^M(\\pi)=\\mathbb{E}_{r \\sim M(\\pi)}[r]$. In the bandit\nlearning problem, we proceed in rounds, pulling one arm $\\pi$ each round and\nobserving a reward sampled from $M(\\pi)$. With knowledge of $\\mathcal{M}$,\nsupposing that the true model $M\\in \\mathcal{M}$, the objective is to identify\nan arm $\\hat{\\pi}$ of near-maximal mean reward $f^M(\\hat{\\pi})$ with high\nprobability in a bounded number of rounds. If this is possible, then the model\nclass is said to be learnable.\n  Importantly, a result of \\cite{hanneke2023bandit} shows there exist model\nclasses for which learnability is undecidable. However, the model class they\nconsider features deterministic rewards, and they raise the question of whether\nlearnability is decidable for classes containing sufficiently noisy models. For\nthe first time, we answer this question in the positive by giving a complete\ncharacterization of learnability for model classes with arbitrary noise. In\naddition to that, we also describe the full spectrum of possible optimal query\ncomplexities. Further, we prove adaptivity is sometimes necessary to achieve\nthe optimal query complexity. Last, we revisit an important complexity measure\nfor interactive decision making, the Decision-Estimation-Coefficient\n\\citep{foster2021statistical,foster2023tight}, and propose a new variant of the\nDEC which also characterizes learnability in this setting.\n","authors":["Steve Hanneke","Kun Wang"],"pdf_url":"https://arxiv.org/pdf/2410.09597v2.pdf","comment":null}],"Software Engineering":[{"id":"http://arxiv.org/abs/2501.10313v1","updated":"2025-01-17T17:35:14Z","published":"2025-01-17T17:35:14Z","title":"Addressing Popularity Bias in Third-Party Library Recommendations Using\n  LLMs","summary":"  Recommender systems for software engineering (RSSE) play a crucial role in\nautomating development tasks by providing relevant suggestions according to the\ndeveloper's context. However, they suffer from the so-called popularity bias,\ni.e., the phenomenon of recommending popular items that might be irrelevant to\nthe current task. In particular, the long-tail effect can hamper the system's\nperformance in terms of accuracy, thus leading to false positives in the\nprovided recommendations. Foundation models are the most advanced generative\nAI-based models that achieve relevant results in several SE tasks.\n  This paper aims to investigate the capability of large language models (LLMs)\nto address the popularity bias in recommender systems of third-party libraries\n(TPLs). We conduct an ablation study experimenting with state-of-the-art\ntechniques to mitigate the popularity bias, including fine-tuning and\npopularity penalty mechanisms. Our findings reveal that the considered LLMs\ncannot address the popularity bias in TPL recommenders, even though fine-tuning\nand post-processing penalty mechanism contributes to increasing the overall\ndiversity of the provided recommendations. In addition, we discuss the\nlimitations of LLMs in this context and suggest potential improvements to\naddress the popularity bias in TPL recommenders, thus paving the way for\nadditional experiments in this direction.\n","authors":["Claudio Di Sipio","Juri Di Rocco","Davide Di Ruscio","Vladyslav Bulhakov"],"pdf_url":"https://arxiv.org/pdf/2501.10313v1.pdf","comment":"Accepted at the 1st International Workshop on Fairness in Software\n  Systems, co-located with SANER2025"},{"id":"http://arxiv.org/abs/2501.10269v1","updated":"2025-01-17T15:56:32Z","published":"2025-01-17T15:56:32Z","title":"Grey-Box Fuzzing in Constrained Ultra-Large Systems: Lessons for SE\n  Community","summary":"  Testing ultra-large microservices-based FinTech systems presents significant\nchallenges, including restricted access to production environments, complex\ndependencies, and stringent security constraints. We propose SandBoxFuzz, a\nscalable grey-box fuzzing technique that addresses these limitations by\nleveraging aspect-oriented programming and runtime reflection to enable dynamic\nspecification mining, generating targeted inputs for constrained environments.\nSandBoxFuzz also introduces a log-based coverage mechanism, seamlessly\nintegrated into the build pipeline, eliminating the need for runtime coverage\nagents that are often infeasible in industrial settings. SandBoxFuzz has been\nsuccessfully deployed to Ant Group's production line and, compared to an\ninitial solution built on a state-of-the-art fuzzing framework, it demonstrates\nsuperior performance in their microservices software. SandBoxFuzz achieves a\n7.5% increase in branch coverage, identifies 1,850 additional exceptions, and\nreduces setup time from hours to minutes, highlighting its effectiveness and\npractical utility in a real-world industrial environment. By open-sourcing\nSandBoxFuzz, we provide a practical and effective tool for researchers and\npractitioners to test large-scale microservices systems.\n","authors":["Jiazhao Yu","Yanlun Tu","Zhanlei Zhang","Tiehua Zhang","Cheng Xu","Weigang Wu","Hong Jin Kang","Xi Zheng"],"pdf_url":"https://arxiv.org/pdf/2501.10269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10200v1","updated":"2025-01-17T13:48:32Z","published":"2025-01-17T13:48:32Z","title":"Test Wars: A Comparative Study of SBST, Symbolic Execution, and\n  LLM-Based Approaches to Unit Test Generation","summary":"  Generating tests automatically is a key and ongoing area of focus in software\nengineering research. The emergence of Large Language Models (LLMs) has opened\nup new opportunities, given their ability to perform a wide spectrum of tasks.\nHowever, the effectiveness of LLM-based approaches compared to traditional\ntechniques such as search-based software testing (SBST) and symbolic execution\nremains uncertain. In this paper, we perform an extensive study of automatic\ntest generation approaches based on three tools: EvoSuite for SBST, Kex for\nsymbolic execution, and TestSpark for LLM-based test generation. We evaluate\ntools performance on the GitBug Java dataset and compare them using various\nexecution-based and feature-based metrics. Our results show that while\nLLM-based test generation is promising, it falls behind traditional methods in\nterms of coverage. However, it significantly outperforms them in mutation\nscores, suggesting that LLMs provide a deeper semantic understanding of code.\nLLM-based approach also performed worse than SBST and symbolic execution-based\napproaches w.r.t. fault detection capabilities. Additionally, our feature-based\nanalysis shows that all tools are primarily affected by the complexity and\ninternal dependencies of the class under test (CUT), with LLM-based approaches\nbeing especially sensitive to the CUT size.\n","authors":["Azat Abdullin","Pouria Derakhshanfar","Annibale Panichella"],"pdf_url":"https://arxiv.org/pdf/2501.10200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00329v2","updated":"2025-01-17T12:53:37Z","published":"2024-11-30T03:02:50Z","title":"Language Models in Software Development Tasks: An Experimental Analysis\n  of Energy and Accuracy","summary":"  The use of generative AI-based coding assistants like ChatGPT and Github\nCopilot is a reality in contemporary software development. Many of these tools\nare provided as remote APIs. Using third-party APIs raises data privacy and\nsecurity concerns for client companies, which motivates the use of\nlocally-deployed language models. In this study, we explore the trade-off\nbetween model accuracy and energy consumption, aiming to provide valuable\ninsights to help developers make informed decisions when selecting a language\nmodel. We investigate the performance of 18 families of LLMs in typical\nsoftware development tasks on two real-world infrastructures, a commodity GPU\nand a powerful AI-specific GPU. Given that deploying LLMs locally requires\npowerful infrastructure which might not be affordable for everyone, we consider\nboth full-precision and quantized models. Our findings reveal that employing a\nbig LLM with a higher energy budget does not always translate to significantly\nimproved accuracy. Additionally, quantized versions of large models generally\noffer better efficiency and accuracy compared to full-precision versions of\nmedium-sized ones. Apart from that, not a single model is suitable for all\ntypes of software development tasks.\n","authors":["Negar Alizadeh","Boris Belchev","Nishant Saurabh","Patricia Kelbert","Fernando Castor"],"pdf_url":"https://arxiv.org/pdf/2412.00329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09592v2","updated":"2025-01-17T12:02:04Z","published":"2025-01-16T15:17:33Z","title":"Clinicians don't know what explanations they need: A case study on\n  eliciting AI software explainability requirements","summary":"  This paper analyses how software developers elicit explainability\nrequirements when creating a software application with an AI component, through\na case study using AI in the medical context of predicting cerebral palsy (CP)\nrisk in infants. Following a small software development team at a Norwegian\nhospital, we observe their process of simultaneously developing the AI\napplication and discovering what explanations clinicians require from the AI\npredictions. Since clinicians struggled to articulate their explainability\nneeds before interacting with the system, an iterative approach proved\neffective: the team started with minimal explanations and refined these based\non clinicians' responses during real patient examinations. Our preliminary\nfindings from the first two iterations show that clinicians valued\n\"interrogative explanations\" - i.e., tools that let them explore and compare\nthe AI predictions with their own assessments - over detailed technical\nexplanations of the AI model's inner workings. Based on our analysis, we\nsuggest that successful explainability requirements emerge through iterative\ncollaboration between developers and users rather than being fully specified\nupfront. To the best of our knowledge, this is the first empirical case study\non eliciting explainability requirements in software engineering.\n","authors":["Tor Sporsem","Stine Rasdal Finserås","Inga Strümke"],"pdf_url":"https://arxiv.org/pdf/2501.09592v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11440v2","updated":"2025-01-17T11:20:02Z","published":"2024-07-16T07:18:45Z","title":"End-user Comprehension of Transfer Risks in Smart Contracts","summary":"  Smart contracts are increasingly used in critical use cases (e.g., financial\ntransactions). Thus, it is pertinent to ensure that end-users understand the\ntransfer risks in smart contracts. To address this, we investigate end-user\ncomprehension of risks in the most popular Ethereum smart contract (i.e., USD\nTether (USDT)) and their prevalence in the top ERC-20 smart contracts. We focus\non five transfer risks with severe impact on transfer outcomes and user\nobjectives, including users being blacklisted, contract being paused, and\ncontract being arbitrarily upgraded. Firstly, we conducted a user study\ninvestigating end-user comprehension of smart contract transfer risks with 110\nparticipants and USDT/MetaMask. Secondly, we performed manual and automated\nsource code analysis of the next top (78) ERC-20 smart contracts (after USDT)\nto identify the prevalence of these risks. Results show that end-users do not\ncomprehend real risks: most (up to 71.8% of) users believe contract upgrade and\nblacklisting are highly severe/surprising. More importantly, twice as many\nusers find it easier to discover successful outcomes than risky outcomes using\nthe USDT/MetaMask UI flow. These results hold regardless of the self-rated\nprogramming and Web3 proficiency of participants. Furthermore, our source code\nanalysis demonstrates that the examined risks are prevalent in up to 19.2% of\nthe top ERC-20 contracts. Additionally, we discovered (three) other risks with\nup to 25.6% prevalence in these contracts. This study informs the need to\nprovide explainable smart contracts, understandable UI and relevant information\nfor risky outcomes.\n","authors":["Yustynn Panicker","Ezekiel Soremekun","Sudipta Chattopadhyay","Sumei Sun"],"pdf_url":"https://arxiv.org/pdf/2407.11440v2.pdf","comment":"Conditionally Accepted at CHI 2025"},{"id":"http://arxiv.org/abs/2309.00900v3","updated":"2025-01-17T11:18:37Z","published":"2023-09-02T10:32:53Z","title":"Large Process Models: A Vision for Business Process Management in the\n  Age of Generative AI","summary":"  The continued success of Large Language Models (LLMs) and other generative\nartificial intelligence approaches highlights the advantages that large\ninformation corpora can have over rigidly defined symbolic models, but also\nserves as a proof-point of the challenges that purely statistics-based\napproaches have in terms of safety and trustworthiness. As a framework for\ncontextualizing the potential, as well as the limitations of LLMs and other\nfoundation model-based technologies, we propose the concept of a Large Process\nModel (LPM) that combines the correlation power of LLMs with the analytical\nprecision and reliability of knowledge-based systems and automated reasoning\napproaches. LPMs are envisioned to directly utilize the wealth of process\nmanagement experience that experts have accumulated, as well as process\nperformance data of organizations with diverse characteristics, e.g.,\\\nregarding size, region, or industry. In this vision, the proposed LPM would\nallow organizations to receive context-specific (tailored) process and other\nbusiness models, analytical deep-dives, and improvement recommendations. As\nsuch, they would allow to substantially decrease the time and effort required\nfor business transformation, while also allowing for deeper, more impactful,\nand more actionable insights than previously possible. We argue that\nimplementing an LPM is feasible, but also highlight limitations and research\nchallenges that need to be solved to implement particular aspects of the LPM\nvision.\n","authors":["Timotheus Kampik","Christian Warmuth","Adrian Rebmann","Ron Agam","Lukas N. P. Egger","Andreas Gerber","Johannes Hoffart","Jonas Kolk","Philipp Herzig","Gero Decker","Han van der Aa","Artem Polyvyanyy","Stefanie Rinderle-Ma","Ingo Weber","Matthias Weidlich"],"pdf_url":"https://arxiv.org/pdf/2309.00900v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10037v1","updated":"2025-01-17T08:47:29Z","published":"2025-01-17T08:47:29Z","title":"Exploring Code Comprehension in Scientific Programming: Preliminary\n  Insights from Research Scientists","summary":"  Scientific software-defined as computer programs, scripts, or code used in\nscientific research, data analysis, modeling, or simulation-has become central\nto modern research. However, there is limited research on the readability and\nunderstandability of scientific code, both of which are vital for effective\ncollaboration and reproducibility in scientific research. This study surveys 57\nresearch scientists from various disciplines to explore their programming\nbackgrounds, practices, and the challenges they face regarding code\nreadability. Our findings reveal that most participants learn programming\nthrough self-study or on the-job training, with 57.9% lacking formal\ninstruction in writing readable code. Scientists mainly use Python and R,\nrelying on comments and documentation for readability. While most consider code\nreadability essential for scientific reproducibility, they often face issues\nwith inadequate documentation and poor naming conventions, with challenges\nincluding cryptic names and inconsistent conventions. Our findings also show\nlow adoption of code quality tools and a trend towards utilizing large language\nmodels to improve code quality. These findings offer practical insights into\nenhancing coding practices and supporting sustainable development in scientific\nsoftware.\n","authors":["Alyssia Chen","Carol Wong","Bonita Sharif","Anthony Peruma"],"pdf_url":"https://arxiv.org/pdf/2501.10037v1.pdf","comment":"The 33rd IEEE/ACM International Conference on Program Comprehension\n  (ICPC 2025) - Early Research Achievements Track"},{"id":"http://arxiv.org/abs/2312.13632v4","updated":"2025-01-17T06:09:13Z","published":"2023-12-21T07:48:54Z","title":"TraceFL: Interpretability-Driven Debugging in Federated Learning via\n  Neuron Provenance","summary":"  In Federated Learning, clients train models on local data and send updates to\na central server, which aggregates them into a global model using a fusion\nalgorithm. This collaborative yet privacy-preserving training comes at a cost.\nFL developers face significant challenges in attributing global model\npredictions to specific clients. Localizing responsible clients is a crucial\nstep towards (a) excluding clients primarily responsible for incorrect\npredictions and (b) encouraging clients who contributed high-quality models to\ncontinue participating in the future. Existing ML debugging approaches are\ninherently inapplicable as they are designed for single-model, centralized\ntraining.\n  We introduce TraceFL, a fine-grained neuron provenance capturing mechanism\nthat identifies clients responsible for a global model's prediction by tracking\nthe flow of information from individual clients to the global model. Since\ninference on different inputs activates a different set of neurons of the\nglobal model, TraceFL dynamically quantifies the significance of the global\nmodel's neurons in a given prediction, identifying the most crucial neurons in\nthe global model. It then maps them to the corresponding neurons in every\nparticipating client to determine each client's contribution, ultimately\nlocalizing the responsible client. We evaluate TraceFL on six datasets,\nincluding two real-world medical imaging datasets and four neural networks,\nincluding advanced models such as GPT. TraceFL achieves 99% accuracy in\nlocalizing the responsible client in FL tasks spanning both image and text\nclassification tasks. At a time when state-of-the-artML debugging approaches\nare mostly domain-specific (e.g., image classification only), TraceFL is the\nfirst technique to enable highly accurate automated reasoning across a wide\nrange of FL applications.\n","authors":["Waris Gill","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2312.13632v4.pdf","comment":"Accepted at 2025 IEEE/ACM 47th International Conference on Software\n  Engineering (ICSE)"},{"id":"http://arxiv.org/abs/2501.09955v1","updated":"2025-01-17T05:04:23Z","published":"2025-01-17T05:04:23Z","title":"Metamorphic Testing for Smart Contract Validation:A Case Study of\n  Ethereum-Based Crowdfunding Contracts","summary":"  Blockchain smart contracts play a crucial role in automating and securing\nagreements in diverse domains such as finance, healthcare, and supply chains.\nDespite their critical applications, testing these contracts often receives\nless attention than their development, leaving significant risks due to the\nimmutability of smart contracts post-deployment. A key challenge in the testing\nof smart contracts is the oracle problem, where the exact expected outcomes are\nnot well defined, complicating systematic testing efforts.\n  Metamorphic Testing (MT) addresses the oracle problem by using Metamorphic\nRelations (MRs) to validate smart contracts. MRs define how output should\nchange relative to specific input modifications, determining whether the tests\npass or fail. In this work, we apply MT to test an Ethereum-based crowdfunding\nsmart contract, focusing on core functionalities such as state transitions and\ndonation tracking.\n  We identify a set of MRs tailored for smart contract testing and generate\ntest cases for these MRs. To assess the effectiveness of this approach, we use\nthe Vertigo mutation testing tool to create faulty versions of the smart\ncontract. The experimental results show that our MRs detected 25.65% of the\ntotal mutants generated, with the most effective MRs achieving a mutant-killing\nrate of 89%. These results highlight the utility of MT to ensure the\nreliability and quality of blockchain-based smart contracts.\n","authors":["Irving Jared Villanueva","Madhusudan Srinivasan","Faqeer Ur Rehman"],"pdf_url":"https://arxiv.org/pdf/2501.09955v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09434v2","updated":"2025-01-17T04:36:01Z","published":"2025-01-16T10:04:19Z","title":"Agile System Development Lifecycle for AI Systems: Decision Architecture","summary":"  Agile system development life cycle (SDLC) focuses on typical functional and\nnon-functional system requirements for developing traditional software systems.\nHowever, Artificial Intelligent (AI) systems are different in nature and have\ndistinct attributes such as (1) autonomy, (2) adaptiveness, (3) content\ngeneration, (4) decision-making, (5) predictability and (6) recommendation.\nAgile SDLC needs to be enhanced to support the AI system development and\nongoing post-deployment adaptation. The challenge is: how can agile SDLC be\nenhanced to support AI systems? The scope of this paper is limited to AI system\nenabled decision automation. Thus, this paper proposes the use of decision\nscience to enhance the agile SDLC to support the AI system development.\nDecision science is the study of decision-making, which seems useful to\nidentify, analyse and describe decisions and their architecture subject to\nautomation via AI systems. Specifically, this paper discusses the decision\narchitecture in detail within the overall context of agile SDLC for AI systems.\nThe application of the proposed approach is demonstrated with the help of an\nexample scenario of insurance claim processing. This initial work indicated the\nusability of a decision science to enhancing the agile SDLC for designing and\nimplementing the AI systems for decision-automation. This work provides an\ninitial foundation for further work in this new area of decision architecture\nand agile SDLC for AI systems.\n","authors":["Asif Q. Gill"],"pdf_url":"https://arxiv.org/pdf/2501.09434v2.pdf","comment":"11, 4"},{"id":"http://arxiv.org/abs/2409.20550v2","updated":"2025-01-17T01:44:44Z","published":"2024-09-30T17:51:15Z","title":"LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism,\n  and Mitigation","summary":"  Code generation aims to automatically generate code from input requirements,\nsignificantly enhancing development efficiency. Recent large language models\n(LLMs) based approaches have shown promising results and revolutionized code\ngeneration task. Despite the promising performance, LLMs often generate\ncontents with hallucinations, especially for the code generation scenario\nrequiring the handling of complex contextual dependencies in practical\ndevelopment process. Although previous study has analyzed hallucinations in\nLLM-powered code generation, the study is limited to standalone function\ngeneration. In this paper, we conduct an empirical study to study the\nphenomena, mechanism, and mitigation of LLM hallucinations within more\npractical and complex development contexts in repository-level generation\nscenario. First, we manually examine the code generation results from six\nmainstream LLMs to establish a hallucination taxonomy of LLM-generated code.\nNext, we elaborate on the phenomenon of hallucinations, analyze their\ndistribution across different models. We then analyze causes of hallucinations\nand identify four potential factors contributing to hallucinations. Finally, we\npropose an RAG-based mitigation method, which demonstrates consistent\neffectiveness in all studied LLMs. The replication package including code,\ndata, and experimental results is available at\nhttps://github.com/DeepSoftwareAnalytics/LLMCodingHallucination\n","authors":["Ziyao Zhang","Yanlin Wang","Chong Wang","Jiachi Chen","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2409.20550v2.pdf","comment":"Accepted by ISSTA 2025"},{"id":"http://arxiv.org/abs/2501.09892v1","updated":"2025-01-17T00:42:33Z","published":"2025-01-17T00:42:33Z","title":"Learning from Mistakes: Understanding Ad-hoc Logs through Analyzing\n  Accidental Commits","summary":"  Developers often insert temporary \"print\" or \"log\" instructions into their\ncode to help them better understand runtime behavior, usually when the code is\nnot behaving as they expected. Despite the fact that such monitoring\ninstructions, or \"ad-hoc logs,\" are so commonly used by developers, there is\nalmost no existing literature that studies developers' practices in how they\nuse them. This paucity of knowledge of the use of these ephemeral logs may be\nlargely due to the fact that they typically only exist in the developers' local\nenvironments and are removed before they commit their code to their revision\ncontrol system. In this work, we overcome this challenge by observing that\ndevelopers occasionally mistakenly forget to remove such instructions before\ncommitting, and then they remove them shortly later. Additionally, we further\nstudy such developer logging practices by watching and analyzing live-streamed\ncoding videos. Through these empirical approaches, we study where, how, and why\ndevelopers use ad-hoc logs to better understand their code and its execution.\nWe collect 27 GB of accidental commits that removed 548,880 ad-hoc logs in\nJavaScript from GitHub Archive repositories to provide the first large-scale\ndataset and empirical studies on ad-hoc logging practices. Our results reveal\nseveral illuminating findings, including a particular propensity for developers\nto use ad-hoc logs in asynchronous and callback functions. Our findings provide\nboth empirical evidence and a valuable dataset for researchers and tool\ndevelopers seeking to enhance ad-hoc logging practices, and potentially deepen\nour understanding of developers' practices towards understanding of software's\nruntime behaviors.\n","authors":["Yi-Hung Chou","Yiyang Min","April Yi Wang","James A. Jones"],"pdf_url":"https://arxiv.org/pdf/2501.09892v1.pdf","comment":"Accepted at MSR 2025"},{"id":"http://arxiv.org/abs/2501.09888v1","updated":"2025-01-17T00:23:44Z","published":"2025-01-17T00:23:44Z","title":"Understanding the Effectiveness of LLMs in Automated Self-Admitted\n  Technical Debt Repayment","summary":"  Self-Admitted Technical Debt (SATD), cases where developers intentionally\nacknowledge suboptimal solutions in code through comments, poses a significant\nchallenge to software maintainability. Left unresolved, SATD can degrade code\nquality and increase maintenance costs. While Large Language Models (LLMs) have\nshown promise in tasks like code generation and program repair, their potential\nin automated SATD repayment remains underexplored.\n  In this paper, we identify three key challenges in training and evaluating\nLLMs for SATD repayment: (1) dataset representativeness and scalability, (2)\nremoval of irrelevant SATD repayments, and (3) limitations of existing\nevaluation metrics. To address the first two dataset-related challenges, we\nadopt a language-independent SATD tracing tool and design a 10-step filtering\npipeline to extract SATD repayments from repositories, resulting two\nlarge-scale datasets: 58,722 items for Python and 97,347 items for Java. To\nimprove evaluation, we introduce two diff-based metrics, BLEU-diff and\nCrystalBLEU-diff, which measure code changes rather than whole code.\nAdditionally, we propose another new metric, LEMOD, which is both interpretable\nand informative. Using our new benchmarks and evaluation metrics, we evaluate\ntwo types of automated SATD repayment methods: fine-tuning smaller models, and\nprompt engineering with five large-scale models. Our results reveal that\nfine-tuned small models achieve comparable Exact Match (EM) scores to\nprompt-based approaches but underperform on BLEU-based metrics and LEMOD.\nNotably, Gemma-2-9B leads in EM, addressing 10.1% of Python and 8.1% of Java\nSATDs, while Llama-3.1-70B-Instruct and GPT-4o-mini excel on BLEU-diff,\nCrystalBLEU-diff, and LEMOD metrics. Our work contributes a robust benchmark,\nimproved evaluation metrics, and a comprehensive evaluation of LLMs, advancing\nresearch on automated SATD repayment.\n","authors":["Mohammad Sadegh Sheikhaei","Yuan Tian","Shaowei Wang","Bowen Xu"],"pdf_url":"https://arxiv.org/pdf/2501.09888v1.pdf","comment":"This is a preprint submitted to ACM Transactions on Software\n  Engineering and Methodology (TOSEM)"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2501.10360v1","updated":"2025-01-17T18:59:55Z","published":"2025-01-17T18:59:55Z","title":"FaceXBench: Evaluating Multimodal LLMs on Face Understanding","summary":"  Multimodal Large Language Models (MLLMs) demonstrate impressive\nproblem-solving abilities across a wide range of tasks and domains. However,\ntheir capacity for face understanding has not been systematically studied. To\naddress this gap, we introduce FaceXBench, a comprehensive benchmark designed\nto evaluate MLLMs on complex face understanding tasks. FaceXBench includes\n5,000 multimodal multiple-choice questions derived from 25 public datasets and\na newly created dataset, FaceXAPI. These questions cover 14 tasks across 6\nbroad categories, assessing MLLMs' face understanding abilities in bias and\nfairness, face authentication, recognition, analysis, localization and tool\nretrieval. Using FaceXBench, we conduct an extensive evaluation of 26\nopen-source MLLMs alongside 2 proprietary models, revealing the unique\nchallenges in complex face understanding tasks. We analyze the models across\nthree evaluation settings: zero-shot, in-context task description, and\nchain-of-thought prompting. Our detailed analysis reveals that current MLLMs,\nincluding advanced models like GPT-4o, and GeminiPro 1.5, show significant room\nfor improvement. We believe FaceXBench will be a crucial resource for\ndeveloping MLLMs equipped to perform sophisticated face understanding. Code:\nhttps://github.com/Kartik-3004/facexbench\n","authors":["Kartik Narayan","Vibashan VS","Vishal M. Patel"],"pdf_url":"https://arxiv.org/pdf/2501.10360v1.pdf","comment":"Project Page: https://kartik-3004.github.io/facexbench/"},{"id":"http://arxiv.org/abs/2501.10357v1","updated":"2025-01-17T18:57:57Z","published":"2025-01-17T18:57:57Z","title":"Zero-Shot Monocular Scene Flow Estimation in the Wild","summary":"  Large models have shown generalization across datasets for many low-level\nvision tasks, like depth estimation, but no such general models exist for scene\nflow. Even though scene flow has wide potential use, it is not used in practice\nbecause current predictive models do not generalize well. We identify three key\nchallenges and propose solutions for each.First, we create a method that\njointly estimates geometry and motion for accurate prediction. Second, we\nalleviate scene flow data scarcity with a data recipe that affords us 1M\nannotated training samples across diverse synthetic scenes. Third, we evaluate\ndifferent parameterizations for scene flow prediction and adopt a natural and\neffective parameterization. Our resulting model outperforms existing methods as\nwell as baselines built on large-scale models in terms of 3D end-point error,\nand shows zero-shot generalization to the casually captured videos from DAVIS\nand the robotic manipulation scenes from RoboTAP. Overall, our approach makes\nscene flow prediction more practical in-the-wild.\n","authors":["Yiqing Liang","Abhishek Badki","Hang Su","James Tompkin","Orazio Gallo"],"pdf_url":"https://arxiv.org/pdf/2501.10357v1.pdf","comment":"Project Website: https://research.nvidia.com/labs/zero_msf"},{"id":"http://arxiv.org/abs/2501.10343v1","updated":"2025-01-17T18:34:47Z","published":"2025-01-17T18:34:47Z","title":"3rd Workshop on Maritime Computer Vision (MaCVi) 2025: Challenge Results","summary":"  The 3rd Workshop on Maritime Computer Vision (MaCVi) 2025 addresses maritime\ncomputer vision for Unmanned Surface Vehicles (USV) and underwater. This report\noffers a comprehensive overview of the findings from the challenges. We provide\nboth statistical and qualitative analyses, evaluating trends from over 700\nsubmissions. All datasets, evaluation code, and the leaderboard are available\nto the public at https://macvi.org/workshop/macvi25.\n","authors":["Benjamin Kiefer","Lojze Žust","Jon Muhovič","Matej Kristan","Janez Perš","Matija Teršek","Uma Mudenagudi Chaitra Desai","Arnold Wiliem","Marten Kreis","Nikhil Akalwadi","Yitong Quan","Zhiqiang Zhong","Zhe Zhang","Sujie Liu","Xuran Chen","Yang Yang","Matej Fabijanić","Fausto Ferreira","Seongju Lee","Junseok Lee","Kyoobin Lee","Shanliang Yao","Runwei Guan","Xiaoyu Huang","Yi Ni","Himanshu Kumar","Yuan Feng","Yi-Ching Cheng","Tzu-Yu Lin","Chia-Ming Lee","Chih-Chung Hsu","Jannik Sheikh","Andreas Michel","Wolfgang Gross","Martin Weinmann","Josip Šarić","Yipeng Lin","Xiang Yang","Nan Jiang","Yutang Lu","Fei Feng","Ali Awad","Evan Lucas","Ashraf Saleem","Ching-Heng Cheng","Yu-Fan Lin","Tzu-Yu Lin","Chih-Chung Hsu"],"pdf_url":"https://arxiv.org/pdf/2501.10343v1.pdf","comment":"Part of the MaCVi 2025 workshop"},{"id":"http://arxiv.org/abs/2412.19794v4","updated":"2025-01-17T18:18:21Z","published":"2024-12-27T18:47:05Z","title":"MVTamperBench: Evaluating Robustness of Vision-Language Models","summary":"  Multimodal Large Language Models (MLLMs) have driven major advances in video\nunderstanding, yet their vulnerability to adversarial tampering and\nmanipulations remains underexplored. To address this gap, we introduce\nMVTamperBench, a benchmark that systematically evaluates MLLM robustness\nagainst five prevalent tampering techniques: rotation, masking, substitution,\nrepetition, and dropping. Built from 3.4K original videos-expanded to over 17K\ntampered clips spanning 19 video tasks.\n  MVTamperBench challenges models to detect manipulations in spatial and\ntemporal coherence. We evaluate 45 recent MLLMs from 15+ model families,\nrevealing substantial variability in resilience across tampering types and\nshowing that larger parameter counts do not necessarily guarantee robustness.\nMVTamperBench sets a new benchmark for developing tamper-resilient MLLM in\nsafety-critical applications, including detecting clickbait, preventing harmful\ncontent distribution, and enforcing policies on media platforms. We release all\ncode and data to foster open research in trustworthy video understanding.\n  Code: https://amitbcp.github.io/MVTamperBench/ Data:\nhttps://huggingface.co/datasets/Srikant86/MVTamperBench\n","authors":["Amit Agarwal","Srikant Panda","Angeline Charles","Bhargava Kumar","Hitesh Patel","Priyaranjan Pattnayak","Taki Hasan Rafi","Tejaswini Kumar","Dong-Kyu Chae"],"pdf_url":"https://arxiv.org/pdf/2412.19794v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10325v1","updated":"2025-01-17T17:56:52Z","published":"2025-01-17T17:56:52Z","title":"DiffStereo: High-Frequency Aware Diffusion Model for Stereo Image\n  Restoration","summary":"  Diffusion models (DMs) have achieved promising performance in image\nrestoration but haven't been explored for stereo images. The application of DM\nin stereo image restoration is confronted with a series of challenges. The need\nto reconstruct two images exacerbates DM's computational cost. Additionally,\nexisting latent DMs usually focus on semantic information and remove\nhigh-frequency details as redundancy during latent compression, which is\nprecisely what matters for image restoration. To address the above problems, we\npropose a high-frequency aware diffusion model, DiffStereo for stereo image\nrestoration as the first attempt at DM in this domain. Specifically, DiffStereo\nfirst learns latent high-frequency representations (LHFR) of HQ images. DM is\nthen trained in the learned space to estimate LHFR for stereo images, which are\nfused into a transformer-based stereo image restoration network providing\nbeneficial high-frequency information of corresponding HQ images. The\nresolution of LHFR is kept the same as input images, which preserves the\ninherent texture from distortion. And the compression in channels alleviates\nthe computational burden of DM. Furthermore, we devise a position encoding\nscheme when integrating the LHFR into the restoration network, enabling\ndistinctive guidance in different depths of the restoration network.\nComprehensive experiments verify that by combining generative DM and\ntransformer, DiffStereo achieves both higher reconstruction accuracy and better\nperceptual quality on stereo super-resolution, deblurring, and low-light\nenhancement compared with state-of-the-art methods.\n","authors":["Huiyun Cao","Yuan Shi","Bin Xia","Xiaoyu Jin","Wenming Yang"],"pdf_url":"https://arxiv.org/pdf/2501.10325v1.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2501.10324v1","updated":"2025-01-17T17:56:27Z","published":"2025-01-17T17:56:27Z","title":"New Fashion Products Performance Forecasting: A Survey on Evolutions,\n  Models and Emerging Trends","summary":"  The fast fashion industry's insatiable demand for new styles and rapid\nproduction cycles has led to a significant environmental burden.\nOverproduction, excessive waste, and harmful chemicals have contributed to the\nnegative environmental impact of the industry. To mitigate these issues, a\nparadigm shift that prioritizes sustainability and efficiency is urgently\nneeded. Integrating learning-based predictive analytics into the fashion\nindustry represents a significant opportunity to address environmental\nchallenges and drive sustainable practices. By forecasting fashion trends and\noptimizing production, brands can reduce their ecological footprint while\nremaining competitive in a rapidly changing market. However, one of the key\nchallenges in forecasting fashion sales is the dynamic nature of consumer\npreferences. Fashion is acyclical, with trends constantly evolving and\nresurfacing. In addition, cultural changes and unexpected events can disrupt\nestablished patterns. This problem is also known as New Fashion Products\nPerformance Forecasting (NFPPF), and it has recently gained more and more\ninterest in the global research landscape. Given its multidisciplinary nature,\nthe field of NFPPF has been approached from many different angles. This\ncomprehensive survey wishes to provide an up-to-date overview that focuses on\nlearning-based NFPPF strategies. The survey is based on the Preferred Reporting\nItems for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow,\nallowing for a systematic and complete literature review. In particular, we\npropose the first taxonomy that covers the learning panorama for NFPPF,\nexamining in detail the different methodologies used to increase the amount of\nmultimodal information, as well as the state-of-the-art available datasets.\nFinally, we discuss the challenges and future directions.\n","authors":["Andrea Avogaro","Luigi Capogrosso","Andrea Toaiari","Franco Fummi","Marco Cristani"],"pdf_url":"https://arxiv.org/pdf/2501.10324v1.pdf","comment":"Accepted at the Springer Nature Computer Science journal"},{"id":"http://arxiv.org/abs/2501.10318v1","updated":"2025-01-17T17:41:47Z","published":"2025-01-17T17:41:47Z","title":"HiMix: Reducing Computational Complexity in Large Vision-Language Models","summary":"  Benefiting from recent advancements in large language models and modality\nalignment techniques, existing Large Vision-Language Models(LVLMs) have\nachieved prominent performance across a wide range of scenarios. However, the\nexcessive computational complexity limits the widespread use of these models in\npractical applications. We argue that one main bottleneck in computational\ncomplexity is caused by the involvement of redundant vision sequences in model\ncomputation. This is inspired by a reassessment of the efficiency of vision and\nlanguage information transmission in the language decoder of LVLMs. Then, we\npropose a novel hierarchical vision-language interaction mechanism called\nHierarchical Vision injection for Mixture Attention (HiMix). In HiMix, only the\nlanguage sequence undergoes full forward propagation, while the vision sequence\ninteracts with the language at specific stages within each language decoder\nlayer. It is striking that our approach significantly reduces computational\ncomplexity with minimal performance loss. Specifically, HiMix achieves a 10x\nreduction in the computational cost of the language decoder across multiple\nLVLM models while maintaining comparable performance. This highlights the\nadvantages of our method, and we hope our research brings new perspectives to\nthe field of vision-language understanding. Project Page:\nhttps://xuange923.github.io/HiMix\n","authors":["Xuange Zhang","Dengjie Li","Bo Liu","Zenghao Bao","Yao Zhou","Baisong Yang","Zhongying Liu","Yujie Zhong","Zheng Zhao","Tongtong Yuan"],"pdf_url":"https://arxiv.org/pdf/2501.10318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09600v2","updated":"2025-01-17T17:07:31Z","published":"2025-01-16T15:22:06Z","title":"Mesh2SLAM in VR: A Fast Geometry-Based SLAM Framework for Rapid\n  Prototyping in Virtual Reality Applications","summary":"  SLAM is a foundational technique with broad applications in robotics and\nAR/VR. SLAM simulations evaluate new concepts, but testing on\nresource-constrained devices, such as VR HMDs, faces challenges: high\ncomputational cost and restricted sensor data access. This work proposes a\nsparse framework using mesh geometry projections as features, which improves\nefficiency and circumvents direct sensor data access, advancing SLAM research\nas we demonstrate in VR and through numerical evaluation.\n","authors":["Carlos Augusto Pinheiro de Sousa","Heiko Hamann","Oliver Deussen"],"pdf_url":"https://arxiv.org/pdf/2501.09600v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10283v1","updated":"2025-01-17T16:26:24Z","published":"2025-01-17T16:26:24Z","title":"GSTAR: Gaussian Surface Tracking and Reconstruction","summary":"  3D Gaussian Splatting techniques have enabled efficient photo-realistic\nrendering of static scenes. Recent works have extended these approaches to\nsupport surface reconstruction and tracking. However, tracking dynamic surfaces\nwith 3D Gaussians remains challenging due to complex topology changes, such as\nsurfaces appearing, disappearing, or splitting. To address these challenges, we\npropose GSTAR, a novel method that achieves photo-realistic rendering, accurate\nsurface reconstruction, and reliable 3D tracking for general dynamic scenes\nwith changing topology. Given multi-view captures as input, GSTAR binds\nGaussians to mesh faces to represent dynamic objects. For surfaces with\nconsistent topology, GSTAR maintains the mesh topology and tracks the meshes\nusing Gaussians. In regions where topology changes, GSTAR adaptively unbinds\nGaussians from the mesh, enabling accurate registration and the generation of\nnew surfaces based on these optimized Gaussians. Additionally, we introduce a\nsurface-based scene flow method that provides robust initialization for\ntracking between frames. Experiments demonstrate that our method effectively\ntracks and reconstructs dynamic surfaces, enabling a range of applications. Our\nproject page with the code release is available at\nhttps://chengwei-zheng.github.io/GSTAR/.\n","authors":["Chengwei Zheng","Lixin Xue","Juan Zarate","Jie Song"],"pdf_url":"https://arxiv.org/pdf/2501.10283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09374v2","updated":"2025-01-17T15:52:06Z","published":"2024-10-12T05:35:27Z","title":"ESVO2: Direct Visual-Inertial Odometry with Stereo Event Cameras","summary":"  Event-based visual odometry is a specific branch of visual Simultaneous\nLocalization and Mapping (SLAM) techniques, which aims at solving tracking and\nmapping subproblems (typically in parallel), by exploiting the special working\nprinciples of neuromorphic (i.e., event-based) cameras. Due to the\nmotion-dependent nature of event data, explicit data association (i.e., feature\nmatching) under large-baseline view-point changes is difficult to establish,\nmaking direct methods a more rational choice. However, state-of-the-art direct\nmethods are limited by the high computational complexity of the mapping\nsub-problem and the degeneracy of camera pose tracking in certain degrees of\nfreedom (DoF) in rotation. In this paper, we tackle these issues by building an\nevent-based stereo visual-inertial odometry system on top of a direct pipeline.\nSpecifically, to speed up the mapping operation, we propose an efficient\nstrategy for sampling contour points according to the local dynamics of events.\nThe mapping performance is also improved in terms of structure completeness and\nlocal smoothness by merging the temporal stereo and static stereo results. To\ncircumvent the degeneracy of camera pose tracking in recovering the pitch and\nyaw components of general 6-DoF motion, we introduce IMU measurements as motion\npriors via pre-integration. To this end, a compact back-end is proposed for\ncontinuously updating the IMU bias and predicting the linear velocity, enabling\nan accurate motion prediction for camera pose tracking. The resulting system\nscales well with modern high-resolution event cameras and leads to better\nglobal positioning accuracy in large-scale outdoor environments. Extensive\nevaluations on five publicly available datasets featuring different resolutions\nand scenarios justify the superior performance of the proposed system against\nfive state-of-the-art methods.\n","authors":["Junkai Niu","Sheng Zhong","Xiuyuan Lu","Shaojie Shen","Guillermo Gallego","Yi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.09374v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10266v1","updated":"2025-01-17T15:48:37Z","published":"2025-01-17T15:48:37Z","title":"MutualForce: Mutual-Aware Enhancement for 4D Radar-LiDAR 3D Object\n  Detection","summary":"  Radar and LiDAR have been widely used in autonomous driving as LiDAR provides\nrich structure information, and radar demonstrates high robustness under\nadverse weather. Recent studies highlight the effectiveness of fusing radar and\nLiDAR point clouds. However, challenges remain due to the modality misalignment\nand information loss during feature extractions. To address these issues, we\npropose a 4D radar-LiDAR framework to mutually enhance their representations.\nInitially, the indicative features from radar are utilized to guide both radar\nand LiDAR geometric feature learning. Subsequently, to mitigate their sparsity\ngap, the shape information from LiDAR is used to enrich radar BEV features.\nExtensive experiments on the View-of-Delft (VoD) dataset demonstrate our\napproach's superiority over existing methods, achieving the highest mAP of\n71.76% across the entire area and 86.36\\% within the driving corridor.\nEspecially for cars, we improve the AP by 4.17% and 4.20% due to the strong\nindicative features and symmetric shapes.\n","authors":["Xiangyuan Peng","Huawei Sun","Kay Bierzynski","Anton Fischbacher","Lorenzo Servadei","Robert Wille"],"pdf_url":"https://arxiv.org/pdf/2501.10266v1.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2405.04392v2","updated":"2025-01-17T15:21:52Z","published":"2024-05-07T15:14:49Z","title":"BILTS: A Bi-Invariant Similarity Measure for Robust Object Trajectory\n  Recognition under Reference Frame Variations","summary":"  When similar object motions are performed in diverse contexts but are meant\nto be recognized under a single classification, these contextual variations act\nas disturbances that negatively affect accurate motion recognition. In this\npaper, we focus on contextual variations caused by reference frame variations.\nTo robustly deal with these variations, similarity measures have been\nintroduced that compare object motion trajectories in a context-invariant\nmanner. However, most are highly sensitive to noise near singularities, where\nthe measure is not uniquely defined, and lack bi-invariance (invariance to both\nworld and body frame variations). To address these issues, we propose the novel\n\\textit{Bi-Invariant Local Trajectory-Shape Similarity} (BILTS) measure.\nCompared to other measures, the BILTS measure uniquely offers bi-invariance,\nboundedness, and third-order shape identity. Aimed at practical\nimplementations, we devised a discretized and regularized version of the BILTS\nmeasure which shows exceptional robustness to singularities. This is\ndemonstrated through rigorous recognition experiments using multiple datasets.\nOn average, BILTS attained the highest recognition ratio and least sensitivity\nto contextual variations compared to other invariant object motion similarity\nmeasures. We believe that the BILTS measure is a valuable tool for recognizing\nmotions performed in diverse contexts and has potential in other applications,\nincluding the recognition, segmentation, and adaptation of both motion and\nforce trajectories.\n","authors":["Arno Verduyn","Erwin Aertbeliën","Glenn Maes","Joris De Schutter","Maxim Vochten"],"pdf_url":"https://arxiv.org/pdf/2405.04392v2.pdf","comment":"This work has been submitted as a regular research paper for\n  consideration in the Journal of Intelligent & Robotic Systems. The content in\n  this preprint is identical to the version submitted for peer review, except\n  for formatting differences required by the journal"},{"id":"http://arxiv.org/abs/2403.03728v2","updated":"2025-01-17T15:15:15Z","published":"2024-03-06T14:18:24Z","title":"Bridging Diversity and Uncertainty in Active learning with\n  Self-Supervised Pre-Training","summary":"  This study addresses the integration of diversity-based and uncertainty-based\nsampling strategies in active learning, particularly within the context of\nself-supervised pre-trained models. We introduce a straightforward heuristic\ncalled TCM that mitigates the cold start problem while maintaining strong\nperformance across various data levels. By initially applying TypiClust for\ndiversity sampling and subsequently transitioning to uncertainty sampling with\nMargin, our approach effectively combines the strengths of both strategies. Our\nexperiments demonstrate that TCM consistently outperforms existing methods\nacross various datasets in both low and high data regimes.\n","authors":["Paul Doucet","Benjamin Estermann","Till Aczel","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2403.03728v2.pdf","comment":"Accepted at ICLR 2024 Workshop on Practical Machine Learning for Low\n  Resource Settings (PML4LRS)"},{"id":"http://arxiv.org/abs/2501.10219v1","updated":"2025-01-17T14:33:05Z","published":"2025-01-17T14:33:05Z","title":"Robust Egoistic Rigid Body Localization","summary":"  We consider a robust and self-reliant (or \"egoistic\") variation of the rigid\nbody localization (RBL) problem, in which a primary rigid body seeks to\nestimate the pose (i.e., location and orientation) of another rigid body (or\n\"target\"), relative to its own, without the assistance of external\ninfrastructure, without prior knowledge of the shape of the target, and taking\ninto account the possibility that the available observations are incomplete.\nThree complementary contributions are then offered for such a scenario. The\nfirst is a method to estimate the translation vector between the center point\nof both rigid bodies, which unlike existing techniques does not require that\nboth objects have the same shape or even the same number of landmark points.\nThis technique is shown to significantly outperform the state-of-the-art (SotA)\nunder complete information, but to be sensitive to data erasures, even when\nenhanced by matrix completion methods. The second contribution, designed to\noffer improved performance in the presence of incomplete information, offers a\nrobust alternative to the latter, at the expense of a slight relative loss\nunder complete information. Finally, the third contribution is a scheme for the\nestimation of the rotation matrix describing the relative orientation of the\ntarget rigid body with respect to the primary. Comparisons of the proposed\nschemes and SotA techniques demonstrate the advantage of the contributed\nmethods in terms of root mean square error (RMSE) performance under fully\ncomplete information and incomplete conditions.\n","authors":["Niclas Führling","Giuseppe Thadeu Freitas de Abreu","David González G.","Osvaldo Gonsa"],"pdf_url":"https://arxiv.org/pdf/2501.10219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10733v5","updated":"2025-01-17T14:22:06Z","published":"2024-10-14T17:15:07Z","title":"Deep Compression Autoencoder for Efficient High-Resolution Diffusion\n  Models","summary":"  We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder\nmodels for accelerating high-resolution diffusion models. Existing autoencoder\nmodels have demonstrated impressive results at a moderate spatial compression\nratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for\nhigh spatial compression ratios (e.g., 64x). We address this challenge by\nintroducing two key techniques: (1) Residual Autoencoding, where we design our\nmodels to learn residuals based on the space-to-channel transformed features to\nalleviate the optimization difficulty of high spatial-compression autoencoders;\n(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases\ntraining strategy for mitigating the generalization penalty of high\nspatial-compression autoencoders. With these designs, we improve the\nautoencoder's spatial compression ratio up to 128 while maintaining the\nreconstruction quality. Applying our DC-AE to latent diffusion models, we\nachieve significant speedup without accuracy drop. For example, on ImageNet\n512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup\non H100 GPU for UViT-H while achieving a better FID, compared with the widely\nused SD-VAE-f8 autoencoder. Our code is available at\nhttps://github.com/mit-han-lab/efficientvit.\n","authors":["Junyu Chen","Han Cai","Junsong Chen","Enze Xie","Shang Yang","Haotian Tang","Muyang Li","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2410.10733v5.pdf","comment":"Preprint. First two authors contributed equally to this work. Update:\n  fix typo"},{"id":"http://arxiv.org/abs/2501.10212v1","updated":"2025-01-17T14:12:52Z","published":"2025-01-17T14:12:52Z","title":"Disharmony: Forensics using Reverse Lighting Harmonization","summary":"  Content generation and manipulation approaches based on deep learning methods\nhave seen significant advancements, leading to an increased need for techniques\nto detect whether an image has been generated or edited. Another area of\nresearch focuses on the insertion and harmonization of objects within images.\nIn this study, we explore the potential of using harmonization data in\nconjunction with a segmentation model to enhance the detection of edited image\nregions. These edits can be either manually crafted or generated using deep\nlearning methods. Our findings demonstrate that this approach can effectively\nidentify such edits. Existing forensic models often overlook the detection of\nharmonized objects in relation to the background, but our proposed Disharmony\nNetwork addresses this gap. By utilizing an aggregated dataset of harmonization\ntechniques, our model outperforms existing forensic networks in identifying\nharmonized objects integrated into their backgrounds, and shows potential for\ndetecting various forms of edits, including virtual try-on tasks.\n","authors":["Philip Wootaek Shin","Jack Sampson","Vijaykrishnan Narayanan","Andres Marquez","Mahantesh Halappanavar"],"pdf_url":"https://arxiv.org/pdf/2501.10212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10209v1","updated":"2025-01-17T14:08:32Z","published":"2025-01-17T14:08:32Z","title":"Hypercone Assisted Contour Generation for Out-of-Distribution Detection","summary":"  Recent advances in the field of out-of-distribution (OOD) detection have\nplaced great emphasis on learning better representations suited to this task.\nWhile there are distance-based approaches, distributional awareness has seldom\nbeen exploited for better performance. We present HAC$_k$-OOD, a novel OOD\ndetection method that makes no distributional assumption about the data, but\nautomatically adapts to its distribution. Specifically, HAC$_k$-OOD constructs\na set of hypercones by maximizing the angular distance to neighbors in a given\ndata-point's vicinity to approximate the contour within which in-distribution\n(ID) data-points lie. Experimental results show state-of-the-art FPR@95 and\nAUROC performance on Near-OOD detection and on Far-OOD detection on the\nchallenging CIFAR-100 benchmark without explicitly training for OOD\nperformance.\n","authors":["Annita Vapsi","Andrés Muñoz","Nancy Thomas","Keshav Ramani","Daniel Borrajo"],"pdf_url":"https://arxiv.org/pdf/2501.10209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10199v1","updated":"2025-01-17T13:48:04Z","published":"2025-01-17T13:48:04Z","title":"Adaptive Clustering for Efficient Phenotype Segmentation of UAV\n  Hyperspectral Data","summary":"  Unmanned Aerial Vehicles (UAVs) combined with Hyperspectral imaging (HSI)\noffer potential for environmental and agricultural applications by capturing\ndetailed spectral information that enables the prediction of invisible features\nlike biochemical leaf properties. However, the data-intensive nature of HSI\nposes challenges for remote devices, which have limited computational resources\nand storage. This paper introduces an Online Hyperspectral Simple Linear\nIterative Clustering algorithm (OHSLIC) framework for real-time tree phenotype\nsegmentation. OHSLIC reduces inherent noise and computational demands through\nadaptive incremental clustering and a lightweight neural network, which\nphenotypes trees using leaf contents such as chlorophyll, carotenoids, and\nanthocyanins. A hyperspectral dataset is created using a custom simulator that\nincorporates realistic leaf parameters, and light interactions. Results\ndemonstrate that OHSLIC achieves superior regression accuracy and segmentation\nperformance compared to pixel- or window-based methods while significantly\nreducing inference time. The method`s adaptive clustering enables dynamic\ntrade-offs between computational efficiency and accuracy, paving the way for\nscalable edge-device deployment in HSI applications.\n","authors":["Ciem Cornelissen","Sam Leroux","Pieter Simoens"],"pdf_url":"https://arxiv.org/pdf/2501.10199v1.pdf","comment":"accepted WACV 2025 GeoCV workshop"},{"id":"http://arxiv.org/abs/2501.10197v1","updated":"2025-01-17T13:44:54Z","published":"2025-01-17T13:44:54Z","title":"CSHNet: A Novel Information Asymmetric Image Translation Method","summary":"  Despite advancements in cross-domain image translation, challenges persist in\nasymmetric tasks such as SAR-to-Optical and Sketch-to-Instance conversions,\nwhich involve transforming data from a less detailed domain into one with\nricher content. Traditional CNN-based methods are effective at capturing fine\ndetails but struggle with global structure, leading to unwanted merging of\nimage regions. To address this, we propose the CNN-Swin Hybrid Network\n(CSHNet), which combines two key modules: Swin Embedded CNN (SEC) and CNN\nEmbedded Swin (CES), forming the SEC-CES-Bottleneck (SCB). SEC leverages CNN's\ndetailed feature extraction while integrating the Swin Transformer's structural\nbias. CES, in turn, preserves the Swin Transformer's global integrity,\ncompensating for CNN's lack of focus on structure. Additionally, CSHNet\nincludes two components designed to enhance cross-domain information retention:\nthe Interactive Guided Connection (IGC), which enables dynamic information\nexchange between SEC and CES, and Adaptive Edge Perception Loss (AEPL), which\nmaintains structural boundaries during translation. Experimental results show\nthat CSHNet outperforms existing methods in both visual quality and performance\nmetrics across scene-level and instance-level datasets. Our code is available\nat: https://github.com/XduShi/CSHNet.\n","authors":["Xi Yang","Haoyuan Shi","Zihan Wang","Nannan Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2501.10197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.13309v2","updated":"2025-01-17T13:28:01Z","published":"2023-12-20T04:35:00Z","title":"Generate E-commerce Product Background by Integrating Category\n  Commonality and Personalized Style","summary":"  The state-of-the-art methods for e-commerce product background generation\nsuffer from the inefficiency of designing product-wise prompts when scaling up\nthe production, as well as the ineffectiveness of describing fine-grained\nstyles when customizing personalized backgrounds for some specific brands. To\naddress these obstacles, we integrate the category commonality and personalized\nstyle into diffusion models. Concretely, we propose a Category-Wise Generator\nto enable large-scale background generation with only one model for the first\ntime. A unique identifier in the prompt is assigned to each category, whose\nattention is located on the background by a mask-guided cross attention layer\nto learn the category-wise style. Furthermore, for products with specific and\nfine-grained requirements in layout, elements, etc, a Personality-Wise\nGenerator is devised to learn such personalized style directly from a reference\nimage to resolve textual ambiguities, and is trained in a self-supervised\nmanner for more efficient training data usage. To advance research in this\nfield, the first large-scale e-commerce product background generation dataset\nBG60k is constructed, which covers more than 60k product images from over 2k\ncategories. Experiments demonstrate that our method could generate high-quality\nbackgrounds for different categories, and maintain the personalized background\nstyle of reference images. BG60k will be available at\n\\url{https://github.com/Whileherham/BG60k}.\n","authors":["Haohan Wang","Wei Feng","Yaoyu Li","Zheng Zhang","Jingjing Lv","Junjie Shen","Zhangang Lin","Jingping Shao"],"pdf_url":"https://arxiv.org/pdf/2312.13309v2.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.08295v2","updated":"2025-01-17T13:22:51Z","published":"2025-01-14T18:22:21Z","title":"LayerAnimate: Layer-specific Control for Animation","summary":"  Animated video separates foreground and background elements into layers, with\ndistinct processes for sketching, refining, coloring, and in-betweening.\nExisting video generation methods typically treat animation as a monolithic\ndata domain, lacking fine-grained control over individual layers. In this\npaper, we introduce LayerAnimate, a novel architectural approach that enhances\nfine-grained control over individual animation layers within a video diffusion\nmodel, allowing users to independently manipulate foreground and background\nelements in distinct layers. To address the challenge of limited layer-specific\ndata, we propose a data curation pipeline that features automated element\nsegmentation, motion-state hierarchical merging, and motion coherence\nrefinement. Through quantitative and qualitative comparisons, and user study,\nwe demonstrate that LayerAnimate outperforms current methods in terms of\nanimation quality, control precision, and usability, making it an ideal tool\nfor both professional animators and amateur enthusiasts. This framework opens\nup new possibilities for layer-specific animation applications and creative\nflexibility. Our code is available at https://layeranimate.github.io.\n","authors":["Yuxue Yang","Lue Fan","Zuzeng Lin","Feng Wang","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.08295v2.pdf","comment":"Project page: https://layeranimate.github.io"},{"id":"http://arxiv.org/abs/2501.10157v1","updated":"2025-01-17T12:42:30Z","published":"2025-01-17T12:42:30Z","title":"Structure-guided Deep Multi-View Clustering","summary":"  Deep multi-view clustering seeks to utilize the abundant information from\nmultiple views to improve clustering performance. However, most of the existing\nclustering methods often neglect to fully mine multi-view structural\ninformation and fail to explore the distribution of multi-view data, limiting\nclustering performance. To address these limitations, we propose a\nstructure-guided deep multi-view clustering model. Specifically, we introduce a\npositive sample selection strategy based on neighborhood relationships, coupled\nwith a corresponding loss function. This strategy constructs multi-view nearest\nneighbor graphs to dynamically redefine positive sample pairs, enabling the\nmining of local structural information within multi-view data and enhancing the\nreliability of positive sample selection. Additionally, we introduce a Gaussian\ndistribution model to uncover latent structural information and introduce a\nloss function to reduce discrepancies between view embeddings. These two\nstrategies explore multi-view structural information and data distribution from\ndifferent perspectives, enhancing consistency across views and increasing\nintra-cluster compactness. Experimental evaluations demonstrate the efficacy of\nour method, showing significant improvements in clustering performance on\nmultiple benchmark datasets compared to state-of-the-art multi-view clustering\napproaches.\n","authors":["Jinrong Cui","Xiaohuang Wu","Haitao Zhang","Chongjie Dong","Jie Wen"],"pdf_url":"https://arxiv.org/pdf/2501.10157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10144v1","updated":"2025-01-17T12:12:33Z","published":"2025-01-17T12:12:33Z","title":"A Vision-Language Framework for Multispectral Scene Representation Using\n  Language-Grounded Features","summary":"  Scene understanding in remote sensing often faces challenges in generating\naccurate representations for complex environments such as various land use\nareas or coastal regions, which may also include snow, clouds, or haze. To\naddress this, we present a vision-language framework named Spectral LLaVA,\nwhich integrates multispectral data with vision-language alignment techniques\nto enhance scene representation and description. Using the BigEarthNet v2\ndataset from Sentinel-2, we establish a baseline with RGB-based scene\ndescriptions and further demonstrate substantial improvements through the\nincorporation of multispectral information. Our framework optimizes a\nlightweight linear projection layer for alignment while keeping the vision\nbackbone of SpectralGPT frozen. Our experiments encompass scene classification\nusing linear probing and language modeling for jointly performing scene\nclassification and description generation. Our results highlight Spectral\nLLaVA's ability to produce detailed and accurate descriptions, particularly for\nscenarios where RGB data alone proves inadequate, while also enhancing\nclassification performance by refining SpectralGPT features into semantically\nmeaningful representations.\n","authors":["Enes Karanfil","Nevrez Imamoglu","Erkut Erdem","Aykut Erdem"],"pdf_url":"https://arxiv.org/pdf/2501.10144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.18373v3","updated":"2025-01-17T11:53:42Z","published":"2023-11-30T09:14:37Z","title":"A Survey on Deep Learning for Polyp Segmentation: Techniques, Challenges\n  and Future Trends","summary":"  Early detection and assessment of polyps play a crucial role in the\nprevention and treatment of colorectal cancer (CRC). Polyp segmentation\nprovides an effective solution to assist clinicians in accurately locating and\nsegmenting polyp regions. In the past, people often relied on manually\nextracted lower-level features such as color, texture, and shape, which often\nhad issues capturing global context and lacked robustness to complex scenarios.\nWith the advent of deep learning, more and more outstanding medical image\nsegmentation algorithms based on deep learning networks have emerged, making\nsignificant progress in this field. This paper provides a comprehensive review\nof polyp segmentation algorithms. We first review some traditional algorithms\nbased on manually extracted features and deep segmentation algorithms, then\ndetail benchmark datasets related to the topic. Specifically, we carry out a\ncomprehensive evaluation of recent deep learning models and results based on\npolyp sizes, considering the pain points of research topics and differences in\nnetwork structures. Finally, we discuss the challenges of polyp segmentation\nand future trends in this field. The models, benchmark datasets, and source\ncode links we collected are all published at\nhttps://github.com/taozh2017/Awesome-Polyp-Segmentation.\n","authors":["Jiaxin Mei","Tao Zhou","Kaiwen Huang","Yizhe Zhang","Yi Zhou","Ye Wu","Huazhu Fu"],"pdf_url":"https://arxiv.org/pdf/2311.18373v3.pdf","comment":"Have been published in Visual Intelligence"},{"id":"http://arxiv.org/abs/2403.16954v2","updated":"2025-01-17T11:42:58Z","published":"2024-03-25T17:16:27Z","title":"Isolated Diffusion: Optimizing Multi-Concept Text-to-Image Generation\n  Training-Freely with Isolated Diffusion Guidance","summary":"  Large-scale text-to-image diffusion models have achieved great success in\nsynthesizing high-quality and diverse images given target text prompts. Despite\nthe revolutionary image generation ability, current state-of-the-art models\nstill struggle to deal with multi-concept generation accurately in many cases.\nThis phenomenon is known as ``concept bleeding\" and displays as the unexpected\noverlapping or merging of various concepts. This paper presents a general\napproach for text-to-image diffusion models to address the mutual interference\nbetween different subjects and their attachments in complex scenes, pursuing\nbetter text-image consistency. The core idea is to isolate the synthesizing\nprocesses of different concepts. We propose to bind each attachment to\ncorresponding subjects separately with split text prompts. Besides, we\nintroduce a revision method to fix the concept bleeding problem in\nmulti-subject synthesis. We first depend on pre-trained object detection and\nsegmentation models to obtain the layouts of subjects. Then we isolate and\nresynthesize each subject individually with corresponding text prompts to avoid\nmutual interference. Overall, we achieve a training-free strategy, named\nIsolated Diffusion, to optimize multi-concept text-to-image synthesis. It is\ncompatible with the latest Stable Diffusion XL (SDXL) and prior Stable\nDiffusion (SD) models. We compare our approach with alternative methods using a\nvariety of multi-concept text prompts and demonstrate its effectiveness with\nclear advantages in text-image consistency and user study.\n","authors":["Jingyuan Zhu","Huimin Ma","Jiansheng Chen","Jian Yuan"],"pdf_url":"https://arxiv.org/pdf/2403.16954v2.pdf","comment":"Accepted by IEEE Transactions on Visualization and Computer Graphics"},{"id":"http://arxiv.org/abs/2501.10131v1","updated":"2025-01-17T11:39:47Z","published":"2025-01-17T11:39:47Z","title":"ACE: Anatomically Consistent Embeddings in Composition and Decomposition","summary":"  Medical images acquired from standardized protocols show consistent\nmacroscopic or microscopic anatomical structures, and these structures consist\nof composable/decomposable organs and tissues, but existing self-supervised\nlearning (SSL) methods do not appreciate such composable/decomposable structure\nattributes inherent to medical images. To overcome this limitation, this paper\nintroduces a novel SSL approach called ACE to learn anatomically consistent\nembedding via composition and decomposition with two key branches: (1) global\nconsistency, capturing discriminative macro-structures via extracting global\nfeatures; (2) local consistency, learning fine-grained anatomical details from\ncomposable/decomposable patch features via corresponding matrix matching.\nExperimental results across 6 datasets 2 backbones, evaluated in few-shot\nlearning, fine-tuning, and property analysis, show ACE's superior robustness,\ntransferability, and clinical potential. The innovations of our ACE lie in\ngrid-wise image cropping, leveraging the intrinsic properties of\ncompositionality and decompositionality of medical images, bridging the\nsemantic gap from high-level pathologies to low-level tissue anomalies, and\nproviding a new SSL method for medical imaging.\n","authors":["Ziyu Zhou","Haozhe Luo","Mohammad Reza Hosseinzadeh Taher","Jiaxuan Pang","Xiaowei Ding","Michael Gotway","Jianming Liang"],"pdf_url":"https://arxiv.org/pdf/2501.10131v1.pdf","comment":"Accepted by WACV 2025"},{"id":"http://arxiv.org/abs/2501.10129v1","updated":"2025-01-17T11:36:38Z","published":"2025-01-17T11:36:38Z","title":"Spatio-temporal Graph Learning on Adaptive Mined Key Frames for\n  High-performance Multi-Object Tracking","summary":"  In the realm of multi-object tracking, the challenge of accurately capturing\nthe spatial and temporal relationships between objects in video sequences\nremains a significant hurdle. This is further complicated by frequent\noccurrences of mutual occlusions among objects, which can lead to tracking\nerrors and reduced performance in existing methods. Motivated by these\nchallenges, we propose a novel adaptive key frame mining strategy that\naddresses the limitations of current tracking approaches. Specifically, we\nintroduce a Key Frame Extraction (KFE) module that leverages reinforcement\nlearning to adaptively segment videos, thereby guiding the tracker to exploit\nthe intrinsic logic of the video content. This approach allows us to capture\nstructured spatial relationships between different objects as well as the\ntemporal relationships of objects across frames. To tackle the issue of object\nocclusions, we have developed an Intra-Frame Feature Fusion (IFF) module.\nUnlike traditional graph-based methods that primarily focus on inter-frame\nfeature fusion, our IFF module uses a Graph Convolutional Network (GCN) to\nfacilitate information exchange between the target and surrounding objects\nwithin a frame. This innovation significantly enhances target\ndistinguishability and mitigates tracking loss and appearance similarity due to\nocclusions. By combining the strengths of both long and short trajectories and\nconsidering the spatial relationships between objects, our proposed tracker\nachieves impressive results on the MOT17 dataset, i.e., 68.6 HOTA, 81.0 IDF1,\n66.6 AssA, and 893 IDS, proving its effectiveness and accuracy.\n","authors":["Futian Wang","Fengxiang Liu","Xiao Wang"],"pdf_url":"https://arxiv.org/pdf/2501.10129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10128v1","updated":"2025-01-17T11:32:33Z","published":"2025-01-17T11:32:33Z","title":"FECT: Classification of Breast Cancer Pathological Images Based on\n  Fusion Features","summary":"  Breast cancer is one of the most common cancers among women globally, with\nearly diagnosis and precise classification being crucial. With the advancement\nof deep learning and computer vision, the automatic classification of breast\ntissue pathological images has emerged as a research focus. Existing methods\ntypically rely on singular cell or tissue features and lack design\nconsiderations for morphological characteristics of challenging-to-classify\ncategories, resulting in suboptimal classification performance. To address\nthese problems, we proposes a novel breast cancer tissue classification model\nthat Fused features of Edges, Cells, and Tissues (FECT), employing the\nResMTUNet and an attention-based aggregator to extract and aggregate these\nfeatures. Extensive testing on the BRACS dataset demonstrates that our model\nsurpasses current advanced methods in terms of classification accuracy and F1\nscores. Moreover, due to its feature fusion that aligns with the diagnostic\napproach of pathologists, our model exhibits interpretability and holds promise\nfor significant roles in future clinical applications.\n","authors":["Jiacheng Hao","Yiqing Liu","Siqi Zeng","Yonghong He"],"pdf_url":"https://arxiv.org/pdf/2501.10128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.04162v2","updated":"2025-01-17T11:30:28Z","published":"2023-08-08T09:48:00Z","title":"Expression Prompt Collaboration Transformer for Universal Referring\n  Video Object Segmentation","summary":"  Audio-guided Video Object Segmentation (A-VOS) and Referring Video Object\nSegmentation (R-VOS) are two highly related tasks that both aim to segment\nspecific objects from video sequences according to expression prompts. However,\ndue to the challenges of modeling representations for different modalities,\nexisting methods struggle to strike a balance between interaction flexibility\nand localization precision. In this paper, we address this problem from two\nperspectives: the alignment of audio and text and the deep interaction among\naudio, text, and visual modalities. First, we propose a universal architecture,\nthe Expression Prompt Collaboration Transformer, herein EPCFormer. Next, we\npropose an Expression Alignment (EA) mechanism for audio and text. The proposed\nEPCFormer exploits the fact that audio and text prompts referring to the same\nobjects are semantically equivalent by using contrastive learning for both\ntypes of expressions. Then, to facilitate deep interactions among audio, text,\nand visual modalities, we introduce an Expression-Visual Attention (EVA)\nmodule. The knowledge of video object segmentation in terms of the expression\nprompts can seamlessly transfer between the two tasks by deeply exploring\ncomplementary cues between text and audio. Experiments on well-recognized\nbenchmarks demonstrate that our EPCFormer attains state-of-the-art results on\nboth tasks. The source code will be made publicly available at\nhttps://github.com/lab206/EPCFormer.\n","authors":["Jiajun Chen","Jiacheng Lin","Guojin Zhong","Haolong Fu","Ke Nai","Kailun Yang","Zhiyong Li"],"pdf_url":"https://arxiv.org/pdf/2308.04162v2.pdf","comment":"Accepted to Knowledge-Based Systems (KBS). The source code will be\n  made publicly available at https://github.com/lab206/EPCFormer"},{"id":"http://arxiv.org/abs/2501.07888v2","updated":"2025-01-17T11:06:34Z","published":"2025-01-14T06:54:39Z","title":"Tarsier2: Advancing Large Vision-Language Models from Detailed Video\n  Description to Comprehensive Video Understanding","summary":"  We introduce Tarsier2, a state-of-the-art large vision-language model (LVLM)\ndesigned for generating detailed and accurate video descriptions, while also\nexhibiting superior general video understanding capabilities. Tarsier2 achieves\nsignificant advancements through three key upgrades: (1) Scaling pre-training\ndata from 11M to 40M video-text pairs, enriching both volume and diversity; (2)\nPerforming fine-grained temporal alignment during supervised fine-tuning; (3)\nUsing model-based sampling to automatically construct preference data and\napplying DPO training for optimization. Extensive experiments show that\nTarsier2-7B consistently outperforms leading proprietary models, including\nGPT-4o and Gemini 1.5 Pro, in detailed video description tasks. On the DREAM-1K\nbenchmark, Tarsier2-7B improves F1 by 2.8\\% over GPT-4o and 5.8\\% over\nGemini-1.5-Pro. In human side-by-side evaluations, Tarsier2-7B shows a +8.6\\%\nperformance advantage over GPT-4o and +24.9\\% over Gemini-1.5-Pro. Tarsier2-7B\nalso sets new state-of-the-art results across 15 public benchmarks, spanning\ntasks such as video question-answering, video grounding, hallucination test,\nand embodied question-answering, demonstrating its versatility as a robust\ngeneralist vision-language model.\n","authors":["Liping Yuan","Jiawei Wang","Haomiao Sun","Yuchen Zhang","Yuan Lin"],"pdf_url":"https://arxiv.org/pdf/2501.07888v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17458v2","updated":"2025-01-17T10:59:58Z","published":"2024-06-25T10:53:57Z","title":"Continuous Urban Change Detection from Satellite Image Time Series with\n  Temporal Feature Refinement and Multi-Task Integration","summary":"  Urbanization advances at unprecedented rates, resulting in negative effects\non the environment and human well-being. Remote sensing has the potential to\nmitigate these effects by supporting sustainable development strategies with\naccurate information on urban growth. Deep learning-based methods have achieved\npromising urban change detection results from optical satellite image pairs\nusing convolutional neural networks (ConvNets), transformers, and a multi-task\nlearning setup. However, transformers have not been leveraged for urban change\ndetection with multi-temporal data, i.e., >2 images, and multi-task learning\nmethods lack integration approaches that combine change and segmentation\noutputs. To fill this research gap, we propose a continuous urban change\ndetection method that identifies changes in each consecutive image pair of a\nsatellite image time series (SITS). Specifically, we propose a temporal feature\nrefinement (TFR) module that utilizes self-attention to improve ConvNet-based\nmulti-temporal building representations. Furthermore, we propose a multi-task\nintegration (MTI) module that utilizes Markov networks to find an optimal\nbuilding map time series based on segmentation and dense change outputs. The\nproposed method effectively identifies urban changes based on high-resolution\nSITS acquired by the PlanetScope constellation (F1 score 0.551) and Gaofen-2\n(F1 score 0.440). Moreover, our experiments on two challenging datasets\ndemonstrate the effectiveness of the proposed method compared to bi-temporal\nand multi-temporal urban change detection and segmentation methods.\n","authors":["Sebastian Hafner","Heng Fang","Hossein Azizpour","Yifang Ban"],"pdf_url":"https://arxiv.org/pdf/2406.17458v2.pdf","comment":"Under review at IEEE Transactions on Geoscience and Remote Sensing,\n  Code will be available at https://github.com/SebastianHafner/ContUrbanCD.git"},{"id":"http://arxiv.org/abs/2412.16146v2","updated":"2025-01-17T10:56:33Z","published":"2024-12-20T18:50:36Z","title":"Mamba2D: A Natively Multi-Dimensional State-Space Model for Vision Tasks","summary":"  State-Space Models (SSMs) have recently emerged as a powerful and efficient\nalternative to the long-standing transformer architecture. However, existing\nSSM conceptualizations retain deeply rooted biases from their roots in natural\nlanguage processing. This constrains their ability to appropriately model the\nspatially-dependent characteristics of visual inputs. In this paper, we address\nthese limitations by re-deriving modern selective state-space techniques,\nstarting from a natively multidimensional formulation. Currently, prior works\nattempt to apply natively 1D SSMs to 2D data (i.e. images) by relying on\narbitrary combinations of 1D scan directions to capture spatial dependencies.\nIn contrast, Mamba2D improves upon this with a single 2D scan direction that\nfactors in both dimensions of the input natively, effectively modelling spatial\ndependencies when constructing hidden states. Mamba2D shows comparable\nperformance to prior adaptations of SSMs for vision tasks, on standard image\nclassification evaluations with the ImageNet-1K dataset. Source code is\navailable at https://github.com/cocoalex00/Mamba2D.\n","authors":["Enis Baty","Alejandro Hernández Díaz","Chris Bridges","Rebecca Davidson","Steve Eckersley","Simon Hadfield"],"pdf_url":"https://arxiv.org/pdf/2412.16146v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10110v1","updated":"2025-01-17T10:53:03Z","published":"2025-01-17T10:53:03Z","title":"DiffVSR: Enhancing Real-World Video Super-Resolution with Diffusion\n  Models for Advanced Visual Quality and Temporal Consistency","summary":"  Diffusion models have demonstrated exceptional capabilities in image\ngeneration and restoration, yet their application to video super-resolution\nfaces significant challenges in maintaining both high fidelity and temporal\nconsistency. We present DiffVSR, a diffusion-based framework for real-world\nvideo super-resolution that effectively addresses these challenges through key\ninnovations. For intra-sequence coherence, we develop a multi-scale temporal\nattention module and temporal-enhanced VAE decoder that capture fine-grained\nmotion details. To ensure inter-sequence stability, we introduce a noise\nrescheduling mechanism with an interweaved latent transition approach, which\nenhances temporal consistency without additional training overhead. We propose\na progressive learning strategy that transitions from simple to complex\ndegradations, enabling robust optimization despite limited high-quality video\ndata. Extensive experiments demonstrate that DiffVSR delivers superior results\nin both visual quality and temporal consistency, setting a new performance\nstandard in real-world video super-resolution.\n","authors":["Xiaohui Li","Yihao Liu","Shuo Cao","Ziyan Chen","Shaobin Zhuang","Xiangyu Chen","Yinan He","Yi Wang","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2501.10110v1.pdf","comment":"Project page: \\url{https://xh9998.github.io/DiffVSR-project/}"},{"id":"http://arxiv.org/abs/2501.10105v1","updated":"2025-01-17T10:45:22Z","published":"2025-01-17T10:45:22Z","title":"Universal Actions for Enhanced Embodied Foundation Models","summary":"  Training on diverse, internet-scale data is a key factor in the success of\nrecent large foundation models. Yet, using the same recipe for building\nembodied agents has faced noticeable difficulties. Despite the availability of\nmany crowd-sourced embodied datasets, their action spaces often exhibit\nsignificant heterogeneity due to distinct physical embodiment and control\ninterfaces for different robots, causing substantial challenges in developing\nembodied foundation models using cross-domain data. In this paper, we introduce\nUniAct, a new embodied foundation modeling framework operating in a tokenized\nUniversal Action Space. Our learned universal actions capture the generic\natomic behaviors across diverse robots by exploiting their shared structural\nfeatures, and enable enhanced cross-domain data utilization and\ncross-embodiment generalizations by eliminating the notorious heterogeneity.\nThe universal actions can be efficiently translated back to heterogeneous\nactionable commands by simply adding embodiment-specific details, from which\nfast adaptation to new robots becomes simple and straightforward. Our 0.5B\ninstantiation of UniAct outperforms 14X larger SOTA embodied foundation models\nin extensive evaluations on various real-world and simulation robots,\nshowcasing exceptional cross-embodiment control and adaptation capability,\nhighlighting the crucial benefit of adopting universal actions. Project page:\nhttps://github.com/2toinf/UniAct\n","authors":["Jinliang Zheng","Jianxiong Li","Dongxiu Liu","Yinan Zheng","Zhihao Wang","Zhonghong Ou","Yu Liu","Jingjing Liu","Ya-Qin Zhang","Xianyuan Zhan"],"pdf_url":"https://arxiv.org/pdf/2501.10105v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2501.10098v1","updated":"2025-01-17T10:35:58Z","published":"2025-01-17T10:35:58Z","title":"landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D\n  Images","summary":"  Anatomical landmark localization in 2D/3D images is a critical task in\nmedical imaging. Although many general-purpose tools exist for landmark\nlocalization in classical computer vision tasks, such as pose estimation, they\nlack the specialized features and modularity necessary for anatomical landmark\nlocalization applications in the medical domain. Therefore, we introduce\nlandmarker, a Python package built on PyTorch. The package provides a\ncomprehensive, flexible toolkit for developing and evaluating landmark\nlocalization algorithms, supporting a range of methodologies, including static\nand adaptive heatmap regression. landmarker enhances the accuracy of landmark\nidentification, streamlines research and development processes, and supports\nvarious image formats and preprocessing pipelines. Its modular design allows\nusers to customize and extend the toolkit for specific datasets and\napplications, accelerating innovation in medical imaging. landmarker addresses\na critical need for precision and customization in landmark localization tasks\nnot adequately met by existing general-purpose pose estimation tools.\n","authors":["Jef Jonkers","Luc Duchateau","Glenn Van Wallendael","Sofie Van Hoecke"],"pdf_url":"https://arxiv.org/pdf/2501.10098v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2307.15977v3","updated":"2025-01-17T10:33:14Z","published":"2023-07-29T13:00:42Z","title":"Model Synthesis for Zero-Shot Model Attribution","summary":"  Nowadays, generative models are shaping various fields such as art, design,\nand human-computer interaction, yet accompanied by challenges related to\ncopyright infringement and content management. In response, existing research\nseeks to identify the unique fingerprints on the images they generate, which\ncan be leveraged to attribute the generated images to their source models.\nExisting methods, however, are constrained to identifying models within a\nstatic set included in the classifier training, failing to adapt to newly\nemerged unseen models dynamically. To bridge this gap, we aim to develop a\ngeneralized model fingerprint extractor capable of zero-shot attribution,\neffectively attributes unseen models without exposure during training. Central\nto our method is a model synthesis technique, which generates numerous\nsynthetic models mimicking the fingerprint patterns of real-world generative\nmodels. The design of the synthesis technique is motivated by observations on\nhow the basic generative model's architecture building blocks and parameters\ninfluence fingerprint patterns, and it is validated through two designed\nmetrics that examine synthetic models' fidelity and diversity. Our experiments\ndemonstrate that this fingerprint extractor, trained solely on synthetic\nmodels, achieves impressive zero-shot generalization on a wide range of\nreal-world generative models, improving model identification and verification\naccuracy on unseen models by over 40% and 15%, respectively, compared to\nexisting approaches.\n","authors":["Tianyun Yang","Juan Cao","Danding Wang","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2307.15977v3.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2309.00494v2","updated":"2025-01-17T10:31:13Z","published":"2023-09-01T14:40:25Z","title":"Multi-stage Deep Learning Artifact Reduction for Pallel-beam Computed\n  Tomography","summary":"  Computed Tomography (CT) using synchrotron radiation is a powerful technique\nthat, compared to lab-CT techniques, boosts high spatial and temporal\nresolution while also providing access to a range of contrast-formation\nmechanisms. The acquired projection data is typically processed by a\ncomputational pipeline composed of multiple stages. Artifacts introduced during\ndata acquisition can propagate through the pipeline, and degrade image quality\nin the reconstructed images. Recently, deep learning has shown significant\npromise in enhancing image quality for images representing scientific data.\nThis success has driven increasing adoption of deep learning techniques in CT\nimaging. Various approaches have been proposed to incorporate deep learning\ninto computational pipelines, but each has limitations in addressing artifacts\neffectively and efficiently in synchrotron CT, either in properly addressing\nthe specific artifacts, or in computational efficiency.\n  Recognizing these challenges, we introduce a novel method that incorporates\nseparate deep learning models at each stage of the tomography\npipeline-projection, sinogram, and reconstruction-to address specific artifacts\nlocally in a data-driven way. Our approach includes bypass connections that\nfeed both the outputs from previous stages and raw data to subsequent stages,\nminimizing the risk of error propagation. Extensive evaluations on both\nsimulated and real-world datasets illustrate that our approach effectively\nreduces artifacts and outperforms comparison methods.\n","authors":["Jiayang Shi","Daniel M. Pelt","K. Joost Batenburg"],"pdf_url":"https://arxiv.org/pdf/2309.00494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10089v1","updated":"2025-01-17T10:16:18Z","published":"2025-01-17T10:16:18Z","title":"Classifier Ensemble for Efficient Uncertainty Calibration of Deep Neural\n  Networks for Image Classification","summary":"  This paper investigates novel classifier ensemble techniques for uncertainty\ncalibration applied to various deep neural networks for image classification.\nWe evaluate both accuracy and calibration metrics, focusing on Expected\nCalibration Error (ECE) and Maximum Calibration Error (MCE). Our work compares\ndifferent methods for building simple yet efficient classifier ensembles,\nincluding majority voting and several metamodel-based approaches. Our\nevaluation reveals that while state-of-the-art deep neural networks for image\nclassification achieve high accuracy on standard datasets, they frequently\nsuffer from significant calibration errors. Basic ensemble techniques like\nmajority voting provide modest improvements, while metamodel-based ensembles\nconsistently reduce ECE and MCE across all architectures. Notably, the largest\nof our compared metamodels demonstrate the most substantial calibration\nimprovements, with minimal impact on accuracy. Moreover, classifier ensembles\nwith metamodels outperform traditional model ensembles in calibration\nperformance, while requiring significantly fewer parameters. In comparison to\ntraditional post-hoc calibration methods, our approach removes the need for a\nseparate calibration dataset. These findings underscore the potential of our\nproposed metamodel-based classifier ensembles as an efficient and effective\napproach to improving model calibration, thereby contributing to more reliable\ndeep learning systems.\n","authors":["Michael Schulze","Nikolas Ebert","Laurenz Reichardt","Oliver Wasenmüller"],"pdf_url":"https://arxiv.org/pdf/2501.10089v1.pdf","comment":"This paper has been accepted at International Conference on Computer\n  Vision Theory and Applications (VISAPP), 2025"},{"id":"http://arxiv.org/abs/2410.05820v2","updated":"2025-01-17T10:01:30Z","published":"2024-10-08T08:49:47Z","title":"IncSAR: A Dual Fusion Incremental Learning Framework for SAR Target\n  Recognition","summary":"  Deep learning techniques have achieved significant success in Synthetic\nAperture Radar (SAR) target recognition using predefined datasets in static\nscenarios. However, real-world applications demand that models incrementally\nlearn new information without forgetting previously acquired knowledge. The\nchallenge of catastrophic forgetting, where models lose past knowledge when\nadapting to new tasks, remains a critical issue. In this paper, we introduce\nIncSAR, an incremental learning framework designed to tackle catastrophic\nforgetting in SAR target recognition. IncSAR combines the power of a Vision\nTransformer (ViT) and a custom-designed Convolutional Neural Network (CNN) in a\ndual-branch architecture, integrated via a late-fusion strategy. Additionally,\nwe explore the use of TinyViT to reduce computational complexity and propose an\nattention mechanism to dynamically enhance feature representation. To mitigate\nthe speckle noise inherent in SAR images, we employ a denoising module based on\na neural network approximation of Robust Principal Component Analysis (RPCA),\nleveraging a simple neural network for efficient noise reduction in SAR\nimagery. Moreover, a random projection layer improves the linear separability\nof features, and a variant of Linear Discriminant Analysis (LDA) decorrelates\nextracted class prototypes for better generalization. Extensive experiments on\nthe MSTAR, SAR-AIRcraft-1.0, and OpenSARShip benchmark datasets demonstrate\nthat IncSAR significantly outperforms state-of-the-art approaches, achieving a\n99.63\\% average accuracy and a 0.33\\% performance drop, representing an 89\\%\nimprovement in retention compared to existing techniques. The source code is\navailable at https://github.com/geokarant/IncSAR.\n","authors":["George Karantaidis","Athanasios Pantsios","Ioannis Kompatsiaris","Symeon Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2410.05820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10081v1","updated":"2025-01-17T09:55:41Z","published":"2025-01-17T09:55:41Z","title":"Leveraging Confident Image Regions for Source-Free Domain-Adaptive\n  Object Detection","summary":"  Source-free domain-adaptive object detection is an interesting but scarcely\naddressed topic. It aims at adapting a source-pretrained detector to a distinct\ntarget domain without resorting to source data during adaptation. So far, there\nis no data augmentation scheme tailored to source-free domain-adaptive object\ndetection. To this end, this paper presents a novel data augmentation approach\nthat cuts out target image regions where the detector is confident, augments\nthem along with their respective pseudo-labels, and joins them into a\nchallenging target image to adapt the detector. As the source data is out of\nreach during adaptation, we implement our approach within a teacher-student\nlearning paradigm to ensure that the model does not collapse during the\nadaptation procedure. We evaluated our approach on three adaptation benchmarks\nof traffic scenes, scoring new state-of-the-art on two of them.\n","authors":["Mohamed Lamine Mekhalfi","Davide Boscaini","Fabio Poiesi"],"pdf_url":"https://arxiv.org/pdf/2501.10081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10080v1","updated":"2025-01-17T09:55:05Z","published":"2025-01-17T09:55:05Z","title":"Few-shot Structure-Informed Machinery Part Segmentation with Foundation\n  Models and Graph Neural Networks","summary":"  This paper proposes a novel approach to few-shot semantic segmentation for\nmachinery with multiple parts that exhibit spatial and hierarchical\nrelationships. Our method integrates the foundation models CLIPSeg and Segment\nAnything Model (SAM) with the interest point detector SuperPoint and a graph\nconvolutional network (GCN) to accurately segment machinery parts. By providing\n1 to 25 annotated samples, our model, evaluated on a purely synthetic dataset\ndepicting a truck-mounted loading crane, achieves effective segmentation across\nvarious levels of detail. Training times are kept under five minutes on\nconsumer GPUs. The model demonstrates robust generalization to real data,\nachieving a qualitative synthetic-to-real generalization with a $J\\&F$ score of\n92.2 on real data using 10 synthetic support samples. When benchmarked on the\nDAVIS 2017 dataset, it achieves a $J\\&F$ score of 71.5 in semi-supervised video\nsegmentation with three support samples. This method's fast training times and\neffective generalization to real data make it a valuable tool for autonomous\nsystems interacting with machinery and infrastructure, and illustrate the\npotential of combined and orchestrated foundation models for few-shot\nsegmentation tasks.\n","authors":["Michael Schwingshackl","Fabio Francisco Oberweger","Markus Murschitz"],"pdf_url":"https://arxiv.org/pdf/2501.10080v1.pdf","comment":"Accepted at Winter Conference on Applications of Computer Vision\n  (WACV) 2025. Code and available at\n  https://github.com/AIT-Assistive-Autonomous-Systems/Hopomop"},{"id":"http://arxiv.org/abs/2411.19939v2","updated":"2025-01-17T09:50:55Z","published":"2024-11-29T18:56:37Z","title":"VLSBench: Unveiling Visual Leakage in Multimodal Safety","summary":"  Safety concerns of Multimodal large language models (MLLMs) have gradually\nbecome an important problem in various applications. Surprisingly, previous\nworks indicate a counter-intuitive phenomenon that using textual unlearning to\nalign MLLMs achieves comparable safety performances with MLLMs trained with\nimage-text pairs. To explain such a counter-intuitive phenomenon, we discover a\nvisual safety information leakage (VSIL) problem in existing multimodal safety\nbenchmarks, i.e., the potentially risky and sensitive content in the image has\nbeen revealed in the textual query. In this way, MLLMs can easily refuse these\nsensitive text-image queries according to textual queries. However, image-text\npairs without VSIL are common in real-world scenarios and are overlooked by\nexisting multimodal safety benchmarks. To this end, we construct multimodal\nvisual leakless safety benchmark (VLSBench) preventing visual safety leakage\nfrom image to textual query with 2.4k image-text pairs. Experimental results\nindicate that VLSBench poses a significant challenge to both open-source and\nclose-source MLLMs, including LLaVA, Qwen2-VL, Llama3.2-Vision, and GPT-4o.\nThis study demonstrates that textual alignment is enough for multimodal safety\nscenarios with VSIL, while multimodal alignment is a more promising solution\nfor multimodal safety scenarios without VSIL. Please see our code and data at:\nhttps://hxhcreate.github.io/vlsbench.github.io/\n","authors":["Xuhao Hu","Dongrui Liu","Hao Li","Xuanjing Huang","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2411.19939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10075v1","updated":"2025-01-17T09:47:27Z","published":"2025-01-17T09:47:27Z","title":"Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and\n  MModalCC Framework","summary":"  Remote sensing change captioning (RSICC) aims to describe changes between\nbitemporal images in natural language. Existing methods often fail under\nchallenges like illumination differences, viewpoint changes, blur effects,\nleading to inaccuracies, especially in no-change regions. Moreover, the images\nacquired at different spatial resolutions and have registration errors tend to\naffect the captions. To address these issues, we introduce SECOND-CC, a novel\nRSICC dataset featuring high-resolution RGB image pairs, semantic segmentation\nmaps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of\nbitemporal RS images and 30,205 sentences describing the differences between\nimages. Additionally, we propose MModalCC, a multimodal framework that\nintegrates semantic and visual data using advanced attention mechanisms,\nincluding Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross\nAttention (MGCA). Detailed ablation studies and attention visualizations\nfurther demonstrate its effectiveness and ability to address RSICC challenges.\nComprehensive experiments show that MModalCC outperforms state-of-the-art RSICC\nmethods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on\nBLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and\ncodebase publicly available to facilitate future research at\nhttps://github.com/ChangeCapsInRS/SecondCC\n","authors":["Ali Can Karaca","M. Enes Ozelbas","Saadettin Berber","Orkhan Karimli","Turabi Yildirim","M. Fatih Amasyali"],"pdf_url":"https://arxiv.org/pdf/2501.10075v1.pdf","comment":"This work has been submitted to the IEEE Transactions on Geoscience\n  and Remote Sensing journal for possible publication"},{"id":"http://arxiv.org/abs/2501.10074v1","updated":"2025-01-17T09:46:27Z","published":"2025-01-17T09:46:27Z","title":"SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and\n  Chain-of-Thought for Embodied Task Planning","summary":"  Spatial reasoning is an essential problem in embodied AI research. Efforts to\nenhance spatial reasoning abilities through supplementary spatial data and\nfine-tuning have proven limited and ineffective when addressing complex\nembodied tasks, largely due to their dependence on language-based outputs.\nWhile some approaches have introduced a point-based action space to mitigate\nthis issue, they fall short in managing more intricate tasks within complex\nenvironments. This deficiency arises from their failure to fully exploit the\ninherent thinking and reasoning capabilities that are fundamental strengths of\nVision-Language Models (VLMs). To address these limitations, we propose a novel\napproach named SpatialCoT, specifically designed to bolster the spatial\nreasoning capabilities of VLMs. Our approach comprises two stages: spatial\ncoordinate bi-directional alignment, which aligns vision-language inputs with\nspatial coordinates, and chain-of-thought spatial grounding, which harnesses\nthe reasoning capabilities of language models for advanced spatial reasoning.\nWe evaluate SpatialCoT on challenging navigation and manipulation tasks, both\nin simulation and real-world settings. Experimental results demonstrate that\nour method significantly outperforms previous state-of-the-art approaches in\nboth tasks.\n","authors":["Yuecheng Liu","Dafeng Chi","Shiguang Wu","Zhanguang Zhang","Yaochen Hu","Lingfeng Zhang","Yingxue Zhang","Shuang Wu","Tongtong Cao","Guowei Huang","Guangjian Tian","Xingyue Quan","Jianye Hao","Yuzheng Zhuang"],"pdf_url":"https://arxiv.org/pdf/2501.10074v1.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2501.10071v1","updated":"2025-01-17T09:43:14Z","published":"2025-01-17T09:43:14Z","title":"CLIP-PCQA: Exploring Subjective-Aligned Vision-Language Modeling for\n  Point Cloud Quality Assessment","summary":"  In recent years, No-Reference Point Cloud Quality Assessment (NR-PCQA)\nresearch has achieved significant progress. However, existing methods mostly\nseek a direct mapping function from visual data to the Mean Opinion Score\n(MOS), which is contradictory to the mechanism of practical subjective\nevaluation. To address this, we propose a novel language-driven PCQA method\nnamed CLIP-PCQA. Considering that human beings prefer to describe visual\nquality using discrete quality descriptions (e.g., \"excellent\" and \"poor\")\nrather than specific scores, we adopt a retrieval-based mapping strategy to\nsimulate the process of subjective assessment. More specifically, based on the\nphilosophy of CLIP, we calculate the cosine similarity between the visual\nfeatures and multiple textual features corresponding to different quality\ndescriptions, in which process an effective contrastive loss and learnable\nprompts are introduced to enhance the feature extraction. Meanwhile, given the\npersonal limitations and bias in subjective experiments, we further covert the\nfeature similarities into probabilities and consider the Opinion Score\nDistribution (OSD) rather than a single MOS as the final target. Experimental\nresults show that our CLIP-PCQA outperforms other State-Of-The-Art (SOTA)\napproaches.\n","authors":["Yating Liu","Yujie Zhang","Ziyu Shan","Yiling Xu"],"pdf_url":"https://arxiv.org/pdf/2501.10071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09365v4","updated":"2025-01-17T09:40:59Z","published":"2024-05-15T14:17:44Z","title":"SARATR-X: Towards Building A Foundation Model for SAR Target Recognition","summary":"  Despite the remarkable progress in synthetic aperture radar automatic target\nrecognition (SAR ATR), recent efforts have concentrated on detecting and\nclassifying a specific category, e.g., vehicles, ships, airplanes, or\nbuildings. One of the fundamental limitations of the top-performing SAR ATR\nmethods is that the learning paradigm is supervised, task-specific,\nlimited-category, closed-world learning, which depends on massive amounts of\naccurately annotated samples that are expensively labeled by expert SAR\nanalysts and have limited generalization capability and scalability. In this\nwork, we make the first attempt towards building a foundation model for SAR\nATR, termed SARATR-X. SARATR-X learns generalizable representations via\nself-supervised learning (SSL) and provides a cornerstone for label-efficient\nmodel adaptation to generic SAR target detection and classification tasks.\nSpecifically, SARATR-X is trained on 0.18 M unlabelled SAR target samples,\nwhich are curated by combining contemporary benchmarks and constitute the\nlargest publicly available dataset till now. Considering the characteristics of\nSAR images, a backbone tailored for SAR ATR is carefully designed, and a\ntwo-step SSL method endowed with multi-scale gradient features was applied to\nensure the feature diversity and model scalability of SARATR-X. The\ncapabilities of SARATR-X are evaluated on classification under few-shot and\nrobustness settings and detection across various categories and scenes, and\nimpressive performance is achieved, often competitive with or even superior to\nprior fully supervised, semi-supervised, or self-supervised algorithms. Our\nSARATR-X and the curated dataset are released at\nhttps://github.com/waterdisappear/SARATR-X to foster research into foundation\nmodels for SAR image interpretation.\n","authors":["Weijie Li","Wei Yang","Yuenan Hou","Li Liu","Yongxiang Liu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2405.09365v4.pdf","comment":"20 pages, 9 figures"},{"id":"http://arxiv.org/abs/2501.10067v1","updated":"2025-01-17T09:38:43Z","published":"2025-01-17T09:38:43Z","title":"FiLo++: Zero-/Few-Shot Anomaly Detection by Fused Fine-Grained\n  Descriptions and Deformable Localization","summary":"  Anomaly detection methods typically require extensive normal samples from the\ntarget class for training, limiting their applicability in scenarios that\nrequire rapid adaptation, such as cold start. Zero-shot and few-shot anomaly\ndetection do not require labeled samples from the target class in advance,\nmaking them a promising research direction. Existing zero-shot and few-shot\napproaches often leverage powerful multimodal models to detect and localize\nanomalies by comparing image-text similarity. However, their handcrafted\ngeneric descriptions fail to capture the diverse range of anomalies that may\nemerge in different objects, and simple patch-level image-text matching often\nstruggles to localize anomalous regions of varying shapes and sizes. To address\nthese issues, this paper proposes the FiLo++ method, which consists of two key\ncomponents. The first component, Fused Fine-Grained Descriptions (FusDes),\nutilizes large language models to generate anomaly descriptions for each object\ncategory, combines both fixed and learnable prompt templates and applies a\nruntime prompt filtering method, producing more accurate and task-specific\ntextual descriptions. The second component, Deformable Localization (DefLoc),\nintegrates the vision foundation model Grounding DINO with position-enhanced\ntext descriptions and a Multi-scale Deformable Cross-modal Interaction (MDCI)\nmodule, enabling accurate localization of anomalies with various shapes and\nsizes. In addition, we design a position-enhanced patch matching approach to\nimprove few-shot anomaly detection performance. Experiments on multiple\ndatasets demonstrate that FiLo++ achieves significant performance improvements\ncompared with existing methods. Code will be available at\nhttps://github.com/CASIA-IVA-Lab/FiLo.\n","authors":["Zhaopeng Gu","Bingke Zhu","Guibo Zhu","Yingying Chen","Ming Tang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2501.10067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10064v1","updated":"2025-01-17T09:29:33Z","published":"2025-01-17T09:29:33Z","title":"One-D-Piece: Image Tokenizer Meets Quality-Controllable Compression","summary":"  Current image tokenization methods require a large number of tokens to\ncapture the information contained within images. Although the amount of\ninformation varies across images, most image tokenizers only support\nfixed-length tokenization, leading to inefficiency in token allocation. In this\nstudy, we introduce One-D-Piece, a discrete image tokenizer designed for\nvariable-length tokenization, achieving quality-controllable mechanism. To\nenable variable compression rate, we introduce a simple but effective\nregularization mechanism named \"Tail Token Drop\" into discrete one-dimensional\nimage tokenizers. This method encourages critical information to concentrate at\nthe head of the token sequence, enabling support of variadic tokenization,\nwhile preserving state-of-the-art reconstruction quality. We evaluate our\ntokenizer across multiple reconstruction quality metrics and find that it\ndelivers significantly better perceptual quality than existing\nquality-controllable compression methods, including JPEG and WebP, at smaller\nbyte sizes. Furthermore, we assess our tokenizer on various downstream computer\nvision tasks, including image classification, object detection, semantic\nsegmentation, and depth estimation, confirming its adaptability to numerous\napplications compared to other variable-rate methods. Our approach demonstrates\nthe versatility of variable-length discrete image tokenization, establishing a\nnew paradigm in both compression efficiency and reconstruction performance.\nFinally, we validate the effectiveness of tail token drop via detailed analysis\nof tokenizers.\n","authors":["Keita Miwa","Kento Sasaki","Hidehisa Arai","Tsubasa Takahashi","Yu Yamaguchi"],"pdf_url":"https://arxiv.org/pdf/2501.10064v1.pdf","comment":"Our Project Page:\n  https://turingmotors.github.io/one-d-piece-tokenizer"},{"id":"http://arxiv.org/abs/2404.03703v3","updated":"2025-01-17T09:03:57Z","published":"2024-04-04T07:49:39Z","title":"Mitigating analytical variability in fMRI results with style transfer","summary":"  We propose a novel approach to improve the reproducibility of neuroimaging\nresults by converting statistic maps across different functional MRI pipelines.\nWe make the assumption that pipelines used to compute fMRI statistic maps can\nbe considered as a style component and we propose to use different generative\nmodels, among which, Generative Adversarial Networks (GAN) and Diffusion Models\n(DM) to convert statistic maps across different pipelines. We explore the\nperformance of multiple GAN frameworks, and design a new DM framework for\nunsupervised multi-domain styletransfer. We constrain the generation of 3D fMRI\nstatistic maps using the latent space of an auxiliary classifier that\ndistinguishes statistic maps from different pipelines and extend traditional\nsampling techniques used in DM to improve the transition performance. Our\nexperiments demonstrate that our proposed methods aresuccessful: pipelines can\nindeed be transferred as a style component, providing animportant source of\ndata augmentation for future medical studies.\n","authors":["Elodie Germani","Camille Maumet","Elisa Fromont"],"pdf_url":"https://arxiv.org/pdf/2404.03703v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12709v2","updated":"2025-01-17T09:03:17Z","published":"2024-12-17T09:23:46Z","title":"Accelerating lensed quasars discovery and modeling with physics-informed\n  variational autoencoders","summary":"  Strongly lensed quasars provide valuable insights into the rate of cosmic\nexpansion, the distribution of dark matter in foreground deflectors, and the\ncharacteristics of quasar hosts. However, detecting them in astronomical images\nis difficult due to the prevalence of non-lensing objects. To address this\nchallenge, we developed a generative deep learning model called VariLens, built\nupon a physics-informed variational autoencoder. This model seamlessly\nintegrates three essential modules: image reconstruction, object\nclassification, and lens modeling, offering a fast and comprehensive approach\nto strong lens analysis. VariLens is capable of rapidly determining both (1)\nthe probability that an object is a lens system and (2) key parameters of a\nsingular isothermal ellipsoid (SIE) mass model -- including the Einstein radius\n($\\theta_\\mathrm{E}$), lens center, and ellipticity -- in just milliseconds\nusing a single CPU. A direct comparison of VariLens estimates with traditional\nlens modeling for 20 known lensed quasars within the Subaru Hyper Suprime-Cam\n(HSC) footprint shows good agreement, with both results consistent within\n$2\\sigma$ for systems with $\\theta_\\mathrm{E}<3$ arcsecs. To identify new\nlensed quasar candidates, we begin with an initial sample of approximately 80\nmillion sources, combining HSC data with multiwavelength information from\nvarious surveys. After applying a photometric preselection aimed at locating\n$z>1.5$ sources, the number of candidates is reduced to 710,966. Subsequently,\nVariLens highlights 13,831 sources, each showing a high likelihood of being a\nlens. A visual assessment of these objects results in 42 promising candidates\nthat await spectroscopic confirmation. These results underscore the potential\nof automated deep learning pipelines to efficiently detect and model strong\nlenses in large datasets.\n","authors":["Irham T. Andika","Stefan Schuldt","Sherry H. Suyu","Satadru Bag","Raoul Cañameras","Alejandra Melo","Claudio Grillo","James H. H. Chan"],"pdf_url":"https://arxiv.org/pdf/2412.12709v2.pdf","comment":"Submitted to the Astronomy & Astrophysics journal and updated to\n  reflect the revised version. The paper consists of 17 main pages, 14 figures,\n  and 5 tables. We welcome feedback and comments from readers!"},{"id":"http://arxiv.org/abs/2501.10040v1","updated":"2025-01-17T08:56:17Z","published":"2025-01-17T08:56:17Z","title":"LWGANet: A Lightweight Group Attention Backbone for Remote Sensing\n  Visual Tasks","summary":"  Remote sensing (RS) visual tasks have gained significant academic and\npractical importance. However, they encounter numerous challenges that hinder\neffective feature extraction, including the detection and recognition of\nmultiple objects exhibiting substantial variations in scale within a single\nimage. While prior dual-branch or multi-branch architectural strategies have\nbeen effective in managing these object variances, they have concurrently\nresulted in considerable increases in computational demands and parameter\ncounts. Consequently, these architectures are rendered less viable for\ndeployment on resource-constrained devices. Contemporary lightweight backbone\nnetworks, designed primarily for natural images, frequently encounter\ndifficulties in effectively extracting features from multi-scale objects, which\ncompromises their efficacy in RS visual tasks. This article introduces LWGANet,\na specialized lightweight backbone network tailored for RS visual tasks,\nincorporating a novel lightweight group attention (LWGA) module designed to\naddress these specific challenges. LWGA module, tailored for RS imagery,\nadeptly harnesses redundant features to extract a wide range of spatial\ninformation, from local to global scales, without introducing additional\ncomplexity or computational overhead. This facilitates precise feature\nextraction across multiple scales within an efficient framework.LWGANet was\nrigorously evaluated across twelve datasets, which span four crucial RS visual\ntasks: scene classification, oriented object detection, semantic segmentation,\nand change detection. The results confirm LWGANet's widespread applicability\nand its ability to maintain an optimal balance between high performance and low\ncomplexity, achieving SOTA results across diverse datasets. LWGANet emerged as\na novel solution for resource-limited scenarios requiring robust RS image\nprocessing capabilities.\n","authors":["Wei Lu","Si-Bao Chen","Chris H. Q. Ding","Jin Tang","Bin Luo"],"pdf_url":"https://arxiv.org/pdf/2501.10040v1.pdf","comment":"12 pages, 8 figures, Remote sensing"},{"id":"http://arxiv.org/abs/2404.01604v3","updated":"2025-01-17T08:33:10Z","published":"2024-04-02T02:52:05Z","title":"WaveDH: Wavelet Sub-bands Guided ConvNet for Efficient Image Dehazing","summary":"  The surge in interest regarding image dehazing has led to notable\nadvancements in deep learning-based single image dehazing approaches,\nexhibiting impressive performance in recent studies. Despite these strides,\nmany existing methods fall short in meeting the efficiency demands of practical\napplications. In this paper, we introduce WaveDH, a novel and compact ConvNet\ndesigned to address this efficiency gap in image dehazing. Our WaveDH leverages\nwavelet sub-bands for guided up-and-downsampling and frequency-aware feature\nrefinement. The key idea lies in utilizing wavelet decomposition to extract\nlow-and-high frequency components from feature levels, allowing for faster\nprocessing while upholding high-quality reconstruction. The downsampling block\nemploys a novel squeeze-and-attention scheme to optimize the feature\ndownsampling process in a structurally compact manner through wavelet domain\nlearning, preserving discriminative features while discarding noise components.\nIn our upsampling block, we introduce a dual-upsample and fusion mechanism to\nenhance high-frequency component awareness, aiding in the reconstruction of\nhigh-frequency details. Departing from conventional dehazing methods that treat\nlow-and-high frequency components equally, our feature refinement block\nstrategically processes features with a frequency-aware approach. By employing\na coarse-to-fine methodology, it not only refines the details at frequency\nlevels but also significantly optimizes computational costs. The refinement is\nperformed in a maximum 8x downsampled feature space, striking a favorable\nefficiency-vs-accuracy trade-off. Extensive experiments demonstrate that our\nmethod, WaveDH, outperforms many state-of-the-art methods on several image\ndehazing benchmarks with significantly reduced computational costs. Our code is\navailable at https://github.com/AwesomeHwang/WaveDH.\n","authors":["Seongmin Hwang","Daeyoung Han","Cheolkon Jung","Moongu Jeon"],"pdf_url":"https://arxiv.org/pdf/2404.01604v3.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2307.09059v4","updated":"2025-01-17T08:32:40Z","published":"2023-07-18T08:23:46Z","title":"Text-guided Image Restoration and Semantic Enhancement for Text-to-Image\n  Person Retrieval","summary":"  The goal of Text-to-Image Person Retrieval (TIPR) is to retrieve specific\nperson images according to the given textual descriptions. A primary challenge\nin this task is bridging the substantial representational gap between visual\nand textual modalities. The prevailing methods map texts and images into\nunified embedding space for matching, while the intricate semantic\ncorrespondences between texts and images are still not effectively constructed.\nTo address this issue, we propose a novel TIPR framework to build fine-grained\ninteractions and alignment between person images and the corresponding texts.\nSpecifically, via fine-tuning the Contrastive Language-Image Pre-training\n(CLIP) model, a visual-textual dual encoder is firstly constructed, to\npreliminarily align the image and text features. Secondly, a Text-guided Image\nRestoration (TIR) auxiliary task is proposed to map abstract textual entities\nto specific image regions, improving the alignment between local textual and\nvisual embeddings. Additionally, a cross-modal triplet loss is presented to\nhandle hard samples, and further enhance the model's discriminability for minor\ndifferences. Moreover, a pruning-based text data augmentation approach is\nproposed to enhance focus on essential elements in descriptions, thereby\navoiding excessive model attention to less significant information. The\nexperimental results show our proposed method outperforms state-of-the-art\nmethods on three popular benchmark datasets, and the code will be made publicly\navailable at https://github.com/Delong-liu-bupt/SEN.\n","authors":["Delong Liu","Haiwen Li","Zhicheng Zhao","Yuan Dong"],"pdf_url":"https://arxiv.org/pdf/2307.09059v4.pdf","comment":"The paper was withdrawn due to a dispute among the authors regarding\n  the content of the article"},{"id":"http://arxiv.org/abs/2501.09278v2","updated":"2025-01-17T08:20:59Z","published":"2025-01-16T03:54:06Z","title":"Text-guided Synthetic Geometric Augmentation for Zero-shot 3D\n  Understanding","summary":"  Zero-shot recognition models require extensive training data for\ngeneralization. However, in zero-shot 3D classification, collecting 3D data and\ncaptions is costly and laborintensive, posing a significant barrier compared to\n2D vision. Recent advances in generative models have achieved unprecedented\nrealism in synthetic data production, and recent research shows the potential\nfor using generated data as training data. Here, naturally raising the\nquestion: Can synthetic 3D data generated by generative models be used as\nexpanding limited 3D datasets? In response, we present a synthetic 3D dataset\nexpansion method, Textguided Geometric Augmentation (TeGA). TeGA is tailored\nfor language-image-3D pretraining, which achieves SoTA in zero-shot 3D\nclassification, and uses a generative textto-3D model to enhance and extend\nlimited 3D datasets. Specifically, we automatically generate text-guided\nsynthetic 3D data and introduce a consistency filtering strategy to discard\nnoisy samples where semantics and geometric shapes do not match with text. In\nthe experiment to double the original dataset size using TeGA, our approach\ndemonstrates improvements over the baselines, achieving zeroshot performance\ngains of 3.0% on Objaverse-LVIS, 4.6% on ScanObjectNN, and 8.7% on ModelNet40.\nThese results demonstrate that TeGA effectively bridges the 3D data gap,\nenabling robust zero-shot 3D classification even with limited real training\ndata and paving the way for zero-shot 3D vision application.\n","authors":["Kohei Torimi","Ryosuke Yamada","Daichi Otsuka","Kensho Hara","Yuki M. Asano","Hirokatsu Kataoka","Yoshimitsu Aoki"],"pdf_url":"https://arxiv.org/pdf/2501.09278v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10021v1","updated":"2025-01-17T08:10:53Z","published":"2025-01-17T08:10:53Z","title":"X-Dyna: Expressive Dynamic Human Image Animation","summary":"  We introduce X-Dyna, a novel zero-shot, diffusion-based pipeline for\nanimating a single human image using facial expressions and body movements\nderived from a driving video, that generates realistic, context-aware dynamics\nfor both the subject and the surrounding environment. Building on prior\napproaches centered on human pose control, X-Dyna addresses key shortcomings\ncausing the loss of dynamic details, enhancing the lifelike qualities of human\nvideo animations. At the core of our approach is the Dynamics-Adapter, a\nlightweight module that effectively integrates reference appearance context\ninto the spatial attentions of the diffusion backbone while preserving the\ncapacity of motion modules in synthesizing fluid and intricate dynamic details.\nBeyond body pose control, we connect a local control module with our model to\ncapture identity-disentangled facial expressions, facilitating accurate\nexpression transfer for enhanced realism in animated scenes. Together, these\ncomponents form a unified framework capable of learning physical human motion\nand natural scene dynamics from a diverse blend of human and scene videos.\nComprehensive qualitative and quantitative evaluations demonstrate that X-Dyna\noutperforms state-of-the-art methods, creating highly lifelike and expressive\nanimations. The code is available at https://github.com/bytedance/X-Dyna.\n","authors":["Di Chang","Hongyi Xu","You Xie","Yipeng Gao","Zhengfei Kuang","Shengqu Cai","Chenxu Zhang","Guoxian Song","Chao Wang","Yichun Shi","Zeyuan Chen","Shijie Zhou","Linjie Luo","Gordon Wetzstein","Mohammad Soleymani"],"pdf_url":"https://arxiv.org/pdf/2501.10021v1.pdf","comment":"Project page:https://x-dyna.github.io/xdyna.github.io/\n  Code:https://github.com/bytedance/X-Dyna"},{"id":"http://arxiv.org/abs/2501.10020v1","updated":"2025-01-17T08:09:06Z","published":"2025-01-17T08:09:06Z","title":"Textoon: Generating Vivid 2D Cartoon Characters from Text Descriptions","summary":"  The 2D cartoon style is a prominent art form in digital character creation,\nparticularly popular among younger audiences. While advancements in digital\nhuman technology have spurred extensive research into photorealistic digital\nhumans and 3D characters, interactive 2D cartoon characters have received\ncomparatively less attention. Unlike 3D counterparts, which require\nsophisticated construction and resource-intensive rendering, Live2D, a\nwidely-used format for 2D cartoon characters, offers a more efficient\nalternative, which allows to animate 2D characters in a manner that simulates\n3D movement without the necessity of building a complete 3D model. Furthermore,\nLive2D employs lightweight HTML5 (H5) rendering, improving both accessibility\nand efficiency. In this technical report, we introduce Textoon, an innovative\nmethod for generating diverse 2D cartoon characters in the Live2D format based\non text descriptions. The Textoon leverages cutting-edge language and vision\nmodels to comprehend textual intentions and generate 2D appearance, capable of\ncreating a wide variety of stunning and interactive 2D characters within one\nminute. The project homepage is https://human3daigc.github.io/Textoon_webpage/.\n","authors":["Chao He","Jianqiang Ren","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2501.10020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10018v1","updated":"2025-01-17T08:03:02Z","published":"2025-01-17T08:03:02Z","title":"DiffuEraser: A Diffusion Model for Video Inpainting","summary":"  Recent video inpainting algorithms integrate flow-based pixel propagation\nwith transformer-based generation to leverage optical flow for restoring\ntextures and objects using information from neighboring frames, while\ncompleting masked regions through visual Transformers. However, these\napproaches often encounter blurring and temporal inconsistencies when dealing\nwith large masks, highlighting the need for models with enhanced generative\ncapabilities. Recently, diffusion models have emerged as a prominent technique\nin image and video generation due to their impressive performance. In this\npaper, we introduce DiffuEraser, a video inpainting model based on stable\ndiffusion, designed to fill masked regions with greater details and more\ncoherent structures. We incorporate prior information to provide initialization\nand weak conditioning,which helps mitigate noisy artifacts and suppress\nhallucinations. Additionally, to improve temporal consistency during\nlong-sequence inference, we expand the temporal receptive fields of both the\nprior model and DiffuEraser, and further enhance consistency by leveraging the\ntemporal smoothing property of Video Diffusion Models. Experimental results\ndemonstrate that our proposed method outperforms state-of-the-art techniques in\nboth content completeness and temporal consistency while maintaining acceptable\nefficiency.\n","authors":["Xiaowen Li","Haolan Xue","Peiran Ren","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2501.10018v1.pdf","comment":"11pages, 13figures"},{"id":"http://arxiv.org/abs/2501.06770v2","updated":"2025-01-17T08:02:51Z","published":"2025-01-12T10:31:33Z","title":"SuperNeRF-GAN: A Universal 3D-Consistent Super-Resolution Framework for\n  Efficient and Enhanced 3D-Aware Image Synthesis","summary":"  Neural volume rendering techniques, such as NeRF, have revolutionized\n3D-aware image synthesis by enabling the generation of images of a single scene\nor object from various camera poses. However, the high computational cost of\nNeRF presents challenges for synthesizing high-resolution (HR) images. Most\nexisting methods address this issue by leveraging 2D super-resolution, which\ncompromise 3D-consistency. Other methods propose radiance manifolds or\ntwo-stage generation to achieve 3D-consistent HR synthesis, yet they are\nlimited to specific synthesis tasks, reducing their universality. To tackle\nthese challenges, we propose SuperNeRF-GAN, a universal framework for\n3D-consistent super-resolution. A key highlight of SuperNeRF-GAN is its\nseamless integration with NeRF-based 3D-aware image synthesis methods and it\ncan simultaneously enhance the resolution of generated images while preserving\n3D-consistency and reducing computational cost. Specifically, given a\npre-trained generator capable of producing a NeRF representation such as\ntri-plane, we first perform volume rendering to obtain a low-resolution image\nwith corresponding depth and normal map. Then, we employ a NeRF\nSuper-Resolution module which learns a network to obtain a high-resolution\nNeRF. Next, we propose a novel Depth-Guided Rendering process which contains\nthree simple yet effective steps, including the construction of a\nboundary-correct multi-depth map through depth aggregation, a normal-guided\ndepth super-resolution and a depth-guided NeRF rendering. Experimental results\ndemonstrate the superior efficiency, 3D-consistency, and quality of our\napproach. Additionally, ablation studies confirm the effectiveness of our\nproposed components.\n","authors":["Peng Zheng","Linzhi Huang","Yizhou Yu","Yi Chang","Yilin Wang","Rui Ma"],"pdf_url":"https://arxiv.org/pdf/2501.06770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08850v2","updated":"2025-01-17T08:02:09Z","published":"2024-09-13T14:06:12Z","title":"DX2CT: Diffusion Model for 3D CT Reconstruction from Bi or Mono-planar\n  2D X-ray(s)","summary":"  Computational tomography (CT) provides high-resolution medical imaging, but\nit can expose patients to high radiation. X-ray scanners have low radiation\nexposure, but their resolutions are low. This paper proposes a new conditional\ndiffusion model, DX2CT, that reconstructs three-dimensional (3D) CT volumes\nfrom bi or mono-planar X-ray image(s). Proposed DX2CT consists of two key\ncomponents: 1) modulating feature maps extracted from two-dimensional (2D)\nX-ray(s) with 3D positions of CT volume using a new transformer and 2)\neffectively using the modulated 3D position-aware feature maps as conditions of\nDX2CT. In particular, the proposed transformer can provide conditions with rich\ninformation of a target CT slice to the conditional diffusion model, enabling\nhigh-quality CT reconstruction. Our experiments with the bi or mono-planar\nX-ray(s) benchmark datasets show that proposed DX2CT outperforms several\nstate-of-the-art methods. Our codes and model will be available at:\nhttps://www.github.com/intyeger/DX2CT.\n","authors":["Yun Su Jeong","Hye Bin Yoo","Il Yong Chun"],"pdf_url":"https://arxiv.org/pdf/2409.08850v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10011v1","updated":"2025-01-17T07:48:37Z","published":"2025-01-17T07:48:37Z","title":"Mitigating Hallucinations on Object Attributes using Multiview Images\n  and Negative Instructions","summary":"  Current popular Large Vision-Language Models (LVLMs) are suffering from\nHallucinations on Object Attributes (HoOA), leading to incorrect determination\nof fine-grained attributes in the input images. Leveraging significant\nadvancements in 3D generation from a single image, this paper proposes a novel\nmethod to mitigate HoOA in LVLMs. This method utilizes multiview images sampled\nfrom generated 3D representations as visual prompts for LVLMs, thereby\nproviding more visual information from other viewpoints. Furthermore, we\nobserve the input order of multiple multiview images significantly affects the\nperformance of LVLMs. Consequently, we have devised Multiview Image Augmented\nVLM (MIAVLM), incorporating a Multiview Attributes Perceiver (MAP) submodule\ncapable of simultaneously eliminating the influence of input image order and\naligning visual information from multiview images with Large Language Models\n(LLMs). Besides, we designed and employed negative instructions to mitigate\nLVLMs' bias towards ``Yes\" responses. Comprehensive experiments demonstrate the\neffectiveness of our method.\n","authors":["Zhijie Tan","Yuzhi Li","Shengwei Meng","Xiang Yuan","Weiping Li","Tong Mo","Bingce Wang","Xu Chu"],"pdf_url":"https://arxiv.org/pdf/2501.10011v1.pdf","comment":"2025 IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2025)"},{"id":"http://arxiv.org/abs/2501.09999v1","updated":"2025-01-17T07:30:16Z","published":"2025-01-17T07:30:16Z","title":"Deep Learning for Early Alzheimer Disease Detection with MRI Scans","summary":"  Alzheimer's Disease is a neurodegenerative condition characterized by\ndementia and impairment in neurological function. The study primarily focuses\non the individuals above age 40, affecting their memory, behavior, and\ncognitive processes of the brain. Alzheimer's disease requires diagnosis by a\ndetailed assessment of MRI scans and neuropsychological tests of the patients.\nThis project compares existing deep learning models in the pursuit of enhancing\nthe accuracy and efficiency of AD diagnosis, specifically focusing on the\nConvolutional Neural Network, Bayesian Convolutional Neural Network, and the\nU-net model with the Open Access Series of Imaging Studies brain MRI dataset.\nBesides, to ensure robustness and reliability in the model evaluations, we\naddress the challenge of imbalance in data. We then perform rigorous evaluation\nto determine strengths and weaknesses for each model by considering\nsensitivity, specificity, and computational efficiency. This comparative\nanalysis would shed light on the future role of AI in revolutionizing AD\ndiagnostics but also paved ways for future innovation in medical imaging and\nthe management of neurodegenerative diseases.\n","authors":["Mohammad Rafsan","Tamer Oraby","Upal Roy","Sanjeev Kumar","Hansapani Rodrigo"],"pdf_url":"https://arxiv.org/pdf/2501.09999v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09994v1","updated":"2025-01-17T07:24:58Z","published":"2025-01-17T07:24:58Z","title":"Multi-Modal Attention Networks for Enhanced Segmentation and Depth\n  Estimation of Subsurface Defects in Pulse Thermography","summary":"  AI-driven pulse thermography (PT) has become a crucial tool in\nnon-destructive testing (NDT), enabling automatic detection of hidden anomalies\nin various industrial components. Current state-of-the-art techniques feed\nsegmentation and depth estimation networks compressed PT sequences using either\nPrincipal Component Analysis (PCA) or Thermographic Signal Reconstruction\n(TSR). However, treating these two modalities independently constrains the\nperformance of PT inspection models as these representations possess\ncomplementary semantic features. To address this limitation, this work proposes\nPT-Fusion, a multi-modal attention-based fusion network that fuses both PCA and\nTSR modalities for defect segmentation and depth estimation of subsurface\ndefects in PT setups. PT-Fusion introduces novel feature fusion modules,\nEncoder Attention Fusion Gate (EAFG) and Attention Enhanced Decoding Block\n(AEDB), to fuse PCA and TSR features for enhanced segmentation and depth\nestimation of subsurface defects. In addition, a novel data augmentation\ntechnique is proposed based on random data sampling from thermographic\nsequences to alleviate the scarcity of PT datasets. The proposed method is\nbenchmarked against state-of-the-art PT inspection models, including U-Net,\nattention U-Net, and 3D-CNN on the Universit\\'e Laval IRT-PVC dataset. The\nresults demonstrate that PT-Fusion outperforms the aforementioned models in\ndefect segmentation and depth estimation accuracies with a margin of 10%.\n","authors":["Mohammed Salah","Naoufel Werghi","Davor Svetinovic","Yusra Abdulrahman"],"pdf_url":"https://arxiv.org/pdf/2501.09994v1.pdf","comment":"Pulse thermography, infrared thermography, defect segmentation,\n  multi-modal networks, attention mechanism"},{"id":"http://arxiv.org/abs/2412.11076v3","updated":"2025-01-17T07:21:34Z","published":"2024-12-15T06:20:41Z","title":"MoRe: Class Patch Attention Needs Regularization for Weakly Supervised\n  Semantic Segmentation","summary":"  Weakly Supervised Semantic Segmentation (WSSS) with image-level labels\ntypically uses Class Activation Maps (CAM) to achieve dense predictions.\nRecently, Vision Transformer (ViT) has provided an alternative to generate\nlocalization maps from class-patch attention. However, due to insufficient\nconstraints on modeling such attention, we observe that the Localization\nAttention Maps (LAM) often struggle with the artifact issue, i.e., patch\nregions with minimal semantic relevance are falsely activated by class tokens.\nIn this work, we propose MoRe to address this issue and further explore the\npotential of LAM. Our findings suggest that imposing additional regularization\non class-patch attention is necessary. To this end, we first view the attention\nas a novel directed graph and propose the Graph Category Representation module\nto implicitly regularize the interaction among class-patch entities. It ensures\nthat class tokens dynamically condense the related patch information and\nsuppress unrelated artifacts at a graph level. Second, motivated by the\nobservation that CAM from classification weights maintains smooth localization\nof objects, we devise the Localization-informed Regularization module to\nexplicitly regularize the class-patch attention. It directly mines the token\nrelations from CAM and further supervises the consistency between class and\npatch tokens in a learnable manner. Extensive experiments are conducted on\nPASCAL VOC and MS COCO, validating that MoRe effectively addresses the artifact\nissue and achieves state-of-the-art performance, surpassing recent single-stage\nand even multi-stage methods. Code is available at\nhttps://github.com/zwyang6/MoRe.\n","authors":["Zhiwei Yang","Yucong Meng","Kexue Fu","Shuo Wang","Zhijian Song"],"pdf_url":"https://arxiv.org/pdf/2412.11076v3.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2404.13733v4","updated":"2025-01-17T07:15:16Z","published":"2024-04-21T18:19:27Z","title":"Elucidating the Design Space of Dataset Condensation","summary":"  Dataset condensation, a concept within data-centric learning, efficiently\ntransfers critical attributes from an original dataset to a synthetic version,\nmaintaining both diversity and realism. This approach significantly improves\nmodel training efficiency and is adaptable across multiple application areas.\nPrevious methods in dataset condensation have faced challenges: some incur high\ncomputational costs which limit scalability to larger datasets (e.g., MTT,\nDREAM, and TESLA), while others are restricted to less optimal design spaces,\nwhich could hinder potential improvements, especially in smaller datasets\n(e.g., SRe2L, G-VBSM, and RDED). To address these limitations, we propose a\ncomprehensive design framework that includes specific, effective strategies\nlike implementing soft category-aware matching and adjusting the learning rate\nschedule. These strategies are grounded in empirical evidence and theoretical\nbacking. Our resulting approach, Elucidate Dataset Condensation (EDC),\nestablishes a benchmark for both small and large-scale dataset condensation. In\nour testing, EDC achieves state-of-the-art accuracy, reaching 48.6% on\nImageNet-1k with a ResNet-18 model at an IPC of 10, which corresponds to a\ncompression ratio of 0.78%. This performance exceeds those of SRe2L, G-VBSM,\nand RDED by margins of 27.3%, 17.2%, and 6.6%, respectively.\n","authors":["Shitong Shao","Zikai Zhou","Huanran Chen","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2404.13733v4.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2312.10725v2","updated":"2025-01-17T07:01:43Z","published":"2023-12-17T14:14:31Z","title":"Harnessing small projectors and multiple views for efficient vision\n  pretraining","summary":"  Recent progress in self-supervised (SSL) visual representation learning has\nled to the development of several different proposed frameworks that rely on\naugmentations of images but use different loss functions. However, there are\nfew theoretically grounded principles to guide practice, so practical\nimplementation of each SSL framework requires several heuristics to achieve\ncompetitive performance. In this work, we build on recent analytical results to\ndesign practical recommendations for competitive and efficient SSL that are\ngrounded in theory. Specifically, recent theory tells us that existing SSL\nframeworks are minimizing the same idealized loss, which is to learn features\nthat best match the data similarity kernel defined by the augmentations used.\nWe show how this idealized loss can be reformulated to a functionally\nequivalent loss that is more efficient to compute. We study the implicit bias\nof using gradient descent to minimize our reformulated loss function and find\nthat using a stronger orthogonalization constraint with a reduced projector\ndimensionality should yield good representations. Furthermore, the theory tells\nus that approximating the reformulated loss should be improved by increasing\nthe number of augmentations, and as such using multiple augmentations should\nlead to improved convergence. We empirically verify our findings on CIFAR, STL\nand Imagenet datasets, wherein we demonstrate an improved linear readout\nperformance when training a ResNet-backbone using our theoretically grounded\nrecommendations. Remarkably, we also demonstrate that by leveraging these\ninsights, we can reduce the pretraining dataset size by up to 2$\\times$ while\nmaintaining downstream accuracy simply by using more data augmentations. Taken\ntogether, our work provides theoretically grounded recommendations that can be\nused to improve SSL convergence and efficiency.\n","authors":["Kumar Krishna Agrawal","Arna Ghosh","Shagun Sodhani","Adam Oberman","Blake Richards"],"pdf_url":"https://arxiv.org/pdf/2312.10725v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.00095v2","updated":"2025-01-17T06:53:45Z","published":"2024-11-27T15:45:02Z","title":"OPCap:Object-aware Prompting Captioning","summary":"  In the field of image captioning, the phenomenon where missing or nonexistent\nobjects are used to explain an image is referred to as object bias (or\nhallucination). To mitigate this issue, we propose a target-aware prompting\nstrategy. This method first extracts object labels and their spatial\ninformation from the image using an object detector. Then, an attribute\npredictor further refines the semantic features of the objects. These refined\nfeatures are subsequently integrated and fed into the decoder, enhancing the\nmodel's understanding of the image context. Experimental results on the COCO\nand nocaps datasets demonstrate that OPCap effectively mitigates hallucination\nand significantly improves the quality of generated captions.\n","authors":["Feiyang Huang"],"pdf_url":"https://arxiv.org/pdf/2412.00095v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09982v1","updated":"2025-01-17T06:46:10Z","published":"2025-01-17T06:46:10Z","title":"RichSpace: Enriching Text-to-Video Prompt Space via Text Embedding\n  Interpolation","summary":"  Text-to-video generation models have made impressive progress, but they still\nstruggle with generating videos with complex features. This limitation often\narises from the inability of the text encoder to produce accurate embeddings,\nwhich hinders the video generation model. In this work, we propose a novel\napproach to overcome this challenge by selecting the optimal text embedding\nthrough interpolation in the embedding space. We demonstrate that this method\nenables the video generation model to produce the desired videos. Additionally,\nwe introduce a simple algorithm using perpendicular foot embeddings and cosine\nsimilarity to identify the optimal interpolation embedding. Our findings\nhighlight the importance of accurate text embeddings and offer a pathway for\nimproving text-to-video generation performance.\n","authors":["Yuefan Cao","Chengyue Gong","Xiaoyu Li","Yingyu Liang","Zhizhou Sha","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2501.09982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14197v3","updated":"2025-01-17T06:46:00Z","published":"2024-08-26T11:53:09Z","title":"Driving in the Occupancy World: Vision-Centric 4D Occupancy Forecasting\n  and Planning via World Models for Autonomous Driving","summary":"  World models envision potential future states based on various ego actions.\nThey embed extensive knowledge about the driving environment, facilitating safe\nand scalable autonomous driving. Most existing methods primarily focus on\neither data generation or the pretraining paradigms of world models. Unlike the\naforementioned prior works, we propose Drive-OccWorld, which adapts a\nvision-centric 4D forecasting world model to end-to-end planning for autonomous\ndriving. Specifically, we first introduce a semantic and motion-conditional\nnormalization in the memory module, which accumulates semantic and dynamic\ninformation from historical BEV embeddings. These BEV features are then\nconveyed to the world decoder for future occupancy and flow forecasting,\nconsidering both geometry and spatiotemporal modeling. Additionally, we propose\ninjecting flexible action conditions, such as velocity, steering angle,\ntrajectory, and commands, into the world model to enable controllable\ngeneration and facilitate a broader range of downstream applications.\nFurthermore, we explore integrating the generative capabilities of the 4D world\nmodel with end-to-end planning, enabling continuous forecasting of future\nstates and the selection of optimal trajectories using an occupancy-based cost\nfunction. Comprehensive experiments conducted on the nuScenes,\nnuScenes-Occupancy, and Lyft-Level5 datasets illustrate that our method can\ngenerate plausible and controllable 4D occupancy, paving the way for\nadvancements in driving world generation and end-to-end planning. Project page:\nhttps://drive-occworld.github.io/\n","authors":["Yu Yang","Jianbiao Mei","Yukai Ma","Siliang Du","Wenqing Chen","Yijie Qian","Yuxiang Feng","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2408.14197v3.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2411.18967v2","updated":"2025-01-17T06:44:38Z","published":"2024-11-28T07:36:29Z","title":"Deep Plug-and-Play HIO Approach for Phase Retrieval","summary":"  In the phase retrieval problem, the aim is the recovery of an unknown image\nfrom intensity-only measurements such as Fourier intensity. Although there are\nseveral solution approaches, solving this problem is challenging due to its\nnonlinear and ill-posed nature. Recently, learning-based approaches have\nemerged as powerful alternatives to the analytical methods for several inverse\nproblems. In the context of phase retrieval, a novel plug-and-play approach\nthat exploits learning-based prior and efficient update steps has been\npresented at the Computational Optical Sensing and Imaging topical meeting,\nwith demonstrated state-of-the-art performance. The key idea was to incorporate\nlearning-based prior to the Gerchberg-Saxton type algorithms through\nplug-and-play regularization. In this paper, we present the mathematical\ndevelopment of the method including the derivation of its analytical update\nsteps based on half-quadratic splitting and comparatively evaluate its\nperformance through extensive simulations on a large test dataset. The results\nshow the effectiveness of the method in terms of both image quality,\ncomputational efficiency, and robustness to initialization and noise.\n","authors":["Cagatay Isil","Figen S. Oktem"],"pdf_url":"https://arxiv.org/pdf/2411.18967v2.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.09980v1","updated":"2025-01-17T06:43:03Z","published":"2025-01-17T06:43:03Z","title":"Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm\n  Hemodynamics","summary":"  Intracranial aneurysm (IA) is a common cerebrovascular disease that is\nusually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if\nruptured. Although clinical practice is usually based on individual factors and\nmorphological features of the aneurysm, its pathophysiology and hemodynamic\nmechanisms remain controversial. To address the limitations of current\nresearch, this study constructed a comprehensive hemodynamic dataset of\nintracranial aneurysms. The dataset is based on 466 real aneurysm models, and\n10,000 synthetic models were generated by resection and deformation operations,\nincluding 466 aneurysm-free models and 9,534 deformed aneurysm models. The\ndataset also provides medical image-like segmentation mask files to support\ninsightful analysis. In addition, the dataset contains hemodynamic data\nmeasured at eight steady-state flow rates (0.001 to 0.004 kg/s), including\ncritical parameters such as flow velocity, pressure, and wall shear stress,\nproviding a valuable resource for investigating aneurysm pathogenesis and\nclinical prediction. This dataset will help advance the understanding of the\npathologic features and hemodynamic mechanisms of intracranial aneurysms and\nsupport in-depth research in related fields. Dataset hosted at\nhttps://github.com/Xigui-Li/Aneumo.\n","authors":["Xigui Li","Yuanye Zhou","Feiyang Xiao","Xin Guo","Yichi Zhang","Chen Jiang","Jianchao Ge","Xiansheng Wang","Qimeng Wang","Taiwei Zhang","Chensen Lin","Yuan Cheng","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2501.09980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09978v1","updated":"2025-01-17T06:40:20Z","published":"2025-01-17T06:40:20Z","title":"GaussianAvatar-Editor: Photorealistic Animatable Gaussian Head Avatar\n  Editor","summary":"  We introduce GaussianAvatar-Editor, an innovative framework for text-driven\nediting of animatable Gaussian head avatars that can be fully controlled in\nexpression, pose, and viewpoint. Unlike static 3D Gaussian editing, editing\nanimatable 4D Gaussian avatars presents challenges related to motion occlusion\nand spatial-temporal inconsistency. To address these issues, we propose the\nWeighted Alpha Blending Equation (WABE). This function enhances the blending\nweight of visible Gaussians while suppressing the influence on non-visible\nGaussians, effectively handling motion occlusion during editing. Furthermore,\nto improve editing quality and ensure 4D consistency, we incorporate\nconditional adversarial learning into the editing process. This strategy helps\nto refine the edited results and maintain consistency throughout the animation.\nBy integrating these methods, our GaussianAvatar-Editor achieves photorealistic\nand consistent results in animatable 4D Gaussian editing. We conduct\ncomprehensive experiments across various subjects to validate the effectiveness\nof our proposed techniques, which demonstrates the superiority of our approach\nover existing methods. More results and code are available at: [Project\nLink](https://xiangyueliu.github.io/GaussianAvatar-Editor/).\n","authors":["Xiangyue Liu","Kunming Luo","Heng Li","Qi Zhang","Yuan Liu","Li Yi","Ping Tan"],"pdf_url":"https://arxiv.org/pdf/2501.09978v1.pdf","comment":"Accepted to 3DV 2025. [Project\n  Link](https://xiangyueliu.github.io/GaussianAvatar-Editor/)"},{"id":"http://arxiv.org/abs/2501.08443v3","updated":"2025-01-17T06:33:23Z","published":"2024-12-26T05:41:31Z","title":"Instruction-Guided Fusion of Multi-Layer Visual Features in Large\n  Vision-Language Models","summary":"  Large Vision-Language Models (LVLMs) have achieved remarkable success in a\nwide range of multimodal tasks by integrating pre-trained vision encoders and\nlarge language models. However, current LVLMs primarily rely on visual features\nextracted from the final layers of the vision encoder, overlooking the\ncomplementary information available in shallower layers. While recent\napproaches have explored the use of multilayer visual features in LVLMs, they\ntend to be task-agnostic and fail to examine the dependencies of hierarchical\nvisual features on specific tasks. To address these gaps, we systematically\ninvestigate the contributions of visual features from different encoder layers\nusing 18 benchmarks spanning 6 task categories. Our findings reveal that\nmultilayer features provide complementary strengths with varying task\ndependencies, and uniform fusion leads to suboptimal performance. Building on\nthese insights, we propose the instruction-guided vision aggregator, a module\nthat dynamically integrates multi-layer visual features based on textual\ninstructions, without increasing the number of visual tokens. Extensive\nevaluations demonstrate the superior performance of our method. Additionally,\nan in-depth analysis of the aggregator's behavior highlights the dominance of\nmid-to-high-level features in semantic-rich tasks and the critical role of\nlow-level features in fine-grained perception.\n","authors":["Xu Li","Yi Zheng","Haotian Chen","Xiaolei Chen","Yuxuan Liang","Chenghang Lai","Bin Li","Xiangyang Xue"],"pdf_url":"https://arxiv.org/pdf/2501.08443v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09967v1","updated":"2025-01-17T06:16:57Z","published":"2025-01-17T06:16:57Z","title":"Explainable artificial intelligence (XAI): from inherent explainability\n  to large language models","summary":"  Artificial Intelligence (AI) has continued to achieve tremendous success in\nrecent times. However, the decision logic of these frameworks is often not\ntransparent, making it difficult for stakeholders to understand, interpret or\nexplain their behavior. This limitation hinders trust in machine learning\nsystems and causes a general reluctance towards their adoption in practical\napplications, particularly in mission-critical domains like healthcare and\nautonomous driving. Explainable AI (XAI) techniques facilitate the\nexplainability or interpretability of machine learning models, enabling users\nto discern the basis of the decision and possibly avert undesirable behavior.\nThis comprehensive survey details the advancements of explainable AI methods,\nfrom inherently interpretable models to modern approaches for achieving\ninterpretability of various black box models, including large language models\n(LLMs). Additionally, we review explainable AI techniques that leverage LLM and\nvision-language model (VLM) frameworks to automate or improve the\nexplainability of other machine learning models. The use of LLM and VLM as\ninterpretability methods particularly enables high-level, semantically\nmeaningful explanations of model decisions and behavior. Throughout the paper,\nwe highlight the scientific principles, strengths and weaknesses of\nstate-of-the-art methods and outline different areas of improvement. Where\nappropriate, we also present qualitative and quantitative comparison results of\nvarious methods to show how they compare. Finally, we discuss the key\nchallenges of XAI and directions for future research.\n","authors":["Fuseini Mumuni","Alhassan Mumuni"],"pdf_url":"https://arxiv.org/pdf/2501.09967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19070v3","updated":"2025-01-17T06:13:20Z","published":"2023-10-29T16:49:45Z","title":"Myriad: Large Multimodal Model by Applying Vision Experts for Industrial\n  Anomaly Detection","summary":"  Due to the training configuration, traditional industrial anomaly detection\n(IAD) methods have to train a specific model for each deployment scenario,\nwhich is insufficient to meet the requirements of modern design and\nmanufacturing. On the contrary, large multimodal models~(LMMs) have shown\neminent generalization ability on various vision tasks, and their perception\nand comprehension capabilities imply the potential of applying LMMs on IAD\ntasks. However, we observe that even though the LMMs have abundant knowledge\nabout industrial anomaly detection in the textual domain, the LMMs are unable\nto leverage the knowledge due to the modality gap between textual and visual\ndomains. To stimulate the relevant knowledge in LMMs and adapt the LMMs towards\nanomaly detection tasks, we introduce existing IAD methods as vision experts\nand present a novel large multimodal model applying vision experts for\nindustrial anomaly detection~(abbreviated to {Myriad}). Specifically, we\nutilize the anomaly map generated by the vision experts as guidance for LMMs,\nsuch that the vision model is guided to pay more attention to anomalous\nregions. Then, the visual features are modulated via an adapter to fit the\nanomaly detection tasks, which are fed into the language model together with\nthe vision expert guidance and human instructions to generate the final\noutputs. Extensive experiments are applied on MVTec-AD, VisA, and PCB Bank\nbenchmarks demonstrate that our proposed method not only performs favorably\nagainst state-of-the-art methods, but also inherits the flexibility and\ninstruction-following ability of LMMs in the field of IAD. Source code and\npre-trained models are publicly available at\n\\url{https://github.com/tzjtatata/Myriad}.\n","authors":["Yuanze Li","Haolin Wang","Shihao Yuan","Ming Liu","Debin Zhao","Yiwen Guo","Chen Xu","Guangming Shi","Wangmeng Zuo"],"pdf_url":"https://arxiv.org/pdf/2310.19070v3.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2312.13632v4","updated":"2025-01-17T06:09:13Z","published":"2023-12-21T07:48:54Z","title":"TraceFL: Interpretability-Driven Debugging in Federated Learning via\n  Neuron Provenance","summary":"  In Federated Learning, clients train models on local data and send updates to\na central server, which aggregates them into a global model using a fusion\nalgorithm. This collaborative yet privacy-preserving training comes at a cost.\nFL developers face significant challenges in attributing global model\npredictions to specific clients. Localizing responsible clients is a crucial\nstep towards (a) excluding clients primarily responsible for incorrect\npredictions and (b) encouraging clients who contributed high-quality models to\ncontinue participating in the future. Existing ML debugging approaches are\ninherently inapplicable as they are designed for single-model, centralized\ntraining.\n  We introduce TraceFL, a fine-grained neuron provenance capturing mechanism\nthat identifies clients responsible for a global model's prediction by tracking\nthe flow of information from individual clients to the global model. Since\ninference on different inputs activates a different set of neurons of the\nglobal model, TraceFL dynamically quantifies the significance of the global\nmodel's neurons in a given prediction, identifying the most crucial neurons in\nthe global model. It then maps them to the corresponding neurons in every\nparticipating client to determine each client's contribution, ultimately\nlocalizing the responsible client. We evaluate TraceFL on six datasets,\nincluding two real-world medical imaging datasets and four neural networks,\nincluding advanced models such as GPT. TraceFL achieves 99% accuracy in\nlocalizing the responsible client in FL tasks spanning both image and text\nclassification tasks. At a time when state-of-the-artML debugging approaches\nare mostly domain-specific (e.g., image classification only), TraceFL is the\nfirst technique to enable highly accurate automated reasoning across a wide\nrange of FL applications.\n","authors":["Waris Gill","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2312.13632v4.pdf","comment":"Accepted at 2025 IEEE/ACM 47th International Conference on Software\n  Engineering (ICSE)"},{"id":"http://arxiv.org/abs/2406.14534v3","updated":"2025-01-17T05:59:20Z","published":"2024-06-20T17:47:30Z","title":"Epicardium Prompt-guided Real-time Cardiac Ultrasound Frame-to-volume\n  Registration","summary":"  A comprehensive guidance view for cardiac interventional surgery can be\nprovided by the real-time fusion of the intraoperative 2D images and\npreoperative 3D volume based on the ultrasound frame-to-volume registration.\nHowever, cardiac ultrasound images are characterized by a low signal-to-noise\nratio and small differences between adjacent frames, coupled with significant\ndimension variations between 2D frames and 3D volumes to be registered,\nresulting in real-time and accurate cardiac ultrasound frame-to-volume\nregistration being a very challenging task. This paper introduces a lightweight\nend-to-end Cardiac Ultrasound frame-to-volume Registration network, termed\nCU-Reg. Specifically, the proposed model leverages epicardium prompt-guided\nanatomical clues to reinforce the interaction of 2D sparse and 3D dense\nfeatures, followed by a voxel-wise local-global aggregation of enhanced\nfeatures, thereby boosting the cross-dimensional matching effectiveness of\nlow-quality ultrasound modalities. We further embed an inter-frame\ndiscriminative regularization term within the hybrid supervised learning to\nincrease the distinction between adjacent slices in the same ultrasound volume\nto ensure registration stability. Experimental results on the reprocessed CAMUS\ndataset demonstrate that our CU-Reg surpasses existing methods in terms of\nregistration accuracy and efficiency, meeting the guidance requirements of\nclinical cardiac interventional surgery.\n","authors":["Long Lei","Jun Zhou","Jialun Pei","Baoliang Zhao","Yueming Jin","Yuen-Chun Jeremy Teoh","Jing Qin","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2406.14534v3.pdf","comment":"This paper has been accepted by MICCAI 2024"},{"id":"http://arxiv.org/abs/2501.09960v1","updated":"2025-01-17T05:23:26Z","published":"2025-01-17T05:23:26Z","title":"Discrete Prior-based Temporal-coherent Content Prediction for Blind Face\n  Video Restoration","summary":"  Blind face video restoration aims to restore high-fidelity details from\nvideos subjected to complex and unknown degradations. This task poses a\nsignificant challenge of managing temporal heterogeneity while at the same time\nmaintaining stable face attributes. In this paper, we introduce a Discrete\nPrior-based Temporal-Coherent content prediction transformer to address the\nchallenge, and our model is referred to as DP-TempCoh. Specifically, we\nincorporate a spatial-temporal-aware content prediction module to synthesize\nhigh-quality content from discrete visual priors, conditioned on degraded video\ntokens. To further enhance the temporal coherence of the predicted content, a\nmotion statistics modulation module is designed to adjust the content, based on\ndiscrete motion priors in terms of cross-frame mean and variance. As a result,\nthe statistics of the predicted content can match with that of real videos over\ntime. By performing extensive experiments, we verify the effectiveness of the\ndesign elements and demonstrate the superior performance of our DP-TempCoh in\nboth synthetically and naturally degraded video restoration.\n","authors":["Lianxin Xie","Bingbing Zheng","Wen Xue","Yunfei Zhang","Le Jiang","Ruotao Xu","Si Wu","Hau-San Wong"],"pdf_url":"https://arxiv.org/pdf/2501.09960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17134v3","updated":"2025-01-17T05:23:10Z","published":"2023-05-26T17:59:21Z","title":"NeuManifold: Neural Watertight Manifold Reconstruction with Efficient\n  and High-Quality Rendering Support","summary":"  We present a method for generating high-quality watertight manifold meshes\nfrom multi-view input images. Existing volumetric rendering methods are robust\nin optimization but tend to generate noisy meshes with poor topology.\nDifferentiable rasterization-based methods can generate high-quality meshes but\nare sensitive to initialization. Our method combines the benefits of both\nworlds; we take the geometry initialization obtained from neural volumetric\nfields, and further optimize the geometry as well as a compact neural texture\nrepresentation with differentiable rasterizers. Through extensive experiments,\nwe demonstrate that our method can generate accurate mesh reconstructions with\nfaithful appearance that are comparable to previous volume rendering methods\nwhile being an order of magnitude faster in rendering. We also show that our\ngenerated mesh and neural texture reconstruction is compatible with existing\ngraphics pipelines and enables downstream 3D applications such as simulation.\nProject page: https://sarahweiii.github.io/neumanifold/\n","authors":["Xinyue Wei","Fanbo Xiang","Sai Bi","Anpei Chen","Kalyan Sunkavalli","Zexiang Xu","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2305.17134v3.pdf","comment":"Project page: https://sarahweiii.github.io/neumanifold/"},{"id":"http://arxiv.org/abs/2404.01249v2","updated":"2025-01-17T05:13:29Z","published":"2024-04-01T17:12:47Z","title":"FireANTs: Adaptive Riemannian Optimization for Multi-Scale Diffeomorphic\n  Matching","summary":"  The paper proposes FireANTs, the first multi-scale Adaptive Riemannian\nOptimization algorithm for dense diffeomorphic image matching. One of the most\ncritical and understudied aspects of diffeomorphic image matching algorithms\nare its highly ill-conditioned nature. We quantitatively capture the extent of\nill-conditioning in a typical MRI matching task, motivating the need for an\nadaptive optimization algorithm for diffeomorphic matching. To this end,\nFireANTs generalizes the concept of momentum and adaptive estimates of the\nHessian to mitigate this ill-conditioning in the non-Euclidean space of\ndiffeomorphisms. Unlike common non-Euclidean manifolds, we also formalize\nconsiderations for multi-scale optimization of diffeomorphisms. Our rigorous\nmathematical results and operational contributions lead to a state-of-the-art\ndense matching algorithm that can be applied to generic image data with\nremarkable accuracy and robustness. We demonstrate consistent improvements in\nimage matching performance across a spectrum of community-standard medical and\nbiological correspondence matching challenges spanning a wide variety of image\nmodalities, anatomies, resolutions, acquisition protocols, and preprocessing\npipelines. This improvement is supplemented by from 300x up to 3200x speedup\nover existing state-of-the-art algorithms. For the first time, we perform\ndiffeomorphic matching of sub-micron mouse cortex volumes at native resolution.\nOur fast implementation also enables hyperparameter studies that were\nintractable with existing correspondence matching algorithms.\n","authors":["Rohit Jena","Pratik Chaudhari","James C. Gee"],"pdf_url":"https://arxiv.org/pdf/2404.01249v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04565v2","updated":"2025-01-17T05:13:06Z","published":"2025-01-08T15:25:19Z","title":"Learnable Scaled Gradient Descent for Guaranteed Robust Tensor PCA","summary":"  Robust tensor principal component analysis (RTPCA) aims to separate the\nlow-rank and sparse components from multi-dimensional data, making it an\nessential technique in the signal processing and computer vision fields.\nRecently emerging tensor singular value decomposition (t-SVD) has gained\nconsiderable attention for its ability to better capture the low-rank structure\nof tensors compared to traditional matrix SVD. However, existing methods often\nrely on the computationally expensive tensor nuclear norm (TNN), which limits\ntheir scalability for real-world tensors. To address this issue, we explore an\nefficient scaled gradient descent (SGD) approach within the t-SVD framework for\nthe first time, and propose the RTPCA-SGD method. Theoretically, we rigorously\nestablish the recovery guarantees of RTPCA-SGD under mild assumptions,\ndemonstrating that with appropriate parameter selection, it achieves linear\nconvergence to the true low-rank tensor at a constant rate, independent of the\ncondition number. To enhance its practical applicability, we further propose a\nlearnable self-supervised deep unfolding model, which enables effective\nparameter learning. Numerical experiments on both synthetic and real-world\ndatasets demonstrate the superior performance of the proposed methods while\nmaintaining competitive computational efficiency, especially consuming less\ntime than RTPCA-TNN.\n","authors":["Lanlan Feng","Ce Zhu","Yipeng Liu","Saiprasad Ravishankar","Longxiu Huang"],"pdf_url":"https://arxiv.org/pdf/2501.04565v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00771v2","updated":"2025-01-17T04:47:11Z","published":"2024-10-01T15:07:07Z","title":"Empowering Large Language Model for Continual Video Question Answering\n  with Collaborative Prompting","summary":"  In recent years, the rapid increase in online video content has underscored\nthe limitations of static Video Question Answering (VideoQA) models trained on\nfixed datasets, as they struggle to adapt to new questions or tasks posed by\nnewly available content. In this paper, we explore the novel challenge of\nVideoQA within a continual learning framework, and empirically identify a\ncritical issue: fine-tuning a large language model (LLM) for a sequence of\ntasks often results in catastrophic forgetting. To address this, we propose\nCollaborative Prompting (ColPro), which integrates specific question constraint\nprompting, knowledge acquisition prompting, and visual temporal awareness\nprompting. These prompts aim to capture textual question context, visual\ncontent, and video temporal dynamics in VideoQA, a perspective underexplored in\nprior research. Experimental results on the NExT-QA and DramaQA datasets show\nthat ColPro achieves superior performance compared to existing approaches,\nachieving 55.14\\% accuracy on NExT-QA and 71.24\\% accuracy on DramaQA,\nhighlighting its practical relevance and effectiveness.\n","authors":["Chen Cai","Zheng Wang","Jianjun Gao","Wenyang Liu","Ye Lu","Runzhong Zhang","Kim-Hui Yap"],"pdf_url":"https://arxiv.org/pdf/2410.00771v2.pdf","comment":"Accepted by main EMNLP 2024"},{"id":"http://arxiv.org/abs/2501.09947v1","updated":"2025-01-17T04:14:09Z","published":"2025-01-17T04:14:09Z","title":"Surface-SOS: Self-Supervised Object Segmentation via Neural Surface\n  Representation","summary":"  Self-supervised Object Segmentation (SOS) aims to segment objects without any\nannotations. Under conditions of multi-camera inputs, the structural, textural\nand geometrical consistency among each view can be leveraged to achieve\nfine-grained object segmentation. To make better use of the above information,\nwe propose Surface representation based Self-supervised Object Segmentation\n(Surface-SOS), a new framework to segment objects for each view by 3D surface\nrepresentation from multi-view images of a scene. To model high-quality\ngeometry surfaces for complex scenes, we design a novel scene representation\nscheme, which decomposes the scene into two complementary neural representation\nmodules respectively with a Signed Distance Function (SDF). Moreover,\nSurface-SOS is able to refine single-view segmentation with multi-view\nunlabeled images, by introducing coarse segmentation masks as additional input.\nTo the best of our knowledge, Surface-SOS is the first self-supervised approach\nthat leverages neural surface representation to break the dependence on large\namounts of annotated data and strong constraints. These constraints typically\ninvolve observing target objects against a static background or relying on\ntemporal supervision in videos. Extensive experiments on standard benchmarks\nincluding LLFF, CO3D, BlendedMVS, TUM and several real-world scenes show that\nSurface-SOS always yields finer object masks than its NeRF-based counterparts\nand surpasses supervised single-view baselines remarkably. Code is available\nat: https://github.com/zhengxyun/Surface-SOS.\n","authors":["Xiaoyun Zheng","Liwei Liao","Jianbo Jiao","Feng Gao","Ronggang Wang"],"pdf_url":"https://arxiv.org/pdf/2501.09947v1.pdf","comment":"Accepted by TIP"},{"id":"http://arxiv.org/abs/2406.04829v4","updated":"2025-01-17T03:39:23Z","published":"2024-06-07T10:54:40Z","title":"IOR: Inversed Objects Replay for Incremental Object Detection","summary":"  Existing Incremental Object Detection (IOD) methods partially alleviate\ncatastrophic forgetting when incrementally detecting new objects in real-world\nscenarios. However, many of these methods rely on the assumption that unlabeled\nold-class objects may co-occur with labeled new-class objects in the\nincremental data. When unlabeled old-class objects are absent, the performance\nof existing methods tends to degrade. The absence can be mitigated by\ngenerating old-class samples, but it incurs high costs. This paper argues that\nprevious generation-based IOD suffers from redundancy, both in the use of\ngenerative models, which require additional training and storage, and in the\noverproduction of generated samples, many of which do not contribute\nsignificantly to performance improvements. To eliminate the redundancy, we\npropose Inversed Objects Replay (IOR). Specifically, we generate old-class\nsamples by inversing the original detectors, thus eliminating the necessity of\ntraining and storing additional generative models. We propose augmented replay\nto reuse the objects in generated samples, reducing redundant generations.\nMoreover, we propose high-value knowledge distillation focusing on the\npositions of old-class objects overwhelmed by the background, which transfers\nthe knowledge to the incremental detector. Extensive experiments conducted on\nMS COCO 2017 demonstrate that our method can efficiently improve detection\nperformance in IOD scenarios with the absence of old-class objects.\n","authors":["Zijia An","Boyu Diao","Libo Huang","Ruiqi Liu","Zhulin An","Yongjun Xu"],"pdf_url":"https://arxiv.org/pdf/2406.04829v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09938v1","updated":"2025-01-17T03:29:41Z","published":"2025-01-17T03:29:41Z","title":"A Multi-Scale Feature Extraction and Fusion Deep Learning Method for\n  Classification of Wheat Diseases","summary":"  Wheat is an important source of dietary fiber and protein that is negatively\nimpacted by a number of risks to its growth. The difficulty of identifying and\nclassifying wheat diseases is discussed with an emphasis on wheat loose smut,\nleaf rust, and crown and root rot. Addressing conditions like crown and root\nrot, this study introduces an innovative approach that integrates multi-scale\nfeature extraction with advanced image segmentation techniques to enhance\nclassification accuracy. The proposed method uses neural network models\nXception, Inception V3, and ResNet 50 to train on a large wheat disease\nclassification dataset 2020 in conjunction with an ensemble of machine vision\nclassifiers, including voting and stacking. The study shows that the suggested\nmethodology has a superior accuracy of 99.75% in the classification of wheat\ndiseases when compared to current state-of-the-art approaches. A deep learning\nensemble model Xception showed the highest accuracy.\n","authors":["Sajjad Saleem","Adil Hussain","Nabila Majeed","Zahid Akhtar","Kamran Siddique"],"pdf_url":"https://arxiv.org/pdf/2501.09938v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09935v1","updated":"2025-01-17T03:16:15Z","published":"2025-01-17T03:16:15Z","title":"Physics-informed DeepCT: Sinogram Wavelet Decomposition Meets Masked\n  Diffusion","summary":"  Diffusion model shows remarkable potential on sparse-view computed tomography\n(SVCT) reconstruction. However, when a network is trained on a limited sample\nspace, its generalization capability may be constrained, which degrades\nperformance on unfamiliar data. For image generation tasks, this can lead to\nissues such as blurry details and inconsistencies between regions. To alleviate\nthis problem, we propose a Sinogram-based Wavelet random decomposition And\nRandom mask diffusion Model (SWARM) for SVCT reconstruction. Specifically,\nintroducing a random mask strategy in the sinogram effectively expands the\nlimited training sample space. This enables the model to learn a broader range\nof data distributions, enhancing its understanding and generalization of data\nuncertainty. In addition, applying a random training strategy to the\nhigh-frequency components of the sinogram wavelet enhances feature\nrepresentation and improves the ability to capture details in different\nfrequency bands, thereby improving performance and robustness. Two-stage\niterative reconstruction method is adopted to ensure the global consistency of\nthe reconstructed image while refining its details. Experimental results\ndemonstrate that SWARM outperforms competing approaches in both quantitative\nand qualitative performance across various datasets.\n","authors":["Zekun Zhou","Tan Liu","Bing Yu","Yanru Gong","Liu Shi","Qiegen Liu"],"pdf_url":"https://arxiv.org/pdf/2501.09935v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08881v3","updated":"2025-01-17T02:51:41Z","published":"2024-08-03T20:41:35Z","title":"Challenge Summary U-MedSAM: Uncertainty-aware MedSAM for Medical Image\n  Segmentation","summary":"  Medical Image Foundation Models have proven to be powerful tools for mask\nprediction across various datasets. However, accurately assessing the\nuncertainty of their predictions remains a significant challenge. To address\nthis, we propose a new model, U-MedSAM, which integrates the MedSAM model with\nan uncertainty-aware loss function and the Sharpness-Aware Minimization\n(SharpMin) optimizer. The uncertainty-aware loss function automatically\ncombines region-based, distribution-based, and pixel-based loss designs to\nenhance segmentation accuracy and robustness. SharpMin improves generalization\nby finding flat minima in the loss landscape, thereby reducing overfitting. Our\nmethod was evaluated in the CVPR24 MedSAM on Laptop challenge, where U-MedSAM\ndemonstrated promising performance.\n","authors":["Xin Wang","Xiaoyu Liu","Peng Huang","Pu Huang","Shu Hu","Hongtu Zhu"],"pdf_url":"https://arxiv.org/pdf/2408.08881v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2405.17496"},{"id":"http://arxiv.org/abs/2501.09927v1","updated":"2025-01-17T02:47:25Z","published":"2025-01-17T02:47:25Z","title":"IE-Bench: Advancing the Measurement of Text-Driven Image Editing for\n  Human Perception Alignment","summary":"  Recent advances in text-driven image editing have been significant, yet the\ntask of accurately evaluating these edited images continues to pose a\nconsiderable challenge. Different from the assessment of text-driven image\ngeneration, text-driven image editing is characterized by simultaneously\nconditioning on both text and a source image. The edited images often retain an\nintrinsic connection to the original image, which dynamically change with the\nsemantics of the text. However, previous methods tend to solely focus on\ntext-image alignment or have not aligned with human perception. In this work,\nwe introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to\nenhance the assessment of text-driven edited images. IE-Bench includes a\ndatabase contains diverse source images, various editing prompts and the\ncorresponding results different editing methods, and total 3,010 Mean Opinion\nScores (MOS) provided by 25 human subjects. Furthermore, we introduce IE-QA, a\nmulti-modality source-aware quality assessment method for text-driven image\nediting. To the best of our knowledge, IE-Bench offers the first IQA dataset\nand model tailored for text-driven image editing. Extensive experiments\ndemonstrate IE-QA's superior subjective-alignments on the text-driven image\nediting task compared with previous metrics. We will make all related data and\ncode available to the public.\n","authors":["Shangkun Sun","Bowen Qu","Xiaoyu Liang","Songlin Fan","Wei Gao"],"pdf_url":"https://arxiv.org/pdf/2501.09927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09926v1","updated":"2025-01-17T02:47:14Z","published":"2025-01-17T02:47:14Z","title":"ForestProtector: An IoT Architecture Integrating Machine Vision and Deep\n  Reinforcement Learning for Efficient Wildfire Monitoring","summary":"  Early detection of forest fires is crucial to minimizing the environmental\nand socioeconomic damage they cause. Indeed, a fire's duration directly\ncorrelates with the difficulty and cost of extinguishing it. For instance, a\nfire burning for 1 minute might require 1 liter of water to extinguish, while a\n2-minute fire could demand 100 liters, and a 10-minute fire might necessitate\n1,000 liters. On the other hand, existing fire detection systems based on novel\ntechnologies (e.g., remote sensing, PTZ cameras, UAVs) are often expensive and\nrequire human intervention, making continuous monitoring of large areas\nimpractical. To address this challenge, this work proposes a low-cost forest\nfire detection system that utilizes a central gateway device with computer\nvision capabilities to monitor a 360{\\deg} field of view for smoke at long\ndistances. A deep reinforcement learning agent enhances surveillance by\ndynamically controlling the camera's orientation, leveraging real-time sensor\ndata (smoke levels, ambient temperature, and humidity) from distributed IoT\ndevices. This approach enables automated wildfire monitoring across expansive\nareas while reducing false positives.\n","authors":["Kenneth Bonilla-Ormachea","Horacio Cuizaga","Edwin Salcedo","Sebastian Castro","Sergio Fernandez-Testa","Misael Mamani"],"pdf_url":"https://arxiv.org/pdf/2501.09926v1.pdf","comment":"Accepted for publication in the proceedings of the 11th International\n  Conference on Automation, Robotics, and Applications (ICARA 2025)"},{"id":"http://arxiv.org/abs/2501.09921v1","updated":"2025-01-17T02:27:59Z","published":"2025-01-17T02:27:59Z","title":"TalkingEyes: Pluralistic Speech-Driven 3D Eye Gaze Animation","summary":"  Although significant progress has been made in the field of speech-driven 3D\nfacial animation recently, the speech-driven animation of an indispensable\nfacial component, eye gaze, has been overlooked by recent research. This is\nprimarily due to the weak correlation between speech and eye gaze, as well as\nthe scarcity of audio-gaze data, making it very challenging to generate 3D eye\ngaze motion from speech alone. In this paper, we propose a novel data-driven\nmethod which can generate diverse 3D eye gaze motions in harmony with the\nspeech. To achieve this, we firstly construct an audio-gaze dataset that\ncontains about 14 hours of audio-mesh sequences featuring high-quality eye gaze\nmotion, head motion and facial motion simultaneously. The motion data is\nacquired by performing lightweight eye gaze fitting and face reconstruction on\nvideos from existing audio-visual datasets. We then tailor a novel\nspeech-to-motion translation framework in which the head motions and eye gaze\nmotions are jointly generated from speech but are modeled in two separate\nlatent spaces. This design stems from the physiological knowledge that the\nrotation range of eyeballs is less than that of head. Through mapping the\nspeech embedding into the two latent spaces, the difficulty in modeling the\nweak correlation between speech and non-verbal motion is thus attenuated.\nFinally, our TalkingEyes, integrated with a speech-driven 3D facial motion\ngenerator, can synthesize eye gaze motion, eye blinks, head motion and facial\nmotion collectively from speech. Extensive quantitative and qualitative\nevaluations demonstrate the superiority of the proposed method in generating\ndiverse and natural 3D eye gaze motions from speech. The project page of this\npaper is: https://lkjkjoiuiu.github.io/TalkingEyes_Home/\n","authors":["Yixiang Zhuang","Chunshan Ma","Yao Cheng","Xuan Cheng","Jing Liao","Juncong Lin"],"pdf_url":"https://arxiv.org/pdf/2501.09921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07227v3","updated":"2025-01-17T02:27:29Z","published":"2025-01-13T11:28:49Z","title":"MECD+: Unlocking Event-Level Causal Graph Discovery for Video Reasoning","summary":"  Video causal reasoning aims to achieve a high-level understanding of videos\nfrom a causal perspective. However, it exhibits limitations in its scope,\nprimarily executed in a question-answering paradigm and focusing on brief video\nsegments containing isolated events and basic causal relations, lacking\ncomprehensive and structured causality analysis for videos with multiple\ninterconnected events. To fill this gap, we introduce a new task and dataset,\nMulti-Event Causal Discovery (MECD). It aims to uncover the causal relations\nbetween events distributed chronologically across long videos. Given visual\nsegments and textual descriptions of events, MECD identifies the causal\nassociations between these events to derive a comprehensive and structured\nevent-level video causal graph explaining why and how the result event\noccurred. To address the challenges of MECD, we devise a novel framework\ninspired by the Granger Causality method, incorporating an efficient mask-based\nevent prediction model to perform an Event Granger Test. It estimates causality\nby comparing the predicted result event when premise events are masked versus\nunmasked. Furthermore, we integrate causal inference techniques such as\nfront-door adjustment and counterfactual inference to mitigate challenges in\nMECD like causality confounding and illusory causality. Additionally, context\nchain reasoning is introduced to conduct more robust and generalized reasoning.\nExperiments validate the effectiveness of our framework in reasoning complete\ncausal relations, outperforming GPT-4o and VideoChat2 by 5.77% and 2.70%,\nrespectively. Further experiments demonstrate that causal relation graphs can\nalso contribute to downstream video understanding tasks such as video question\nanswering and video event prediction.\n","authors":["Tieyuan Chen","Huabin Liu","Yi Wang","Yihang Chen","Tianyao He","Chaofan Gan","Huanyu He","Weiyao Lin"],"pdf_url":"https://arxiv.org/pdf/2501.07227v3.pdf","comment":"IEEE TPAMI Submission. continuous work of arXiv:2409.17647 (NeurIPS\n  2024)"},{"id":"http://arxiv.org/abs/2408.07832v8","updated":"2025-01-17T02:18:00Z","published":"2024-07-31T14:49:35Z","title":"LADDER: Language Driven Slice Discovery and Error Rectification","summary":"  Error slice discovery is crucial to diagnose and mitigate model errors.\nCurrent clustering or discrete attribute-based slice discovery methods face key\nlimitations: 1) clustering results in incoherent slices, while assigning\ndiscrete attributes to slices leads to incomplete coverage of error patterns\ndue to missing or insufficient attributes; 2) these methods lack complex\nreasoning, preventing them from fully explaining model biases; 3) they fail to\nintegrate \\textit{domain knowledge}, limiting their usage in specialized fields\n\\eg radiology. We propose\\ladder (\\underline{La}nguage-\\underline{D}riven\n\\underline{D}iscovery and \\underline{E}rror \\underline{R}ectification), to\naddress the limitations by: (1) leveraging the flexibility of natural language\nto address incompleteness, (2) employing LLM's latent \\textit{domain knowledge}\nand advanced reasoning to analyze sentences and derive testable hypotheses\ndirectly, identifying biased attributes, and form coherent error slices without\nclustering. Existing mitigation methods typically address only the\nworst-performing group, often amplifying errors in other subgroups. In\ncontrast,\\ladder generates pseudo attributes from the discovered hypotheses to\nmitigate errors across all biases without explicit attribute annotations or\nprior knowledge of bias. Rigorous evaluations on 6 datasets spanning natural\nand medical images -- comparing 200+ classifiers with diverse architectures,\npretraining strategies, and LLMs -- show that\\ladder consistently outperforms\nexisting baselines in discovering and mitigating biases.\n","authors":["Shantanu Ghosh","Rayan Syed","Chenyu Wang","Clare B. Poynton","Shyam Visweswaran","Kayhan Batmanghelich"],"pdf_url":"https://arxiv.org/pdf/2408.07832v8.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02427v2","updated":"2025-01-17T01:47:13Z","published":"2025-01-05T03:12:30Z","title":"MetaNeRV: Meta Neural Representations for Videos with Spatial-Temporal\n  Guidance","summary":"  Neural Representations for Videos (NeRV) has emerged as a promising implicit\nneural representation (INR) approach for video analysis, which represents\nvideos as neural networks with frame indexes as inputs. However, NeRV-based\nmethods are time-consuming when adapting to a large number of diverse videos,\nas each video requires a separate NeRV model to be trained from scratch. In\naddition, NeRV-based methods spatially require generating a high-dimension\nsignal (i.e., an entire image) from the input of a low-dimension timestamp, and\na video typically consists of tens of frames temporally that have a minor\nchange between adjacent frames. To improve the efficiency of video\nrepresentation, we propose Meta Neural Representations for Videos, named\nMetaNeRV, a novel framework for fast NeRV representation for unseen videos.\nMetaNeRV leverages a meta-learning framework to learn an optimal parameter\ninitialization, which serves as a good starting point for adapting to new\nvideos. To address the unique spatial and temporal characteristics of video\nmodality, we further introduce spatial-temporal guidance to improve the\nrepresentation capabilities of MetaNeRV. Specifically, the spatial guidance\nwith a multi-resolution loss aims to capture the information from different\nresolution stages, and the temporal guidance with an effective progressive\nlearning strategy could gradually refine the number of fitted frames during the\nmeta-learning process. Extensive experiments conducted on multiple datasets\ndemonstrate the superiority of MetaNeRV for video representations and video\ncompression.\n","authors":["Jialong Guo","Ke liu","Jiangchao Yao","Zhihua Wang","Jiajun Bu","Haishuai Wang"],"pdf_url":"https://arxiv.org/pdf/2501.02427v2.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2501.09905v1","updated":"2025-01-17T01:32:18Z","published":"2025-01-17T01:32:18Z","title":"SLIM: Sim-to-Real Legged Instructive Manipulation via Long-Horizon\n  Visuomotor Learning","summary":"  We present a low-cost quadruped manipulation system that solves long-horizon\nreal-world tasks, trained by reinforcement learning purely in simulation. The\nsystem comprises 1) a hierarchical design of a high-level policy for\nvisual-mobile manipulation following instructions, and a low-level policy for\nquadruped movement and limb-control, 2) a progressive policy expansion approach\nfor solving the long-horizon task together with a teacher-student framework for\nefficient high-level training of the high-level visuomotor policy, and 3) a\nsuite of techniques for minimizing sim-to-real gaps.\n  With budget-friendly but limited reliability and performance hardware, and\njust one wrist-mounted RGB camera, the entire system fully trained in\nsimulation achieves high success rates for long horizon tasks involving search,\nmove, grasp, and drop-into, with fluid sim-to-real transfer in a wide variety\nof indoor and outdoor scenes and lighting conditions.Extensive real-world\nevaluations show that on the long horizon mobile manipulation tasks, our system\nachieves good performance when transferred to real both in terms of task\nsuccess rate and execution efficiency. Finally, we discuss the necessity of our\nsim-to-real techniques for legged mobile manipulation, and show their ablation\nperformance.\n","authors":["Haichao Zhang","Haonan Yu","Le Zhao","Andrew Choi","Qinxun Bai","Yiqing Yang","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2501.09905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.03415v4","updated":"2025-01-17T01:13:19Z","published":"2022-03-04T06:41:40Z","title":"Keep It Accurate and Robust: An Enhanced Nuclei Analysis Framework","summary":"  Accurate segmentation and classification of nuclei in histology images is\ncritical but challenging due to nuclei heterogeneity, staining variations, and\ntissue complexity. Existing methods often struggle with limited dataset\nvariability, with patches extracted from similar whole slide images (WSI),\nmaking models prone to falling into local optima. Here we propose a new\nframework to address this limitation and enable robust nuclear analysis. Our\nmethod leverages dual-level ensemble modeling to overcome issues stemming from\nlimited dataset variation. Intra-ensembling applies diverse transformations to\nindividual samples, while inter-ensembling combines networks of different\nscales. We also introduce enhancements to the HoVer-Net architecture, including\nupdated encoders, nested dense decoding and model regularization strategy. We\nachieve state-of-the-art results on public benchmarks, including 1st place for\nnuclear composition prediction and 3rd place for segmentation/classification in\nthe 2022 Colon Nuclei Identification and Counting (CoNIC) Challenge. This\nsuccess validates our approach for accurate histological nuclei analysis.\nExtensive experiments and ablation studies provide insights into optimal\nnetwork design choices and training techniques. In conclusion, this work\nproposes an improved framework advancing the state-of-the-art in nuclei\nanalysis. We release our code and models\n(https://github.com/WinnieLaugh/CONIC_Pathology_AI) to serve as a toolkit for\nthe community.\n","authors":["Wenhua Zhang","Sen Yang","Meiwei Luo","Chuan He","Yuchen Li","Jun Zhang","Xiyue Wang","Fang Wang"],"pdf_url":"https://arxiv.org/pdf/2203.03415v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09898v1","updated":"2025-01-17T01:01:44Z","published":"2025-01-17T01:01:44Z","title":"FoundationStereo: Zero-Shot Stereo Matching","summary":"  Tremendous progress has been made in deep stereo matching to excel on\nbenchmark datasets through per-domain fine-tuning. However, achieving strong\nzero-shot generalization - a hallmark of foundation models in other computer\nvision tasks - remains challenging for stereo matching. We introduce\nFoundationStereo, a foundation model for stereo depth estimation designed to\nachieve strong zero-shot generalization. To this end, we first construct a\nlarge-scale (1M stereo pairs) synthetic training dataset featuring large\ndiversity and high photorealism, followed by an automatic self-curation\npipeline to remove ambiguous samples. We then design a number of network\narchitecture components to enhance scalability, including a side-tuning feature\nbackbone that adapts rich monocular priors from vision foundation models to\nmitigate the sim-to-real gap, and long-range context reasoning for effective\ncost volume filtering. Together, these components lead to strong robustness and\naccuracy across domains, establishing a new standard in zero-shot stereo depth\nestimation.\n","authors":["Bowen Wen","Matthew Trepte","Joseph Aribido","Jan Kautz","Orazio Gallo","Stan Birchfield"],"pdf_url":"https://arxiv.org/pdf/2501.09898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09887v1","updated":"2025-01-17T00:18:34Z","published":"2025-01-17T00:18:34Z","title":"FLORA: Formal Language Model Enables Robust Training-free Zero-shot\n  Object Referring Analysis","summary":"  Object Referring Analysis (ORA), commonly known as referring expression\ncomprehension, requires the identification and localization of specific objects\nin an image based on natural descriptions. Unlike generic object detection, ORA\nrequires both accurate language understanding and precise visual localization,\nmaking it inherently more complex. Although recent pre-trained large visual\ngrounding detectors have achieved significant progress, they heavily rely on\nextensively labeled data and time-consuming learning. To address these, we\nintroduce a novel, training-free framework for zero-shot ORA, termed FLORA\n(Formal Language for Object Referring and Analysis). FLORA harnesses the\ninherent reasoning capabilities of large language models (LLMs) and integrates\na formal language model - a logical framework that regulates language within\nstructured, rule-based descriptions - to provide effective zero-shot ORA. More\nspecifically, our formal language model (FLM) enables an effective,\nlogic-driven interpretation of object descriptions without necessitating any\ntraining processes. Built upon FLM-regulated LLM outputs, we further devise a\nBayesian inference framework and employ appropriate off-the-shelf interpretive\nmodels to finalize the reasoning, delivering favorable robustness against LLM\nhallucinations and compelling ORA performance in a training-free manner. In\npractice, our FLORA boosts the zero-shot performance of existing pretrained\ngrounding detectors by up to around 45%. Our comprehensive evaluation across\ndifferent challenging datasets also confirms that FLORA consistently surpasses\ncurrent state-of-the-art zero-shot methods in both detection and segmentation\ntasks associated with zero-shot ORA. We believe our probabilistic parsing and\nreasoning of the LLM outputs elevate the reliability and interpretability of\nzero-shot ORA. We shall release codes upon publication.\n","authors":["Zhe Chen","Zijing Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09887v1.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2501.10338v1","updated":"2025-01-17T18:23:10Z","published":"2025-01-17T18:23:10Z","title":"Perception of Visual Variables on Virtual Wall-Sized Tiled Displays in\n  Immersive Environments","summary":"  We investigate the perception of visual variables on wall-sized tiled\ndisplays within an immersive environment. We designed and conducted two formal\nuser studies focusing on elementary visualization reading tasks in VR. The\nfirst study compared three different virtual display arrangements (Flat,\nCylinder, and Cockpit). It showed that participants made smaller errors on\nvirtual curved walls (Cylinder and Cockpit) compared to Flat. Following that,\nwe compared the results with those from a previous study conducted in a\nreal-world setting. The comparative analysis showed that virtual curved walls\nresulted in smaller errors than the real-world flat wall display, but with\nlonger task completion time. The second study evaluated the impact of four 3D\nuser interaction techniques (Selection, Walking, Steering, and Teleportation)\non performing the elementary task on the virtual Flat wall display. The results\nconfirmed that interaction techniques further improved task performance.\nFinally, we discuss the limitations and future work.\n","authors":["Dongyun Han","Anastasia Bezerianos","Petra Isenberg","Isaac Cho"],"pdf_url":"https://arxiv.org/pdf/2501.10338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10288v1","updated":"2025-01-17T16:31:40Z","published":"2025-01-17T16:31:40Z","title":"Design Patterns for the Common Good: Building Better Technologies Using\n  the Wisdom of Virtue Ethics","summary":"  Virtue ethics is a philosophical tradition that emphasizes the cultivation of\nvirtues in achieving the common good. It has been suggested to be an effective\nframework for envisioning more ethical technology, yet previous work on virtue\nethics and technology design has remained at theoretical recommendations.\nTherefore, we propose an approach for identifying user experience design\npatterns that embody particular virtues to more concretely articulate virtuous\ntechnology designs. As a proof of concept for our approach, we documented seven\ndesign patterns for social media that uphold the virtues of Catholic Social\nTeaching. We interviewed 24 technology researchers and industry practitioners\nto evaluate these patterns. We found that overall the patterns enact the\nvirtues they were identified to embody; our participants valued that the\npatterns fostered intentional conversations and personal connections. We pave a\npath for technology professionals to incorporate diverse virtue traditions into\nthe development of technologies that support human flourishing.\n","authors":["Louisa Conwill","Megan K. Levis","Karla Badillo-Urquiola","Walter J. Scheirer"],"pdf_url":"https://arxiv.org/pdf/2501.10288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22324v2","updated":"2025-01-17T16:03:08Z","published":"2024-10-29T17:57:33Z","title":"Perceptions of Blind Adults on Non-Visual Mobile Text Entry","summary":"  Text input on mobile devices without physical keys can be challenging for\npeople who are blind or low-vision. We interview 12 blind adults about their\nexperiences with current mobile text input to provide insights into what sorts\nof interface improvements may be the most beneficial. We identify three primary\nthemes that were experiences or opinions shared by participants: the poor\naccuracy of dictation, difficulty entering text in noisy environments, and\ndifficulty correcting errors in entered text. We also discuss an experimental\nnon-visual text input method with each participant to solicit opinions on the\nmethod and probe their willingness to learn a novel method. We find that the\nlargest concern was the time required to learn a new technique. We find that\nthe majority of our participants do not use word predictions while typing but\ninstead find it faster to finish typing words manually. Finally, we distill\nfive future directions for non-visual text input: improved dictation, less\nreliance on or improved audio feedback, improved error correction, reducing the\nbarrier to entry for new methods, and more fluid non-visual word predictions.\n","authors":["Dylan Gaines","Keith Vertanen"],"pdf_url":"https://arxiv.org/pdf/2410.22324v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13265v2","updated":"2025-01-17T13:51:21Z","published":"2024-12-17T19:00:52Z","title":"Nods of Agreement: Webcam-Driven Avatars Improve Meeting Outcomes and\n  Avatar Satisfaction Over Audio-Driven or Static Avatars in All-Avatar Work\n  Videoconferencing","summary":"  Avatars are edging into mainstream videoconferencing, but evaluation of how\navatar animation modalities contribute to work meeting outcomes has been\nlimited. We report a within-group videoconferencing experiment in which 68\nemployees of a global technology company, in 16 groups, used the same stylized\navatars in three modalities (static picture, audio-animation, and\nwebcam-animation) to complete collaborative decision-making tasks.\nQuantitatively, for meeting outcomes, webcam-animated avatars improved meeting\neffectiveness over the picture modality and were also reported to be more\ncomfortable and inclusive than both other modalities. In terms of avatar\nsatisfaction, there was a similar preference for webcam animation as compared\nto both other modalities. Our qualitative analysis shows participants\nexpressing a preference for the holistic motion of webcam animation, and that\nmeaningful movement outweighs realism for meeting outcomes, as evidenced\nthrough a systematic overview of ten thematic factors. We discuss implications\nfor research and commercial deployment and conclude that webcam-animated\navatars are a plausible alternative to video in work meetings.\n","authors":["Fang Ma","Ju Zhang","Lev Tankelevitch","Payod Panda","Torang Asadi","Charlie Hewitt","Lohit Petikam","James Clemoes","Marco Gillies","Xueni Pan","Sean Rintel","Marta Wilczkowiak"],"pdf_url":"https://arxiv.org/pdf/2412.13265v2.pdf","comment":"to be published in PACM HCI"},{"id":"http://arxiv.org/abs/2501.10168v1","updated":"2025-01-17T12:59:34Z","published":"2025-01-17T12:59:34Z","title":"Unveiling High-dimensional Backstage: A Survey for Reliable Visual\n  Analytics with Dimensionality Reduction","summary":"  Dimensionality reduction (DR) techniques are essential for visually analyzing\nhigh-dimensional data. However, visual analytics using DR often face\nunreliability, stemming from factors such as inherent distortions in DR\nprojections. This unreliability can lead to analytic insights that misrepresent\nthe underlying data, potentially resulting in misguided decisions. To tackle\nthese reliability challenges, we review 133 papers that address the\nunreliability of visual analytics using DR. Through this review, we contribute\n(1) a workflow model that describes the interaction between analysts and\nmachines in visual analytics using DR, and (2) a taxonomy that identifies where\nand why reliability issues arise within the workflow, along with existing\nsolutions for addressing them. Our review reveals ongoing challenges in the\nfield, whose significance and urgency are validated by five expert researchers.\nThis review also finds that the current research landscape is skewed toward\ndeveloping new DR techniques rather than their interpretation or evaluation,\nwhere we discuss how the HCI community can contribute to broadening this focus.\n","authors":["Hyeon Jeon","Hyunwook Lee","Yun-Hsin Kuo","Taehyun Yang","Daniel Archambault","Sungahn Ko","Takanori Fujiwara","Kwan-Liu Ma","Jinwook Seo"],"pdf_url":"https://arxiv.org/pdf/2501.10168v1.pdf","comment":"In Proceedings of the SIGCHI Conference on Human Factors in Computing\n  Systems (CHI '25)"},{"id":"http://arxiv.org/abs/2501.09233v2","updated":"2025-01-17T12:48:09Z","published":"2025-01-16T01:35:16Z","title":"Redefining Affordance via Computational Rationality","summary":"  Affordances, a foundational concept in human-computer interaction and design,\nhave traditionally been explained by direct-perception theories, which assume\nthat individuals perceive action possibilities directly from the environment.\nHowever, these theories fall short of explaining how affordances are perceived,\nlearned, refined, or misperceived, and how users choose between multiple\naffordances in dynamic contexts. This paper introduces a novel affordance\ntheory grounded in Computational Rationality, positing that humans construct\ninternal representations of the world based on bounded sensory inputs. Within\nthese internal models, affordances are inferred through two core mechanisms:\nfeature recognition and hypothetical motion trajectories. Our theory redefines\naffordance perception as a decision-making process, driven by two components:\nconfidence (the perceived likelihood of successfully executing an action) and\npredicted utility (the expected value of the outcome). By balancing these\nfactors, individuals make informed decisions about which actions to take. Our\ntheory frames affordances perception as dynamic, continuously learned, and\nrefined through reinforcement and feedback. We validate the theory via thought\nexperiments and demonstrate its applicability across diverse types of\naffordances (e.g., physical, digital, social). Beyond clarifying and\ngeneralizing the understanding of affordances across contexts, our theory\nserves as a foundation for improving design communication and guiding the\ndevelopment of more adaptive and intuitive systems that evolve with user\ncapabilities.\n","authors":["Yi-Chi Liao","Christian Holz"],"pdf_url":"https://arxiv.org/pdf/2501.09233v2.pdf","comment":"IUI 2025 Paper"},{"id":"http://arxiv.org/abs/2501.10137v1","updated":"2025-01-17T11:59:56Z","published":"2025-01-17T11:59:56Z","title":"Visual Exploration of Stopword Probabilities in Topic Models","summary":"  Stopword removal is a critical stage in many Machine Learning methods but\noften receives little consideration, it interferes with the model\nvisualizations and disrupts user confidence. Inappropriately chosen or hastily\nomitted stopwords not only lead to suboptimal performance but also\nsignificantly affect the quality of models, thus reducing the willingness of\npractitioners and stakeholders to rely on the output visualizations. This paper\nproposes a novel extraction method that provides a corpus-specific\nprobabilistic estimation of stopword likelihood and an interactive\nvisualization system to support their analysis. We evaluated our approach and\ninterface using real-world data, a commonly used Machine Learning method (Topic\nModelling), and a comprehensive qualitative experiment probing user confidence.\nThe results of our work show that our system increases user confidence in the\ncredibility of topic models by (1) returning reasonable probabilities, (2)\ngenerating an appropriate and representative extension of common stopword\nlists, and (3) providing an adjustable threshold for estimating and analyzing\nstopwords visually. Finally, we discuss insights, recommendations, and best\npractices to support practitioners while improving the output of Machine\nLearning methods and topic model visualizations with robust stopword analysis\nand removal.\n","authors":["Shuangjiang Xue","Pierre Le Bras","David A. Robb","Mike J. Chantler","Stefano Padilla"],"pdf_url":"https://arxiv.org/pdf/2501.10137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10134v1","updated":"2025-01-17T11:49:49Z","published":"2025-01-17T11:49:49Z","title":"Exploring the Impact of Generative Artificial Intelligence in Education:\n  A Thematic Analysis","summary":"  The recent advancements in Generative Artificial intelligence (GenAI)\ntechnology have been transformative for the field of education. Large Language\nModels (LLMs) such as ChatGPT and Bard can be leveraged to automate boilerplate\ntasks, create content for personalised teaching, and handle repetitive tasks to\nallow more time for creative thinking. However, it is important to develop\nguidelines, policies, and assessment methods in the education sector to ensure\nthe responsible integration of these tools. In this article, thematic analysis\nhas been performed on seven essays obtained from professionals in the education\nsector to understand the advantages and pitfalls of using GenAI models such as\nChatGPT and Bard in education. Exploratory Data Analysis (EDA) has been\nperformed on the essays to extract further insights from the text. The study\nfound several themes which highlight benefits and drawbacks of GenAI tools, as\nwell as suggestions to overcome these limitations and ensure that students are\nusing these tools in a responsible and ethical manner.\n","authors":["Abhishek Kaushik","Sargam Yadav","Andrew Browne","David Lillis","David Williams","Jack Mc Donnell","Peadar Grant","Siobhan Connolly Kernan","Shubham Sharma","Mansi Arora"],"pdf_url":"https://arxiv.org/pdf/2501.10134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10662v4","updated":"2025-01-17T11:02:03Z","published":"2024-07-15T12:25:49Z","title":"XEQ Scale for Evaluating XAI Experience Quality","summary":"  Explainable Artificial Intelligence (XAI) aims to improve the transparency of\nautonomous decision-making through explanations. Recent literature has\nemphasised users' need for holistic \"multi-shot\" explanations and personalised\nengagement with XAI systems. We refer to this user-centred interaction as an\nXAI Experience. Despite advances in creating XAI experiences, evaluating them\nin a user-centred manner has remained challenging. In response, we developed\nthe XAI Experience Quality (XEQ) Scale. XEQ quantifies the quality of\nexperiences across four dimensions: learning, utility, fulfilment and\nengagement. These contributions extend the state-of-the-art of XAI evaluation,\nmoving beyond the one-dimensional metrics frequently developed to assess\nsingle-shot explanations. This paper presents the XEQ scale development and\nvalidation process, including content validation with XAI experts, and\ndiscriminant and construct validation through a large-scale pilot study. Our\npilot study results offer strong evidence that establishes the XEQ Scale as a\ncomprehensive framework for evaluating user-centred XAI experiences.\n","authors":["Anjana Wijekoon","Nirmalie Wiratunga","David Corsar","Kyle Martin","Ikechukwu Nkisi-Orji","Belen Díaz-Agudo","Derek Bridge"],"pdf_url":"https://arxiv.org/pdf/2407.10662v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10091v1","updated":"2025-01-17T10:25:41Z","published":"2025-01-17T10:25:41Z","title":"How Do Programming Students Use Generative AI?","summary":"  Programming students have a widespread access to powerful Generative AI tools\nlike ChatGPT. While this can help understand the learning material and assist\nwith exercises, educators are voicing more and more concerns about an\nover-reliance on generated outputs and lack of critical thinking skills. It is\nthus important to understand how students actually use generative AI and what\nimpact this could have on their learning behavior. To this end, we conducted a\nstudy including an exploratory experiment with 37 programming students, giving\nthem monitored access to ChatGPT while solving a code understanding and\nimproving exercise. While only 23 of the students actually opted to use the\nchatbot, the majority of those eventually prompted it to simply generate a full\nsolution. We observed two prevalent usage strategies: to seek knowledge about\ngeneral concepts and to directly generate solutions. Instead of using the bot\nto comprehend the code and their own mistakes, students often got trapped in a\nvicious cycle of submitting wrong generated code and then asking the bot for a\nfix. Those who self-reported using generative AI regularly were more likely to\nprompt the bot to generate a solution. Our findings indicate that concerns\nabout potential decrease in programmers' agency and productivity with\nGenerative AI are justified. We discuss how researchers and educators can\nrespond to the potential risk of students uncritically over-relying on\ngenerative AI. We also discuss potential modifications to our study design for\nlarge-scale replications.\n","authors":["Christian Rahe","Walid Maalej"],"pdf_url":"https://arxiv.org/pdf/2501.10091v1.pdf","comment":"preprint; accepted to ACM International Conference on the Foundations\n  of Software Engineering (FSE) 2025"},{"id":"http://arxiv.org/abs/2407.17482v2","updated":"2025-01-17T09:17:30Z","published":"2024-07-02T08:07:27Z","title":"Reinforcement Learning from Human Feedback: Whose Culture, Whose Values,\n  Whose Perspectives?","summary":"  We argue for the epistemic and ethical advantages of pluralism in\nReinforcement Learning from Human Feedback (RLHF) in the context of Large\nLanguage Models (LLM). Drawing on social epistemology and pluralist philosophy\nof science, we suggest ways in which RHLF can be made more responsive to human\nneeds and how we can address challenges along the way. The paper concludes with\nan agenda for change, i.e. concrete, actionable steps to improve LLM\ndevelopment.\n","authors":["Kristian González Barman","Simon Lohse","Henk de Regt"],"pdf_url":"https://arxiv.org/pdf/2407.17482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09951v1","updated":"2025-01-17T04:37:17Z","published":"2025-01-17T04:37:17Z","title":"Discord's Design Encourages \"Third Place\" Social Media Experiences","summary":"  In light of the diminishing presence of physical third places -- informal\ngathering spaces essential for social connection -- this study explores how the\nsocial media platform Discord fosters third-place experiences. Drawing on\nOldenburg's conceptual framework, we analyze how Discord's design elements\nsupport the creation of virtual third places that foster both dyadic and\ncommunity-based relationships. Through 25 semi-structured interviews with\nactive Discord users, we identified 21 design elements aligned with Oldenburg's\nthird-place characteristics. These elements cluster around four core\nprinciples: providing themed spaces for repeated interactions, supporting user\nautonomy and customization, facilitating mutually engaging activities, and\nenabling casual, low-pressure interactions. This work contributes to\nunderstanding how intentional platform design can cultivate virtual spaces that\nsupport meaningful social connections. The findings have implications for\ndesigning future social technologies that can help address growing concerns\nabout social isolation in an increasingly digital world.\n","authors":["JaeWon Kim","Thea Klein-Balajee","Ryan M. Kelly","Alexis Hiniker"],"pdf_url":"https://arxiv.org/pdf/2501.09951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09930v1","updated":"2025-01-17T03:02:51Z","published":"2025-01-17T03:02:51Z","title":"TeamVision: An AI-powered Learning Analytics System for Supporting\n  Reflection in Team-based Healthcare Simulation","summary":"  Healthcare simulations help learners develop teamwork and clinical skills in\na risk-free setting, promoting reflection on real-world practices through\nstructured debriefs. However, despite video's potential, it is hard to use,\nleaving a gap in providing concise, data-driven summaries for supporting\neffective debriefing. Addressing this, we present TeamVision, an AI-powered\nmultimodal learning analytics (MMLA) system that captures voice presence,\nautomated transcriptions, body rotation, and positioning data, offering\neducators a dashboard to guide debriefs immediately after simulations. We\nconducted an in-the-wild study with 56 teams (221 students) and recorded\ndebriefs led by six teachers using TeamVision. Follow-up interviews with 15\nstudents and five teachers explored perceptions of its usefulness, accuracy,\nand trustworthiness. This paper examines: i) how TeamVision was used in\ndebriefing, ii) what educators found valuable and challenging, and iii)\nperceptions of its effectiveness. Results suggest TeamVision enables flexible\ndebriefing and highlights the challenges and implications of using AI-powered\nsystems in healthcare simulation.\n","authors":["Vanessa Echeverria","Linxuan Zhao","Riordan Alfredo","Mikaela Milesi","Yuequiao Jin","Sophie Abel","Jie Yan","Lixiang Yan","Xinyu Li","Samantha Dix","Rosie Wotherspoon","Hollie Jaggard","Abra Osborne","Simon Buckingham Shum","Dragan Gasevic","Roberto Martinez-Maldonado"],"pdf_url":"https://arxiv.org/pdf/2501.09930v1.pdf","comment":"Accepted to CHI 2025"},{"id":"http://arxiv.org/abs/2501.09910v1","updated":"2025-01-17T01:48:15Z","published":"2025-01-17T01:48:15Z","title":"Chatbot apologies: Beyond bullshit","summary":"  Apologies serve essential functions for moral agents such as expressing\nremorse, taking responsibility, and repairing trust. LLM-based chatbots\nroutinely produce output that has the linguistic form of an apology. However,\nthey do this simply because they are echoing the kinds of things that humans\nsay. Moreover, there are reasons to think that chatbots are not the kind of\nlinguistic or moral agents capable of apology. To put the point bluntly:\nChatbot apologies are bullshit. This paper offers several arguments for this\nconclusion, drawing on the nature of morally-serious apologies, the linguistic\nagency required to perform them, and the moral agency required for them to\nmatter. We conclude by considering some consequences for how chatbots should be\ndesigned and how we ought to think about them.\n","authors":["P. D. Magnus","Alessandra Buccella","Jason D'Cruz"],"pdf_url":"https://arxiv.org/pdf/2501.09910v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2403.15780v3","updated":"2025-01-17T18:42:52Z","published":"2024-03-23T09:32:23Z","title":"A Fairness-Oriented Reinforcement Learning Approach for the Operation\n  and Control of Shared Micromobility Services","summary":"  As Machine Learning grows in popularity across various fields, equity has\nbecome a key focus for the AI community. However, fairness-oriented approaches\nare still underexplored in smart mobility. Addressing this gap, our study\ninvestigates the balance between performance optimization and algorithmic\nfairness in shared micromobility services providing a novel framework based on\nReinforcement Learning. Exploiting Q-learning, the proposed methodology\nachieves equitable outcomes in terms of the Gini index across different areas\ncharacterized by their distance from central hubs. Through vehicle rebalancing,\nthe provided scheme maximizes operator performance while ensuring fairness\nprinciples for users, reducing iniquity by up to 85% while only increasing\ncosts by 30% (w.r.t. applying no equity adjustment). A case study with\nsynthetic data validates our insights and highlights the importance of fairness\nin urban micromobility (source code:\nhttps://github.com/mcederle99/FairMSS.git).\n","authors":["Matteo Cederle","Luca Vittorio Piron","Marina Ceccon","Federico Chiariotti","Alessandro Fabris","Marco Fabris","Gian Antonio Susto"],"pdf_url":"https://arxiv.org/pdf/2403.15780v3.pdf","comment":"6 pages, 3 figures, accepted at the 2025 American Control Conference\n  (ACC) on January 17th, 2025"},{"id":"http://arxiv.org/abs/2501.10348v1","updated":"2025-01-17T18:42:46Z","published":"2025-01-17T18:42:46Z","title":"Credit Risk Identification in Supply Chains Using Generative Adversarial\n  Networks","summary":"  Credit risk management within supply chains has emerged as a critical\nresearch area due to its significant implications for operational stability and\nfinancial sustainability. The intricate interdependencies among supply chain\nparticipants mean that credit risks can propagate across networks, with impacts\nvarying by industry. This study explores the application of Generative\nAdversarial Networks (GANs) to enhance credit risk identification in supply\nchains. GANs enable the generation of synthetic credit risk scenarios,\naddressing challenges related to data scarcity and imbalanced datasets. By\nleveraging GAN-generated data, the model improves predictive accuracy while\neffectively capturing dynamic and temporal dependencies in supply chain data.\nThe research focuses on three representative industries-manufacturing (steel),\ndistribution (pharmaceuticals), and services (e-commerce) to assess\nindustry-specific credit risk contagion. Experimental results demonstrate that\nthe GAN-based model outperforms traditional methods, including logistic\nregression, decision trees, and neural networks, achieving superior accuracy,\nrecall, and F1 scores. The findings underscore the potential of GANs in\nproactive risk management, offering robust tools for mitigating financial\ndisruptions in supply chains. Future research could expand the model by\nincorporating external market factors and supplier relationships to further\nenhance predictive capabilities. Keywords- Generative Adversarial Networks\n(GANs); Supply Chain Risk; Credit Risk Identification; Machine Learning; Data\nAugmentation\n","authors":["Zizhou Zhang","Xinshi Li","Yu Cheng","Zhenrui Chen","Qianying Liu"],"pdf_url":"https://arxiv.org/pdf/2501.10348v1.pdf","comment":"The paper will be published and indexed by IEEE at 2025 8th\n  International Conference on Advanced Algorithms and Control Engineering\n  (ICAACE 2025)"},{"id":"http://arxiv.org/abs/2501.10347v1","updated":"2025-01-17T18:40:38Z","published":"2025-01-17T18:40:38Z","title":"ColNet: Collaborative Optimization in Decentralized Federated Multi-task\n  Learning Systems","summary":"  The integration of Federated Learning (FL) and Multi-Task Learning (MTL) has\nbeen explored to address client heterogeneity, with Federated Multi-Task\nLearning (FMTL) treating each client as a distinct task. However, most existing\nresearch focuses on data heterogeneity (e.g., addressing non-IID data) rather\nthan task heterogeneity, where clients solve fundamentally different tasks.\nAdditionally, much of the work relies on centralized settings with a server\nmanaging the federation, leaving the more challenging domain of decentralized\nFMTL largely unexplored. Thus, this work bridges this gap by proposing ColNet,\na framework designed for heterogeneous tasks in decentralized federated\nenvironments. ColNet divides models into the backbone and task-specific layers,\nforming groups of similar clients, with group leaders performing\nconflict-averse cross-group aggregation. A pool of experiments with different\nfederations demonstrated ColNet outperforms the compared aggregation schemes in\ndecentralized settings with label and task heterogeneity scenarios.\n","authors":["Chao Feng","Nicolas Fazli Kohler","Alberto Huertas Celdran","Gerome Bovet","Burkhard Stiller"],"pdf_url":"https://arxiv.org/pdf/2501.10347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10342v1","updated":"2025-01-17T18:33:58Z","published":"2025-01-17T18:33:58Z","title":"Hybrid Deep Learning Model for epileptic seizure classification by using\n  1D-CNN with multi-head attention mechanism","summary":"  Epilepsy is a prevalent neurological disorder globally, impacting around 50\nmillion people \\cite{WHO_epilepsy_50million}. Epileptic seizures result from\nsudden abnormal electrical activity in the brain, which can be read as sudden\nand significant changes in the EEG signal of the brain. The signal can vary in\nseverity and frequency, which results in loss of consciousness and muscle\ncontractions for a short period of time \\cite{epilepsyfoundation_myoclonic}.\nIndividuals with epilepsy often face significant employment challenges due to\nsafety concerns in certain work environments. Many jobs that involve working at\nheights, operating heavy machinery, or in other potentially hazardous settings\nmay be restricted for people with seizure disorders. This certainly limits job\noptions and economic opportunities for those living with epilepsy.\n","authors":["Mohammed Guhdar","Ramadhan J. Mstafa","Abdulhakeem O. Mohammed"],"pdf_url":"https://arxiv.org/pdf/2501.10342v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09327v2","updated":"2025-01-17T18:30:04Z","published":"2025-01-16T06:52:58Z","title":"On Learning Informative Trajectory Embeddings for Imitation,\n  Classification and Regression","summary":"  In real-world sequential decision making tasks like autonomous driving,\nrobotics, and healthcare, learning from observed state-action trajectories is\ncritical for tasks like imitation, classification, and clustering. For example,\nself-driving cars must replicate human driving behaviors, while robots and\nhealthcare systems benefit from modeling decision sequences, whether or not\nthey come from expert data. Existing trajectory encoding methods often focus on\nspecific tasks or rely on reward signals, limiting their ability to generalize\nacross domains and tasks. Inspired by the success of embedding models like CLIP\nand BERT in static domains, we propose a novel method for embedding\nstate-action trajectories into a latent space that captures the skills and\ncompetencies in the dynamic underlying decision-making processes. This method\noperates without the need for reward labels, enabling better generalization\nacross diverse domains and tasks. Our contributions are threefold: (1) We\nintroduce a trajectory embedding approach that captures multiple abilities from\nstate-action data. (2) The learned embeddings exhibit strong representational\npower across downstream tasks, including imitation, classification, clustering,\nand regression. (3) The embeddings demonstrate unique properties, such as\ncontrolling agent behaviors in IQ-Learn and an additive structure in the latent\nspace. Experimental results confirm that our method outperforms traditional\napproaches, offering more flexible and powerful trajectory representations for\nvarious applications. Our code is available at\nhttps://github.com/Erasmo1015/vte.\n","authors":["Zichang Ge","Changyu Chen","Arunesh Sinha","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2501.09327v2.pdf","comment":"AAMAS 2025"},{"id":"http://arxiv.org/abs/2403.01204v2","updated":"2025-01-17T18:15:40Z","published":"2024-03-02T12:45:01Z","title":"Stochastic gradient descent for streaming linear and rectified linear\n  systems with adversarial corruptions","summary":"  We propose SGD-exp, a stochastic gradient descent approach for linear and\nReLU regressions under Massart noise (adversarial semi-random corruption model)\nfor the fully streaming setting. We show novel nearly linear convergence\nguarantees of SGD-exp to the true parameter with up to $50\\%$ Massart\ncorruption rate, and with any corruption rate in the case of symmetric\noblivious corruptions. This is the first convergence guarantee result for\nrobust ReLU regression in the streaming setting, and it shows the improved\nconvergence rate over previous robust methods for $L_1$ linear regression due\nto a choice of an exponentially decaying step size, known for its efficiency in\npractice. Our analysis is based on the drift analysis of a discrete stochastic\nprocess, which could also be interesting on its own.\n","authors":["Halyun Jeong","Deanna Needell","Elizaveta Rebrova"],"pdf_url":"https://arxiv.org/pdf/2403.01204v2.pdf","comment":"Submitted to a journal"},{"id":"http://arxiv.org/abs/2501.10324v1","updated":"2025-01-17T17:56:27Z","published":"2025-01-17T17:56:27Z","title":"New Fashion Products Performance Forecasting: A Survey on Evolutions,\n  Models and Emerging Trends","summary":"  The fast fashion industry's insatiable demand for new styles and rapid\nproduction cycles has led to a significant environmental burden.\nOverproduction, excessive waste, and harmful chemicals have contributed to the\nnegative environmental impact of the industry. To mitigate these issues, a\nparadigm shift that prioritizes sustainability and efficiency is urgently\nneeded. Integrating learning-based predictive analytics into the fashion\nindustry represents a significant opportunity to address environmental\nchallenges and drive sustainable practices. By forecasting fashion trends and\noptimizing production, brands can reduce their ecological footprint while\nremaining competitive in a rapidly changing market. However, one of the key\nchallenges in forecasting fashion sales is the dynamic nature of consumer\npreferences. Fashion is acyclical, with trends constantly evolving and\nresurfacing. In addition, cultural changes and unexpected events can disrupt\nestablished patterns. This problem is also known as New Fashion Products\nPerformance Forecasting (NFPPF), and it has recently gained more and more\ninterest in the global research landscape. Given its multidisciplinary nature,\nthe field of NFPPF has been approached from many different angles. This\ncomprehensive survey wishes to provide an up-to-date overview that focuses on\nlearning-based NFPPF strategies. The survey is based on the Preferred Reporting\nItems for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow,\nallowing for a systematic and complete literature review. In particular, we\npropose the first taxonomy that covers the learning panorama for NFPPF,\nexamining in detail the different methodologies used to increase the amount of\nmultimodal information, as well as the state-of-the-art available datasets.\nFinally, we discuss the challenges and future directions.\n","authors":["Andrea Avogaro","Luigi Capogrosso","Andrea Toaiari","Franco Fummi","Marco Cristani"],"pdf_url":"https://arxiv.org/pdf/2501.10324v1.pdf","comment":"Accepted at the Springer Nature Computer Science journal"},{"id":"http://arxiv.org/abs/2501.10322v1","updated":"2025-01-17T17:51:53Z","published":"2025-01-17T17:51:53Z","title":"Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level\n  Processing for Robust, Adaptable Language Models","summary":"  Tokenization is a fundamental step in natural language processing, breaking\ntext into units that computational models can process. While learned subword\ntokenizers have become the de-facto standard, they present challenges such as\nlarge vocabularies, limited adaptability to new domains or languages, and\nsensitivity to spelling errors and variations. To overcome these limitations,\nwe investigate a hierarchical architecture for autoregressive language\nmodelling that combines character-level and word-level processing. It employs a\nlightweight character-level encoder to convert character sequences into word\nembeddings, which are then processed by a word-level backbone model and decoded\nback into characters via a compact character-level decoder. This method retains\nthe sequence compression benefits of word-level tokenization without relying on\na rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion\nparameters, that hierarchical transformers match the downstream task\nperformance of subword-tokenizer-based models while exhibiting significantly\ngreater robustness to input perturbations. Additionally, during continued\npretraining on an out-of-domain language, our model trains almost twice as\nfast, achieves superior performance on the target language, and retains more of\nits previously learned knowledge. Hierarchical transformers pave the way for\nNLP systems that are more robust, flexible, and generalizable across languages\nand domains.\n","authors":["Pit Neitemeier","Björn Deiseroth","Constantin Eichenberg","Lukas Balles"],"pdf_url":"https://arxiv.org/pdf/2501.10322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10321v1","updated":"2025-01-17T17:51:22Z","published":"2025-01-17T17:51:22Z","title":"Towards Human-Guided, Data-Centric LLM Co-Pilots","summary":"  Machine learning (ML) has the potential to revolutionize healthcare, but its\nadoption is often hindered by the disconnect between the needs of domain\nexperts and translating these needs into robust and valid ML tools. Despite\nrecent advances in LLM-based co-pilots to democratize ML for non-technical\ndomain experts, these systems remain predominantly focused on model-centric\naspects while overlooking critical data-centric challenges. This limitation is\nproblematic in complex real-world settings where raw data often contains\ncomplex issues, such as missing values, label noise, and domain-specific\nnuances requiring tailored handling. To address this we introduce CliMB-DC, a\nhuman-guided, data-centric framework for LLM co-pilots that combines advanced\ndata-centric tools with LLM-driven reasoning to enable robust, context-aware\ndata processing. At its core, CliMB-DC introduces a novel, multi-agent\nreasoning system that combines a strategic coordinator for dynamic planning and\nadaptation with a specialized worker agent for precise execution. Domain\nexpertise is then systematically incorporated to guide the reasoning process\nusing a human-in-the-loop approach. To guide development, we formalize a\ntaxonomy of key data-centric challenges that co-pilots must address.\nThereafter, to address the dimensions of the taxonomy, we integrate\nstate-of-the-art data-centric tools into an extensible, open-source\narchitecture, facilitating the addition of new tools from the research\ncommunity. Empirically, using real-world healthcare datasets we demonstrate\nCliMB-DC's ability to transform uncurated datasets into ML-ready formats,\nsignificantly outperforming existing co-pilot baselines for handling\ndata-centric challenges. CliMB-DC promises to empower domain experts from\ndiverse domains -- healthcare, finance, social sciences and more -- to actively\nparticipate in driving real-world impact using ML.\n","authors":["Evgeny Saveliev","Jiashuo Liu","Nabeel Seedat","Anders Boyd","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2501.10321v1.pdf","comment":"Saveliev, Liu & Seedat contributed equally"},{"id":"http://arxiv.org/abs/2209.07600v4","updated":"2025-01-17T16:52:03Z","published":"2022-09-15T20:27:54Z","title":"STPOTR: Simultaneous Human Trajectory and Pose Prediction Using a\n  Non-Autoregressive Transformer for Robot Following Ahead","summary":"  In this paper, we develop a neural network model to predict future human\nmotion from an observed human motion history. We propose a non-autoregressive\ntransformer architecture to leverage its parallel nature for easier training\nand fast, accurate predictions at test time. The proposed architecture divides\nhuman motion prediction into two parts: 1) the human trajectory, which is the\nhip joint 3D position over time and 2) the human pose which is the all other\njoints 3D positions over time with respect to a fixed hip joint. We propose to\nmake the two predictions simultaneously, as the shared representation can\nimprove the model performance. Therefore, the model consists of two sets of\nencoders and decoders. First, a multi-head attention module applied to encoder\noutputs improves human trajectory. Second, another multi-head self-attention\nmodule applied to encoder outputs concatenated with decoder outputs facilitates\nlearning of temporal dependencies. Our model is well-suited for robotic\napplications in terms of test accuracy and speed, and compares favorably with\nrespect to state-of-the-art methods. We demonstrate the real-world\napplicability of our work via the Robot Follow-Ahead task, a challenging yet\npractical case study for our proposed model.\n","authors":["Mohammad Mahdavian","Payam Nikdel","Mahdi TaherAhmadi","Mo Chen"],"pdf_url":"https://arxiv.org/pdf/2209.07600v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15839v2","updated":"2025-01-17T16:49:25Z","published":"2024-06-22T12:59:12Z","title":"The Effect of Similarity Measures on Accurate Stability Estimates for\n  Local Surrogate Models in Text-based Explainable AI","summary":"  Recent work has investigated the vulnerability of local surrogate methods to\nadversarial perturbations on a machine learning (ML) model's inputs, where the\nexplanation is manipulated while the meaning and structure of the original\ninput remains similar under the complex model. Although weaknesses across many\nmethods have been shown to exist, the reasons behind why remain little\nexplored. Central to the concept of adversarial attacks on explainable AI (XAI)\nis the similarity measure used to calculate how one explanation differs from\nanother. A poor choice of similarity measure can lead to erroneous conclusions\non the efficacy of an XAI method. Too sensitive a measure results in\nexaggerated vulnerability, while too coarse understates its weakness. We\ninvestigate a variety of similarity measures designed for text-based ranked\nlists, including Kendall's Tau, Spearman's Footrule, and Rank-biased Overlap to\ndetermine how substantial changes in the type of measure or threshold of\nsuccess affect the conclusions generated from common adversarial attack\nprocesses. Certain measures are found to be overly sensitive, resulting in\nerroneous estimates of stability.\n","authors":["Christopher Burger","Charles Walter","Thai Le"],"pdf_url":"https://arxiv.org/pdf/2406.15839v2.pdf","comment":"11 pages, 8 Tables (Minor edits for clarity and grammar)"},{"id":"http://arxiv.org/abs/2412.18263v4","updated":"2025-01-17T16:40:21Z","published":"2024-12-24T08:25:38Z","title":"High-Rank Irreducible Cartesian Tensor Decomposition and Bases of\n  Equivariant Spaces","summary":"  Irreducible Cartesian tensors (ICTs) play a crucial role in the design of\nequivariant graph neural networks, as well as in theoretical chemistry and\nchemical physics. Meanwhile, the design space of available linear operations on\ntensors that preserve symmetry presents a significant challenge. The ICT\ndecomposition and a basis of this equivariant space are difficult to obtain for\nhigh-rank tensors. After decades of research, Bonvicini (2024) recently\nachieves an explicit ICT decomposition for $n=5$ with factorial time/space\ncomplexity. In this work we, for the first time, obtains decomposition matrices\nfor ICTs up to rank $n=9$ with reduced and affordable complexity, by\nconstructing what we call path matrices. The path matrices are obtained via\nperforming chain-like contractions with Clebsch-Gordan matrices following the\nparentage scheme. We prove and leverage that the concatenation of path matrices\nis an orthonormal change-of-basis matrix between the Cartesian tensor product\nspace and the spherical direct sum spaces. Furthermore, we identify a complete\northogonal basis for the equivariant space, rather than a spanning set\n(Pearce-Crump, 2023), through this path matrices technique. To the best of our\nknowledge, this is also the first analytic, rather than numerical, method for\ntheoretically obtaining arbitrary rank orthogonal ICT decomposition matrices\nand orthogonal equivariant bases. We further extend our result to the arbitrary\ntensor product and direct sum spaces, enabling free design between different\nspaces while keeping symmetry. The Python code is available at\nhttps://github.com/ShihaoShao-GH/ICT-decomposition-and-equivariant-bases, where\nthe $n=6,\\dots,9$ ICT decomposition matrices are obtained in 1s, 3s, 11s, and\n4m32s on 28-cores Intel(R) Xeon(R) Gold 6330 CPU @ 2.00GHz, respectively.\n","authors":["Shihao Shao","Yikang Li","Zhouchen Lin","Qinghua Cui"],"pdf_url":"https://arxiv.org/pdf/2412.18263v4.pdf","comment":"47 pages"},{"id":"http://arxiv.org/abs/2409.00753v2","updated":"2025-01-17T16:37:23Z","published":"2024-09-01T15:46:55Z","title":"Generalized Multi-hop Traffic Pressure for Heterogeneous Traffic\n  Perimeter Control","summary":"  Perimeter control (PC) prevents loss of traffic network capacity due to\ncongestion in urban areas. Homogeneous PC allows all access points to a\nprotected region to have identical permitted inflow. However, homogeneous PC\nperforms poorly when the congestion in the protected region is heterogeneous\n(e.g., imbalanced demand) since the homogeneous PC does not consider specific\ntraffic conditions around each perimeter intersection. When the protected\nregion has spatially heterogeneous congestion, one needs to modulate the\nperimeter inflow rate to be higher near low-density regions and vice versa for\nhigh-density regions. A na\\\"ive approach is to leverage 1-hop traffic pressure\nto measure traffic condition around perimeter intersections, but such metric is\ntoo spatially myopic for PC. To address this issue, we formulate multi-hop\ndownstream pressure grounded on Markov chain theory, which ``looks deeper''\ninto the protected region beyond perimeter intersections. In addition, we\nformulate a two-stage hierarchical control scheme that can leverage this novel\nmulti-hop pressure to redistribute the total permitted inflow provided by a\npre-trained deep reinforcement learning homogeneous control policy.\nExperimental results show that our heterogeneous PC approaches leveraging\nmulti-hop pressure significantly outperform homogeneous PC in scenarios where\nthe origin-destination flows are highly imbalanced with high spatial\nheterogeneity. Moveover, our approach is shown to be robust against turning\nratio uncertainties by a sensitivity analysis.\n","authors":["Xiaocan Li","Xiaoyu Wang","Ilia Smirnov","Scott Sanner","Baher Abdulhai"],"pdf_url":"https://arxiv.org/pdf/2409.00753v2.pdf","comment":"11 pages main body, 13 figures, journal paper"},{"id":"http://arxiv.org/abs/2401.07836v3","updated":"2025-01-17T16:35:27Z","published":"2024-01-15T17:06:02Z","title":"Two Types of AI Existential Risk: Decisive and Accumulative","summary":"  The conventional discourse on existential risks (x-risks) from AI typically\nfocuses on abrupt, dire events caused by advanced AI systems, particularly\nthose that might achieve or surpass human-level intelligence. These events have\nsevere consequences that either lead to human extinction or irreversibly\ncripple human civilization to a point beyond recovery. This discourse, however,\noften neglects the serious possibility of AI x-risks manifesting incrementally\nthrough a series of smaller yet interconnected disruptions, gradually crossing\ncritical thresholds over time. This paper contrasts the conventional \"decisive\nAI x-risk hypothesis\" with an \"accumulative AI x-risk hypothesis.\" While the\nformer envisions an overt AI takeover pathway, characterized by scenarios like\nuncontrollable superintelligence, the latter suggests a different causal\npathway to existential catastrophes. This involves a gradual accumulation of\ncritical AI-induced threats such as severe vulnerabilities and systemic erosion\nof economic and political structures. The accumulative hypothesis suggests a\nboiling frog scenario where incremental AI risks slowly converge, undermining\nsocietal resilience until a triggering event results in irreversible collapse.\nThrough systems analysis, this paper examines the distinct assumptions\ndifferentiating these two hypotheses. It is then argued that the accumulative\nview can reconcile seemingly incompatible perspectives on AI risks. The\nimplications of differentiating between these causal pathways -- the decisive\nand the accumulative -- for the governance of AI as well as long-term AI safety\nare discussed.\n","authors":["Atoosa Kasirzadeh"],"pdf_url":"https://arxiv.org/pdf/2401.07836v3.pdf","comment":"Journal article for Philosophical Studies"},{"id":"http://arxiv.org/abs/2501.10290v1","updated":"2025-01-17T16:34:45Z","published":"2025-01-17T16:34:45Z","title":"Pairwise Elimination with Instance-Dependent Guarantees for Bandits with\n  Cost Subsidy","summary":"  Multi-armed bandits (MAB) are commonly used in sequential online\ndecision-making when the reward of each decision is an unknown random variable.\nIn practice however, the typical goal of maximizing total reward may be less\nimportant than minimizing the total cost of the decisions taken, subject to a\nreward constraint. For example, we may seek to make decisions that have at\nleast the reward of a reference ``default'' decision, with as low a cost as\npossible. This problem was recently introduced in the Multi-Armed Bandits with\nCost Subsidy (MAB-CS) framework. MAB-CS is broadly applicable to problem\ndomains where a primary metric (cost) is constrained by a secondary metric\n(reward), and the rewards are unknown. In our work, we address variants of\nMAB-CS including ones with reward constrained by the reward of a known\nreference arm or by the subsidized best reward. We introduce the\nPairwise-Elimination (PE) algorithm for the known reference arm variant and\ngeneralize PE to PE-CS for the subsidized best reward variant. Our\ninstance-dependent analysis of PE and PE-CS reveals that both algorithms have\nan order-wise logarithmic upper bound on Cost and Quality Regret, making our\npolicies the first with such a guarantee. Moreover, by comparing our upper and\nlower bound results we establish that PE is order-optimal for all known\nreference arm problem instances. Finally, experiments are conducted using the\nMovieLens 25M and Goodreads datasets for both PE and PE-CS revealing the\neffectiveness of PE and the superior balance between performance and\nreliability offered by PE-CS compared to baselines from the literature.\n","authors":["Ishank Juneja","Carlee Joe-Wong","Osman Yağan"],"pdf_url":"https://arxiv.org/pdf/2501.10290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09635v3","updated":"2025-01-17T16:11:42Z","published":"2024-11-14T18:01:02Z","title":"Counterfactual Uncertainty Quantification of Factual Estimand of\n  Efficacy from Before-and-After Treatment Repeated Measures Randomized\n  Controlled Trials","summary":"  The ideal estimand for comparing treatment $Rx$ with a control $C$ is the\n$\\textit{counterfactual}$ efficacy $Rx:C$, the expected differential outcome\nbetween $Rx$ and $C$ if each patient were given $\\textit{both}$. One hundred\nyears ago, Neyman (1923a) proved unbiased $\\textit{point estimation}$ of\ncounterfactual efficacy from designed $\\textit{factual}$ experiments is\nachievable. But he left the determination of how much might the counterfactual\nvariance of this estimate be smaller than the factual variance as an open\nchallenge. This article shows $\\textit{counterfactual}$ uncertainty\nquantification (CUQ), quantifying uncertainty for factual point estimates but\nin a counterfactual setting, is achievable for Randomized Controlled Trials\n(RCTs) with Before-and-After treatment Repeated Measures which are common in\nmany therapeutic areas. We achieve CUQ whose variability is typically smaller\nthan factual UQ by creating a new statistical modeling principle called ETZ.\n  We urge caution in using predictors with measurement error which violates\nstandard regression assumption and can cause $\\textit{attenuation}$ in\nestimating treatment effects. Fortunately, we prove that, for traditional\nmedicine in general, and for targeted therapy with efficacy defined as averaged\nover the population, counterfactual point estimation is unbiased. However, for\nboth Real Human and Digital Twins approaches, predicting treatment effect in\n$\\textit{subgroups}$ may have attenuation bias.\n","authors":["Xingya Wang","Yang Han","Yushi Liu","Szu-Yu Tang","Jason C. Hsu"],"pdf_url":"https://arxiv.org/pdf/2411.09635v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12215v2","updated":"2025-01-17T16:04:05Z","published":"2023-06-21T12:15:57Z","title":"Automated Machine Learning for Remaining Useful Life Predictions","summary":"  Being able to predict the remaining useful life (RUL) of an engineering\nsystem is an important task in prognostics and health management. Recently,\ndata-driven approaches to RUL predictions are becoming prevalent over\nmodel-based approaches since no underlying physical knowledge of the\nengineering system is required. Yet, this just replaces required expertise of\nthe underlying physics with machine learning (ML) expertise, which is often\nalso not available. Automated machine learning (AutoML) promises to build\nend-to-end ML pipelines automatically enabling domain experts without ML\nexpertise to create their own models. This paper introduces AutoRUL, an\nAutoML-driven end-to-end approach for automatic RUL predictions. AutoRUL\ncombines fine-tuned standard regression methods to an ensemble with high\npredictive power. By evaluating the proposed method on eight real-world and\nsynthetic datasets against state-of-the-art hand-crafted models, we show that\nAutoML provides a viable alternative to hand-crafted data-driven RUL\npredictions. Consequently, creating RUL predictions can be made more accessible\nfor domain experts using AutoML by eliminating ML expertise from data-driven\nmodel construction.\n","authors":["Marc-André Zöller","Fabian Mauthe","Peter Zeiler","Marius Lindauer","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2306.12215v2.pdf","comment":"Manuscript accepted at IEEE SMC 2023"},{"id":"http://arxiv.org/abs/2501.10273v1","updated":"2025-01-17T16:01:05Z","published":"2025-01-17T16:01:05Z","title":"SEANN: A Domain-Informed Neural Network for Epidemiological Insights","summary":"  In epidemiology, traditional statistical methods such as logistic regression,\nlinear regression, and other parametric models are commonly employed to\ninvestigate associations between predictors and health outcomes. However,\nnon-parametric machine learning techniques, such as deep neural networks\n(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for\nthis task. Despite their potential, these methods face challenges due to the\nlimited availability of high-quality, high-quantity data in this field. To\naddress these challenges, we introduce SEANN, a novel approach for informed\nDNNs that leverages a prevalent form of domain-specific knowledge: Pooled\nEffect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,\nin different forms, and represent a quantitative form of a scientific\nconsensus. By direct integration within the learning procedure using a custom\nloss, we experimentally demonstrate significant improvements in the\ngeneralizability of predictive performances and the scientific plausibility of\nextracted relationships compared to a domain-knowledge agnostic neural network\nin a scarce and noisy data setting.\n","authors":["Jean-Baptiste Guimbaud","Marc Plantevit","Léa Maître","Rémy Cazabet"],"pdf_url":"https://arxiv.org/pdf/2501.10273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14904v2","updated":"2025-01-17T15:59:34Z","published":"2024-06-21T06:51:13Z","title":"Enhancing reliability in prediction intervals using point forecasters:\n  Heteroscedastic Quantile Regression and Width-Adaptive Conformal Inference","summary":"  Constructing prediction intervals for time series forecasting is challenging,\nparticularly when practitioners rely solely on point forecasts. While previous\nresearch has focused on creating increasingly efficient intervals, we argue\nthat standard measures alone are inadequate. Beyond efficiency, prediction\nintervals must adapt their width based on the difficulty of the prediction\nwhile preserving coverage regardless of complexity. To address these issues, we\npropose combining Heteroscedastic Quantile Regression (HQR) with Width-Adaptive\nConformal Inference (WACI). This integrated procedure guarantees theoretical\ncoverage and enables interval widths to vary with predictive uncertainty. We\nassess its performance using both a synthetic example and a real world\nElectricity Price Forecasting scenario. Our results show that this combined\napproach meets or surpasses typical benchmarks for validity and efficiency,\nwhile also fulfilling important yet often overlooked practical requirements.\n","authors":["Carlos Sebastián","Carlos E. González-Guillén","Jesús Juan"],"pdf_url":"https://arxiv.org/pdf/2406.14904v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.08101v2","updated":"2025-01-17T15:57:52Z","published":"2024-05-13T18:28:39Z","title":"Can machine learning unlock new insights into high-frequency trading?","summary":"  We design and train machine learning models to capture the nonlinear\ninteractions between financial market dynamics and high-frequency trading (HFT)\nactivity. In doing so, we introduce new metrics to identify liquidity-demanding\nand -supplying HFT strategies. Both types of HFT strategies increase activity\nin response to information events and decrease it when trading speed is\nrestricted, with liquidity-supplying strategies demonstrating greater\nresponsiveness. Liquidity-demanding HFT is positively linked with latency\narbitrage opportunities, whereas liquidity-supplying HFT is negatively related,\naligning with theoretical expectations. Our metrics have implications for\nunderstanding the information production process in financial markets.\n","authors":["G. Ibikunle","B. Moews","D. Muravyev","K. Rzayev"],"pdf_url":"https://arxiv.org/pdf/2405.08101v2.pdf","comment":"66 pages, 6 figures, 11 tables"},{"id":"http://arxiv.org/abs/2501.10261v1","updated":"2025-01-17T15:42:42Z","published":"2025-01-17T15:42:42Z","title":"Logarithmic Regret for Nonlinear Control","summary":"  We address the problem of learning to control an unknown nonlinear dynamical\nsystem through sequential interactions. Motivated by high-stakes applications\nin which mistakes can be catastrophic, such as robotics and healthcare, we\nstudy situations where it is possible for fast sequential learning to occur.\nFast sequential learning is characterized by the ability of the learning agent\nto incur logarithmic regret relative to a fully-informed baseline. We\ndemonstrate that fast sequential learning is achievable in a diverse class of\ncontinuous control problems where the system dynamics depend smoothly on\nunknown parameters, provided the optimal control policy is persistently\nexciting. Additionally, we derive a regret bound which grows with the square\nroot of the number of interactions for cases where the optimal policy is not\npersistently exciting. Our results provide the first regret bounds for\ncontrolling nonlinear dynamical systems depending nonlinearly on unknown\nparameters. We validate the trends our theory predicts in simulation on a\nsimple dynamical system.\n","authors":["James Wang","Bruce D. Lee","Ingvar Ziemann","Nikolai Matni"],"pdf_url":"https://arxiv.org/pdf/2501.10261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10258v1","updated":"2025-01-17T15:40:03Z","published":"2025-01-17T15:40:03Z","title":"DADA: Dual Averaging with Distance Adaptation","summary":"  We present a novel universal gradient method for solving convex optimization\nproblems. Our algorithm -- Dual Averaging with Distance Adaptation (DADA) -- is\nbased on the classical scheme of dual averaging and dynamically adjusts its\ncoefficients based on observed gradients and the distance between iterates and\nthe starting point, eliminating the need for problem-specific parameters. DADA\nis a universal algorithm that simultaneously works for a broad spectrum of\nproblem classes, provided the local growth of the objective function around its\nminimizer can be bounded. Particular examples of such problem classes are\nnonsmooth Lipschitz functions, Lipschitz-smooth functions, H\\\"older-smooth\nfunctions, functions with high-order Lipschitz derivative,\nquasi-self-concordant functions, and $(L_0,L_1)$-smooth functions. Crucially,\nDADA is applicable to both unconstrained and constrained problems, even when\nthe domain is unbounded, without requiring prior knowledge of the number of\niterations or desired accuracy.\n","authors":["Mohammad Moshtaghifar","Anton Rodomanov","Daniil Vankov","Sebastian Stich"],"pdf_url":"https://arxiv.org/pdf/2501.10258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10256v1","updated":"2025-01-17T15:39:21Z","published":"2025-01-17T15:39:21Z","title":"Unsupervised Rhythm and Voice Conversion of Dysarthric to Healthy Speech\n  for ASR","summary":"  Automatic speech recognition (ASR) systems are well known to perform poorly\non dysarthric speech. Previous works have addressed this by speaking rate\nmodification to reduce the mismatch with typical speech. Unfortunately, these\napproaches rely on transcribed speech data to estimate speaking rates and\nphoneme durations, which might not be available for unseen speakers. Therefore,\nwe combine unsupervised rhythm and voice conversion methods based on\nself-supervised speech representations to map dysarthric to typical speech. We\nevaluate the outputs with a large ASR model pre-trained on healthy speech\nwithout further fine-tuning and find that the proposed rhythm conversion\nespecially improves performance for speakers of the Torgo corpus with more\nsevere cases of dysarthria. Code and audio samples are available at\nhttps://idiap.github.io/RnV .\n","authors":["Karl El Hajal","Enno Hermann","Ajinkya Kulkarni","Mathew Magimai. -Doss"],"pdf_url":"https://arxiv.org/pdf/2501.10256v1.pdf","comment":"Accepted at ICASSP 2025 Satellite Workshop: Workshop on Speech\n  Pathology Analysis and DEtection (SPADE)"},{"id":"http://arxiv.org/abs/2501.09274v2","updated":"2025-01-17T15:22:00Z","published":"2025-01-16T03:44:16Z","title":"Large Language Model is Secretly a Protein Sequence Optimizer","summary":"  We consider the protein sequence engineering problem, which aims to find\nprotein sequences with high fitness levels, starting from a given wild-type\nsequence. Directed evolution has been a dominating paradigm in this field which\nhas an iterative process to generate variants and select via experimental\nfeedback. We demonstrate large language models (LLMs), despite being trained on\nmassive texts, are secretly protein sequence optimizers. With a directed\nevolutionary method, LLM can perform protein engineering through Pareto and\nexperiment-budget constrained optimization, demonstrating success on both\nsynthetic and experimental fitness landscapes.\n","authors":["Yinkai Wang","Jiaxing He","Yuanqi Du","Xiaohui Chen","Jianan Canal Li","Li-Ping Liu","Xiaolin Xu","Soha Hassoun"],"pdf_url":"https://arxiv.org/pdf/2501.09274v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2403.03728v2","updated":"2025-01-17T15:15:15Z","published":"2024-03-06T14:18:24Z","title":"Bridging Diversity and Uncertainty in Active learning with\n  Self-Supervised Pre-Training","summary":"  This study addresses the integration of diversity-based and uncertainty-based\nsampling strategies in active learning, particularly within the context of\nself-supervised pre-trained models. We introduce a straightforward heuristic\ncalled TCM that mitigates the cold start problem while maintaining strong\nperformance across various data levels. By initially applying TypiClust for\ndiversity sampling and subsequently transitioning to uncertainty sampling with\nMargin, our approach effectively combines the strengths of both strategies. Our\nexperiments demonstrate that TCM consistently outperforms existing methods\nacross various datasets in both low and high data regimes.\n","authors":["Paul Doucet","Benjamin Estermann","Till Aczel","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2403.03728v2.pdf","comment":"Accepted at ICLR 2024 Workshop on Practical Machine Learning for Low\n  Resource Settings (PML4LRS)"},{"id":"http://arxiv.org/abs/2501.10245v1","updated":"2025-01-17T15:14:58Z","published":"2025-01-17T15:14:58Z","title":"Over-the-Air Multi-Sensor Inference with Neural Networks Using\n  Memristor-Based Analog Computing","summary":"  Deep neural networks provide reliable solutions for many classification and\nregression tasks; however, their application in real-time wireless systems with\nsimple sensor networks is limited due to high energy consumption and\nsignificant bandwidth needs. This study proposes a multi-sensor wireless\ninference system with memristor-based analog computing. Given the sensors'\nlimited computational capabilities, the features from the network's front end\nare transmitted to a central device where an $L_p$-norm inspired approximation\nof the maximum operation is employed to achieve transformation-invariant\nfeatures, enabling efficient over-the-air transmission. We also introduce a\ntrainable over-the-air sensor fusion method based on $L_p$-norm inspired\ncombining function that customizes sensor fusion to match the network and\nsensor distribution characteristics, enhancing adaptability. To address the\nenergy constraints of sensors, we utilize memristors, known for their\nenergy-efficient in-memory computing, enabling analog-domain computations that\nreduce energy use and computational overhead in edge computing. This dual\napproach of memristors and $L_p$-norm inspired sensor fusion fosters\nenergy-efficient computational and transmission paradigms and serves as a\npractical energy-efficient solution with minimal performance loss.\n","authors":["Busra Tegin","Muhammad Atif Ali","Tolga M Duman"],"pdf_url":"https://arxiv.org/pdf/2501.10245v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2501.10240v1","updated":"2025-01-17T15:09:57Z","published":"2025-01-17T15:09:57Z","title":"Challenges and recommendations for Electronic Health Records data\n  extraction and preparation for dynamic prediction modelling in hospitalized\n  patients -- a practical guide","summary":"  Dynamic predictive modeling using electronic health record (EHR) data has\ngained significant attention in recent years. The reliability and\ntrustworthiness of such models depend heavily on the quality of the underlying\ndata, which is largely determined by the stages preceding the model\ndevelopment: data extraction from EHR systems and data preparation. We list\nover forty challenges encountered during these stages and provide actionable\nrecommendations for addressing them. These challenges are organized into four\ncategories: cohort definition, outcome definition, feature engineering, and\ndata cleaning. This list is designed to serve as a practical guide for data\nextraction engineers and researchers, supporting better practices and improving\nthe quality and real-world applicability of dynamic prediction models in\nclinical settings.\n","authors":["Elena Albu","Shan Gao","Pieter Stijnen","Frank E. Rademakers","Bas C T van Bussel","Taya Collyer","Tina Hernandez-Boussard","Laure Wynants","Ben Van Calster"],"pdf_url":"https://arxiv.org/pdf/2501.10240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10235v1","updated":"2025-01-17T15:00:20Z","published":"2025-01-17T15:00:20Z","title":"SpaceTime: Causal Discovery from Non-Stationary Time Series","summary":"  Understanding causality is challenging and often complicated by changing\ncausal relationships over time and across environments. Climate patterns, for\nexample, shift over time with recurring seasonal trends, while also depending\non geographical characteristics such as ecosystem variability. Existing methods\nfor discovering causal graphs from time series either assume stationarity, do\nnot permit both temporal and spatial distribution changes, or are unaware of\nlocations with the same causal relationships. In this work, we therefore unify\nthe three tasks of causal graph discovery in the non-stationary multi-context\nsetting, of reconstructing temporal regimes, and of partitioning datasets and\ntime intervals into those where invariant causal relationships hold. To\nconstruct a consistent score that forms the basis of our method, we employ the\nMinimum Description Length principle. Our resulting algorithm SPACETIME\nsimultaneously accounts for heterogeneity across space and non-stationarity\nover time. Given multiple time series, it discovers regime changepoints and a\ntemporal causal graph using non-parametric functional modeling and kernelized\ndiscrepancy testing. We also show that our method provides insights into\nreal-world phenomena such as river-runoff measured at different catchments and\nbiosphere-atmosphere interactions across ecosystems.\n","authors":["Sarah Mameche","Lénaïg Cornanguer","Urmi Ninad","Jilles Vreeken"],"pdf_url":"https://arxiv.org/pdf/2501.10235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10234v1","updated":"2025-01-17T14:56:20Z","published":"2025-01-17T14:56:20Z","title":"Counterfactual Explanations for k-means and Gaussian Clustering","summary":"  Counterfactuals have been recognized as an effective approach to explain\nclassifier decisions. Nevertheless, they have not yet been considered in the\ncontext of clustering. In this work, we propose the use of counterfactuals to\nexplain clustering solutions. First, we present a general definition for\ncounterfactuals for model-based clustering that includes plausibility and\nfeasibility constraints. Then we consider the counterfactual generation problem\nfor k-means and Gaussian clustering assuming Euclidean distance. Our approach\ntakes as input the factual, the target cluster, a binary mask indicating\nactionable or immutable features and a plausibility factor specifying how far\nfrom the cluster boundary the counterfactual should be placed. In the k-means\nclustering case, analytical mathematical formulas are presented for computing\nthe optimal solution, while in the Gaussian clustering case (assuming full,\ndiagonal, or spherical covariances) our method requires the numerical solution\nof a nonlinear equation with a single parameter only. We demonstrate the\nadvantages of our approach through illustrative examples and quantitative\nexperimental comparisons.\n","authors":["Georgios Vardakas","Antonia Karra","Evaggelia Pitoura","Aristidis Likas"],"pdf_url":"https://arxiv.org/pdf/2501.10234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10229v1","updated":"2025-01-17T14:51:03Z","published":"2025-01-17T14:51:03Z","title":"Amortized Bayesian Mixture Models","summary":"  Finite mixtures are a broad class of models useful in scenarios where\nobserved data is generated by multiple distinct processes but without explicit\ninformation about the responsible process for each data point. Estimating\nBayesian mixture models is computationally challenging due to issues such as\nhigh-dimensional posterior inference and label switching. Furthermore,\ntraditional methods such as MCMC are applicable only if the likelihoods for\neach mixture component are analytically tractable.\n  Amortized Bayesian Inference (ABI) is a simulation-based framework for\nestimating Bayesian models using generative neural networks. This allows the\nfitting of models without explicit likelihoods, and provides fast inference.\nABI is therefore an attractive framework for estimating mixture models. This\npaper introduces a novel extension of ABI tailored to mixture models. We\nfactorize the posterior into a distribution of the parameters and a\ndistribution of (categorical) mixture indicators, which allows us to use a\ncombination of generative neural networks for parameter inference, and\nclassification networks for mixture membership identification. The proposed\nframework accommodates both independent and dependent mixture models, enabling\nfiltering and smoothing. We validate and demonstrate our approach through\nsynthetic and real-world datasets.\n","authors":["Šimon Kucharský","Paul Christian Bürkner"],"pdf_url":"https://arxiv.org/pdf/2501.10229v1.pdf","comment":"34 pages, 17 figures"},{"id":"http://arxiv.org/abs/2501.10221v1","updated":"2025-01-17T14:37:54Z","published":"2025-01-17T14:37:54Z","title":"Modelling Activity Scheduling Behaviour with Deep Generative Machine\n  Learning","summary":"  We model human activity scheduling behaviour using a deep generative machine\nlearning approach. Activity schedules, which represent the activities and\nassociated travel behaviours of individuals, are a core component of many\napplied models in the transport, energy and epidemiology domains. Our data\ndriven approach learns human preferences and scheduling logic without the need\nfor complex interacting combinations of sub-models and custom-rules, this makes\nour approach significantly faster and simpler to operate that existing\napproaches. We find activity schedule data combines aspects of both continuous\nimage data and also discrete text data, requiring novel approaches. We\nadditionally contribute a novel schedule representation and comprehensive\nevaluation framework for generated schedules. Evaluation shows our approach is\nable to rapidly generate large, diverse and realistic synthetic samples of\nactivity schedules.\n","authors":["Fred Shone","Tim Hillel"],"pdf_url":"https://arxiv.org/pdf/2501.10221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13780v2","updated":"2025-01-17T14:26:37Z","published":"2024-10-17T17:19:48Z","title":"Optimal Quantization for Matrix Multiplication","summary":"  Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|\\bar{A}\\|_F, \\|\\bar{B}\\|_F$ and\n$\\|\\bar{A}^\\top \\bar{B}\\|_F$, where $\\bar{A},\\bar{B}$ are versions of $A,B$\nwith zero-centered columns, respectively. For iid Gaussian matrices our\nquantizer achieves the lower bound and is, thus, asymptotically optimal. A\npractical low-complexity version of our quantizer achieves performance quite\nclose to optimal. In addition, we derive rate-distortion function for matrix\nmultiplication of iid Gaussian matrices, which exhibits an interesting\nphase-transition at $R\\approx 0.906$ bit/entry.\n","authors":["Or Ordentlich","Yury Polyanskiy"],"pdf_url":"https://arxiv.org/pdf/2410.13780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10216v1","updated":"2025-01-17T14:23:54Z","published":"2025-01-17T14:23:54Z","title":"The Relevance of AWS Chronos: An Evaluation of Standard Methods for Time\n  Series Forecasting with Limited Tuning","summary":"  A systematic comparison of Chronos, a transformer-based time series\nforecasting framework, against traditional approaches including ARIMA and\nProphet. We evaluate these models across multiple time horizons and user\ncategories, with a focus on the impact of historical context length. Our\nanalysis reveals that while Chronos demonstrates superior performance for\nlonger-term predictions and maintains accuracy with increased context,\ntraditional models show significant degradation as context length increases. We\nfind that prediction quality varies systematically between user classes,\nsuggesting that underlying behavior patterns always influence model\nperformance. This study provides a case for deploying Chronos in real-world\napplications where limited model tuning is feasible, especially in scenarios\nrequiring longer prediction.\n","authors":["Matthew Baron","Alex Karpinski"],"pdf_url":"https://arxiv.org/pdf/2501.10216v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10214v1","updated":"2025-01-17T14:13:48Z","published":"2025-01-17T14:13:48Z","title":"Temporal Graph MLP Mixer for Spatio-Temporal Forecasting","summary":"  Spatiotemporal forecasting is critical in applications such as traffic\nprediction, climate modeling, and environmental monitoring. However, the\nprevalence of missing data in real-world sensor networks significantly\ncomplicates this task. In this paper, we introduce the Temporal Graph MLP-Mixer\n(T-GMM), a novel architecture designed to address these challenges. The model\ncombines node-level processing with patch-level subgraph encoding to capture\nlocalized spatial dependencies while leveraging a three-dimensional MLP-Mixer\nto handle temporal, spatial, and feature-based dependencies. Experiments on the\nAQI, ENGRAD, PV-US and METR-LA datasets demonstrate the model's ability to\neffectively forecast even in the presence of significant missing data. While\nnot surpassing state-of-the-art models in all scenarios, the T-GMM exhibits\nstrong learning capabilities, particularly in capturing long-range\ndependencies. These results highlight its potential for robust, scalable\nspatiotemporal forecasting.\n","authors":["Muhammad Bilal","Luis Carretero Lopez"],"pdf_url":"https://arxiv.org/pdf/2501.10214v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01477v2","updated":"2025-01-17T14:10:15Z","published":"2024-11-03T08:30:29Z","title":"DPCL-Diff: The Temporal Knowledge Graph Reasoning Based on Graph Node\n  Diffusion Model with Dual-Domain Periodic Contrastive Learning","summary":"  Temporal knowledge graph (TKG) reasoning that infers future missing facts is\nan essential and challenging task. Predicting future events typically relies on\nclosely related historical facts, yielding more accurate results for repetitive\nor periodic events. However, for future events with sparse historical\ninteractions, the effectiveness of this method, which focuses on leveraging\nhigh-frequency historical information, diminishes. Recently, the capabilities\nof diffusion models in image generation have opened new opportunities for TKG\nreasoning. Therefore, we propose a graph node diffusion model with dual-domain\nperiodic contrastive learning (DPCL-Diff). Graph node diffusion model (GNDiff)\nintroduces noise into sparsely related events to simulate new events,\ngenerating high-quality data that better conforms to the actual distribution.\nThis generative mechanism significantly enhances the model's ability to reason\nabout new events. Additionally, the dual-domain periodic contrastive learning\n(DPCL) maps periodic and non-periodic event entities to Poincar\\'e and\nEuclidean spaces, leveraging their characteristics to distinguish similar\nperiodic events effectively. Experimental results on four public datasets\ndemonstrate that DPCL-Diff significantly outperforms state-of-the-art TKG\nmodels in event prediction, demonstrating our approach's effectiveness. This\nstudy also investigates the combined effectiveness of GNDiff and DPCL in TKG\ntasks.\n","authors":["Yukun Cao","Lisheng Wang","Luobin Huang"],"pdf_url":"https://arxiv.org/pdf/2411.01477v2.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2501.10209v1","updated":"2025-01-17T14:08:32Z","published":"2025-01-17T14:08:32Z","title":"Hypercone Assisted Contour Generation for Out-of-Distribution Detection","summary":"  Recent advances in the field of out-of-distribution (OOD) detection have\nplaced great emphasis on learning better representations suited to this task.\nWhile there are distance-based approaches, distributional awareness has seldom\nbeen exploited for better performance. We present HAC$_k$-OOD, a novel OOD\ndetection method that makes no distributional assumption about the data, but\nautomatically adapts to its distribution. Specifically, HAC$_k$-OOD constructs\na set of hypercones by maximizing the angular distance to neighbors in a given\ndata-point's vicinity to approximate the contour within which in-distribution\n(ID) data-points lie. Experimental results show state-of-the-art FPR@95 and\nAUROC performance on Near-OOD detection and on Far-OOD detection on the\nchallenging CIFAR-100 benchmark without explicitly training for OOD\nperformance.\n","authors":["Annita Vapsi","Andrés Muñoz","Nancy Thomas","Keshav Ramani","Daniel Borrajo"],"pdf_url":"https://arxiv.org/pdf/2501.10209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14393v4","updated":"2025-01-17T13:56:50Z","published":"2024-06-20T15:12:27Z","title":"Jailbreaking as a Reward Misspecification Problem","summary":"  The widespread adoption of large language models (LLMs) has raised concerns\nabout their safety and reliability, particularly regarding their vulnerability\nto adversarial attacks. In this paper, we propose a novel perspective that\nattributes this vulnerability to reward misspecification during the alignment\nprocess. This misspecification occurs when the reward function fails to\naccurately capture the intended behavior, leading to misaligned model outputs.\nWe introduce a metric ReGap to quantify the extent of reward misspecification\nand demonstrate its effectiveness and robustness in detecting harmful backdoor\nprompts. Building upon these insights, we present ReMiss, a system for\nautomated red teaming that generates adversarial prompts in a\nreward-misspecified space. ReMiss achieves state-of-the-art attack success\nrates on the AdvBench benchmark against various target aligned LLMs while\npreserving the human readability of the generated prompts. Furthermore, these\nattacks on open-source models demonstrate high transferability to closed-source\nmodels like GPT-4o and out-of-distribution tasks from HarmBench. Detailed\nanalysis highlights the unique advantages of the proposed reward\nmisspecification objective compared to previous methods, offering new insights\nfor improving LLM safety and robustness.\n","authors":["Zhihui Xie","Jiahui Gao","Lei Li","Zhenguo Li","Qi Liu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2406.14393v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10202v1","updated":"2025-01-17T13:51:14Z","published":"2025-01-17T13:51:14Z","title":"Provably Safeguarding a Classifier from OOD and Adversarial Samples: an\n  Extreme Value Theory Approach","summary":"  This paper introduces a novel method, Sample-efficient Probabilistic\nDetection using Extreme Value Theory (SPADE), which transforms a classifier\ninto an abstaining classifier, offering provable protection against\nout-of-distribution and adversarial samples. The approach is based on a\nGeneralized Extreme Value (GEV) model of the training distribution in the\nclassifier's latent space, enabling the formal characterization of OOD samples.\nInterestingly, under mild assumptions, the GEV model also allows for formally\ncharacterizing adversarial samples. The abstaining classifier, which rejects\nsamples based on their assessment by the GEV model, provably avoids OOD and\nadversarial samples. The empirical validation of the approach, conducted on\nvarious neural architectures (ResNet, VGG, and Vision Transformer) and medium\nand large-sized datasets (CIFAR-10, CIFAR-100, and ImageNet), demonstrates its\nfrugality, stability, and efficiency compared to the state of the art.\n","authors":["Nicolas Atienza","Christophe Labreuche","Johanne Cohen","Michele Sebag"],"pdf_url":"https://arxiv.org/pdf/2501.10202v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2407.11812v4","updated":"2025-01-17T13:42:32Z","published":"2024-07-16T15:02:18Z","title":"Boosting drug-disease association prediction for drug repositioning via\n  dual-feature extraction and cross-dual-domain decoding","summary":"  The extraction of biomedical data has significant academic and practical\nvalue in contemporary biomedical sciences. In recent years, drug repositioning,\na cost-effective strategy for drug development by discovering new indications\nfor approved drugs, has gained increasing attention. However, many existing\ndrug repositioning methods focus on mining information from adjacent nodes in\nbiomedical networks without considering the potential inter-relationships\nbetween the feature spaces of drugs and diseases. This can lead to inaccurate\nencoding, resulting in biased mined drug-disease association information. To\naddress this limitation, we propose a new model called Dual-Feature Drug\nRepurposing Neural Network (DFDRNN). DFDRNN allows the mining of two features\n(similarity and association) from the drug-disease biomedical networks to\nencode drugs and diseases. A self-attention mechanism is utilized to extract\nneighbor feature information. It incorporates two dual-feature extraction\nmodules: the single-domain dual-feature extraction (SDDFE) module for\nextracting features within a single domain (drugs or diseases) and the\ncross-domain dual-feature extraction (CDDFE) module for extracting features\nacross domains. By utilizing these modules, we ensure more appropriate encoding\nof drugs and diseases. A cross-dual-domain decoder is also designed to predict\ndrug-disease associations in both domains. Our proposed DFDRNN model\noutperforms six state-of-the-art methods on four benchmark datasets, achieving\nan average AUROC of 0.946 and an average AUPR of 0.597. Case studies on two\ndiseases show that the proposed DFDRNN model can be applied in real-world\nscenarios, demonstrating its significant potential in drug repositioning.\n","authors":["Enqiang Zhu","Xiang Li","Chanjuan Liu","Nikhil R. Pal"],"pdf_url":"https://arxiv.org/pdf/2407.11812v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10195v1","updated":"2025-01-17T13:39:51Z","published":"2025-01-17T13:39:51Z","title":"Contributions to the Decision Theoretic Foundations of Machine Learning\n  and Robust Statistics under Weakly Structured Information","summary":"  This habilitation thesis is cumulative and, therefore, is collecting and\nconnecting research that I (together with several co-authors) have conducted\nover the last few years. Thus, the absolute core of the work is formed by the\nten publications listed on page 5 under the name Contributions 1 to 10. The\nreferences to the complete versions of these articles are also found in this\nlist, making them as easily accessible as possible for readers wishing to dive\ndeep into the different research projects. The chapters following this thesis,\nnamely Parts A to C and the concluding remarks, serve to place the articles in\na larger scientific context, to (briefly) explain their respective content on a\nless formal level, and to highlight some interesting perspectives for future\nresearch in their respective contexts. Naturally, therefore, the following\npresentation has neither the level of detail nor the formal rigor that can\n(hopefully) be found in the papers. The purpose of the following text is to\nprovide the reader an easy and high-level access to this interesting and\nimportant research field as a whole, thereby, advertising it to a broader\naudience.\n","authors":["Christoph Jansen"],"pdf_url":"https://arxiv.org/pdf/2501.10195v1.pdf","comment":"Habilitation Thesis"},{"id":"http://arxiv.org/abs/2501.10193v1","updated":"2025-01-17T13:39:10Z","published":"2025-01-17T13:39:10Z","title":"Surrogate-based multiscale analysis of experiments on thermoplastic\n  composites under off-axis loading","summary":"  In this paper, we present a surrogate-based multiscale approach to model\nconstant strain-rate and creep experiments on unidirectional thermoplastic\ncomposites under off-axis loading. In previous contributions, these experiments\nwere modeled through a single-scale micromechanical simulation under the\nassumption of macroscopic homogeneity. Although efficient and accurate in many\nscenarios, simulations with low-off axis angles showed significant\ndiscrepancies with the experiments. It was hypothesized that the mismatch was\ncaused by macroscopic inhomogeneity, which would require a multiscale approach\nto capture it. However, full-field multiscale simulations remain\ncomputationally prohibitive. To address this issue, we replace the micromodel\nwith a Physically Recurrent Neural Network (PRNN), a surrogate model that\ncombines data-driven components with embedded constitutive models to capture\nhistory-dependent behavior naturally. The explainability of the latent space of\nthis network is also explored in a transfer learning strategy that requires no\nre-training. With the surrogate-based simulations, we confirm the hypothesis\nraised on the inhomogeneity of the macroscopic strain field and gain insights\ninto the influence of adjustment of the experimental setup with oblique\nend-tabs. Results from the surrogate-based multiscale approach show better\nagreement with experiments than the single-scale micromechanical approach over\na wide range of settings, although with limited accuracy on the creep\nexperiments, where macroscopic test effects were implicitly taken into account\nin the material properties calibration.\n","authors":["M. A. Maia","I. B. C. M. Rocha","D. Kovačević","F. P. van der Meer"],"pdf_url":"https://arxiv.org/pdf/2501.10193v1.pdf","comment":"21 pages. 31 figures"},{"id":"http://arxiv.org/abs/2304.11960v3","updated":"2025-01-17T13:34:49Z","published":"2023-04-24T09:53:33Z","title":"Bandit on the Hunt: Dynamic Crawling for Cyber Threat Intelligence","summary":"  Public information contains valuable Cyber Threat Intelligence (CTI) that is\nused to prevent attacks in the future. Ideally, the learnings from previous\nattacks help to mitigate all those that follow. While there are standards for\nsharing this information, much of it is shared in non-standardized news\narticles or blog posts. It is a time-consuming task to monitor online sources\nfor threats and even then, one can never be sure, to use the right sources.\nCurrent research propose extractors of Indicators of Compromise from known\nsources, while the identification of new sources is rarely considered. This\npaper proposes a focused crawler focused on the CTI domain based on multi-armed\nbandit ( MAB) and different crawling strategies. It uses SBERT to identify\nrelevant documents, while dynamically adapt its crawling path. We propose a\nsystem called ThreatCrawl, which achieve a harvest rate of over 25% and is able\nto expand its used seed by over 300%, while retaining focus on the topic at\nhand. In addition, this crawler identified previously unknown but highly\nrelevant overview pages, datasets, and domains.\n","authors":["Philipp Kuehn","Dilara Nadermahmoodi","Markus Bayer","Christian Reuter"],"pdf_url":"https://arxiv.org/pdf/2304.11960v3.pdf","comment":"6 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2501.10181v1","updated":"2025-01-17T13:26:12Z","published":"2025-01-17T13:26:12Z","title":"Improved learning rates in multi-unit uniform price auctions","summary":"  Motivated by the strategic participation of electricity producers in\nelectricity day-ahead market, we study the problem of online learning in\nrepeated multi-unit uniform price auctions focusing on the adversarial opposing\nbid setting. The main contribution of this paper is the introduction of a new\nmodeling of the bid space. Indeed, we prove that a learning algorithm\nleveraging the structure of this problem achieves a regret of\n$\\tilde{O}(K^{4/3}T^{2/3})$ under bandit feedback, improving over the bound of\n$\\tilde{O}(K^{7/4}T^{3/4})$ previously obtained in the literature. This\nimproved regret rate is tight up to logarithmic terms. Inspired by electricity\nreserve markets, we further introduce a different feedback model under which\nall winning bids are revealed. This feedback interpolates between the\nfull-information and bandit scenarios depending on the auctions' results. We\nprove that, under this feedback, the algorithm that we propose achieves regret\n$\\tilde{O}(K^{5/2}\\sqrt{T})$.\n","authors":["Marius Potfer","Dorian Baudry","Hugo Richard","Vianney Perchet","Cheng Wan"],"pdf_url":"https://arxiv.org/pdf/2501.10181v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.10179v1","updated":"2025-01-17T13:24:13Z","published":"2025-01-17T13:24:13Z","title":"A Simple but Effective Closed-form Solution for Extreme Multi-label\n  Learning","summary":"  Extreme multi-label learning (XML) is a task of assigning multiple labels\nfrom an extremely large set of labels to each data instance. Many current\nhigh-performance XML models are composed of a lot of hyperparameters, which\ncomplicates the tuning process. Additionally, the models themselves are adapted\nspecifically to XML, which complicates their reimplementation. To remedy this\nproblem, we propose a simple method based on ridge regression for XML. The\nproposed method not only has a closed-form solution but also is composed of a\nsingle hyperparameter. Since there are no precedents on applying ridge\nregression to XML, this paper verified the performance of the method by using\nvarious XML benchmark datasets. Furthermore, we enhanced the prediction of\nlow-frequency labels in XML, which hold informative content. This prediction is\nessential yet challenging because of the limited amount of data. Here, we\nemployed a simple frequency-based weighting. This approach greatly simplifies\nthe process compared with existing techniques. Experimental results revealed\nthat it can achieve levels of performance comparable to, or even exceeding,\nthose of models with numerous hyperparameters. Additionally, we found that the\nfrequency-based weighting significantly improved the predictive performance for\nlow-frequency labels, while requiring almost no changes in implementation. The\nsource code for the proposed method is available on github at\nhttps://github.com/cars1015/XML-ridge.\n","authors":["Kazuma Onishi","Katsuhiko Hayashi"],"pdf_url":"https://arxiv.org/pdf/2501.10179v1.pdf","comment":"10pages, Accepted at ECIR25"},{"id":"http://arxiv.org/abs/2501.10172v1","updated":"2025-01-17T13:07:52Z","published":"2025-01-17T13:07:52Z","title":"Mean and Variance Estimation Complexity in Arbitrary Distributions via\n  Wasserstein Minimization","summary":"  Parameter estimation is a fundamental challenge in machine learning, crucial\nfor tasks such as neural network weight fitting and Bayesian inference. This\npaper focuses on the complexity of estimating translation $\\boldsymbol{\\mu} \\in\n\\mathbb{R}^l$ and shrinkage $\\sigma \\in \\mathbb{R}_{++}$ parameters for a\ndistribution of the form $\\frac{1}{\\sigma^l} f_0 \\left( \\frac{\\boldsymbol{x} -\n\\boldsymbol{\\mu}}{\\sigma} \\right)$, where $f_0$ is a known density in\n$\\mathbb{R}^l$ given $n$ samples. We highlight that while the problem is\nNP-hard for Maximum Likelihood Estimation (MLE), it is possible to obtain\n$\\varepsilon$-approximations for arbitrary $\\varepsilon > 0$ within\n$\\text{poly} \\left( \\frac{1}{\\varepsilon} \\right)$ time using the Wasserstein\ndistance.\n","authors":["Valentio Iverson","Stephen Vavasis"],"pdf_url":"https://arxiv.org/pdf/2501.10172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10162v1","updated":"2025-01-17T12:51:25Z","published":"2025-01-17T12:51:25Z","title":"Convex Physics Informed Neural Networks for the Monge-Ampère Optimal\n  Transport Problem","summary":"  Optimal transportation of raw material from suppliers to customers is an\nissue arising in logistics that is addressed here with a continuous model\nrelying on optimal transport theory. A physics informed neuralnetwork method is\nadvocated here for the solution of the corresponding generalized Monge-Amp`ere\nequation. Convex neural networks are advocated to enforce the convexity of the\nsolution to the Monge-Amp\\`ere equation and obtain a suitable approximation of\nthe optimal transport map. A particular focus is set on the enforcement of\ntransport boundary conditions in the loss function. Numerical experiments\nillustrate the solution to the optimal transport problem in several\nconfigurations, and sensitivity analyses are performed.\n","authors":["Alexandre Caboussat","Anna Peruso"],"pdf_url":"https://arxiv.org/pdf/2501.10162v1.pdf","comment":"17 pages, 14 figures. Submitted to Engineering Computations on 26\n  September 2024"},{"id":"http://arxiv.org/abs/2409.16302v2","updated":"2025-01-17T12:27:40Z","published":"2024-09-10T11:00:24Z","title":"How Redundant Is the Transformer Stack in Speech Representation Models?","summary":"  Self-supervised speech representation models, particularly those leveraging\ntransformer architectures, have demonstrated remarkable performance across\nvarious tasks such as speech recognition, speaker identification, and emotion\ndetection. Recent studies on transformer models revealed a high redundancy\nbetween layers and the potential for significant pruning, which we will\ninvestigate here for transformer-based speech representation models. We perform\na detailed analysis of layer similarity in speech representation models using\nthree similarity metrics: cosine similarity, centered kernel alignment, and\nmutual nearest-neighbor alignment. Our findings reveal a block-like structure\nof high similarity, suggesting two main processing steps and significant\nredundancy of layers. We demonstrate the effectiveness of pruning\ntransformer-based speech representation models without the need for\npost-training, achieving up to 40% reduction in transformer layers while\nmaintaining over 95% of the model's predictive capacity. Furthermore, we employ\na knowledge distillation method to substitute the entire transformer stack with\nmimicking layers, reducing the network size 95-98% and the inference time by up\nto 94%. This substantial decrease in computational load occurs without\nconsiderable performance loss, suggesting that the transformer stack is almost\ncompletely redundant for downstream applications of speech representation\nmodels.\n","authors":["Teresa Dorszewski","Albert Kjøller Jacobsen","Lenka Tětková","Lars Kai Hansen"],"pdf_url":"https://arxiv.org/pdf/2409.16302v2.pdf","comment":"To appear at ICASSP 2025 (excluding appendix)"},{"id":"http://arxiv.org/abs/2501.10153v1","updated":"2025-01-17T12:24:28Z","published":"2025-01-17T12:24:28Z","title":"Region-wise stacking ensembles for estimating brain-age using MRI","summary":"  Predictive modeling using structural magnetic resonance imaging (MRI) data is\na prominent approach to study brain-aging. Machine learning algorithms and\nfeature extraction methods have been employed to improve predictions and\nexplore healthy and accelerated aging e.g. neurodegenerative and psychiatric\ndisorders. The high-dimensional MRI data pose challenges to building\ngeneralizable and interpretable models as well as for data privacy. Common\npractices are resampling or averaging voxels within predefined parcels, which\nreduces anatomical specificity and biological interpretability as voxels within\na region may differently relate to aging. Effectively, naive fusion by\naveraging can result in information loss and reduced accuracy. We present a\nconceptually novel two-level stacking ensemble (SE) approach. The first level\ncomprises regional models for predicting individuals' age based on voxel-wise\ninformation, fused by a second-level model yielding final predictions. Eight\ndata fusion scenarios were explored using as input Gray matter volume (GMV)\nestimates from four datasets covering the adult lifespan. Performance, measured\nusing mean absolute error (MAE), R2, correlation and prediction bias, showed\nthat SE outperformed the region-wise averages. The best performance was\nobtained when first-level regional predictions were obtained as out-of-sample\npredictions on the application site with second-level models trained on\nindependent and site-specific data (MAE=4.75 vs baseline regional mean GMV\nMAE=5.68). Performance improved as more datasets were used for training.\nFirst-level predictions showed improved and more robust aging signal providing\nnew biological insights and enhanced data privacy. Overall, the SE improves\naccuracy compared to the baseline while preserving or enhancing data privacy.\n","authors":["Georgios Antonopoulos","Shammi More","Simon B. Eickhoff","Federico Raimondo","Kaustubh R. Patil"],"pdf_url":"https://arxiv.org/pdf/2501.10153v1.pdf","comment":"version1"},{"id":"http://arxiv.org/abs/2501.10141v1","updated":"2025-01-17T12:05:24Z","published":"2025-01-17T12:05:24Z","title":"Enhancing UAV Path Planning Efficiency Through Accelerated Learning","summary":"  Unmanned Aerial Vehicles (UAVs) are increasingly essential in various fields\nsuch as surveillance, reconnaissance, and telecommunications. This study aims\nto develop a learning algorithm for the path planning of UAV wireless\ncommunication relays, which can reduce storage requirements and accelerate Deep\nReinforcement Learning (DRL) convergence. Assuming the system possesses terrain\nmaps of the area and can estimate user locations using localization algorithms\nor direct GPS reporting, it can input these parameters into the learning\nalgorithms to achieve optimized path planning performance. However, higher\nresolution terrain maps are necessary to extract topological information such\nas terrain height, object distances, and signal blockages. This requirement\nincreases memory and storage demands on UAVs while also lengthening convergence\ntimes in DRL algorithms. Similarly, defining the telecommunication coverage map\nin UAV wireless communication relays using these terrain maps and user position\nestimations demands higher memory and storage utilization for the learning path\nplanning algorithms. Our approach reduces path planning training time by\napplying a dimensionality reduction technique based on Principal Component\nAnalysis (PCA), sample combination, Prioritized Experience Replay (PER), and\nthe combination of Mean Squared Error (MSE) and Mean Absolute Error (MAE) loss\ncalculations in the coverage map estimates, thereby enhancing a Twin Delayed\nDeep Deterministic Policy Gradient (TD3) algorithm. The proposed solution\nreduces the convergence episodes needed for basic training by approximately\nfour times compared to the traditional TD3.\n","authors":["Joseanne Viana","Boris Galkin","Lester Ho","Holger Claussen"],"pdf_url":"https://arxiv.org/pdf/2501.10141v1.pdf","comment":"This paper was accepted in https://camad2024.ieee-camad.org/\n  conference but it is not available from the conference yet"},{"id":"http://arxiv.org/abs/2501.10139v1","updated":"2025-01-17T12:01:56Z","published":"2025-01-17T12:01:56Z","title":"Conformal Prediction Sets with Improved Conditional Coverage using Trust\n  Scores","summary":"  Standard conformal prediction offers a marginal guarantee on coverage, but\nfor prediction sets to be truly useful, they should ideally ensure coverage\nconditional on each test point. Unfortunately, it is impossible to achieve\nexact, distribution-free conditional coverage in finite samples. In this work,\nwe propose an alternative conformal prediction algorithm that targets coverage\nwhere it matters most--in instances where a classifier is overconfident in its\nincorrect predictions. We start by dissecting miscoverage events in\nmarginally-valid conformal prediction, and show that miscoverage rates vary\nbased on the classifier's confidence and its deviation from the Bayes optimal\nclassifier. Motivated by this insight, we develop a variant of conformal\nprediction that targets coverage conditional on a reduced set of two variables:\nthe classifier's confidence in a prediction and a nonparametric trust score\nthat measures its deviation from the Bayes classifier. Empirical evaluation on\nmultiple image datasets shows that our method generally improves conditional\ncoverage properties compared to standard conformal prediction, including\nclass-conditional coverage, coverage over arbitrary subgroups, and coverage\nover demographic groups.\n","authors":["Jivat Neet Kaur","Michael I. Jordan","Ahmed Alaa"],"pdf_url":"https://arxiv.org/pdf/2501.10139v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10137v1","updated":"2025-01-17T11:59:56Z","published":"2025-01-17T11:59:56Z","title":"Visual Exploration of Stopword Probabilities in Topic Models","summary":"  Stopword removal is a critical stage in many Machine Learning methods but\noften receives little consideration, it interferes with the model\nvisualizations and disrupts user confidence. Inappropriately chosen or hastily\nomitted stopwords not only lead to suboptimal performance but also\nsignificantly affect the quality of models, thus reducing the willingness of\npractitioners and stakeholders to rely on the output visualizations. This paper\nproposes a novel extraction method that provides a corpus-specific\nprobabilistic estimation of stopword likelihood and an interactive\nvisualization system to support their analysis. We evaluated our approach and\ninterface using real-world data, a commonly used Machine Learning method (Topic\nModelling), and a comprehensive qualitative experiment probing user confidence.\nThe results of our work show that our system increases user confidence in the\ncredibility of topic models by (1) returning reasonable probabilities, (2)\ngenerating an appropriate and representative extension of common stopword\nlists, and (3) providing an adjustable threshold for estimating and analyzing\nstopwords visually. Finally, we discuss insights, recommendations, and best\npractices to support practitioners while improving the output of Machine\nLearning methods and topic model visualizations with robust stopword analysis\nand removal.\n","authors":["Shuangjiang Xue","Pierre Le Bras","David A. Robb","Mike J. Chantler","Stefano Padilla"],"pdf_url":"https://arxiv.org/pdf/2501.10137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10134v1","updated":"2025-01-17T11:49:49Z","published":"2025-01-17T11:49:49Z","title":"Exploring the Impact of Generative Artificial Intelligence in Education:\n  A Thematic Analysis","summary":"  The recent advancements in Generative Artificial intelligence (GenAI)\ntechnology have been transformative for the field of education. Large Language\nModels (LLMs) such as ChatGPT and Bard can be leveraged to automate boilerplate\ntasks, create content for personalised teaching, and handle repetitive tasks to\nallow more time for creative thinking. However, it is important to develop\nguidelines, policies, and assessment methods in the education sector to ensure\nthe responsible integration of these tools. In this article, thematic analysis\nhas been performed on seven essays obtained from professionals in the education\nsector to understand the advantages and pitfalls of using GenAI models such as\nChatGPT and Bard in education. Exploratory Data Analysis (EDA) has been\nperformed on the essays to extract further insights from the text. The study\nfound several themes which highlight benefits and drawbacks of GenAI tools, as\nwell as suggestions to overcome these limitations and ensure that students are\nusing these tools in a responsible and ethical manner.\n","authors":["Abhishek Kaushik","Sargam Yadav","Andrew Browne","David Lillis","David Williams","Jack Mc Donnell","Peadar Grant","Siobhan Connolly Kernan","Shubham Sharma","Mansi Arora"],"pdf_url":"https://arxiv.org/pdf/2501.10134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09636v2","updated":"2025-01-17T11:44:53Z","published":"2025-01-16T16:25:30Z","title":"LLM-Based Routing in Mixture of Experts: A Novel Framework for Trading","summary":"  Recent advances in deep learning and large language models (LLMs) have\nfacilitated the deployment of the mixture-of-experts (MoE) mechanism in the\nstock investment domain. While these models have demonstrated promising trading\nperformance, they are often unimodal, neglecting the wealth of information\navailable in other modalities, such as textual data. Moreover, the traditional\nneural network-based router selection mechanism fails to consider contextual\nand real-world nuances, resulting in suboptimal expert selection. To address\nthese limitations, we propose LLMoE, a novel framework that employs LLMs as the\nrouter within the MoE architecture. Specifically, we replace the conventional\nneural network-based router with LLMs, leveraging their extensive world\nknowledge and reasoning capabilities to select experts based on historical\nprice data and stock news. This approach provides a more effective and\ninterpretable selection mechanism. Our experiments on multimodal real-world\nstock datasets demonstrate that LLMoE outperforms state-of-the-art MoE models\nand other deep neural network approaches. Additionally, the flexible\narchitecture of LLMoE allows for easy adaptation to various downstream tasks.\n","authors":["Kuan-Ming Liu","Ming-Chih Lo"],"pdf_url":"https://arxiv.org/pdf/2501.09636v2.pdf","comment":"Accepted by AAAI 2025 Workshop on AI for Social Impact - Bridging\n  Innovations in Finance, Social Media, and Crime Prevention"},{"id":"http://arxiv.org/abs/2501.10124v1","updated":"2025-01-17T11:27:58Z","published":"2025-01-17T11:27:58Z","title":"Gene Regulatory Network Inference in the Presence of Selection Bias and\n  Latent Confounders","summary":"  Gene Regulatory Network Inference (GRNI) aims to identify causal\nrelationships among genes using gene expression data, providing insights into\nregulatory mechanisms. A significant yet often overlooked challenge is\nselection bias, a process where only cells meeting specific criteria, such as\ngene expression thresholds, survive or are observed, distorting the true joint\ndistribution of genes and thus biasing GRNI results. Furthermore, gene\nexpression is influenced by latent confounders, such as non-coding RNAs, which\nadd complexity to GRNI. To address these challenges, we propose GISL (Gene\nRegulatory Network Inference in the presence of Selection bias and Latent\nconfounders), a novel algorithm to infer true regulatory relationships in the\npresence of selection and confounding issues. Leveraging data obtained via\nmultiple gene perturbation experiments, we show that the true regulatory\nrelationships, as well as selection processes and latent confounders can be\npartially identified without strong parametric models and under mild graphical\nassumptions. Experimental results on both synthetic and real-world single-cell\ngene expression datasets demonstrate the superiority of GISL over existing\nmethods.\n","authors":["Gongxu Luo","Haoyue Dai","Boyang Sun","Loka Li","Biwei Huang","Petar Stojanov","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.10124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10120v1","updated":"2025-01-17T11:12:28Z","published":"2025-01-17T11:12:28Z","title":"PaSa: An LLM Agent for Comprehensive Academic Paper Search","summary":"  We introduce PaSa, an advanced Paper Search agent powered by large language\nmodels. PaSa can autonomously make a series of decisions, including invoking\nsearch tools, reading papers, and selecting relevant references, to ultimately\nobtain comprehensive and accurate results for complex scholarly queries. We\noptimize PaSa using reinforcement learning with a synthetic dataset,\nAutoScholarQuery, which includes 35k fine-grained academic queries and\ncorresponding papers sourced from top-tier AI conference publications.\nAdditionally, we develop RealScholarQuery, a benchmark collecting real-world\nacademic queries to assess PaSa performance in more realistic scenarios.\nDespite being trained on synthetic data, PaSa significantly outperforms\nexisting baselines on RealScholarQuery, including Google, Google Scholar,\nGoogle with GPT-4 for paraphrased queries, chatGPT (search-enabled GPT-4o),\nGPT-o1, and PaSa-GPT-4o (PaSa implemented by prompting GPT-4o). Notably,\nPaSa-7B surpasses the best Google-based baseline, Google with GPT-4o, by 37.78%\nin recall@20 and 39.90% in recall@50. It also exceeds PaSa-GPT-4o by 30.36% in\nrecall and 4.25% in precision. Model, datasets, and code are available at\nhttps://github.com/bytedance/pasa.\n","authors":["Yichen He","Guanhua Huang","Peiyuan Feng","Yuan Lin","Yuchen Zhang","Hang Li","Weinan E"],"pdf_url":"https://arxiv.org/pdf/2501.10120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10100v1","updated":"2025-01-17T10:39:09Z","published":"2025-01-17T10:39:09Z","title":"Robotic World Model: A Neural Network Simulator for Robust Policy\n  Optimization in Robotics","summary":"  Learning robust and generalizable world models is crucial for enabling\nefficient and scalable robotic control in real-world environments. In this\nwork, we introduce a novel framework for learning world models that accurately\ncapture complex, partially observable, and stochastic dynamics. The proposed\nmethod employs a dual-autoregressive mechanism and self-supervised training to\nachieve reliable long-horizon predictions without relying on domain-specific\ninductive biases, ensuring adaptability across diverse robotic tasks. We\nfurther propose a policy optimization framework that leverages world models for\nefficient training in imagined environments and seamless deployment in\nreal-world systems. Through extensive experiments, our approach consistently\noutperforms state-of-the-art methods, demonstrating superior autoregressive\nprediction accuracy, robustness to noise, and generalization across\nmanipulation and locomotion tasks. Notably, policies trained with our method\nare successfully deployed on ANYmal D hardware in a zero-shot transfer,\nachieving robust performance with minimal sim-to-real performance loss. This\nwork advances model-based reinforcement learning by addressing the challenges\nof long-horizon prediction, error accumulation, and sim-to-real transfer. By\nproviding a scalable and robust framework, the introduced methods pave the way\nfor adaptive and efficient robotic systems in real-world applications.\n","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"https://arxiv.org/pdf/2501.10100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10098v1","updated":"2025-01-17T10:35:58Z","published":"2025-01-17T10:35:58Z","title":"landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D\n  Images","summary":"  Anatomical landmark localization in 2D/3D images is a critical task in\nmedical imaging. Although many general-purpose tools exist for landmark\nlocalization in classical computer vision tasks, such as pose estimation, they\nlack the specialized features and modularity necessary for anatomical landmark\nlocalization applications in the medical domain. Therefore, we introduce\nlandmarker, a Python package built on PyTorch. The package provides a\ncomprehensive, flexible toolkit for developing and evaluating landmark\nlocalization algorithms, supporting a range of methodologies, including static\nand adaptive heatmap regression. landmarker enhances the accuracy of landmark\nidentification, streamlines research and development processes, and supports\nvarious image formats and preprocessing pipelines. Its modular design allows\nusers to customize and extend the toolkit for specific datasets and\napplications, accelerating innovation in medical imaging. landmarker addresses\na critical need for precision and customization in landmark localization tasks\nnot adequately met by existing general-purpose pose estimation tools.\n","authors":["Jef Jonkers","Luc Duchateau","Glenn Van Wallendael","Sofie Van Hoecke"],"pdf_url":"https://arxiv.org/pdf/2501.10098v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2309.00494v2","updated":"2025-01-17T10:31:13Z","published":"2023-09-01T14:40:25Z","title":"Multi-stage Deep Learning Artifact Reduction for Pallel-beam Computed\n  Tomography","summary":"  Computed Tomography (CT) using synchrotron radiation is a powerful technique\nthat, compared to lab-CT techniques, boosts high spatial and temporal\nresolution while also providing access to a range of contrast-formation\nmechanisms. The acquired projection data is typically processed by a\ncomputational pipeline composed of multiple stages. Artifacts introduced during\ndata acquisition can propagate through the pipeline, and degrade image quality\nin the reconstructed images. Recently, deep learning has shown significant\npromise in enhancing image quality for images representing scientific data.\nThis success has driven increasing adoption of deep learning techniques in CT\nimaging. Various approaches have been proposed to incorporate deep learning\ninto computational pipelines, but each has limitations in addressing artifacts\neffectively and efficiently in synchrotron CT, either in properly addressing\nthe specific artifacts, or in computational efficiency.\n  Recognizing these challenges, we introduce a novel method that incorporates\nseparate deep learning models at each stage of the tomography\npipeline-projection, sinogram, and reconstruction-to address specific artifacts\nlocally in a data-driven way. Our approach includes bypass connections that\nfeed both the outputs from previous stages and raw data to subsequent stages,\nminimizing the risk of error propagation. Extensive evaluations on both\nsimulated and real-world datasets illustrate that our approach effectively\nreduces artifacts and outperforms comparison methods.\n","authors":["Jiayang Shi","Daniel M. Pelt","K. Joost Batenburg"],"pdf_url":"https://arxiv.org/pdf/2309.00494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10088v1","updated":"2025-01-17T10:15:03Z","published":"2025-01-17T10:15:03Z","title":"A recursive Bayesian neural network for constitutive modeling of sands\n  under monotonic loading","summary":"  In geotechnical engineering, constitutive models play a crucial role in\ndescribing soil behavior under varying loading conditions. Data-driven deep\nlearning (DL) models offer a promising alternative for developing predictive\nconstitutive models. When prediction is the primary focus, quantifying the\npredictive uncertainty of a trained DL model and communicating this uncertainty\nto end users is crucial for informed decision-making.\n  This study proposes a recursive Bayesian neural network (rBNN) framework,\nwhich builds upon recursive feedforward neural networks (rFFNNs) by introducing\ngeneralized Bayesian inference for uncertainty quantification. A significant\ncontribution of this work is the incorporation of a sliding window approach in\nrFFNNs, allowing the models to effectively capture temporal dependencies across\nload steps. The rBNN extends this framework by treating model parameters as\nrandom variables, with their posterior distributions inferred using generalized\nvariational inference.\n  The proposed framework is validated on two datasets: (i) a numerically\nsimulated consolidated drained (CD) triaxial dataset employing a hardening soil\nmodel and (ii) an experimental dataset comprising 28 CD triaxial tests on\nBaskarp sand. Comparative analyses with LSTM, Bi-LSTM, and GRU models\ndemonstrate that the deterministic rFFNN achieves superior predictive accuracy,\nattributed to its transparent structure and sliding window design. While the\nrBNN marginally trails in accuracy for the experimental case, it provides\nrobust confidence intervals, addressing data sparsity and measurement noise in\nexperimental conditions. The study underscores the trade-offs between\ndeterministic and probabilistic approaches and the potential of rBNNs for\nuncertainty-aware constitutive modeling.\n","authors":["Toiba Noor","Soban Nasir Lone","G. V. Ramana","Rajdip Nayek"],"pdf_url":"https://arxiv.org/pdf/2501.10088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10084v1","updated":"2025-01-17T10:05:11Z","published":"2025-01-17T10:05:11Z","title":"Two-level Solar Irradiance Clustering with Season Identification: A\n  Comparative Analysis","summary":"  Solar irradiance clustering can enhance solar power capacity planning and\nhelp improve forecasting models by identifying similar irradiance patterns\ninfluenced by seasonal and weather changes. In this study, we adopt an\nefficient two-level clustering approach to automatically identify seasons using\nthe clear sky irradiance in first level and subsequently to identify daily\ncloud level as clear, cloudy and partly cloudy within each season in second\nlevel. In the second level of clustering, three methods are compared, namely,\nDaily Irradiance Index (DII or $\\beta$), Euclidean Distance (ED), and Dynamic\nTime Warping (DTW) distance. The DII is computed as the ratio of time integral\nof measured irradiance to time integral of the clear sky irradiance. The\nidentified clusters were compared quantitatively using established clustering\nmetrics and qualitatively by comparing the mean irradiance profiles. The\nresults clearly establish the superiority of the $\\beta$-based clustering\napproach as the leader, setting a new benchmark for solar irradiance clustering\nstudies. Moreover, $\\beta$-based clustering remains effective even for annual\ndata unlike the time-series methods which suffer significant performance\ndegradation. Interestingly, contrary to expectations, ED-based clustering\noutperforms the more compute-intensive DTW distance-based clustering. The\nmethod has been rigorously validated using data from two distinct US locations,\ndemonstrating robust scalability for larger datasets and potential\napplicability for other locations.\n","authors":["Roshni Agrawal","Sivakumar Subramanian","Venkataramana Runkana"],"pdf_url":"https://arxiv.org/pdf/2501.10084v1.pdf","comment":"30 pages, 9 figures, 6 tables"},{"id":"http://arxiv.org/abs/2407.15580v3","updated":"2025-01-17T10:03:39Z","published":"2024-07-22T12:16:56Z","title":"Annealed Multiple Choice Learning: Overcoming limitations of\n  Winner-takes-all with annealing","summary":"  We introduce Annealed Multiple Choice Learning (aMCL) which combines\nsimulated annealing with MCL. MCL is a learning framework handling ambiguous\ntasks by predicting a small set of plausible hypotheses. These hypotheses are\ntrained using the Winner-takes-all (WTA) scheme, which promotes the diversity\nof the predictions. However, this scheme may converge toward an arbitrarily\nsuboptimal local minimum, due to the greedy nature of WTA. We overcome this\nlimitation using annealing, which enhances the exploration of the hypothesis\nspace during training. We leverage insights from statistical physics and\ninformation theory to provide a detailed description of the model training\ntrajectory. Additionally, we validate our algorithm by extensive experiments on\nsynthetic datasets, on the standard UCI benchmark, and on speech separation.\n","authors":["David Perera","Victor Letzelter","Théo Mariotte","Adrien Cortés","Mickael Chen","Slim Essid","Gaël Richard"],"pdf_url":"https://arxiv.org/pdf/2407.15580v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.10077v1","updated":"2025-01-17T09:49:46Z","published":"2025-01-17T09:49:46Z","title":"Double descent in quantum machine learning","summary":"  The double descent phenomenon challenges traditional statistical learning\ntheory by revealing scenarios where larger models do not necessarily lead to\nreduced performance on unseen data. While this counterintuitive behavior has\nbeen observed in a variety of classical machine learning models, particularly\nmodern neural network architectures, it remains elusive within the context of\nquantum machine learning. In this work, we analytically demonstrate that\nquantum learning models can exhibit double descent behavior by drawing on\ninsights from linear regression and random matrix theory. Additionally, our\nnumerical experiments on quantum kernel methods across different real-world\ndatasets and system sizes further confirm the existence of a test error peak, a\ncharacteristic feature of double descent. Our findings provide evidence that\nquantum models can operate in the modern, overparameterized regime without\nexperiencing overfitting, thereby opening pathways to improved learning\nperformance beyond traditional statistical learning theory.\n","authors":["Marie Kempkes","Aroosa Ijaz","Elies Gil-Fuster","Carlos Bravo-Prieto","Jakob Spiegelberg","Evert van Nieuwenburg","Vedran Dunjko"],"pdf_url":"https://arxiv.org/pdf/2501.10077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10075v1","updated":"2025-01-17T09:47:27Z","published":"2025-01-17T09:47:27Z","title":"Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and\n  MModalCC Framework","summary":"  Remote sensing change captioning (RSICC) aims to describe changes between\nbitemporal images in natural language. Existing methods often fail under\nchallenges like illumination differences, viewpoint changes, blur effects,\nleading to inaccuracies, especially in no-change regions. Moreover, the images\nacquired at different spatial resolutions and have registration errors tend to\naffect the captions. To address these issues, we introduce SECOND-CC, a novel\nRSICC dataset featuring high-resolution RGB image pairs, semantic segmentation\nmaps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of\nbitemporal RS images and 30,205 sentences describing the differences between\nimages. Additionally, we propose MModalCC, a multimodal framework that\nintegrates semantic and visual data using advanced attention mechanisms,\nincluding Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross\nAttention (MGCA). Detailed ablation studies and attention visualizations\nfurther demonstrate its effectiveness and ability to address RSICC challenges.\nComprehensive experiments show that MModalCC outperforms state-of-the-art RSICC\nmethods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on\nBLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and\ncodebase publicly available to facilitate future research at\nhttps://github.com/ChangeCapsInRS/SecondCC\n","authors":["Ali Can Karaca","M. Enes Ozelbas","Saadettin Berber","Orkhan Karimli","Turabi Yildirim","M. Fatih Amasyali"],"pdf_url":"https://arxiv.org/pdf/2501.10075v1.pdf","comment":"This work has been submitted to the IEEE Transactions on Geoscience\n  and Remote Sensing journal for possible publication"},{"id":"http://arxiv.org/abs/2501.07124v3","updated":"2025-01-17T09:39:17Z","published":"2025-01-13T08:26:43Z","title":"LLM360 K2: Building a 65B 360-Open-Source Large Language Model from\n  Scratch","summary":"  We detail the training of the LLM360 K2-65B model, scaling up our 360-degree\nOPEN SOURCE approach to the largest and most powerful models under project\nLLM360. While open-source LLMs continue to advance, the answer to \"How are the\nlargest LLMs trained?\" remains unclear within the community. The implementation\ndetails for such high-capacity models are often protected due to business\nconsiderations associated with their high cost. This lack of transparency\nprevents LLM researchers from leveraging valuable insights from prior\nexperience, e.g., \"What are the best practices for addressing loss spikes?\" The\nLLM360 K2 project addresses this gap by providing full transparency and access\nto resources accumulated during the training of LLMs at the largest scale. This\nreport highlights key elements of the K2 project, including our first model, K2\nDIAMOND, a 65 billion-parameter LLM that surpasses LLaMA-65B and rivals\nLLaMA2-70B, while requiring fewer FLOPs and tokens. We detail the\nimplementation steps and present a longitudinal analysis of K2 DIAMOND's\ncapabilities throughout its training process. We also outline ongoing projects\nsuch as TXT360, setting the stage for future models in the series. By offering\npreviously unavailable resources, the K2 project also resonates with the\n360-degree OPEN SOURCE principles of transparency, reproducibility, and\naccessibility, which we believe are vital in the era of resource-intensive AI\nresearch.\n","authors":["Zhengzhong Liu","Bowen Tan","Hongyi Wang","Willie Neiswanger","Tianhua Tao","Haonan Li","Fajri Koto","Yuqi Wang","Suqi Sun","Omkar Pangarkar","Richard Fan","Yi Gu","Victor Miller","Liqun Ma","Liping Tang","Nikhil Ranjan","Yonghao Zhuang","Guowei He","Renxi Wang","Mingkai Deng","Robin Algayres","Yuanzhi Li","Zhiqiang Shen","Preslav Nakov","Eric Xing"],"pdf_url":"https://arxiv.org/pdf/2501.07124v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03594v2","updated":"2025-01-17T09:37:36Z","published":"2024-11-29T05:57:37Z","title":"BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix\n  Sharing and Throughput-oriented Token Batching","summary":"  Large language models (LLMs) increasingly play an important role in a wide\nrange of information processing and management tasks. Many of these tasks are\nperformed in large batches or even offline, and the performance indictor for\nwhich is throughput. These tasks usually show the characteristic of prefix\nsharing, where different prompt input can partially show the common prefix.\nHowever, the existing LLM inference engines tend to optimize the streaming\nrequests and show limitations of supporting the large batched tasks with the\nprefix sharing characteristic. The existing solutions use the LRU-based cache\nto reuse the KV context of common prefix between requests. The KV context that\nare about to be reused may prematurely evicted with the implicit cache\nmanagement. Besides, the streaming oriented systems do not leverage the\nrequest-batch information and can not mix the decoding tokens with the prefill\nchunks to the best for the batched scenarios, and thus fails to saturate the\nGPU. We propose BatchLLM to address the above problems. BatchLLM explicitly\nidentifies the common prefixes globally. The requests sharing the same prefix\nwill be scheduled together to reuse the KV context the best. BatchLLM reorders\nthe requests and schedules the requests with larger ratio of decoding first to\nbetter mix the decoding tokens with the latter prefill chunks, and applies\nmemory-centric token batching to enlarge the token-batch sizes, which helps to\nincrease the GPU utilization. Finally, BatchLLM optimizes the prefix-shared\nAttention kernel with horizontal fusion to reduce tail effect and kernel launch\noverhead. Extensive evaluation shows that BatchLLM outperforms vLLM and SGLang\nby 1.3$\\times$ to 10.8$\\times$ on a set of microbenchmarks and a typical\nindustry workload under different hardware environments.\n","authors":["Zhen Zheng","Xin Ji","Taosong Fang","Fanghao Zhou","Chuanjie Liu","Gang Peng"],"pdf_url":"https://arxiv.org/pdf/2412.03594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.20262v3","updated":"2025-01-17T09:32:54Z","published":"2024-03-29T16:13:31Z","title":"ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language\n  Models","summary":"  Research on Large Language Models (LLMs) has recently witnessed an increasing\ninterest in extending the models' context size to better capture dependencies\nwithin long documents. While benchmarks have been proposed to assess long-range\nabilities, existing efforts primarily considered generic tasks that are not\nnecessarily aligned with real-world applications. In contrast, we propose a new\nbenchmark for long-context LLMs focused on a practical meeting assistant\nscenario in which the long contexts consist of transcripts obtained by\nautomatic speech recognition, presenting unique challenges for LLMs due to the\ninherent noisiness and oral nature of such data. Our benchmark, ELITR-Bench,\naugments the existing ELITR corpus by adding 271 manually crafted questions\nwith their ground-truth answers, as well as noisy versions of meeting\ntranscripts altered to target different Word Error Rate levels. Our experiments\nwith 12 long-context LLMs on ELITR-Bench confirm the progress made across\nsuccessive generations of both proprietary and open models, and point out their\ndiscrepancies in terms of robustness to transcript noise. We also provide a\nthorough analysis of our GPT-4-based evaluation, including insights from a\ncrowdsourcing study. Our findings indicate that while GPT-4's scores align with\nhuman judges, its ability to distinguish beyond three score levels may be\nlimited.\n","authors":["Thibaut Thonet","Jos Rozen","Laurent Besacier"],"pdf_url":"https://arxiv.org/pdf/2403.20262v3.pdf","comment":"Published in COLING 2025"},{"id":"http://arxiv.org/abs/2501.10064v1","updated":"2025-01-17T09:29:33Z","published":"2025-01-17T09:29:33Z","title":"One-D-Piece: Image Tokenizer Meets Quality-Controllable Compression","summary":"  Current image tokenization methods require a large number of tokens to\ncapture the information contained within images. Although the amount of\ninformation varies across images, most image tokenizers only support\nfixed-length tokenization, leading to inefficiency in token allocation. In this\nstudy, we introduce One-D-Piece, a discrete image tokenizer designed for\nvariable-length tokenization, achieving quality-controllable mechanism. To\nenable variable compression rate, we introduce a simple but effective\nregularization mechanism named \"Tail Token Drop\" into discrete one-dimensional\nimage tokenizers. This method encourages critical information to concentrate at\nthe head of the token sequence, enabling support of variadic tokenization,\nwhile preserving state-of-the-art reconstruction quality. We evaluate our\ntokenizer across multiple reconstruction quality metrics and find that it\ndelivers significantly better perceptual quality than existing\nquality-controllable compression methods, including JPEG and WebP, at smaller\nbyte sizes. Furthermore, we assess our tokenizer on various downstream computer\nvision tasks, including image classification, object detection, semantic\nsegmentation, and depth estimation, confirming its adaptability to numerous\napplications compared to other variable-rate methods. Our approach demonstrates\nthe versatility of variable-length discrete image tokenization, establishing a\nnew paradigm in both compression efficiency and reconstruction performance.\nFinally, we validate the effectiveness of tail token drop via detailed analysis\nof tokenizers.\n","authors":["Keita Miwa","Kento Sasaki","Hidehisa Arai","Tsubasa Takahashi","Yu Yamaguchi"],"pdf_url":"https://arxiv.org/pdf/2501.10064v1.pdf","comment":"Our Project Page:\n  https://turingmotors.github.io/one-d-piece-tokenizer"},{"id":"http://arxiv.org/abs/2501.10062v1","updated":"2025-01-17T09:27:08Z","published":"2025-01-17T09:27:08Z","title":"OMoE: Diversifying Mixture of Low-Rank Adaptation by Orthogonal\n  Finetuning","summary":"  Building mixture-of-experts (MoE) architecture for Low-rank adaptation (LoRA)\nis emerging as a potential direction in parameter-efficient fine-tuning (PEFT)\nfor its modular design and remarkable performance. However, simply stacking the\nnumber of experts cannot guarantee significant improvement. In this work, we\nfirst conduct qualitative analysis to indicate that experts collapse to similar\nrepresentations in vanilla MoE, limiting the capacity of modular design and\ncomputational efficiency. Ulteriorly, Our analysis reveals that the performance\nof previous MoE variants maybe limited by a lack of diversity among experts.\nMotivated by these findings, we propose Orthogonal Mixture-of-Experts (OMoE), a\nresource-efficient MoE variant that trains experts in an orthogonal manner to\npromote diversity. In OMoE, a Gram-Schmidt process is leveraged to enforce that\nthe experts' representations lie within the Stiefel manifold. By applying\northogonal constraints directly to the architecture, OMoE keeps the learning\nobjective unchanged, without compromising optimality. Our method is simple and\nalleviates memory bottlenecks, as it incurs minimal experts compared to vanilla\nMoE models. Experiments on diverse commonsense reasoning benchmarks demonstrate\nthat OMoE can consistently achieve stable and efficient performance improvement\nwhen compared with the state-of-the-art methods while significantly reducing\nthe number of required experts.\n","authors":["Jinyuan Feng","Zhiqiang Pu","Tianyi Hu","Dongmin Li","Xiaolin Ai","Huimu Wang"],"pdf_url":"https://arxiv.org/pdf/2501.10062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10054v1","updated":"2025-01-17T09:20:56Z","published":"2025-01-17T09:20:56Z","title":"Accelerating Large Language Models through Partially Linear Feed-Forward\n  Network","summary":"  Large language models (LLMs) demonstrate remarkable capabilities but face\ndeployment challenges due to their massive parameter counts. While existing\ncompression techniques like pruning can reduce model size, it leads to\nsignificant accuracy degradation under high compression ratios. We present a\nnovel perspective inspired by constant folding in compiler optimization. Our\napproach enables parameter reduction by treating activation functions in LLMs\nas linear functions.\n  However, recent LLMs use complex non-linear activations like GELU that\nprevent direct application of this technique. We propose TARDIS, which enables\noptimization of LLMs with non-linear activations by partially approximating\nthem with linear functions in frequently occurring input ranges. For outlier\ninputs, TARDIS employs an online predictor to dynamically fall back to original\ncomputations.\n  Our experiments demonstrate that TARDIS achieves 80% parameter reduction in\nfeed-forward networks, while significantly outperforming state-of-the-art\npruning methods Wanda and RIA with up to 65% higher accuracy. In practical\ndeployments for a 7B model, TARDIS achieves 1.6x end-to-end inference speedup\nwhen integrated with the vLLM serving system, and 1.4x speedup with the widely\nadopted HuggingFace implementation, while incurring only a 10.9% accuracy\ntrade-off.\n","authors":["Gansen Hu","Zhaoguo Wang","Jinglin Wei","Wei Huang","Haibo Chen"],"pdf_url":"https://arxiv.org/pdf/2501.10054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10050v1","updated":"2025-01-17T09:13:49Z","published":"2025-01-17T09:13:49Z","title":"Tracking student skills real-time through a continuous-variable dynamic\n  Bayesian network","summary":"  The field of Knowledge Tracing is focused on predicting the success rate of a\nstudent for a given skill. Modern methods like Deep Knowledge Tracing provide\naccurate estimates given enough data, but being based on neural networks they\nstruggle to explain how these estimates are formed. More classical methods like\nDynamic Bayesian Networks can do this, but they cannot give data on the\naccuracy of their estimates and often struggle to incorporate new observations\nin real-time due to their high computational load.\n  This paper presents a novel method, Performance Distribution Tracing (PDT),\nin which the distribution of the success rate is traced live. It uses a Dynamic\nBayesian Network with continuous random variables as nodes. By tracing the\nsuccess rate distribution, there is always data available on the accuracy of\nany success rate estimation. In addition, it makes it possible to combine data\nfrom similar/related skills to come up with a more informed estimate of success\nrates. This makes it possible to predict exercise success rates, providing both\nexplainability and an accuracy indication, even when an exercise requires a\ncombination of different skills to solve. And through the use of the beta\ndistribution functions as conjugate priors, all distributions are available in\nanalytical form, allowing efficient online updates upon new observations.\nExperiments have shown that the resulting estimates generally feel sufficiently\naccurate to end-users such that they accept recommendations based on them.\n","authors":["Hildo Bijl"],"pdf_url":"https://arxiv.org/pdf/2501.10050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10049v1","updated":"2025-01-17T09:10:34Z","published":"2025-01-17T09:10:34Z","title":"PandaSkill -- Player Performance and Skill Rating in Esports:\n  Application to League of Legends","summary":"  To take the esports scene to the next level, we introduce PandaSkill, a\nframework for assessing player performance and skill rating. Traditional rating\nsystems like Elo and TrueSkill often overlook individual contributions and face\nchallenges in professional esports due to limited game data and fragmented\ncompetitive scenes. PandaSkill leverages machine learning to estimate in-game\nplayer performance from individual player statistics. Each in-game role is\nmodeled independently, ensuring a fair comparison between them. Then, using\nthese performance scores, PandaSkill updates the player skill ratings using the\nBayesian framework OpenSkill in a free-for-all setting. In this setting, skill\nratings are updated solely based on performance scores rather than game\noutcomes, hightlighting individual contributions. To address the challenge of\nisolated rating pools that hinder cross-regional comparisons, PandaSkill\nintroduces a dual-rating system that combines players' regional ratings with a\nmeta-rating representing each region's overall skill level. Applying PandaSkill\nto five years of professional League of Legends matches worldwide, we show that\nour method produces skill ratings that better predict game outcomes and align\nmore closely with expert opinions compared to existing methods.\n","authors":["Maxime De Bois","Flora Parmentier","Raphaël Puget","Matthew Tanti","Jordan Peltier"],"pdf_url":"https://arxiv.org/pdf/2501.10049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10048v1","updated":"2025-01-17T09:09:01Z","published":"2025-01-17T09:09:01Z","title":"Virtual Nodes Improve Long-term Traffic Prediction","summary":"  Effective traffic prediction is a cornerstone of intelligent transportation\nsystems, enabling precise forecasts of traffic flow, speed, and congestion.\nWhile traditional spatio-temporal graph neural networks (ST-GNNs) have achieved\nnotable success in short-term traffic forecasting, their performance in\nlong-term predictions remains limited. This challenge arises from\nover-squashing problem, where bottlenecks and limited receptive fields restrict\ninformation flow and hinder the modeling of global dependencies. To address\nthese challenges, this study introduces a novel framework that incorporates\nvirtual nodes, which are additional nodes added to the graph and connected to\nexisting nodes, in order to aggregate information across the entire graph\nwithin a single GNN layer. Our proposed model incorporates virtual nodes by\nconstructing a semi-adaptive adjacency matrix. This matrix integrates\ndistance-based and adaptive adjacency matrices, allowing the model to leverage\ngeographical information while also learning task-specific features from data.\nExperimental results demonstrate that the inclusion of virtual nodes\nsignificantly enhances long-term prediction accuracy while also improving\nlayer-wise sensitivity to mitigate the over-squashing problem. Virtual nodes\nalso offer enhanced explainability by focusing on key intersections and\nhigh-traffic areas, as shown by the visualization of their adjacency matrix\nweights on road network heat maps. Our advanced approach enhances the\nunderstanding and management of urban traffic systems, making it particularly\nwell-suited for real-world applications.\n","authors":["Xiaoyang Cao","Dingyi Zhuang","Jinhua Zhao","Shenhao Wang"],"pdf_url":"https://arxiv.org/pdf/2501.10048v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03703v3","updated":"2025-01-17T09:03:57Z","published":"2024-04-04T07:49:39Z","title":"Mitigating analytical variability in fMRI results with style transfer","summary":"  We propose a novel approach to improve the reproducibility of neuroimaging\nresults by converting statistic maps across different functional MRI pipelines.\nWe make the assumption that pipelines used to compute fMRI statistic maps can\nbe considered as a style component and we propose to use different generative\nmodels, among which, Generative Adversarial Networks (GAN) and Diffusion Models\n(DM) to convert statistic maps across different pipelines. We explore the\nperformance of multiple GAN frameworks, and design a new DM framework for\nunsupervised multi-domain styletransfer. We constrain the generation of 3D fMRI\nstatistic maps using the latent space of an auxiliary classifier that\ndistinguishes statistic maps from different pipelines and extend traditional\nsampling techniques used in DM to improve the transition performance. Our\nexperiments demonstrate that our proposed methods aresuccessful: pipelines can\nindeed be transferred as a style component, providing animportant source of\ndata augmentation for future medical studies.\n","authors":["Elodie Germani","Camille Maumet","Elisa Fromont"],"pdf_url":"https://arxiv.org/pdf/2404.03703v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12709v2","updated":"2025-01-17T09:03:17Z","published":"2024-12-17T09:23:46Z","title":"Accelerating lensed quasars discovery and modeling with physics-informed\n  variational autoencoders","summary":"  Strongly lensed quasars provide valuable insights into the rate of cosmic\nexpansion, the distribution of dark matter in foreground deflectors, and the\ncharacteristics of quasar hosts. However, detecting them in astronomical images\nis difficult due to the prevalence of non-lensing objects. To address this\nchallenge, we developed a generative deep learning model called VariLens, built\nupon a physics-informed variational autoencoder. This model seamlessly\nintegrates three essential modules: image reconstruction, object\nclassification, and lens modeling, offering a fast and comprehensive approach\nto strong lens analysis. VariLens is capable of rapidly determining both (1)\nthe probability that an object is a lens system and (2) key parameters of a\nsingular isothermal ellipsoid (SIE) mass model -- including the Einstein radius\n($\\theta_\\mathrm{E}$), lens center, and ellipticity -- in just milliseconds\nusing a single CPU. A direct comparison of VariLens estimates with traditional\nlens modeling for 20 known lensed quasars within the Subaru Hyper Suprime-Cam\n(HSC) footprint shows good agreement, with both results consistent within\n$2\\sigma$ for systems with $\\theta_\\mathrm{E}<3$ arcsecs. To identify new\nlensed quasar candidates, we begin with an initial sample of approximately 80\nmillion sources, combining HSC data with multiwavelength information from\nvarious surveys. After applying a photometric preselection aimed at locating\n$z>1.5$ sources, the number of candidates is reduced to 710,966. Subsequently,\nVariLens highlights 13,831 sources, each showing a high likelihood of being a\nlens. A visual assessment of these objects results in 42 promising candidates\nthat await spectroscopic confirmation. These results underscore the potential\nof automated deep learning pipelines to efficiently detect and model strong\nlenses in large datasets.\n","authors":["Irham T. Andika","Stefan Schuldt","Sherry H. Suyu","Satadru Bag","Raoul Cañameras","Alejandra Melo","Claudio Grillo","James H. H. Chan"],"pdf_url":"https://arxiv.org/pdf/2412.12709v2.pdf","comment":"Submitted to the Astronomy & Astrophysics journal and updated to\n  reflect the revised version. The paper consists of 17 main pages, 14 figures,\n  and 5 tables. We welcome feedback and comments from readers!"},{"id":"http://arxiv.org/abs/2501.08995v2","updated":"2025-01-17T08:58:48Z","published":"2025-01-15T18:23:33Z","title":"VECT-GAN: A variationally encoded generative model for overcoming data\n  scarcity in pharmaceutical science","summary":"  Data scarcity in pharmaceutical research has led to reliance on\nlabour-intensive trial-and-error approaches for development rather than\ndata-driven methods. While Machine Learning offers a solution, existing\ndatasets are often small and noisy, limiting their utility. To address this, we\ndeveloped a Variationally Encoded Conditional Tabular Generative Adversarial\nNetwork (VECT-GAN), a novel generative model specifically designed for\naugmenting small, noisy datasets. We introduce a pipeline where data is\naugmented before regression model development and demonstrate that this\nconsistently and significantly improves performance over other state-of-the-art\ntabular generative models. We apply this pipeline across six pharmaceutical\ndatasets, and highlight its real-world applicability by developing novel\npolymers with medically desirable mucoadhesive properties, which we made and\nexperimentally characterised. Additionally, we pre-train the model on the\nChEMBL database of drug-like molecules, leveraging knowledge distillation to\nenhance its generalisability, making it readily available for use on\npharmaceutical datasets containing small molecules, an extremely common\npharmaceutical task. We demonstrate the power of synthetic data for\nregularising small tabular datasets, highlighting its potential to become\nstandard practice in pharmaceutical model development, and make our method,\nincluding VECT-GAN pre-trained on ChEMBL available as a pip package.\n","authors":["Youssef Abdalla","Marrisa Taub","Eleanor Hilton","Priya Akkaraju","Alexander Milanovic","Mine Orlu","Abdul W. Basit","Michael T Cook","Tapabrata Chakraborti","David Shorthouse"],"pdf_url":"https://arxiv.org/pdf/2501.08995v2.pdf","comment":"30 pages, 6 primary figures, 3 supplementary figures"},{"id":"http://arxiv.org/abs/2412.04778v2","updated":"2025-01-17T08:58:17Z","published":"2024-12-06T05:00:01Z","title":"IterL2Norm: Fast Iterative L2-Normalization","summary":"  Transformer-based large language models are a memory-bound model whose\noperation is based on a large amount of data that are marginally reused. Thus,\nthe data movement between a host and accelerator likely dictates the total\nwall-clock time. Layer normalization is one of the key workloads in the\ntransformer model, following each of multi-head attention and feed-forward\nnetwork blocks. To reduce data movement, layer normalization needs to be\nperformed on the same chip as the matrix-matrix multiplication engine. To this\nend, we introduce an iterative L2-normalization method for 1D input\n(IterL2Norm), ensuring fast convergence to the steady-state solution within\nfive iteration steps and high precision, outperforming the fast inverse square\nroot algorithm in six out of nine cases for FP32 and five out of nine for\nBFloat16 across the embedding lengths used in the OPT models. Implemented in\n32/28nm CMOS, the IterL2Norm macro normalizes $d$-dimensional vectors, where\n$64 \\leq d \\leq 1024$, with a latency of 116-227 cycles at 100MHz/1.05V.\n","authors":["ChangMin Ye","Yonguk Sim","Youngchae Kim","SeongMin Jin","Doo Seok Jeong"],"pdf_url":"https://arxiv.org/pdf/2412.04778v2.pdf","comment":"Design, Automation & Test in Europe Conference 2025"},{"id":"http://arxiv.org/abs/2501.08305v2","updated":"2025-01-17T08:56:04Z","published":"2025-01-14T18:41:15Z","title":"Benchmarking Graph Representations and Graph Neural Networks for\n  Multivariate Time Series Classification","summary":"  Multivariate Time Series Classification (MTSC) enables the analysis if\ncomplex temporal data, and thus serves as a cornerstone in various real-world\napplications, ranging from healthcare to finance. Since the relationship among\nvariables in MTS usually contain crucial cues, a large number of graph-based\nMTSC approaches have been proposed, as the graph topology and edges can\nexplicitly represent relationships among variables (channels), where not only\nvarious MTS graph representation learning strategies but also different Graph\nNeural Networks (GNNs) have been explored. Despite such progresses, there is no\ncomprehensive study that fairly benchmarks and investigates the performances of\nexisting widely-used graph representation learning strategies/GNN classifiers\nin the application of different MTSC tasks. In this paper, we present the first\nbenchmark which systematically investigates the effectiveness of the\nwidely-used three node feature definition strategies, four edge feature\nlearning strategies and five GNN architecture, resulting in 60 different\nvariants for graph-based MTSC. These variants are developed and evaluated with\na standardized data pipeline and training/validation/testing strategy on 26\nwidely-used suspensor MTSC datasets. Our experiments highlight that node\nfeatures significantly influence MTSC performance, while the visualization of\nedge features illustrates why adaptive edge learning outperforms other edge\nfeature learning methods. The code of the proposed benchmark is publicly\navailable at\n\\url{https://github.com/CVI-yangwn/Benchmark-GNN-for-Multivariate-Time-Series-Classification}.\n","authors":["Wennuo Yang","Shiling Wu","Yuzhi Zhou","Cheng Luo","Xilin He","Weicheng Xie","Linlin Shen","Siyang Song"],"pdf_url":"https://arxiv.org/pdf/2501.08305v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17188v2","updated":"2025-01-17T08:38:45Z","published":"2024-06-25T00:02:01Z","title":"Geometric Median (GM) Matching for Robust Data Pruning","summary":"  Large-scale data collections in the wild, are invariably noisy. Thus\ndeveloping data pruning strategies that remain robust even in the presence of\ncorruption is critical in practice. In this work, we propose Geometric Median\n($\\gm$) Matching -- a herding style greedy algorithm that yields a $k$-subset\nsuch that the mean of the subset approximates the geometric median of the\n(potentially) noisy dataset. Theoretically, we show that $\\gm$ Matching enjoys\nan improved $\\gO(1/k)$ scaling over $\\gO(1/\\sqrt{k})$ scaling of uniform\nsampling; while achieving {\\bf optimal breakdown point} of {\\bf 1/2} even under\n{\\bf arbitrary} corruption. Extensive experiments across several popular deep\nlearning benchmarks indicate that $\\gm$ Matching consistently improves over\nprior state-of-the-art; the gains become more profound at high rates of\ncorruption and aggressive pruning rates; making $\\gm$ Matching a strong\nbaseline for future research in robust data pruning.\n","authors":["Anish Acharya","Inderjit S Dhillon","Sujay Sanghavi"],"pdf_url":"https://arxiv.org/pdf/2406.17188v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12671v4","updated":"2025-01-17T08:14:18Z","published":"2023-10-19T12:00:33Z","title":"Neural networks for insurance pricing with frequency and severity data:\n  a benchmark study from data preprocessing to technical tariff","summary":"  Insurers usually turn to generalized linear models for modeling claim\nfrequency and severity data. Due to their success in other fields, machine\nlearning techniques are gaining popularity within the actuarial toolbox. Our\npaper contributes to the literature on frequency-severity insurance pricing\nwith machine learning via deep learning structures. We present a benchmark\nstudy on four insurance data sets with frequency and severity targets in the\npresence of multiple types of input features. We compare in detail the\nperformance of: a generalized linear model on binned input data, a\ngradient-boosted tree model, a feed-forward neural network (FFNN), and the\ncombined actuarial neural network (CANN). The CANNs combine a baseline\nprediction established with a GLM and GBM, respectively, with a neural network\ncorrection. We explain the data preprocessing steps with specific focus on the\nmultiple types of input features typically present in tabular insurance data\nsets, such as postal codes, numeric and categorical covariates. Autoencoders\nare used to embed the categorical variables into the neural network, and we\nexplore their potential advantages in a frequency-severity setting. Model\nperformance is evaluated not only on out-of-sample deviance but also using\nstatistical and calibration performance criteria and managerial tools to get\nmore nuanced insights. Finally, we construct global surrogate models for the\nneural nets' frequency and severity models. These surrogates enable the\ntranslation of the essential insights captured by the FFNNs or CANNs to GLMs.\nAs such, a technical tariff table results that can easily be deployed in\npractice.\n","authors":["Freek Holvoet","Katrien Antonio","Roel Henckaerts"],"pdf_url":"https://arxiv.org/pdf/2310.12671v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.16105v2","updated":"2025-01-17T08:02:37Z","published":"2023-09-28T02:13:13Z","title":"Differentially Private Secure Multiplication: Hiding Information in the\n  Rubble of Noise","summary":"  We consider the problem of private distributed multi-party multiplication. It\nis well-established that Shamir secret-sharing coding strategies can enable\nperfect information-theoretic privacy in distributed computation via the\ncelebrated algorithm of Ben Or, Goldwasser and Wigderson (the \"BGW algorithm\").\nHowever, perfect privacy and accuracy require an honest majority, that is, $N\n\\geq 2t+1$ compute nodes are required to ensure privacy against any $t$\ncolluding adversarial nodes. By allowing for some controlled amount of\ninformation leakage and approximate multiplication instead of exact\nmultiplication, we study coding schemes for the setting where the number of\nhonest nodes can be a minority, that is $N< 2t+1.$ We develop a tight\ncharacterization privacy-accuracy trade-off for cases where $N < 2t+1$ by\nmeasuring information leakage using {differential} privacy instead of perfect\nprivacy, and using the mean squared error metric for accuracy. A novel\ntechnical aspect is an intricately layered noise distribution that merges ideas\nfrom differential privacy and Shamir secret-sharing at different layers.\n","authors":["Viveck R. Cadambe","Ateet Devulapalli","Haewon Jeong","Flavio P. Calmon"],"pdf_url":"https://arxiv.org/pdf/2309.16105v2.pdf","comment":"Extended version of papers presented in IEEE ISIT 2022, IEEE ISIT\n  2023 and TPDP 2023"},{"id":"http://arxiv.org/abs/2501.10010v1","updated":"2025-01-17T07:48:18Z","published":"2025-01-17T07:48:18Z","title":"Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph\n  Learning","summary":"  Dynamic graph augmentation is used to improve the performance of dynamic\nGNNs. Most methods assume temporal locality, meaning that recent edges are more\ninfluential than earlier edges. However, for temporal changes in edges caused\nby random noise, overemphasizing recent edges while neglecting earlier ones may\nlead to the model capturing noise. To address this issue, we propose STAA\n(SpatioTemporal Activity-Aware Random Walk Diffusion). STAA identifies nodes\nlikely to have noisy edges in spatiotemporal dimensions. Spatially, it analyzes\ncritical topological positions through graph wavelet coefficients. Temporally,\nit analyzes edge evolution through graph wavelet coefficient change rates.\nThen, random walks are used to reduce the weights of noisy edges, deriving a\ndiffusion matrix containing spatiotemporal information as an augmented\nadjacency matrix for dynamic GNN learning. Experiments on multiple datasets\nshow that STAA outperforms other dynamic graph augmentation methods in node\nclassification and link prediction tasks.\n","authors":["Xu Chu","Hanlin Xue","Bingce Wang","Xiaoyang Liu","Weiping Li","Tong Mo","Tuoyu Feng","Zhijie Tan"],"pdf_url":"https://arxiv.org/pdf/2501.10010v1.pdf","comment":"2025 IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2025)"},{"id":"http://arxiv.org/abs/2408.03195v3","updated":"2025-01-17T07:29:14Z","published":"2024-08-06T13:55:51Z","title":"RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning","summary":"  The advent of the \"pre-train, prompt\" paradigm has recently extended its\ngeneralization ability and data efficiency to graph representation learning,\nfollowing its achievements in Natural Language Processing (NLP). Initial graph\nprompt tuning approaches tailored specialized prompting functions for Graph\nNeural Network (GNN) models pre-trained with specific strategies, such as edge\nprediction, thus limiting their applicability. In contrast, another pioneering\nline of research has explored universal prompting via adding prompts to the\ninput graph's feature space, thereby removing the reliance on specific\npre-training strategies. However, the necessity to add feature prompts to all\nnodes remains an open question. Motivated by findings from prompt tuning\nresearch in the NLP domain, which suggest that highly capable pre-trained\nmodels need less conditioning signal to achieve desired behaviors, we advocate\nfor strategically incorporating necessary and lightweight feature prompts to\ncertain graph nodes to enhance downstream task performance. This introduces a\ncombinatorial optimization problem, requiring a policy to decide 1) which nodes\nto prompt and 2) what specific feature prompts to attach. We then address the\nproblem by framing the prompt incorporation process as a sequential\ndecision-making problem and propose our method, RELIEF, which employs\nReinforcement Learning (RL) to optimize it. At each step, the RL agent selects\na node (discrete action) and determines the prompt content (continuous action),\naiming to maximize cumulative performance gain. Extensive experiments on graph\nand node-level tasks with various pre-training strategies in few-shot scenarios\ndemonstrate that our RELIEF outperforms fine-tuning and other prompt-based\napproaches in classification performance and data efficiency. The code is\navailable at https://github.com/JasonZhujp/RELIEF.\n","authors":["Jiapeng Zhu","Zichen Ding","Jianxiang Yu","Jiaqi Tan","Xiang Li","Weining Qian"],"pdf_url":"https://arxiv.org/pdf/2408.03195v3.pdf","comment":"Accepted by SIGKDD 2025 (camera-ready version). Due to the space\n  limitation, please refer to the V2 version for more details"},{"id":"http://arxiv.org/abs/2404.13733v4","updated":"2025-01-17T07:15:16Z","published":"2024-04-21T18:19:27Z","title":"Elucidating the Design Space of Dataset Condensation","summary":"  Dataset condensation, a concept within data-centric learning, efficiently\ntransfers critical attributes from an original dataset to a synthetic version,\nmaintaining both diversity and realism. This approach significantly improves\nmodel training efficiency and is adaptable across multiple application areas.\nPrevious methods in dataset condensation have faced challenges: some incur high\ncomputational costs which limit scalability to larger datasets (e.g., MTT,\nDREAM, and TESLA), while others are restricted to less optimal design spaces,\nwhich could hinder potential improvements, especially in smaller datasets\n(e.g., SRe2L, G-VBSM, and RDED). To address these limitations, we propose a\ncomprehensive design framework that includes specific, effective strategies\nlike implementing soft category-aware matching and adjusting the learning rate\nschedule. These strategies are grounded in empirical evidence and theoretical\nbacking. Our resulting approach, Elucidate Dataset Condensation (EDC),\nestablishes a benchmark for both small and large-scale dataset condensation. In\nour testing, EDC achieves state-of-the-art accuracy, reaching 48.6% on\nImageNet-1k with a ResNet-18 model at an IPC of 10, which corresponds to a\ncompression ratio of 0.78%. This performance exceeds those of SRe2L, G-VBSM,\nand RDED by margins of 27.3%, 17.2%, and 6.6%, respectively.\n","authors":["Shitong Shao","Zikai Zhou","Huanran Chen","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2404.13733v4.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.15084v2","updated":"2025-01-17T07:12:55Z","published":"2024-12-19T17:29:44Z","title":"AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward\n  Modeling","summary":"  In this paper, we introduce AceMath, a suite of frontier math models that\nexcel in solving complex math problems, along with highly effective reward\nmodels capable of evaluating generated solutions and reliably identifying the\ncorrect ones. To develop the instruction-tuned math models, we propose a\nsupervised fine-tuning (SFT) process that first achieves competitive\nperformance across general domains, followed by targeted fine-tuning for the\nmath domain using a carefully curated set of prompts and synthetically\ngenerated responses. The resulting model, AceMath-72B-Instruct greatly\noutperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop\nmath-specialized reward model, we first construct AceMath-RewardBench, a\ncomprehensive and robust benchmark for evaluating math reward models across\ndiverse problems and difficulty levels. After that, we present a systematic\napproach to build our math reward models. The resulting model, AceMath-72B-RM,\nconsistently outperforms state-of-the-art reward models. Furthermore, when\ncombining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest\naverage rm@8 score across the math reasoning benchmarks. We release model\nweights, training data, and evaluation benchmarks at:\nhttps://research.nvidia.com/labs/adlr/acemath\n","authors":["Zihan Liu","Yang Chen","Mohammad Shoeybi","Bryan Catanzaro","Wei Ping"],"pdf_url":"https://arxiv.org/pdf/2412.15084v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.10725v2","updated":"2025-01-17T07:01:43Z","published":"2023-12-17T14:14:31Z","title":"Harnessing small projectors and multiple views for efficient vision\n  pretraining","summary":"  Recent progress in self-supervised (SSL) visual representation learning has\nled to the development of several different proposed frameworks that rely on\naugmentations of images but use different loss functions. However, there are\nfew theoretically grounded principles to guide practice, so practical\nimplementation of each SSL framework requires several heuristics to achieve\ncompetitive performance. In this work, we build on recent analytical results to\ndesign practical recommendations for competitive and efficient SSL that are\ngrounded in theory. Specifically, recent theory tells us that existing SSL\nframeworks are minimizing the same idealized loss, which is to learn features\nthat best match the data similarity kernel defined by the augmentations used.\nWe show how this idealized loss can be reformulated to a functionally\nequivalent loss that is more efficient to compute. We study the implicit bias\nof using gradient descent to minimize our reformulated loss function and find\nthat using a stronger orthogonalization constraint with a reduced projector\ndimensionality should yield good representations. Furthermore, the theory tells\nus that approximating the reformulated loss should be improved by increasing\nthe number of augmentations, and as such using multiple augmentations should\nlead to improved convergence. We empirically verify our findings on CIFAR, STL\nand Imagenet datasets, wherein we demonstrate an improved linear readout\nperformance when training a ResNet-backbone using our theoretically grounded\nrecommendations. Remarkably, we also demonstrate that by leveraging these\ninsights, we can reduce the pretraining dataset size by up to 2$\\times$ while\nmaintaining downstream accuracy simply by using more data augmentations. Taken\ntogether, our work provides theoretically grounded recommendations that can be\nused to improve SSL convergence and efficiency.\n","authors":["Kumar Krishna Agrawal","Arna Ghosh","Shagun Sodhani","Adam Oberman","Blake Richards"],"pdf_url":"https://arxiv.org/pdf/2312.10725v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.09982v1","updated":"2025-01-17T06:46:10Z","published":"2025-01-17T06:46:10Z","title":"RichSpace: Enriching Text-to-Video Prompt Space via Text Embedding\n  Interpolation","summary":"  Text-to-video generation models have made impressive progress, but they still\nstruggle with generating videos with complex features. This limitation often\narises from the inability of the text encoder to produce accurate embeddings,\nwhich hinders the video generation model. In this work, we propose a novel\napproach to overcome this challenge by selecting the optimal text embedding\nthrough interpolation in the embedding space. We demonstrate that this method\nenables the video generation model to produce the desired videos. Additionally,\nwe introduce a simple algorithm using perpendicular foot embeddings and cosine\nsimilarity to identify the optimal interpolation embedding. Our findings\nhighlight the importance of accurate text embeddings and offer a pathway for\nimproving text-to-video generation performance.\n","authors":["Yuefan Cao","Chengyue Gong","Xiaoyu Li","Yingyu Liang","Zhizhou Sha","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2501.09982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18967v2","updated":"2025-01-17T06:44:38Z","published":"2024-11-28T07:36:29Z","title":"Deep Plug-and-Play HIO Approach for Phase Retrieval","summary":"  In the phase retrieval problem, the aim is the recovery of an unknown image\nfrom intensity-only measurements such as Fourier intensity. Although there are\nseveral solution approaches, solving this problem is challenging due to its\nnonlinear and ill-posed nature. Recently, learning-based approaches have\nemerged as powerful alternatives to the analytical methods for several inverse\nproblems. In the context of phase retrieval, a novel plug-and-play approach\nthat exploits learning-based prior and efficient update steps has been\npresented at the Computational Optical Sensing and Imaging topical meeting,\nwith demonstrated state-of-the-art performance. The key idea was to incorporate\nlearning-based prior to the Gerchberg-Saxton type algorithms through\nplug-and-play regularization. In this paper, we present the mathematical\ndevelopment of the method including the derivation of its analytical update\nsteps based on half-quadratic splitting and comparatively evaluate its\nperformance through extensive simulations on a large test dataset. The results\nshow the effectiveness of the method in terms of both image quality,\ncomputational efficiency, and robustness to initialization and noise.\n","authors":["Cagatay Isil","Figen S. Oktem"],"pdf_url":"https://arxiv.org/pdf/2411.18967v2.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.09980v1","updated":"2025-01-17T06:43:03Z","published":"2025-01-17T06:43:03Z","title":"Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm\n  Hemodynamics","summary":"  Intracranial aneurysm (IA) is a common cerebrovascular disease that is\nusually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if\nruptured. Although clinical practice is usually based on individual factors and\nmorphological features of the aneurysm, its pathophysiology and hemodynamic\nmechanisms remain controversial. To address the limitations of current\nresearch, this study constructed a comprehensive hemodynamic dataset of\nintracranial aneurysms. The dataset is based on 466 real aneurysm models, and\n10,000 synthetic models were generated by resection and deformation operations,\nincluding 466 aneurysm-free models and 9,534 deformed aneurysm models. The\ndataset also provides medical image-like segmentation mask files to support\ninsightful analysis. In addition, the dataset contains hemodynamic data\nmeasured at eight steady-state flow rates (0.001 to 0.004 kg/s), including\ncritical parameters such as flow velocity, pressure, and wall shear stress,\nproviding a valuable resource for investigating aneurysm pathogenesis and\nclinical prediction. This dataset will help advance the understanding of the\npathologic features and hemodynamic mechanisms of intracranial aneurysms and\nsupport in-depth research in related fields. Dataset hosted at\nhttps://github.com/Xigui-Li/Aneumo.\n","authors":["Xigui Li","Yuanye Zhou","Feiyang Xiao","Xin Guo","Yichi Zhang","Chen Jiang","Jianchao Ge","Xiansheng Wang","Qimeng Wang","Taiwei Zhang","Chensen Lin","Yuan Cheng","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2501.09980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.13649v2","updated":"2025-01-17T06:38:23Z","published":"2024-08-24T18:30:15Z","title":"Tree-structured Markov random fields with Poisson marginal distributions","summary":"  A new family of tree-structured Markov random fields for a vector of discrete\ncounting random variables is introduced. According to the characteristics of\nthe family, the marginal distributions of the Markov random fields are all\nPoisson with the same mean, and are untied from the strength or structure of\ntheir built-in dependence. This key feature is uncommon for Markov random\nfields and most convenient for applications purposes. The specific properties\nof this new family confer a straightforward sampling procedure and analytic\nexpressions for the joint probability mass function and the joint probability\ngenerating function of the vector of counting random variables, thus granting\ncomputational methods that scale well to vectors of high dimension. We study\nthe distribution of the sum of random variables constituting a Markov random\nfield from the proposed family, analyze a random variable's individual\ncontribution to that sum through expected allocations, and establish stochastic\norderings to assess a wide understanding of their behavior.\n","authors":["Benjamin Côté","Hélène Cossette","Etienne Marceau"],"pdf_url":"https://arxiv.org/pdf/2408.13649v2.pdf","comment":"27 pages, 10 figures"},{"id":"http://arxiv.org/abs/2501.08443v3","updated":"2025-01-17T06:33:23Z","published":"2024-12-26T05:41:31Z","title":"Instruction-Guided Fusion of Multi-Layer Visual Features in Large\n  Vision-Language Models","summary":"  Large Vision-Language Models (LVLMs) have achieved remarkable success in a\nwide range of multimodal tasks by integrating pre-trained vision encoders and\nlarge language models. However, current LVLMs primarily rely on visual features\nextracted from the final layers of the vision encoder, overlooking the\ncomplementary information available in shallower layers. While recent\napproaches have explored the use of multilayer visual features in LVLMs, they\ntend to be task-agnostic and fail to examine the dependencies of hierarchical\nvisual features on specific tasks. To address these gaps, we systematically\ninvestigate the contributions of visual features from different encoder layers\nusing 18 benchmarks spanning 6 task categories. Our findings reveal that\nmultilayer features provide complementary strengths with varying task\ndependencies, and uniform fusion leads to suboptimal performance. Building on\nthese insights, we propose the instruction-guided vision aggregator, a module\nthat dynamically integrates multi-layer visual features based on textual\ninstructions, without increasing the number of visual tokens. Extensive\nevaluations demonstrate the superior performance of our method. Additionally,\nan in-depth analysis of the aggregator's behavior highlights the dominance of\nmid-to-high-level features in semantic-rich tasks and the critical role of\nlow-level features in fine-grained perception.\n","authors":["Xu Li","Yi Zheng","Haotian Chen","Xiaolei Chen","Yuxuan Liang","Chenghang Lai","Bin Li","Xiangyang Xue"],"pdf_url":"https://arxiv.org/pdf/2501.08443v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09967v1","updated":"2025-01-17T06:16:57Z","published":"2025-01-17T06:16:57Z","title":"Explainable artificial intelligence (XAI): from inherent explainability\n  to large language models","summary":"  Artificial Intelligence (AI) has continued to achieve tremendous success in\nrecent times. However, the decision logic of these frameworks is often not\ntransparent, making it difficult for stakeholders to understand, interpret or\nexplain their behavior. This limitation hinders trust in machine learning\nsystems and causes a general reluctance towards their adoption in practical\napplications, particularly in mission-critical domains like healthcare and\nautonomous driving. Explainable AI (XAI) techniques facilitate the\nexplainability or interpretability of machine learning models, enabling users\nto discern the basis of the decision and possibly avert undesirable behavior.\nThis comprehensive survey details the advancements of explainable AI methods,\nfrom inherently interpretable models to modern approaches for achieving\ninterpretability of various black box models, including large language models\n(LLMs). Additionally, we review explainable AI techniques that leverage LLM and\nvision-language model (VLM) frameworks to automate or improve the\nexplainability of other machine learning models. The use of LLM and VLM as\ninterpretability methods particularly enables high-level, semantically\nmeaningful explanations of model decisions and behavior. Throughout the paper,\nwe highlight the scientific principles, strengths and weaknesses of\nstate-of-the-art methods and outline different areas of improvement. Where\nappropriate, we also present qualitative and quantitative comparison results of\nvarious methods to show how they compare. Finally, we discuss the key\nchallenges of XAI and directions for future research.\n","authors":["Fuseini Mumuni","Alhassan Mumuni"],"pdf_url":"https://arxiv.org/pdf/2501.09967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.13632v4","updated":"2025-01-17T06:09:13Z","published":"2023-12-21T07:48:54Z","title":"TraceFL: Interpretability-Driven Debugging in Federated Learning via\n  Neuron Provenance","summary":"  In Federated Learning, clients train models on local data and send updates to\na central server, which aggregates them into a global model using a fusion\nalgorithm. This collaborative yet privacy-preserving training comes at a cost.\nFL developers face significant challenges in attributing global model\npredictions to specific clients. Localizing responsible clients is a crucial\nstep towards (a) excluding clients primarily responsible for incorrect\npredictions and (b) encouraging clients who contributed high-quality models to\ncontinue participating in the future. Existing ML debugging approaches are\ninherently inapplicable as they are designed for single-model, centralized\ntraining.\n  We introduce TraceFL, a fine-grained neuron provenance capturing mechanism\nthat identifies clients responsible for a global model's prediction by tracking\nthe flow of information from individual clients to the global model. Since\ninference on different inputs activates a different set of neurons of the\nglobal model, TraceFL dynamically quantifies the significance of the global\nmodel's neurons in a given prediction, identifying the most crucial neurons in\nthe global model. It then maps them to the corresponding neurons in every\nparticipating client to determine each client's contribution, ultimately\nlocalizing the responsible client. We evaluate TraceFL on six datasets,\nincluding two real-world medical imaging datasets and four neural networks,\nincluding advanced models such as GPT. TraceFL achieves 99% accuracy in\nlocalizing the responsible client in FL tasks spanning both image and text\nclassification tasks. At a time when state-of-the-artML debugging approaches\nare mostly domain-specific (e.g., image classification only), TraceFL is the\nfirst technique to enable highly accurate automated reasoning across a wide\nrange of FL applications.\n","authors":["Waris Gill","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2312.13632v4.pdf","comment":"Accepted at 2025 IEEE/ACM 47th International Conference on Software\n  Engineering (ICSE)"},{"id":"http://arxiv.org/abs/2302.04344v3","updated":"2025-01-17T05:21:29Z","published":"2023-02-08T21:27:16Z","title":"Learning Dynamical Systems by Leveraging Data from Similar Systems","summary":"  We consider the problem of learning the dynamics of a linear system when one\nhas access to data generated by an auxiliary system that shares similar (but\nnot identical) dynamics, in addition to data from the true system. We use a\nweighted least squares approach, and provide finite sample error bounds of the\nlearned model as a function of the number of samples and various system\nparameters from the two systems as well as the weight assigned to the auxiliary\ndata. We show that the auxiliary data can help to reduce the intrinsic system\nidentification error due to noise, at the price of adding a portion of error\nthat is due to the differences between the two system models. We further\nprovide a data-dependent bound that is computable when some prior knowledge\nabout the systems, such as upper bounds on noise levels and model difference,\nis available. This bound can also be used to determine the weight that should\nbe assigned to the auxiliary data during the model training stage.\n","authors":["Lei Xin","Lintao Ye","George Chiu","Shreyas Sundaram"],"pdf_url":"https://arxiv.org/pdf/2302.04344v3.pdf","comment":"15 pages,9 figures"},{"id":"http://arxiv.org/abs/2501.09954v1","updated":"2025-01-17T04:57:42Z","published":"2025-01-17T04:57:42Z","title":"AIRCHITECT v2: Learning the Hardware Accelerator Design Space through\n  Unified Representations","summary":"  Design space exploration (DSE) plays a crucial role in enabling custom\nhardware architectures, particularly for emerging applications like AI, where\noptimized and specialized designs are essential. With the growing complexity of\ndeep neural networks (DNNs) and the introduction of advanced foundational\nmodels (FMs), the design space for DNN accelerators is expanding at an\nexponential rate. Additionally, this space is highly non-uniform and\nnon-convex, making it increasingly difficult to navigate and optimize.\nTraditional DSE techniques rely on search-based methods, which involve\niterative sampling of the design space to find the optimal solution. However,\nthis process is both time-consuming and often fails to converge to the global\noptima for such design spaces. Recently, AIrchitect v1, the first attempt to\naddress the limitations of search-based techniques, transformed DSE into a\nconstant-time classification problem using recommendation networks. In this\nwork, we propose AIrchitect v2, a more accurate and generalizable\nlearning-based DSE technique applicable to large-scale design spaces that\novercomes the shortcomings of earlier approaches. Specifically, we devise an\nencoder-decoder transformer model that (a) encodes the complex design space\ninto a uniform intermediate representation using contrastive learning and (b)\nleverages a novel unified representation blending the advantages of\nclassification and regression to effectively explore the large DSE space\nwithout sacrificing accuracy. Experimental results evaluated on 10^5 real DNN\nworkloads demonstrate that, on average, AIrchitect v2 outperforms existing\ntechniques by 15% in identifying optimal design points. Furthermore, to\ndemonstrate the generalizability of our method, we evaluate performance on\nunseen model workloads (LLMs) and attain a 1.7x improvement in inference\nlatency on the identified hardware architecture.\n","authors":["Jamin Seo","Akshat Ramachandran","Yu-Chuan Chuang","Anirudh Itagi","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2501.09954v1.pdf","comment":"Accepted to DATE 2025"},{"id":"http://arxiv.org/abs/2411.10435v2","updated":"2025-01-17T04:53:18Z","published":"2024-11-15T18:56:00Z","title":"The Spatial Complexity of Optical Computing and How to Reduce It","summary":"  Similar to algorithms, which consume time and memory to run, hardware\nrequires resources to function. For devices processing physical waves,\nimplementing operations needs sufficient \"space,\" as dictated by wave physics.\nHow much space is needed to perform a certain function is a fundamental\nquestion in optics, with recent research addressing it for given mathematical\noperations, but not for more general computing tasks, e.g., classification.\nInspired by computational complexity theory, we study the \"spatial complexity\"\nof optical computing systems in terms of scaling laws - specifically, how their\nphysical dimensions must scale as the dimension of the mathematical operation\nincreases - and propose a new paradigm for designing optical computing systems:\nspace-efficient neuromorphic optics, based on structural sparsity constraints\nand neural pruning methods motivated by wave physics (notably, the concept of\n\"overlapping nonlocality\"). On two mainstream platforms, free-space optics and\non-chip integrated photonics, our methods demonstrate substantial size\nreductions (to 1%-10% the size of conventional designs) with minimal compromise\non performance. Our theoretical and computational results reveal a trend of\ndiminishing returns on accuracy as structure dimensions increase, providing a\nnew perspective for interpreting and approaching the ultimate limits of optical\ncomputing - a balanced trade-off between device size and accuracy.\n","authors":["Yandong Li","Francesco Monticone"],"pdf_url":"https://arxiv.org/pdf/2411.10435v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17308v2","updated":"2025-01-17T04:30:17Z","published":"2024-09-25T19:35:58Z","title":"Consistent estimation of generative model representations in the data\n  kernel perspective space","summary":"  Generative models, such as large language models and text-to-image diffusion\nmodels, produce relevant information when presented a query. Different models\nmay produce different information when presented the same query. As the\nlandscape of generative models evolves, it is important to develop techniques\nto study and analyze differences in model behaviour. In this paper we present\nnovel theoretical results for embedding-based representations of generative\nmodels in the context of a set of queries. In particular, we establish\nsufficient conditions for the consistent estimation of the model embeddings in\nsituations where the query set and the number of models grow.\n","authors":["Aranyak Acharyya","Michael W. Trosset","Carey E. Priebe","Hayden S. Helm"],"pdf_url":"https://arxiv.org/pdf/2409.17308v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09949v1","updated":"2025-01-17T04:24:31Z","published":"2025-01-17T04:24:31Z","title":"MultiPruner: Balanced Structure Removal in Foundation Models","summary":"  Recently, state-of-the-art approaches for pruning large pre-trained models\n(LPMs) have demonstrated that the training-free removal of non-critical\nresidual blocks in Transformers is viable for reducing model size, achieving\nresults that outperform previous training-free pruning approaches. Motivated by\nthese findings, we extend BlockPruner (Zhong et al., 2024) and propose\nMultiPruner, a pruning approach that surpasses recent training-free pruning\nmethods by adopting a multidimensional, iterative, fine-grained pruning\nstrategy. In MultiPruner, multidimensional pruning reinstates the structural\nbalance in block-pruned models by sequentially compressing along three\ndimensions: i) residual blocks, ii) channels of multilayer perceptrons (MLP),\nand iii) attention heads. This solution enhances zero-shot accuracy on\ndownstream tasks compared to other techniques while improving model compression\nratios, producing compressed models with fewer computing and memory\nrequirements. Extensive experiments demonstrate the advantages of the proposed\nmethod across various large pre-trained models. The code and pruning\nconfigurations are available at\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.\n","authors":["J. Pablo Muñoz","Jinjie Yuan","Nilesh Jain"],"pdf_url":"https://arxiv.org/pdf/2501.09949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.11156v4","updated":"2025-01-17T04:21:47Z","published":"2023-03-17T17:53:19Z","title":"Can AI-Generated Text be Reliably Detected?","summary":"  Large Language Models (LLMs) perform impressively well in various\napplications. However, the potential for misuse of these models in activities\nsuch as plagiarism, generating fake news, and spamming has raised concern about\ntheir responsible use. Consequently, the reliable detection of AI-generated\ntext has become a critical area of research. AI text detectors have shown to be\neffective under their specific settings. In this paper, we stress-test the\nrobustness of these AI text detectors in the presence of an attacker. We\nintroduce recursive paraphrasing attack to stress test a wide range of\ndetection schemes, including the ones using the watermarking as well as neural\nnetwork-based detectors, zero shot classifiers, and retrieval-based detectors.\nOur experiments conducted on passages, each approximately 300 tokens long,\nreveal the varying sensitivities of these detectors to our attacks. Our\nfindings indicate that while our recursive paraphrasing method can\nsignificantly reduce detection rates, it only slightly degrades text quality in\nmany cases, highlighting potential vulnerabilities in current detection systems\nin the presence of an attacker. Additionally, we investigate the susceptibility\nof watermarked LLMs to spoofing attacks aimed at misclassifying human-written\ntext as AI-generated. We demonstrate that an attacker can infer hidden AI text\nsignatures without white-box access to the detection method, potentially\nleading to reputational risks for LLM developers. Finally, we provide a\ntheoretical framework connecting the AUROC of the best possible detector to the\nTotal Variation distance between human and AI text distributions. This analysis\noffers insights into the fundamental challenges of reliable detection as\nlanguage models continue to advance. Our code is publicly available at\nhttps://github.com/vinusankars/Reliability-of-AI-text-detectors.\n","authors":["Vinu Sankar Sadasivan","Aounon Kumar","Sriram Balasubramanian","Wenxiao Wang","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2303.11156v4.pdf","comment":"Published in Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2501.09946v1","updated":"2025-01-17T04:00:50Z","published":"2025-01-17T04:00:50Z","title":"Client-Centric Federated Adaptive Optimization","summary":"  Federated Learning (FL) is a distributed learning paradigm where clients\ncollaboratively train a model while keeping their own data private. With an\nincreasing scale of clients and models, FL encounters two key challenges,\nclient drift due to a high degree of statistical/system heterogeneity, and lack\nof adaptivity. However, most existing FL research is based on unrealistic\nassumptions that virtually ignore system heterogeneity. In this paper, we\npropose Client-Centric Federated Adaptive Optimization, which is a class of\nnovel federated adaptive optimization approaches. We enable several features in\nthis framework such as arbitrary client participation, asynchronous server\naggregation, and heterogeneous local computing, which are ubiquitous in\nreal-world FL systems but are missed in most existing works. We provide a\nrigorous convergence analysis of our proposed framework for general nonconvex\nobjectives, which is shown to converge with the best-known rate. Extensive\nexperiments show that our approaches consistently outperform the baseline by a\nlarge margin across benchmarks.\n","authors":["Jianhui Sun","Xidong Wu","Heng Huang","Aidong Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.09946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13238v4","updated":"2025-01-17T03:44:29Z","published":"2024-05-21T22:53:00Z","title":"Enhancing User Interest based on Stream Clustering and Memory Networks\n  in Large-Scale Recommender Systems","summary":"  Recommender Systems (RSs) provide personalized recommendation service based\non user interest, which are widely used in various platforms. However, there\nare lots of users with sparse interest due to lacking consumption behaviors,\nwhich leads to poor recommendation results for them. This problem is widespread\nin large-scale RSs and is particularly difficult to address. To solve this\nproblem, we propose a novel solution named User Interest Enhancement (UIE)\nwhich enhances user interest including user profile and user history behavior\nsequences using the enhancement vectors and personalized enhancement vector\ngenerated based on stream clustering and memory networks from different\nperspectives. UIE not only remarkably improves model performance on the users\nwith sparse interest but also significantly enhance model performance on other\nusers. UIE is an end-to-end solution which is easy to be implemented based on\nranking model. Moreover, we expand our solution and apply similar methods to\nlong-tail items, which also achieves excellent improvement. Furthermore, we\nconduct extensive offline and online experiments in a large-scale industrial\nRS. The results demonstrate that our model outperforms other models remarkably,\nespecially for the users with sparse interest. Until now, UIE has been fully\ndeployed in multiple large-scale RSs and achieved remarkable improvements.\n","authors":["Peng Liu","Nian Wang","Cong Xu","Ming Zhao","Bin Wang","Yi Ren"],"pdf_url":"https://arxiv.org/pdf/2405.13238v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16950v5","updated":"2025-01-17T03:43:53Z","published":"2024-03-25T17:11:28Z","title":"Aligning with Human Judgement: The Role of Pairwise Preference in Large\n  Language Model Evaluators","summary":"  Large Language Models (LLMs) have demonstrated promising capabilities as\nautomatic evaluators in assessing the quality of generated natural language.\nHowever, LLMs still exhibit biases in evaluation and often struggle to generate\ncoherent evaluations that align with human assessments. In this work, we first\nconduct a systematic study of the misalignment between LLM evaluators and human\nevaluation, revealing that existing calibration methods aimed at mitigating\nbiases of LLMs are insufficient for effectively aligning LLM evaluators.\nInspired by the use of preference data in RLHF, we formulate the evaluation as\na ranking problem and introduce Pairwise-preference Search (PAIRS), an\nuncertainty-guided search-based rank aggregation method that employs LLMs to\nconduct pairwise comparisons locally and efficiently ranks candidate texts\nglobally. PAIRS achieves state-of-the-art performance on representative\nevaluation tasks in long-form generations and demonstrates significant\nimprovements over direct scoring. Furthermore, we provide insights into the\nrole of pairwise preference in quantifying the transitivity of LLMs and\ndemonstrate how PAIRS benefits from calibration using debiased pairwise\nevaluations.\n","authors":["Yinhong Liu","Han Zhou","Zhijiang Guo","Ehsan Shareghi","Ivan Vulić","Anna Korhonen","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2403.16950v5.pdf","comment":"This paper has been accepted by COLM 2024"},{"id":"http://arxiv.org/abs/2501.09938v1","updated":"2025-01-17T03:29:41Z","published":"2025-01-17T03:29:41Z","title":"A Multi-Scale Feature Extraction and Fusion Deep Learning Method for\n  Classification of Wheat Diseases","summary":"  Wheat is an important source of dietary fiber and protein that is negatively\nimpacted by a number of risks to its growth. The difficulty of identifying and\nclassifying wheat diseases is discussed with an emphasis on wheat loose smut,\nleaf rust, and crown and root rot. Addressing conditions like crown and root\nrot, this study introduces an innovative approach that integrates multi-scale\nfeature extraction with advanced image segmentation techniques to enhance\nclassification accuracy. The proposed method uses neural network models\nXception, Inception V3, and ResNet 50 to train on a large wheat disease\nclassification dataset 2020 in conjunction with an ensemble of machine vision\nclassifiers, including voting and stacking. The study shows that the suggested\nmethodology has a superior accuracy of 99.75% in the classification of wheat\ndiseases when compared to current state-of-the-art approaches. A deep learning\nensemble model Xception showed the highest accuracy.\n","authors":["Sajjad Saleem","Adil Hussain","Nabila Majeed","Zahid Akhtar","Kamran Siddique"],"pdf_url":"https://arxiv.org/pdf/2501.09938v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09934v1","updated":"2025-01-17T03:15:03Z","published":"2025-01-17T03:15:03Z","title":"HEART: Achieving Timely Multi-Model Training for\n  Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning","summary":"  The rapid growth of AI-enabled Internet of Vehicles (IoV) calls for efficient\nmachine learning (ML) solutions that can handle high vehicular mobility and\ndecentralized data. This has motivated the emergence of Hierarchical Federated\nLearning over vehicle-edge-cloud architectures (VEC-HFL). Nevertheless, one\naspect which is underexplored in the literature on VEC-HFL is that vehicles\noften need to execute multiple ML tasks simultaneously, where this multi-model\ntraining environment introduces crucial challenges. First, improper aggregation\nrules can lead to model obsolescence and prolonged training times. Second,\nvehicular mobility may result in inefficient data utilization by preventing the\nvehicles from returning their models to the network edge. Third, achieving a\nbalanced resource allocation across diverse tasks becomes of paramount\nimportance as it majorly affects the effectiveness of collaborative training.\nWe take one of the first steps towards addressing these challenges via\nproposing a framework for multi-model training in dynamic VEC-HFL with the goal\nof minimizing global training latency while ensuring balanced training across\nvarious tasks-a problem that turns out to be NP-hard. To facilitate timely\nmodel training, we introduce a hybrid synchronous-asynchronous aggregation\nrule. Building on this, we present a novel method called Hybrid Evolutionary\nAnd gReedy allocaTion (HEART). The framework operates in two stages: first, it\nachieves balanced task scheduling through a hybrid heuristic approach that\ncombines improved Particle Swarm Optimization (PSO) and Genetic Algorithms\n(GA); second, it employs a low-complexity greedy algorithm to determine the\ntraining priority of assigned tasks on vehicles. Experiments on real-world\ndatasets demonstrate the superiority of HEART over existing methods.\n","authors":["Xiaohong Yang","Minghui Liwang","Xianbin Wang","Zhipeng Cheng","Seyyedali Hosseinalipour","Huaiyu Dai","Zhenzhen Jiao"],"pdf_url":"https://arxiv.org/pdf/2501.09934v1.pdf","comment":"14 pages, 6 figures,"},{"id":"http://arxiv.org/abs/2501.09933v1","updated":"2025-01-17T03:14:43Z","published":"2025-01-17T03:14:43Z","title":"Statistical Inference for Sequential Feature Selection after Domain\n  Adaptation","summary":"  In high-dimensional regression, feature selection methods, such as sequential\nfeature selection (SeqFS), are commonly used to identify relevant features.\nWhen data is limited, domain adaptation (DA) becomes crucial for transferring\nknowledge from a related source domain to a target domain, improving\ngeneralization performance. Although SeqFS after DA is an important task in\nmachine learning, none of the existing methods can guarantee the reliability of\nits results. In this paper, we propose a novel method for testing the features\nselected by SeqFS-DA. The main advantage of the proposed method is its\ncapability to control the false positive rate (FPR) below a significance level\n$\\alpha$ (e.g., 0.05). Additionally, a strategic approach is introduced to\nenhance the statistical power of the test. Furthermore, we provide extensions\nof the proposed method to SeqFS with model selection criteria including AIC,\nBIC, and adjusted R-squared. Extensive experiments are conducted on both\nsynthetic and real-world datasets to validate the theoretical results and\ndemonstrate the proposed method's superior performance.\n","authors":["Duong Tan Loc","Nguyen Thang Loi","Vo Nguyen Le Duy"],"pdf_url":"https://arxiv.org/pdf/2501.09933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10960v4","updated":"2025-01-17T03:09:24Z","published":"2024-07-15T17:55:42Z","title":"Fast Matrix Multiplications for Lookup Table-Quantized LLMs","summary":"  The deployment of large language models (LLMs) is often constrained by memory\nbandwidth, where the primary bottleneck is the cost of transferring model\nparameters from the GPU's global memory to its registers. When coupled with\ncustom kernels that fuse the dequantization and matmul operations, weight-only\nquantization can thus enable faster inference by reducing the amount of memory\nmovement. However, developing high-performance kernels for weight-quantized\nLLMs presents substantial challenges, especially when the weights are\ncompressed to non-evenly-divisible bit widths (e.g., 3 bits) with non-uniform,\nlookup table (LUT) quantization. This paper describes FLUTE, a flexible lookup\ntable engine for LUT-quantized LLMs, which uses offline restructuring of the\nquantized weight matrix to minimize bit manipulations associated with\nunpacking, and vectorization and duplication of the lookup table to mitigate\nshared memory bandwidth constraints. At batch sizes < 32 and quantization group\nsize of 128 (typical in LLM inference), the FLUTE kernel can be 2-4x faster\nthan existing GEMM kernels. As an application of FLUTE, we explore a simple\nextension to lookup table-based NormalFloat quantization and apply it to\nquantize LLaMA3 to various configurations, obtaining competitive quantization\nperformance against strong baselines while obtaining an end-to-end throughput\nincrease of 1.5 to 2 times.\n","authors":["Han Guo","William Brandon","Radostin Cholakov","Jonathan Ragan-Kelley","Eric P. Xing","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2407.10960v4.pdf","comment":"EMNLP 2024 (Findings)"},{"id":"http://arxiv.org/abs/2501.09929v1","updated":"2025-01-17T02:55:23Z","published":"2025-01-17T02:55:23Z","title":"Steering Large Language Models with Feature Guided Activation Additions","summary":"  Effective and reliable control over large language model (LLM) behavior is a\nsignificant challenge. While activation steering methods, which add steering\nvectors to a model's hidden states, are a promising approach, existing\ntechniques often lack precision and interpretability in how they influence\nmodel outputs. We introduce Feature Guided Activation Additions (FGAA), a novel\nactivation steering method that leverages insights from Contrastive Activation\nAddition (CAA) and Sparse Autoencoder-Targeted Steering (SAE-TS). By operating\nin the latent space of a Sparse Autoencoder (SAE) and employing optimization\ntechniques to select desired SAE features, FGAA constructs precise steering\nvectors that provide better steering effects while maintaining coherence of\nsteered model outputs. In this regard, evaluations on Gemma-2-2B and Gemma-2-9B\nmodels across various steering tasks demonstrate that FGAA outperforms existing\nsteering methods of CAA, SAE decoder steering, and SAE-TS. Our results also\nhighlight important trade-offs between steering scale and general model\ncapabilities that are consistent across all tested steering methods.\n","authors":["Samuel Soo","Wesley Teng","Chandrasekaran Balaganesh"],"pdf_url":"https://arxiv.org/pdf/2501.09929v1.pdf","comment":"7 maintext pages, 14 appendix pages"},{"id":"http://arxiv.org/abs/2412.15559v3","updated":"2025-01-17T02:50:03Z","published":"2024-12-20T04:36:58Z","title":"Spatial Clustering of Citizen Science Data Improves Downstream Species\n  Distribution Models","summary":"  Citizen science biodiversity data present great opportunities for ecology and\nconservation across vast spatial and temporal scales. However, the\nopportunistic nature of these data lacks the sampling structure required by\nmodeling methodologies that address a pervasive challenge in ecological data\ncollection: imperfect detection, i.e., the likelihood of under-observing\nspecies on field surveys. Occupancy modeling is an example of an approach that\naccounts for imperfect detection by explicitly modeling the observation process\nseparately from the biological process of habitat selection. This produces\nspecies distribution models that speak to the pattern of the species on a\nlandscape after accounting for imperfect detection in the data, rather than the\npattern of species observations corrupted by errors. To achieve this benefit,\noccupancy models require multiple surveys of a site across which the site's\nstatus (i.e., occupied or not) is assumed constant. Since citizen science data\nare not collected under the required repeated-visit protocol, observations may\nbe grouped into sites post hoc. Existing approaches for constructing sites\ndiscard some observations and/or consider only geographic distance and not\nenvironmental similarity. In this study, we compare ten approaches for site\nconstruction in terms of their impact on downstream species distribution models\nfor 31 bird species in Oregon, using observations recorded in the eBird\ndatabase. We find that occupancy models built on sites constructed by spatial\nclustering algorithms perform better than existing alternatives.\n","authors":["Nahian Ahmed","Mark Roth","Tyler A. Hallman","W. Douglas Robinson","Rebecca A. Hutchinson"],"pdf_url":"https://arxiv.org/pdf/2412.15559v3.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2501.09923v1","updated":"2025-01-17T02:40:04Z","published":"2025-01-17T02:40:04Z","title":"Study on a Fast Solver for Combined Field Integral Equations of 3D\n  Conducting Bodies Based on Graph Neural Networks","summary":"  In this paper, we present a graph neural networks (GNNs)-based fast solver\n(GraphSolver) for solving combined field integral equations (CFIEs) of 3D\nconducting bodies. Rao-Wilton-Glisson (RWG) basis functions are employed to\ndiscretely and accurately represent the geometry of 3D conducting bodies. A\nconcise and informative graph representation is then constructed by treating\neach RWG function as a node in the graph, enabling the flow of current between\nnodes. With the transformed graphs, GraphSolver is developed to directly\npredict real and imaginary parts of the x, y and z components of the surface\ncurrent densities at each node (RWG function). Numerical results demonstrate\nthe efficacy of GraphSolver in solving CFIEs for 3D conducting bodies with\nvarying levels of geometric complexity, including basic 3D targets,\nmissile-shaped targets, and airplane-shaped targets.\n","authors":["Tao Shan","Xin Zhang","Di Wu"],"pdf_url":"https://arxiv.org/pdf/2501.09923v1.pdf","comment":"10 pages,11 figures"},{"id":"http://arxiv.org/abs/2402.05982v3","updated":"2025-01-17T02:28:17Z","published":"2024-02-08T13:02:05Z","title":"Decoupled Sequence and Structure Generation for Realistic Antibody\n  Design","summary":"  Recently, deep learning has made rapid progress in antibody design, which\nplays a key role in the advancement of therapeutics. A dominant paradigm is to\ntrain a model to jointly generate the antibody sequence and the structure as a\ncandidate. However, the joint generation requires the model to generate both\nthe discrete amino acid categories and the continuous 3D coordinates; this\nlimits the space of possible architectures and may lead to suboptimal\nperformance. In response, we propose an antibody sequence-structure decoupling\n(ASSD) framework, which separates sequence generation and structure prediction.\nAlthough our approach is simple, our idea allows the use of powerful neural\narchitectures and demonstrates notable performance improvements. We also find\nthat the widely used non-autoregressive generators promote sequences with\noverly repeating tokens. Such sequences are both out-of-distribution and prone\nto undesirable developability properties that can trigger harmful immune\nresponses in patients. To resolve this, we introduce a composition-based\nobjective that allows an efficient trade-off between high performance and low\ntoken repetition. ASSD shows improved performance in various antibody design\nexperiments, while the composition-based objective successfully mitigates token\nrepetition of non-autoregressive models.\n","authors":["Nayoung Kim","Minsu Kim","Sungsoo Ahn","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2402.05982v3.pdf","comment":"22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.14440v3","updated":"2025-01-17T01:49:21Z","published":"2024-05-23T11:14:35Z","title":"Bayesian Adaptive Calibration and Optimal Design","summary":"  The process of calibrating computer models of natural phenomena is essential\nfor applications in the physical sciences, where plenty of domain knowledge can\nbe embedded into simulations and then calibrated against real observations.\nCurrent machine learning approaches, however, mostly rely on rerunning\nsimulations over a fixed set of designs available in the observed data,\npotentially neglecting informative correlations across the design space and\nrequiring a large amount of simulations. Instead, we consider the calibration\nprocess from the perspective of Bayesian adaptive experimental design and\npropose a data-efficient algorithm to run maximally informative simulations\nwithin a batch-sequential process. At each round, the algorithm jointly\nestimates the parameters of the posterior distribution and optimal designs by\nmaximising a variational lower bound of the expected information gain. The\nsimulator is modelled as a sample from a Gaussian process, which allows us to\ncorrelate simulations and observed data with the unknown calibration\nparameters. We show the benefits of our method when compared to related\napproaches across synthetic and real-data problems.\n","authors":["Rafael Oliveira","Dino Sejdinovic","David Howard","Edwin V. Bonilla"],"pdf_url":"https://arxiv.org/pdf/2405.14440v3.pdf","comment":"NeurIPS 2024 final revision"},{"id":"http://arxiv.org/abs/2402.18540v2","updated":"2025-01-17T01:43:21Z","published":"2024-02-28T18:23:49Z","title":"Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt\n  Templates","summary":"  Public LLMs such as the Llama 2-Chat underwent alignment training and were\nconsidered safe. Recently Qi et al. [2024] reported that even benign\nfine-tuning on seemingly safe datasets can give rise to unsafe behaviors in the\nmodels. The current paper is about methods and best practices to mitigate such\nloss of alignment. We focus on the setting where a public model is fine-tuned\nbefore serving users for specific usage, where the model should improve on the\ndownstream task while maintaining alignment. Through extensive experiments on\nseveral chat models (Meta's Llama 2-Chat, Mistral AI's Mistral 7B Instruct\nv0.2, and OpenAI's GPT-3.5 Turbo), this paper uncovers that the prompt\ntemplates used during fine-tuning and inference play a crucial role in\npreserving safety alignment, and proposes the ``Pure Tuning, Safe Testing''\n(PTST) strategy -- fine-tune models without a safety prompt, but include it at\ntest time. This seemingly counterintuitive strategy incorporates an intended\ndistribution shift to encourage alignment preservation. Fine-tuning experiments\non GSM8K, ChatDoctor, and OpenOrca show that PTST significantly reduces the\nrise of unsafe behaviors.\n","authors":["Kaifeng Lyu","Haoyu Zhao","Xinran Gu","Dingli Yu","Anirudh Goyal","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2402.18540v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.09905v1","updated":"2025-01-17T01:32:18Z","published":"2025-01-17T01:32:18Z","title":"SLIM: Sim-to-Real Legged Instructive Manipulation via Long-Horizon\n  Visuomotor Learning","summary":"  We present a low-cost quadruped manipulation system that solves long-horizon\nreal-world tasks, trained by reinforcement learning purely in simulation. The\nsystem comprises 1) a hierarchical design of a high-level policy for\nvisual-mobile manipulation following instructions, and a low-level policy for\nquadruped movement and limb-control, 2) a progressive policy expansion approach\nfor solving the long-horizon task together with a teacher-student framework for\nefficient high-level training of the high-level visuomotor policy, and 3) a\nsuite of techniques for minimizing sim-to-real gaps.\n  With budget-friendly but limited reliability and performance hardware, and\njust one wrist-mounted RGB camera, the entire system fully trained in\nsimulation achieves high success rates for long horizon tasks involving search,\nmove, grasp, and drop-into, with fluid sim-to-real transfer in a wide variety\nof indoor and outdoor scenes and lighting conditions.Extensive real-world\nevaluations show that on the long horizon mobile manipulation tasks, our system\nachieves good performance when transferred to real both in terms of task\nsuccess rate and execution efficiency. Finally, we discuss the necessity of our\nsim-to-real techniques for legged mobile manipulation, and show their ablation\nperformance.\n","authors":["Haichao Zhang","Haonan Yu","Le Zhao","Andrew Choi","Qinxun Bai","Yiqing Yang","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2501.09905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09900v1","updated":"2025-01-17T01:13:44Z","published":"2025-01-17T01:13:44Z","title":"SBAMDT: Bayesian Additive Decision Trees with Adaptive Soft\n  Semi-multivariate Split Rules","summary":"  Bayesian Additive Regression Trees [BART, Chipman et al., 2010] have gained\nsignificant popularity due to their remarkable predictive performance and\nability to quantify uncertainty. However, standard decision tree models rely on\nrecursive data splits at each decision node, using deterministic decision rules\nbased on a single univariate feature. This approach limits their ability to\neffectively capture complex decision boundaries, particularly in scenarios\ninvolving multiple features, such as spatial domains, or when transitions are\neither sharp or smoothly varying. In this paper, we introduce a novel\nprobabilistic additive decision tree model that employs a soft split rule. This\nmethod enables highly flexible splits that leverage both univariate and\nmultivariate features, while also respecting the geometric properties of the\nfeature domain. Notably, the probabilistic split rule adapts dynamically across\ndecision nodes, allowing the model to account for varying levels of smoothness\nin the regression function. We demonstrate the utility of the proposed model\nthrough comparisons with existing tree-based models on synthetic datasets and a\nNew York City education dataset.\n","authors":["Stamatina Lamprinakou","Huiyan Sang","Bledar A. Konomi","Ligang Lu"],"pdf_url":"https://arxiv.org/pdf/2501.09900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04421v2","updated":"2025-01-17T01:11:16Z","published":"2024-09-06T17:30:45Z","title":"RLPF: Reinforcement Learning from Prediction Feedback for User\n  Summarization with LLMs","summary":"  LLM-powered personalization agent systems employ Large Language Models (LLMs)\nto predict users' behavior from their past activities. However, their\neffectiveness often hinges on the ability to effectively leverage extensive,\nlong user historical data due to its inherent noise and length of such data.\nExisting pretrained LLMs may generate summaries that are concise but lack the\nnecessary context for downstream tasks, hindering their utility in\npersonalization systems. To address these challenges, we introduce\nReinforcement Learning from Prediction Feedback (RLPF). RLPF fine-tunes LLMs to\ngenerate concise, human-readable user summaries that are optimized for\ndownstream task performance. By maximizing the usefulness of the generated\nsummaries, RLPF effectively distills extensive user history data while\npreserving essential information for downstream tasks. Our empirical evaluation\ndemonstrates significant improvements in both extrinsic downstream task utility\nand intrinsic summary quality, surpassing baseline methods by up to 22% on\ndownstream task performance and achieving an up to 84.59% win rate on\nFactuality, Abstractiveness, and Readability. RLPF also achieves a remarkable\n74% reduction in context length while improving performance on 16 out of 19\nunseen tasks and/or datasets, showcasing its generalizability. This approach\noffers a promising solution for enhancing LLM personalization by effectively\ntransforming long, noisy user histories into informative and human-readable\nrepresentations.\n","authors":["Jiaxing Wu","Lin Ning","Luyang Liu","Harrison Lee","Neo Wu","Chao Wang","Sushant Prakash","Shawn O'Banion","Bradley Green","Jun Xie"],"pdf_url":"https://arxiv.org/pdf/2409.04421v2.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2501.09898v1","updated":"2025-01-17T01:01:44Z","published":"2025-01-17T01:01:44Z","title":"FoundationStereo: Zero-Shot Stereo Matching","summary":"  Tremendous progress has been made in deep stereo matching to excel on\nbenchmark datasets through per-domain fine-tuning. However, achieving strong\nzero-shot generalization - a hallmark of foundation models in other computer\nvision tasks - remains challenging for stereo matching. We introduce\nFoundationStereo, a foundation model for stereo depth estimation designed to\nachieve strong zero-shot generalization. To this end, we first construct a\nlarge-scale (1M stereo pairs) synthetic training dataset featuring large\ndiversity and high photorealism, followed by an automatic self-curation\npipeline to remove ambiguous samples. We then design a number of network\narchitecture components to enhance scalability, including a side-tuning feature\nbackbone that adapts rich monocular priors from vision foundation models to\nmitigate the sim-to-real gap, and long-range context reasoning for effective\ncost volume filtering. Together, these components lead to strong robustness and\naccuracy across domains, establishing a new standard in zero-shot stereo depth\nestimation.\n","authors":["Bowen Wen","Matthew Trepte","Joseph Aribido","Jan Kautz","Orazio Gallo","Stan Birchfield"],"pdf_url":"https://arxiv.org/pdf/2501.09898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.14593v2","updated":"2025-01-17T01:00:13Z","published":"2024-11-21T21:23:46Z","title":"A Systematic Study of Multi-Agent Deep Reinforcement Learning for Safe\n  and Robust Autonomous Highway Ramp Entry","summary":"  Vehicles today can drive themselves on highways and driverless robotaxis\noperate in major cities, with more sophisticated levels of autonomous driving\nexpected to be available and become more common in the future. Yet, technically\nspeaking, so-called \"Level 5\" (L5) operation, corresponding to full autonomy,\nhas not been achieved. For that to happen, functions such as fully autonomous\nhighway ramp entry must be available, and provide provably safe, and reliably\nrobust behavior to enable full autonomy. We present a systematic study of a\nhighway ramp function that controls the vehicles forward-moving actions to\nminimize collisions with the stream of highway traffic into which a merging\n(ego) vehicle enters. We take a game-theoretic multi-agent (MA) approach to\nthis problem and study the use of controllers based on deep reinforcement\nlearning (DRL). The virtual environment of the MA DRL uses self-play with\nsimulated data where merging vehicles safely learn to control longitudinal\nposition during a taper-type merge. The work presented in this paper extends\nexisting work by studying the interaction of more than two vehicles (agents)\nand does so by systematically expanding the road scene with additional traffic\nand ego vehicles. While previous work on the two-vehicle setting established\nthat collision-free controllers are theoretically impossible in fully\ndecentralized, non-coordinated environments, we empirically show that\ncontrollers learned using our approach are nearly ideal when measured against\nidealized optimal controllers.\n","authors":["Larry Schester","Luis E. Ortiz"],"pdf_url":"https://arxiv.org/pdf/2411.14593v2.pdf","comment":"9 pages, 9 figures; added support ack"},{"id":"http://arxiv.org/abs/2501.09893v1","updated":"2025-01-17T00:45:10Z","published":"2025-01-17T00:45:10Z","title":"Sparse Binary Representation Learning for Knowledge Tracing","summary":"  Knowledge tracing (KT) models aim to predict students' future performance\nbased on their historical interactions. Most existing KT models rely\nexclusively on human-defined knowledge concepts (KCs) associated with\nexercises. As a result, the effectiveness of these models is highly dependent\non the quality and completeness of the predefined KCs. Human errors in labeling\nand the cost of covering all potential underlying KCs can limit model\nperformance.\n  In this paper, we propose a KT model, Sparse Binary Representation KT\n(SBRKT), that generates new KC labels, referred to as auxiliary KCs, which can\naugment the predefined KCs to address the limitations of relying solely on\nhuman-defined KCs. These are learned through a binary vector representation,\nwhere each bit indicates the presence (one) or absence (zero) of an auxiliary\nKC. The resulting discrete representation allows these auxiliary KCs to be\nutilized in training any KT model that incorporates KCs. Unlike pre-trained\ndense embeddings, which are limited to models designed to accept such vectors,\nour discrete representations are compatible with both classical models, such as\nBayesian Knowledge Tracing (BKT), and modern deep learning approaches.\n  To generate this discrete representation, SBRKT employs a binarization method\nthat learns a sparse representation, fully trainable via stochastic gradient\ndescent. Additionally, SBRKT incorporates a recurrent neural network (RNN) to\ncapture temporal dynamics and predict future student responses by effectively\ncombining the auxiliary and predefined KCs. Experimental results demonstrate\nthat SBRKT outperforms the tested baselines on several datasets and achieves\ncompetitive performance on others. Furthermore, incorporating the learned\nauxiliary KCs consistently enhances the performance of BKT across all tested\ndatasets.\n","authors":["Yahya Badran","Christine Preisach"],"pdf_url":"https://arxiv.org/pdf/2501.09893v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09597v2","updated":"2025-01-17T00:25:18Z","published":"2024-10-12T17:23:34Z","title":"A Complete Characterization of Learnability for Stochastic Noisy Bandits","summary":"  We study the stochastic noisy bandit problem with an unknown reward function\n$f^*$ in a known function class $\\mathcal{F}$. Formally, a model $M$ maps arms\n$\\pi$ to a probability distribution $M(\\pi)$ of reward. A model class\n$\\mathcal{M}$ is a collection of models. For each model $M$, define its mean\nreward function $f^M(\\pi)=\\mathbb{E}_{r \\sim M(\\pi)}[r]$. In the bandit\nlearning problem, we proceed in rounds, pulling one arm $\\pi$ each round and\nobserving a reward sampled from $M(\\pi)$. With knowledge of $\\mathcal{M}$,\nsupposing that the true model $M\\in \\mathcal{M}$, the objective is to identify\nan arm $\\hat{\\pi}$ of near-maximal mean reward $f^M(\\hat{\\pi})$ with high\nprobability in a bounded number of rounds. If this is possible, then the model\nclass is said to be learnable.\n  Importantly, a result of \\cite{hanneke2023bandit} shows there exist model\nclasses for which learnability is undecidable. However, the model class they\nconsider features deterministic rewards, and they raise the question of whether\nlearnability is decidable for classes containing sufficiently noisy models. For\nthe first time, we answer this question in the positive by giving a complete\ncharacterization of learnability for model classes with arbitrary noise. In\naddition to that, we also describe the full spectrum of possible optimal query\ncomplexities. Further, we prove adaptivity is sometimes necessary to achieve\nthe optimal query complexity. Last, we revisit an important complexity measure\nfor interactive decision making, the Decision-Estimation-Coefficient\n\\citep{foster2021statistical,foster2023tight}, and propose a new variant of the\nDEC which also characterizes learnability in this setting.\n","authors":["Steve Hanneke","Kun Wang"],"pdf_url":"https://arxiv.org/pdf/2410.09597v2.pdf","comment":null}]},"2025-01-16T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2501.07719v2","updated":"2025-01-16T21:00:53Z","published":"2025-01-13T22:09:44Z","title":"Entailed Between the Lines: Incorporating Implication into NLI","summary":"  Much of human communication depends on implication, conveying meaning beyond\nliteral words to express a wider range of thoughts, intentions, and feelings.\nFor models to better understand and facilitate human communication, they must\nbe responsive to the text's implicit meaning. We focus on Natural Language\nInference (NLI), a core tool for many language tasks, and find that\nstate-of-the-art NLI models and datasets struggle to recognize a range of cases\nwhere entailment is implied, rather than explicit from the text. We formalize\nimplied entailment as an extension of the NLI task and introduce the Implied\nNLI dataset (INLI) to help today's LLMs both recognize a broader variety of\nimplied entailments and to distinguish between implicit and explicit\nentailment. We show how LLMs fine-tuned on INLI understand implied entailment\nand can generalize this understanding across datasets and domains.\n","authors":["Shreya Havaldar","Hamidreza Alvari","John Palowitch","Mohammad Javad Hosseini","Senaka Buthpitiya","Alex Fabrikant"],"pdf_url":"https://arxiv.org/pdf/2501.07719v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09825v1","updated":"2025-01-16T20:24:56Z","published":"2025-01-16T20:24:56Z","title":"Bridging Language Barriers in Healthcare: A Study on Arabic LLMs","summary":"  This paper investigates the challenges of developing large language models\n(LLMs) proficient in both multilingual understanding and medical knowledge. We\ndemonstrate that simply translating medical data does not guarantee strong\nperformance on clinical tasks in the target language. Our experiments reveal\nthat the optimal language mix in training data varies significantly across\ndifferent medical tasks. We find that larger models with carefully calibrated\nlanguage ratios achieve superior performance on native-language clinical tasks.\nFurthermore, our results suggest that relying solely on fine-tuning may not be\nthe most effective approach for incorporating new language knowledge into LLMs.\nInstead, data and computationally intensive pretraining methods may still be\nnecessary to achieve optimal performance in multilingual medical settings.\nThese findings provide valuable guidance for building effective and inclusive\nmedical AI systems for diverse linguistic communities.\n","authors":["Nada Saadi","Tathagata Raha","Clément Christophe","Marco AF Pimentel","Ronnie Rajan","Praveen K Kanithi"],"pdf_url":"https://arxiv.org/pdf/2501.09825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09813v1","updated":"2025-01-16T19:59:16Z","published":"2025-01-16T19:59:16Z","title":"Qwen it detect machine-generated text?","summary":"  This paper describes the approach of the Unibuc - NLP team in tackling the\nColing 2025 GenAI Workshop, Task 1: Binary Multilingual Machine-Generated Text\nDetection. We explored both masked language models and causal models. For\nSubtask A, our best model achieved first-place out of 36 teams when looking at\nF1 Micro (Auxiliary Score) of 0.8333, and second-place when looking at F1 Macro\n(Main Score) of 0.8301\n","authors":["Teodor-George Marchitan","Claudiu Creanga","Liviu P. Dinu"],"pdf_url":"https://arxiv.org/pdf/2501.09813v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09804v1","updated":"2025-01-16T19:23:11Z","published":"2025-01-16T19:23:11Z","title":"Enhancing Generalization in Chain of Thought Reasoning for Smaller\n  Models","summary":"  Chain-of-Thought (CoT) reasoning in smaller language models is a challenging\nnatural language process problem yet highly desirable in many real-life\napplications. Existing CoT knowledge distillation methods often suffer from\noverly conservative memorization in smaller LLMs, leading to low generalization\nconfidence. As fully preserving the CoT ability of teacher model is impossible,\nwe hypothesize that adversarial CoT fine-tuning is crucial for developing\nsmaller LLM with robust CoT generalization. To this end, we propose\n\\textit{PRompt-Assisted Domain-Adversarial fine-tuning} (PRADA), a principled\nfine-tuning framework that integrates diverse CoT domains. Specifically, PRADA\npioneers two CoT improvements in smaller LLM: (1) Recovering the\ndomain-invariant feature insight which typically lost during distillation with\ndomain adversarial fine-tuning; (2) Enhancing the domain adaptability of CoT\nprompt engineering by employing domain-adversarial approaches. We theoretically\ndemonstrate the effectiveness of our approach and empirically show that it\nsignificantly outperforms the state of the arts in a wide range of tasks.\nMoreover, our empirical findings reveal that the smaller LLM, when leveraging\nPRADA, aligns closely with domain knowledge, thereby improving the\nexplainability of our approach.\n","authors":["Maxwell J. Yin","Dingyi Jiang","Yongbing Chen","Boyu Wang","Charles Ling"],"pdf_url":"https://arxiv.org/pdf/2501.09804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09801v1","updated":"2025-01-16T19:12:25Z","published":"2025-01-16T19:12:25Z","title":"Conversational Text Extraction with Large Language Models Using\n  Retrieval-Augmented Systems","summary":"  This study introduces a system leveraging Large Language Models (LLMs) to\nextract text and enhance user interaction with PDF documents via a\nconversational interface. Utilizing Retrieval-Augmented Generation (RAG), the\nsystem provides informative responses to user inquiries while highlighting\nrelevant passages within the PDF. Upon user upload, the system processes the\nPDF, employing sentence embeddings to create a document-specific vector store.\nThis vector store enables efficient retrieval of pertinent sections in response\nto user queries. The LLM then engages in a conversational exchange, using the\nretrieved information to extract text and generate comprehensive, contextually\naware answers. While our approach demonstrates competitive ROUGE values\ncompared to existing state-of-the-art techniques for text extraction and\nsummarization, we acknowledge that further qualitative evaluation is necessary\nto fully assess its effectiveness in real-world applications. The proposed\nsystem gives competitive ROUGE values as compared to existing state-of-the-art\ntechniques for text extraction and summarization, thus offering a valuable tool\nfor researchers, students, and anyone seeking to efficiently extract knowledge\nand gain insights from documents through an intuitive question-answering\ninterface.\n","authors":["Soham Roy","Mitul Goswami","Nisharg Nargund","Suneeta Mohanty","Prasant Kumar Pattnaik"],"pdf_url":"https://arxiv.org/pdf/2501.09801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09798v1","updated":"2025-01-16T19:01:25Z","published":"2025-01-16T19:01:25Z","title":"Computing Optimization-Based Prompt Injections Against Closed-Weights\n  Models By Misusing a Fine-Tuning API","summary":"  We surface a new threat to closed-weight Large Language Models (LLMs) that\nenables an attacker to compute optimization-based prompt injections.\nSpecifically, we characterize how an attacker can leverage the loss-like\ninformation returned from the remote fine-tuning interface to guide the search\nfor adversarial prompts. The fine-tuning interface is hosted by an LLM vendor\nand allows developers to fine-tune LLMs for their tasks, thus providing\nutility, but also exposes enough information for an attacker to compute\nadversarial prompts. Through an experimental analysis, we characterize the\nloss-like values returned by the Gemini fine-tuning API and demonstrate that\nthey provide a useful signal for discrete optimization of adversarial prompts\nusing a greedy search algorithm. Using the PurpleLlama prompt injection\nbenchmark, we demonstrate attack success rates between 65% and 82% on Google's\nGemini family of LLMs. These attacks exploit the classic utility-security\ntradeoff - the fine-tuning interface provides a useful feature for developers\nbut also exposes the LLMs to powerful attacks.\n","authors":["Andrey Labunets","Nishit V. Pandya","Ashish Hooda","Xiaohan Fu","Earlence Fernandes"],"pdf_url":"https://arxiv.org/pdf/2501.09798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09751v1","updated":"2025-01-16T18:58:06Z","published":"2025-01-16T18:58:06Z","title":"OmniThink: Expanding Knowledge Boundaries in Machine Writing through\n  Thinking","summary":"  Machine writing with large language models often relies on\nretrieval-augmented generation. However, these approaches remain confined\nwithin the boundaries of the model's predefined scope, limiting the generation\nof content with rich information. Specifically, vanilla-retrieved information\ntends to lack depth, utility, and suffers from redundancy, which negatively\nimpacts the quality of generated articles, leading to shallow, repetitive, and\nunoriginal outputs. To address these issues, we propose OmniThink, a machine\nwriting framework that emulates the human-like process of iterative expansion\nand reflection. The core idea behind OmniThink is to simulate the cognitive\nbehavior of learners as they progressively deepen their knowledge of the\ntopics. Experimental results demonstrate that OmniThink improves the knowledge\ndensity of generated articles without compromising metrics such as coherence\nand depth. Human evaluations and expert feedback further highlight the\npotential of OmniThink to address real-world challenges in the generation of\nlong-form articles.\n","authors":["Zekun Xi","Wenbiao Yin","Jizhan Fang","Jialong Wu","Runnan Fang","Ningyu Zhang","Jiang Yong","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09749v1","updated":"2025-01-16T18:57:20Z","published":"2025-01-16T18:57:20Z","title":"Enhancing Lexicon-Based Text Embeddings with Large Language Models","summary":"  Recent large language models (LLMs) have demonstrated exceptional performance\non general-purpose text embedding tasks. While dense embeddings have dominated\nrelated research, we introduce the first Lexicon-based EmbeddiNgS (LENS)\nleveraging LLMs that achieve competitive performance on these tasks. Regarding\nthe inherent tokenization redundancy issue and unidirectional attention\nlimitations in traditional causal LLMs, LENS consolidates the vocabulary space\nthrough token embedding clustering, and investigates bidirectional attention\nand various pooling strategies. Specifically, LENS simplifies lexicon matching\nby assigning each dimension to a specific token cluster, where semantically\nsimilar tokens are grouped together, and unlocking the full potential of LLMs\nthrough bidirectional attention. Extensive experiments demonstrate that LENS\noutperforms dense embeddings on the Massive Text Embedding Benchmark (MTEB),\ndelivering compact feature representations that match the sizes of dense\ncounterparts. Notably, combining LENSE with dense embeddings achieves\nstate-of-the-art performance on the retrieval subset of MTEB (i.e. BEIR).\n","authors":["Yibin Lei","Tao Shen","Yu Cao","Andrew Yates"],"pdf_url":"https://arxiv.org/pdf/2501.09749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09745v1","updated":"2025-01-16T18:55:38Z","published":"2025-01-16T18:55:38Z","title":"Suggesting Code Edits in Interactive Machine Learning Notebooks Using\n  Large Language Models","summary":"  Machine learning developers frequently use interactive computational\nnotebooks, such as Jupyter notebooks, to host code for data processing and\nmodel training. Jupyter notebooks provide a convenient tool for writing machine\nlearning pipelines and interactively observing outputs, however, maintaining\nJupyter notebooks, e.g., to add new features or fix bugs, can be challenging\ndue to the length and complexity of the notebooks. Moreover, there is no\nexisting benchmark related to developer edits on Jupyter notebooks. To address\nthis, we present the first dataset of 48,398 Jupyter notebook edits derived\nfrom 20,095 revisions of 792 machine learning repositories on GitHub, and\nperform the first study of the using LLMs to predict code edits in Jupyter\nnotebooks. Our dataset captures granular details of cell-level and line-level\nmodifications, offering a foundation for understanding real-world maintenance\npatterns in machine learning workflows. We observed that the edits on Jupyter\nnotebooks are highly localized, with changes averaging only 166 lines of code\nin repositories. While larger models outperform smaller counterparts in code\nediting, all models have low accuracy on our dataset even after finetuning,\ndemonstrating the complexity of real-world machine learning maintenance tasks.\nOur findings emphasize the critical role of contextual information in improving\nmodel performance and point toward promising avenues for advancing large\nlanguage models' capabilities in engineering machine learning code.\n","authors":["Bihui Jin","Jiayue Wang","Pengyu Nie"],"pdf_url":"https://arxiv.org/pdf/2501.09745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09722v1","updated":"2025-01-16T18:10:37Z","published":"2025-01-16T18:10:37Z","title":"Attention based Bidirectional GRU hybrid model for inappropriate content\n  detection in Urdu language","summary":"  With the increased use of the internet and social networks for online\ndiscussions, the spread of toxic and inappropriate content on social networking\nsites has also increased. Several studies have been conducted in different\nlanguages. However, there is less work done for South Asian languages for\ninappropriate content identification using deep learning techniques. In Urdu\nlanguage, the spellings are not unique, and people write different common\nspellings for the same word, while mixing it other languages, like English in\nthe text makes it more challenging, and limited research work is available to\nprocess such language with the finest algorithms. The use of attention layer\nwith a deep learning model can help handling the long-term dependencies and\nincrease its efficiency . To explore the effects of the attention layer, this\nstudy proposes attention-based Bidirectional GRU hybrid model for identifying\ninappropriate content in Urdu Unicode text language. Four different baseline\ndeep learning models; LSTM, Bi-LSTM, GRU, and TCN, are used to compare the\nperformance of the proposed model. The results of these models were compared\nbased on evaluation metrics, dataset size, and impact of the word embedding\nlayer. The pre-trained Urdu word2Vec embeddings were utilized for our case. Our\nproposed model BiGRU-A outperformed all other baseline models by yielding 84\\%\naccuracy without using pre-trained word2Vec layer. From our experiments, we\nhave established that the attention layer improves the model's efficiency, and\npre-trained word2Vec embedding does not work well with an inappropriate content\ndataset.\n","authors":["Ezzah Shoukat","Rabia Irfan","Iqra Basharat","Muhammad Ali Tahir","Sameen Shaukat"],"pdf_url":"https://arxiv.org/pdf/2501.09722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09719v1","updated":"2025-01-16T18:06:22Z","published":"2025-01-16T18:06:22Z","title":"Comparative Insights from 12 Machine Learning Models in Extracting\n  Economic Ideology from Political Text","summary":"  This study conducts a systematic assessment of the capabilities of 12 machine\nlearning models and model variations in detecting economic ideology. As an\nevaluation benchmark, I use manifesto data spanning six elections in the United\nKingdom and pre-annotated by expert and crowd coders. The analysis assesses the\nperformance of several generative, fine-tuned, and zero-shot models at the\ngranular and aggregate levels. The results show that generative models such as\nGPT-4o and Gemini 1.5 Flash consistently outperform other models against all\nbenchmarks. However, they pose issues of accessibility and resource\navailability. Fine-tuning yielded competitive performance and offers a reliable\nalternative through domain-specific optimization. But its dependency on\ntraining data severely limits scalability. Zero-shot models consistently face\ndifficulties with identifying signals of economic ideology, often resulting in\nnegative associations with human coding. Using general knowledge for the\ndomain-specific task of ideology scaling proved to be unreliable. Other key\nfindings include considerable within-party variation, fine-tuning benefiting\nfrom larger training data, and zero-shot's sensitivity to prompt content. The\nassessments include the strengths and limitations of each model and derive\nbest-practices for automated analyses of political content.\n","authors":["Jihed Ncib"],"pdf_url":"https://arxiv.org/pdf/2501.09719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09706v1","updated":"2025-01-16T17:58:32Z","published":"2025-01-16T17:58:32Z","title":"Domain Adaptation of Foundation LLMs for e-Commerce","summary":"  We present the e-Llama models: 8 billion and 70 billion parameter large\nlanguage models that are adapted towards the e-commerce domain. These models\nare meant as foundation models with deep knowledge about e-commerce, that form\na base for instruction- and fine-tuning. The e-Llama models are obtained by\ncontinuously pretraining the Llama 3.1 base models on 1 trillion tokens of\ndomain-specific data.\n  We discuss our approach and motivate our choice of hyperparameters with a\nseries of ablation studies. To quantify how well the models have been adapted\nto the e-commerce domain, we define and implement a set of multilingual,\ne-commerce specific evaluation tasks.\n  We show that, when carefully choosing the training setup, the Llama 3.1\nmodels can be adapted towards the new domain without sacrificing significant\nperformance on general domain tasks. We also explore the possibility of merging\nthe adapted model and the base model for a better control of the performance\ntrade-off between domains.\n","authors":["Christian Herold","Michael Kozielski","Tala Bazazo","Pavel Petrushkov","Hadi Hashemi","Patrycja Cieplicka","Dominika Basaj","Shahram Khadivi"],"pdf_url":"https://arxiv.org/pdf/2501.09706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09653v1","updated":"2025-01-16T16:48:41Z","published":"2025-01-16T16:48:41Z","title":"The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating\n  Large Language Models","summary":"  The recent rise in the popularity of large language models has spurred the\ndevelopment of extensive code datasets needed to train them. This has left\nlimited code available for collection and use in the downstream investigation\nof specific behaviors, or evaluation of large language models without suffering\nfrom data contamination. To address this problem, we release The Heap, a large\nmultilingual dataset covering 57 programming languages that has been\ndeduplicated with respect to other open datasets of code, enabling researchers\nto conduct fair evaluations of large language models without significant data\ncleaning overhead.\n","authors":["Jonathan Katzy","Razvan Mihai Popescu","Arie van Deursen","Maliheh Izadi"],"pdf_url":"https://arxiv.org/pdf/2501.09653v1.pdf","comment":"Pre-Print. Accepted to FORGE 2025 Dataset Track"},{"id":"http://arxiv.org/abs/2501.09645v1","updated":"2025-01-16T16:37:33Z","published":"2025-01-16T16:37:33Z","title":"CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through\n  Category-Bounding","summary":"  In today's assistant landscape, personalisation enhances interactions,\nfosters long-term relationships, and deepens engagement. However, many systems\nstruggle with retaining user preferences, leading to repetitive user requests\nand disengagement. Furthermore, the unregulated and opaque extraction of user\npreferences in industry applications raises significant concerns about privacy\nand trust, especially in regions with stringent regulations like Europe. In\nresponse to these challenges, we propose a long-term memory system for voice\nassistants, structured around predefined categories. This approach leverages\nLarge Language Models to efficiently extract, store, and retrieve preferences\nwithin these categories, ensuring both personalisation and transparency. We\nalso introduce a synthetic multi-turn, multi-session conversation dataset\n(CarMem), grounded in real industry data, tailored to an in-car voice assistant\nsetting. Benchmarked on the dataset, our system achieves an F1-score of .78 to\n.95 in preference extraction, depending on category granularity. Our\nmaintenance strategy reduces redundant preferences by 95% and contradictory\nones by 92%, while the accuracy of optimal retrieval is at .87. Collectively,\nthe results demonstrate the system's suitability for industrial applications.\n","authors":["Johannes Kirmayr","Lukas Stappen","Phillip Schneider","Florian Matthes","Elisabeth André"],"pdf_url":"https://arxiv.org/pdf/2501.09645v1.pdf","comment":"Accepted for presentation at the International Conference on\n  Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2501.06278v2","updated":"2025-01-16T16:19:24Z","published":"2025-01-10T13:07:11Z","title":"Aligning Brain Activity with Advanced Transformer Models: Exploring the\n  Role of Punctuation in Semantic Processing","summary":"  This research examines the congruence between neural activity and advanced\ntransformer models, emphasizing the semantic significance of punctuation in\ntext understanding. Utilizing an innovative approach originally proposed by\nToneva and Wehbe, we evaluate four advanced transformer models RoBERTa,\nDistiliBERT, ALBERT, and ELECTRA against neural activity data. Our findings\nindicate that RoBERTa exhibits the closest alignment with neural activity,\nsurpassing BERT in accuracy. Furthermore, we investigate the impact of\npunctuation removal on model performance and neural alignment, revealing that\nBERT's accuracy enhances in the absence of punctuation. This study contributes\nto the comprehension of how neural networks represent language and the\ninfluence of punctuation on semantic processing within the human brain.\n","authors":["Zenon Lamprou","Frank Polick","Yashar Moshfeghi"],"pdf_url":"https://arxiv.org/pdf/2501.06278v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09777v1","updated":"2025-01-16T16:15:52Z","published":"2025-01-16T16:15:52Z","title":"Sentiment Analysis in Twitter Social Network Centered on\n  Cryptocurrencies Using Machine Learning","summary":"  Cryptocurrency is a digital currency that uses blockchain technology with\nsecure encryption. Due to the decentralization of these currencies, traditional\nmonetary systems and the capital market of each they, can influence a society.\nTherefore, due to the importance of the issue, the need to understand public\nopinion and analyze people's opinions in this regard increases. To understand\nthe opinions and views of people about different topics, you can take help from\nsocial networks because they are a rich source of opinions. The Twitter social\nnetwork is one of the main platforms where users discuss various topics,\ntherefore, in the shortest time and with the lowest cost, the opinion of the\ncommunity can be measured on this social network. Twitter Sentiment Analysis\n(TSA) is a field that analyzes the sentiment expressed in tweets. Considering\nthat most of TSA's research efforts on cryptocurrencies are focused on English\nlanguage, the purpose of this paper is to investigate the opinions of Iranian\nusers on the Twitter social network about cryptocurrencies and provide the best\nmodel for classifying tweets based on sentiment. In the case of automatic\nanalysis of tweets, managers and officials in the field of economy can gain\nknowledge from the general public's point of view about this issue and use the\ninformation obtained in order to properly manage this phenomenon. For this\npurpose, in this paper, in order to build emotion classification models,\nnatural language processing techniques such as bag of words (BOW) and FastText\nfor text vectorization and classical machine learning algorithms including KNN,\nSVM and Adaboost learning methods Deep including LSTM and BERT model were used\nfor classification, and finally BERT linguistic model had the best accuracy\nwith 83.50%.\n","authors":["Vahid Amiri","Mahmood Ahmadi"],"pdf_url":"https://arxiv.org/pdf/2501.09777v1.pdf","comment":"6 pages and 5 figures"},{"id":"http://arxiv.org/abs/2207.09980v4","updated":"2025-01-16T15:56:56Z","published":"2022-07-20T15:39:30Z","title":"ReFactor GNNs: Revisiting Factorisation-based Models from a\n  Message-Passing Perspective","summary":"  Factorisation-based Models (FMs), such as DistMult, have enjoyed enduring\nsuccess for Knowledge Graph Completion (KGC) tasks, often outperforming Graph\nNeural Networks (GNNs). However, unlike GNNs, FMs struggle to incorporate node\nfeatures and generalise to unseen nodes in inductive settings. Our work bridges\nthe gap between FMs and GNNs by proposing ReFactor GNNs. This new architecture\ndraws upon both modelling paradigms, which previously were largely thought of\nas disjoint. Concretely, using a message-passing formalism, we show how FMs can\nbe cast as GNNs by reformulating the gradient descent procedure as\nmessage-passing operations, which forms the basis of our ReFactor GNNs. Across\na multitude of well-established KGC benchmarks, our ReFactor GNNs achieve\ncomparable transductive performance to FMs, and state-of-the-art inductive\nperformance while using an order of magnitude fewer parameters.\n","authors":["Yihong Chen","Pushkar Mishra","Luca Franceschi","Pasquale Minervini","Pontus Stenetorp","Sebastian Riedel"],"pdf_url":"https://arxiv.org/pdf/2207.09980v4.pdf","comment":"36th Conference on Neural Information Processing Systems (NeurIPS\n  2022)"},{"id":"http://arxiv.org/abs/2501.04484v2","updated":"2025-01-16T15:49:07Z","published":"2025-01-08T13:09:45Z","title":"PolInterviews -- A Dataset of German Politician Public Broadcast\n  Interviews","summary":"  This paper presents a novel dataset of public broadcast interviews featuring\nhigh-ranking German politicians. The interviews were sourced from YouTube,\ntranscribed, processed for speaker identification, and stored in a tidy and\nopen format. The dataset comprises 99 interviews with 33 different German\npoliticians across five major interview formats, containing a total of 28,146\nsentences. As the first of its kind, this dataset offers valuable opportunities\nfor research on various aspects of political communication in the (German)\npolitical contexts, such as agenda-setting, interviewer dynamics, or\npoliticians' self-presentation.\n","authors":["Lukas Birkenmaier","Laureen Sieber","Felix Bergstein"],"pdf_url":"https://arxiv.org/pdf/2501.04484v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17962v4","updated":"2025-01-16T15:47:58Z","published":"2024-06-25T22:44:17Z","title":"Crafting Customisable Characters with LLMs: Introducing SimsChat, a\n  Persona-Driven Role-Playing Agent Framework","summary":"  Large Language Models (LLMs) demonstrate remarkable ability to comprehend\ninstructions and generate human-like text, enabling sophisticated agent\nsimulation beyond basic behavior replication. However, the potential for\ncreating freely customisable characters remains underexplored. We introduce the\nCustomisable Conversation Agent Framework, which employs LLMs to simulate\nreal-world characters through personalised characteristic feature injection,\nenabling diverse character creation according to user preferences. We propose\nthe SimsConv dataset, comprising 68 customised characters and 13,971 multi-turn\nrole-playing dialogues across 1,360 real-world scenes. Characters are initially\ncustomised using pre-defined elements (career, aspiration, traits, skills),\nthen expanded through personal and social profiles. Building on this, we\npresent SimsChat, a freely customisable role-playing agent incorporating\nvarious realistic settings and topic-specified character interactions.\nExperimental results on both SimsConv and WikiRoleEval datasets demonstrate\nSimsChat's superior performance in maintaining character consistency, knowledge\naccuracy, and appropriate question rejection compared to existing models. Our\nframework provides valuable insights for developing more accurate and\ncustomisable human simulacra. Our data and code are publicly available at\nhttps://github.com/Bernard-Yang/SimsChat.\n","authors":["Bohao Yang","Dong Liu","Chenghao Xiao","Kun Zhao","Chen Tang","Chao Li","Lin Yuan","Guang Yang","Lanxiao Huang","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2406.17962v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09604v1","updated":"2025-01-16T15:24:41Z","published":"2025-01-16T15:24:41Z","title":"From Scarcity to Capability: Empowering Fake News Detection in\n  Low-Resource Languages with LLMs","summary":"  The rapid spread of fake news presents a significant global challenge,\nparticularly in low-resource languages like Bangla, which lack adequate\ndatasets and detection tools. Although manual fact-checking is accurate, it is\nexpensive and slow to prevent the dissemination of fake news. Addressing this\ngap, we introduce BanFakeNews-2.0, a robust dataset to enhance Bangla fake news\ndetection. This version includes 11,700 additional, meticulously curated fake\nnews articles validated from credible sources, creating a proportional dataset\nof 47,000 authentic and 13,000 fake news items across 13 categories. In\naddition, we created a manually curated independent test set of 460 fake and\n540 authentic news items for rigorous evaluation. We invest efforts in\ncollecting fake news from credible sources and manually verified while\npreserving the linguistic richness. We develop a benchmark system utilizing\ntransformer-based architectures, including fine-tuned Bidirectional Encoder\nRepresentations from Transformers variants (F1-87\\%) and Large Language Models\nwith Quantized Low-Rank Approximation (F1-89\\%), that significantly outperforms\ntraditional methods. BanFakeNews-2.0 offers a valuable resource to advance\nresearch and application in fake news detection for low-resourced languages. We\npublicly release our dataset and model on Github to foster research in this\ndirection.\n","authors":["Hrithik Majumdar Shibu","Shrestha Datta","Md. Sumon Miah","Nasrullah Sami","Mahruba Sharmin Chowdhury","Md. Saiful Islam"],"pdf_url":"https://arxiv.org/pdf/2501.09604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09561v1","updated":"2025-01-16T14:26:48Z","published":"2025-01-16T14:26:48Z","title":"Stylomech: Unveiling Authorship via Computational Stylometry in English\n  and Romanized Sinhala","summary":"  With the advent of Web 2.0, the development in social technology coupled with\nglobal communication systematically brought positive and negative impacts to\nsociety. Copyright claims and Author identification are deemed crucial as there\nhas been a considerable amount of increase in content violation owing to the\nlack of proper ethics in society. The Author's attribution in both English and\nRomanized Sinhala became a major requirement in the last few decades. As an\narea largely unexplored, particularly within the context of Romanized Sinhala,\nthe research contributes significantly to the field of computational\nlinguistics. The proposed author attribution system offers a unique approach,\nallowing for the comparison of only two sets of text: suspect author and\nanonymous text, a departure from traditional methodologies which often rely on\nlarger corpora. This work focuses on using the numerical representation of\nvarious pairs of the same and different authors allowing for, the model to\ntrain on these representations as opposed to text, this allows for it to apply\nto a multitude of authors and contexts, given that the suspected author text,\nand the anonymous text are of reasonable quality. By expanding the scope of\nauthorship attribution to encompass diverse linguistic contexts, the work\ncontributes to fostering trust and accountability in digital communication,\nespecially in Sri Lanka. This research presents a pioneering approach to author\nattribution in both English and Romanized Sinhala, addressing a critical need\nfor content verification and intellectual property rights enforcement in the\ndigital age.\n","authors":["Nabeelah Faumi","Adeepa Gunathilake","Benura Wickramanayake","Deelaka Dias","TGDK Sumanathilaka"],"pdf_url":"https://arxiv.org/pdf/2501.09561v1.pdf","comment":"3 figure, 1 image"},{"id":"http://arxiv.org/abs/2501.09527v1","updated":"2025-01-16T13:23:07Z","published":"2025-01-16T13:23:07Z","title":"Confidence Estimation for Error Detection in Text-to-SQL Systems","summary":"  Text-to-SQL enables users to interact with databases through natural\nlanguage, simplifying the retrieval and synthesis of information. Despite the\nsuccess of large language models (LLMs) in converting natural language\nquestions into SQL queries, their broader adoption is limited by two main\nchallenges: achieving robust generalization across diverse queries and ensuring\ninterpretative confidence in their predictions. To tackle these issues, our\nresearch investigates the integration of selective classifiers into Text-to-SQL\nsystems. We analyse the trade-off between coverage and risk using entropy based\nconfidence estimation with selective classifiers and assess its impact on the\noverall performance of Text-to-SQL models. Additionally, we explore the models'\ninitial calibration and improve it with calibration techniques for better model\nalignment between confidence and accuracy. Our experimental results show that\nencoder-decoder T5 is better calibrated than in-context-learning GPT 4 and\ndecoder-only Llama 3, thus the designated external entropy-based selective\nclassifier has better performance. The study also reveal that, in terms of\nerror detection, selective classifier with a higher probability detects errors\nassociated with irrelevant questions rather than incorrect query generations.\n","authors":["Oleg Somov","Elena Tutubalina"],"pdf_url":"https://arxiv.org/pdf/2501.09527v1.pdf","comment":"15 pages, 11 figures, to be published in AAAI 2025 Proceedings"},{"id":"http://arxiv.org/abs/2501.09521v1","updated":"2025-01-16T13:16:37Z","published":"2025-01-16T13:16:37Z","title":"Augmenting a Large Language Model with a Combination of Text and Visual\n  Data for Conversational Visualization of Global Geospatial Data","summary":"  We present a method for augmenting a Large Language Model (LLM) with a\ncombination of text and visual data to enable accurate question answering in\nvisualization of scientific data, making conversational visualization possible.\nLLMs struggle with tasks like visual data interaction, as they lack contextual\nvisual information. We address this problem by merging a text description of a\nvisualization and dataset with snapshots of the visualization. We extract their\nessential features into a structured text file, highly compact, yet descriptive\nenough to appropriately augment the LLM with contextual information, without\nany fine-tuning. This approach can be applied to any visualization that is\nalready finally rendered, as long as it is associated with some textual\ndescription.\n","authors":["Omar Mena","Alexandre Kouyoumdjian","Lonni Besançon","Michael Gleicher","Ivan Viola","Anders Ynnerman"],"pdf_url":"https://arxiv.org/pdf/2501.09521v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09512v1","updated":"2025-01-16T12:57:33Z","published":"2025-01-16T12:57:33Z","title":"PIER: A Novel Metric for Evaluating What Matters in Code-Switching","summary":"  Code-switching, the alternation of languages within a single discourse,\npresents a significant challenge for Automatic Speech Recognition. Despite the\nunique nature of the task, performance is commonly measured with established\nmetrics such as Word-Error-Rate (WER). However, in this paper, we question\nwhether these general metrics accurately assess performance on code-switching.\nSpecifically, using both Connectionist-Temporal-Classification and\nEncoder-Decoder models, we show fine-tuning on non-code-switched data from both\nmatrix and embedded language improves classical metrics on code-switching test\nsets, although actual code-switched words worsen (as expected). Therefore, we\npropose Point-of-Interest Error Rate (PIER), a variant of WER that focuses only\non specific words of interest. We instantiate PIER on code-switched utterances\nand show that this more accurately describes the code-switching performance,\nshowing huge room for improvement in future work. This focused evaluation\nallows for a more precise assessment of model performance, particularly in\nchallenging aspects such as inter-word and intra-word code-switching.\n","authors":["Enes Yavuz Ugan","Ngoc-Quan Pham","Leonard Bärmann","Alex Waibel"],"pdf_url":"https://arxiv.org/pdf/2501.09512v1.pdf","comment":"Accepted at ICASSP 2025"},{"id":"http://arxiv.org/abs/2410.13187v3","updated":"2025-01-16T12:46:53Z","published":"2024-10-17T03:32:02Z","title":"aiXcoder-7B: A Lightweight and Effective Large Language Model for Code\n  Processing","summary":"  Large Language Models (LLMs) have been widely used in code completion, and\nresearchers are focusing on scaling up LLMs to improve their accuracy. However,\nlarger LLMs have lower inference efficiency, affecting developers' experience\nand productivity. In this paper, we propose a lightweight and effective LLM for\ncode completion named aiXcoder-7B. Compared to existing LLMs, aiXcoder-7B\nachieves higher code completion accuracy while having smaller scales (i.e., 7\nbillion parameters). We attribute the superiority of aiXcoder-7B to three key\nfactors: (1) Multi-objective training. We employ three training objectives, one\nof which is our proposed Structured Fill-In-the-Middle (SFIM). SFIM considers\nthe syntax structures in code and effectively improves the performance of LLMs\nfor code. (2) Diverse data sampling strategies. They consider inter-file\nrelationships and enhance the capability of LLMs in understanding cross-file\ncontexts. (3) Extensive high-quality data. We establish a rigorous data\ncollection pipeline and consume a total of 1.2 trillion unique tokens for\ntraining aiXcoder-7B. This vast volume of data enables aiXcoder-7B to learn a\nbroad distribution of code. We evaluate aiXcoder-7B in five popular code\ncompletion benchmarks and a new benchmark collected by this paper. The results\nshow that aiXcoder-7B outperforms the latest six LLMs with similar sizes and\neven surpasses four larger LLMs (e.g., StarCoder2-15B and CodeLlama-34B),\npositioning aiXcoder-7B as a lightweight and effective LLM for academia and\nindustry. Finally, we summarize three valuable insights for helping\npractitioners train the next generations of LLMs for code. aiXcoder-7B has been\nopen-souced and gained significant attention. Until January 2025, aiXcoder-7B\nhas received 2,226 GitHub Stars.\n","authors":["Siyuan Jiang","Jia Li","He Zong","Huanyu Liu","Hao Zhu","Shukai Hu","Erlu Li","Jiazheng Ding","Yu Han","Wei Ning","Gen Wang","Yihong Dong","Kechi Zhang","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2410.13187v3.pdf","comment":"(1) Accepted by the 47th International Conference on Software\n  Engineering (ICSE 2025). (2) aiXcoder-7B is available at\n  https://github.com/aixcoder-plugin/aiXcoder-7B"},{"id":"http://arxiv.org/abs/2409.08199v2","updated":"2025-01-16T12:17:18Z","published":"2024-09-12T16:36:39Z","title":"AudioBERT: Audio Knowledge Augmented Language Model","summary":"  Recent studies have identified that language models, pretrained on text-only\ndatasets, often lack elementary visual knowledge, \\textit{e.g.,} colors of\neveryday objects. Motivated by this observation, we ask whether a similar\nshortcoming exists in terms of the \\textit{auditory} knowledge. To answer this\nquestion, we construct a new dataset called AuditoryBench, which consists of\ntwo novel tasks for evaluating auditory knowledge. Based on our analysis using\nthe benchmark, we find that language models also suffer from a severe lack of\nauditory knowledge. To address this limitation, we propose AudioBERT, a novel\nmethod to augment the auditory knowledge of BERT through a retrieval-based\napproach. First, we detect auditory knowledge spans in prompts to query our\nretrieval model efficiently. Then, we inject audio knowledge into BERT and\nswitch on low-rank adaptation for effective adaptation when audio knowledge is\nrequired. Our experiments demonstrate that AudioBERT is quite effective,\nachieving superior performance on the AuditoryBench. The dataset and code are\navailable at \\bulurl{https://github.com/HJ-Ok/AudioBERT}.\n","authors":["Hyunjong Ok","Suho Yoo","Jaeho Lee"],"pdf_url":"https://arxiv.org/pdf/2409.08199v2.pdf","comment":"5 pages, 3 figures, ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.09484v1","updated":"2025-01-16T11:41:14Z","published":"2025-01-16T11:41:14Z","title":"Exploring the Inquiry-Diagnosis Relationship with Advanced Patient\n  Simulators","summary":"  Online medical consultation (OMC) restricts doctors to gathering patient\ninformation solely through inquiries, making the already complex sequential\ndecision-making process of diagnosis even more challenging. Recently, the rapid\nadvancement of large language models has demonstrated a significant potential\nto transform OMC. However, most studies have primarily focused on improving\ndiagnostic accuracy under conditions of relatively sufficient information,\nwhile paying limited attention to the \"inquiry\" phase of the consultation\nprocess. This lack of focus has left the relationship between \"inquiry\" and\n\"diagnosis\" insufficiently explored. In this paper, we first extract real\npatient interaction strategies from authentic doctor-patient conversations and\nuse these strategies to guide the training of a patient simulator that closely\nmirrors real-world behavior. By inputting medical records into our patient\nsimulator to simulate patient responses, we conduct extensive experiments to\nexplore the relationship between \"inquiry\" and \"diagnosis\" in the consultation\nprocess. Experimental results demonstrate that inquiry and diagnosis adhere to\nthe Liebig's law: poor inquiry quality limits the effectiveness of diagnosis,\nregardless of diagnostic capability, and vice versa. Furthermore, the\nexperiments reveal significant differences in the inquiry performance of\nvarious models. To investigate this phenomenon, we categorize the inquiry\nprocess into four types: (1) chief complaint inquiry; (2) specification of\nknown symptoms; (3) inquiry about accompanying symptoms; and (4) gathering\nfamily or medical history. We analyze the distribution of inquiries across the\nfour types for different models to explore the reasons behind their significant\nperformance differences. We plan to open-source the weights and related code of\nour patient simulator at https://github.com/LIO-H-ZEN/PatientSimulator.\n","authors":["Zhaocheng Liu","Quan Tu","Wen Ye","Yu Xiao","Zhishou Zhang","Hengfu Cui","Yalun Zhu","Qiang Ju","Shizheng Li","Jian Xie"],"pdf_url":"https://arxiv.org/pdf/2501.09484v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22944v2","updated":"2025-01-16T11:26:02Z","published":"2024-10-30T12:01:48Z","title":"Focus On This, Not That! Steering LLMs With Adaptive Feature\n  Specification","summary":"  Despite the success of Instruction Tuning (IT) in training large language\nmodels (LLMs) to perform arbitrary user-specified tasks, these models often\nstill leverage spurious or biased features learned from their training data,\nleading to undesired behaviours when deploying them in new contexts. In this\nwork, we introduce Focus Instruction Tuning (FIT), which trains LLMs to\ncondition their responses by focusing on specific features whilst ignoring\nothers, leading to different behaviours based on what features are specified.\nAcross several experimental settings, we show that focus-tuned models can be\nadaptively steered by focusing on different features at inference-time: for\ninstance, robustness can be improved by focusing on task-causal features and\nignoring spurious features, and social bias can be mitigated by ignoring\ndemographic categories. Furthermore, FIT can steer behaviour in new contexts,\ngeneralising under distribution shift and to new unseen features at inference\ntime, and thereby facilitating more robust, fair, and controllable LLM\napplications in real-world environments.\n","authors":["Tom A. Lamb","Adam Davies","Alasdair Paren","Philip H. S. Torr","Francesco Pinto"],"pdf_url":"https://arxiv.org/pdf/2410.22944v2.pdf","comment":"28pages, 14 figures"},{"id":"http://arxiv.org/abs/2501.09775v1","updated":"2025-01-16T10:27:51Z","published":"2025-01-16T10:27:51Z","title":"Multiple Choice Questions: Reasoning Makes Large Language Models (LLMs)\n  More Self-Confident Even When They Are Wrong","summary":"  One of the most widely used methods to evaluate LLMs are Multiple Choice\nQuestion (MCQ) tests. MCQ benchmarks enable the testing of LLM knowledge on\nalmost any topic at scale as the results can be processed automatically. To\nhelp the LLM answer, a few examples called few shots can be included in the\nprompt. Moreover, the LLM can be asked to answer the question directly with the\nselected option or to first provide the reasoning and then the selected answer,\nwhich is known as chain of thought. In addition to checking whether the\nselected answer is correct, the evaluation can look at the LLM-estimated\nprobability of its response as an indication of the confidence of the LLM in\nthe response. In this paper, we study how the LLM confidence in its answer\ndepends on whether the model has been asked to answer directly or to provide\nthe reasoning before answering. The results of the evaluation of questions on a\nwide range of topics in seven different models show that LLMs are more\nconfident in their answers when they provide reasoning before the answer. This\noccurs regardless of whether the selected answer is correct. Our hypothesis is\nthat this behavior is due to the reasoning that modifies the probability of the\nselected answer, as the LLM predicts the answer based on the input question and\nthe reasoning that supports the selection made. Therefore, LLM estimated\nprobabilities seem to have intrinsic limitations that should be understood in\norder to use them in evaluation procedures. Interestingly, the same behavior\nhas been observed in humans, for whom explaining an answer increases confidence\nin its correctness.\n","authors":["Tairan Fu","Javier Conde","Gonzalo Martínez","María Grandury","Pedro Reviriego"],"pdf_url":"https://arxiv.org/pdf/2501.09775v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09451v1","updated":"2025-01-16T10:26:17Z","published":"2025-01-16T10:26:17Z","title":"Scaling Graph-Based Dependency Parsing with Arc Vectorization and\n  Attention-Based Refinement","summary":"  We propose a novel architecture for graph-based dependency parsing that\nexplicitly constructs vectors, from which both arcs and labels are scored. Our\nmethod addresses key limitations of the standard two-pipeline approach by\nunifying arc scoring and labeling into a single network, reducing scalability\nissues caused by the information bottleneck and lack of parameter sharing.\nAdditionally, our architecture overcomes limited arc interactions with\ntransformer layers to efficiently simulate higher-order dependencies.\nExperiments on PTB and UD show that our model outperforms state-of-the-art\nparsers in both accuracy and efficiency.\n","authors":["Nicolas Floquet","Joseph Le Roux","Nadi Tomeh","Thierry Charnois"],"pdf_url":"https://arxiv.org/pdf/2501.09451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11775v2","updated":"2025-01-16T10:20:03Z","published":"2024-08-21T17:00:05Z","title":"Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context\n  Support: For 3GPP Standards","summary":"  Recent studies show that large language models (LLMs) struggle with technical\nstandards in telecommunications. We propose a fine-tuned retrieval-augmented\ngeneration (RAG) system based on the Phi-2 small language model (SLM) to serve\nas an oracle for communication networks. Our developed system leverages\nforward-looking semantic chunking to adaptively determine parsing breakpoints\nbased on embedding similarity, enabling effective processing of diverse\ndocument formats. To handle the challenge of multiple similar contexts in\ntechnical standards, we employ a re-ranking algorithm to prioritize the most\nrelevant retrieved chunks. Recognizing the limitations of Phi-2's small context\nwindow, we implement a recent technique, namely SelfExtend, to expand the\ncontext window during inference, which not only boosts the performance but also\ncan accommodate a wider range of user queries and design requirements from\ncustomers to specialized technicians. For fine-tuning, we utilize the low-rank\nadaptation (LoRA) technique to enhance computational efficiency during training\nand enable effective fine-tuning on small datasets. Our comprehensive\nexperiments demonstrate substantial improvements over existing\nquestion-answering approaches in the telecom domain, achieving performance that\nexceeds larger language models such as GPT-4 (which is about 880 times larger\nin size). This work presents a novel approach to leveraging SLMs for\ncommunication networks, offering a balance of efficiency and performance. This\nwork can serve as a foundation towards agentic language models for networks.\n","authors":["Omar Erak","Nouf Alabbasi","Omar Alhussein","Ismail Lotfi","Amr Hussein","Sami Muhaidat","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2408.11775v2.pdf","comment":"submitted to Proc. IEEE Globecom"},{"id":"http://arxiv.org/abs/2501.09444v1","updated":"2025-01-16T10:17:58Z","published":"2025-01-16T10:17:58Z","title":"Solving the unsolvable: Translating case law in Hong Kong","summary":"  This paper addresses the challenges translating case law under Hong Kong's\nbilingual legal system. It highlights the initial success of translating all\nwritten statutes into Chinese before the 1997 handover, a task mandated by the\nBasic Law. The effort involved significant collaboration among legal,\nlinguistic, and translation experts, resulting in a comprehensive and\nculturally appropriate bilingual legal system. However, translating case law\nremains a significant challenge due to the sheer volume and continuous growth\nof judicial decisions. The paper critiques the governments and judiciarys\nsporadic and uncoordinated efforts to translate case law, contrasting it with\nthe thorough approach previously taken for statute translation. Although the\ngovernment acknowledges the importance of legal bilingualism, it lacks a\nsustainable strategy for translating case law. The Judiciarys position that\ntranslating all judgments is unnecessary, unrealistic, and not cost-effectiveis\nanalyzed and critiqued for its impact on legal transparency and public trust. A\nproposed solution involves leveraging machine translation technology through a\nhuman-machine interactive translation platform, which undergoes two major\ntransitions. Initially based on a neural model, the platform transitions to\nusing a large language model for improved translation accuracy. Furthermore, it\nevolves from a single-agent system to a multi-agent system, incorporating\nTranslator, Annotator, and Proofreader agents. This multi-agent approach,\nsupported by a grant, aims to facilitate efficient, high-quality translation of\njudicial judgments by integrating advanced artificial intelligence and\ncontinuous feedback mechanisms, thus better meeting the needs of a bilingual\nlegal system.\n","authors":["King-kui Sin","Xi Xuan","Chunyu Kit","Clara Ho-yan Chan","Honic Ho-kin Ip"],"pdf_url":"https://arxiv.org/pdf/2501.09444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11005v2","updated":"2025-01-16T10:05:17Z","published":"2024-06-25T20:23:15Z","title":"RAGBench: Explainable Benchmark for Retrieval-Augmented Generation\n  Systems","summary":"  Retrieval-Augmented Generation (RAG) has become a standard architectural\npattern for incorporating domain-specific knowledge into user-facing chat\napplications powered by Large Language Models (LLMs). RAG systems are\ncharacterized by (1) a document retriever that queries a domain-specific corpus\nfor context information relevant to an input query, and (2) an LLM that\ngenerates a response based on the provided query and context. However,\ncomprehensive evaluation of RAG systems remains a challenge due to the lack of\nunified evaluation criteria and annotated datasets. In response, we introduce\nRAGBench: the first comprehensive, large-scale RAG benchmark dataset of 100k\nexamples. It covers five unique industry-specific domains and various RAG task\ntypes. RAGBench examples are sourced from industry corpora such as user\nmanuals, making it particularly relevant for industry applications. Further, we\nformalize the TRACe evaluation framework: a set of explainable and actionable\nRAG evaluation metrics applicable across all RAG domains. We release the\nlabeled dataset at https://huggingface.co/datasets/rungalileo/ragbench.\nRAGBench explainable labels facilitate holistic evaluation of RAG systems,\nenabling actionable feedback for continuous improvement of production\napplications. Thorough extensive benchmarking, we find that LLM-based RAG\nevaluation methods struggle to compete with a finetuned RoBERTa model on the\nRAG evaluation task. We identify areas where existing approaches fall short and\npropose the adoption of RAGBench with TRACe towards advancing the state of RAG\nevaluation systems.\n","authors":["Robert Friel","Masha Belyi","Atindriyo Sanyal"],"pdf_url":"https://arxiv.org/pdf/2407.11005v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09431v1","updated":"2025-01-16T09:59:45Z","published":"2025-01-16T09:59:45Z","title":"A Survey on Responsible LLMs: Inherent Risk, Malicious Use, and\n  Mitigation Strategy","summary":"  While large language models (LLMs) present significant potential for\nsupporting numerous real-world applications and delivering positive social\nimpacts, they still face significant challenges in terms of the inherent risk\nof privacy leakage, hallucinated outputs, and value misalignment, and can be\nmaliciously used for generating toxic content and unethical purposes after been\njailbroken. Therefore, in this survey, we present a comprehensive review of\nrecent advancements aimed at mitigating these issues, organized across the four\nphases of LLM development and usage: data collecting and pre-training,\nfine-tuning and alignment, prompting and reasoning, and post-processing and\nauditing. We elaborate on the recent advances for enhancing the performance of\nLLMs in terms of privacy protection, hallucination reduction, value alignment,\ntoxicity elimination, and jailbreak defenses. In contrast to previous surveys\nthat focus on a single dimension of responsible LLMs, this survey presents a\nunified framework that encompasses these diverse dimensions, providing a\ncomprehensive view of enhancing LLMs to better serve real-world applications.\n","authors":["Huandong Wang","Wenjie Fu","Yingzhou Tang","Zhilong Chen","Yuxi Huang","Jinghua Piao","Chen Gao","Fengli Xu","Tao Jiang","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2501.09431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09426v1","updated":"2025-01-16T09:57:12Z","published":"2025-01-16T09:57:12Z","title":"AutoCBT: An Autonomous Multi-agent Framework for Cognitive Behavioral\n  Therapy in Psychological Counseling","summary":"  Traditional in-person psychological counseling remains primarily niche, often\nchosen by individuals with psychological issues, while online automated\ncounseling offers a potential solution for those hesitant to seek help due to\nfeelings of shame. Cognitive Behavioral Therapy (CBT) is an essential and\nwidely used approach in psychological counseling. The advent of large language\nmodels (LLMs) and agent technology enables automatic CBT diagnosis and\ntreatment. However, current LLM-based CBT systems use agents with a fixed\nstructure, limiting their self-optimization capabilities, or providing hollow,\nunhelpful suggestions due to redundant response patterns. In this work, we\nutilize Quora-like and YiXinLi single-round consultation models to build a\ngeneral agent framework that generates high-quality responses for single-turn\npsychological consultation scenarios. We use a bilingual dataset to evaluate\nthe quality of single-response consultations generated by each framework. Then,\nwe incorporate dynamic routing and supervisory mechanisms inspired by real\npsychological counseling to construct a CBT-oriented autonomous multi-agent\nframework, demonstrating its general applicability. Experimental results\nindicate that AutoCBT can provide higher-quality automated psychological\ncounseling services.\n","authors":["Ancheng Xu","Di Yang","Renhao Li","Jingwei Zhu","Minghuan Tan","Min Yang","Wanxin Qiu","Mingchen Ma","Haihong Wu","Bingyu Li","Feng Sha","Chengming Li","Xiping Hu","Qiang Qu","Derek F. Wong","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2501.09426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09425v1","updated":"2025-01-16T09:55:42Z","published":"2025-01-16T09:55:42Z","title":"Vision-Language Models Do Not Understand Negation","summary":"  Many practical vision-language applications require models that understand\nnegation, e.g., when using natural language to retrieve images which contain\ncertain objects but not others. Despite advancements in vision-language models\n(VLMs) through large-scale training, their ability to comprehend negation\nremains underexplored. This study addresses the question: how well do current\nVLMs understand negation? We introduce NegBench, a new benchmark designed to\nevaluate negation understanding across 18 task variations and 79k examples\nspanning image, video, and medical datasets. The benchmark consists of two core\ntasks designed to evaluate negation understanding in diverse multimodal\nsettings: Retrieval with Negation and Multiple Choice Questions with Negated\nCaptions. Our evaluation reveals that modern VLMs struggle significantly with\nnegation, often performing at chance level. To address these shortcomings, we\nexplore a data-centric approach wherein we finetune CLIP models on large-scale\nsynthetic datasets containing millions of negated captions. We show that this\napproach can result in a 10% increase in recall on negated queries and a 40%\nboost in accuracy on multiple-choice questions with negated captions.\n","authors":["Kumail Alhamoud","Shaden Alshammari","Yonglong Tian","Guohao Li","Philip Torr","Yoon Kim","Marzyeh Ghassemi"],"pdf_url":"https://arxiv.org/pdf/2501.09425v1.pdf","comment":"Project page: https://negbench.github.io"},{"id":"http://arxiv.org/abs/2501.09409v1","updated":"2025-01-16T09:35:15Z","published":"2025-01-16T09:35:15Z","title":"mGeNTE: A Multilingual Resource for Gender-Neutral Language and\n  Translation","summary":"  Gender-neutral language reflects societal and linguistic shifts towards\ngreater inclusivity by avoiding the implication that one gender is the norm\nover others. This is particularly relevant for grammatical gender languages,\nwhich heavily encode the gender of terms for human referents and over-relies on\nmasculine forms, even when gender is unspecified or irrelevant. Language\ntechnologies are known to mirror these inequalities, being affected by a male\nbias and perpetuating stereotypical associations when translating into\nlanguages with extensive gendered morphology. In such cases, gender-neutral\nlanguage can help avoid undue binary assumptions. However, despite its\nimportance for creating fairer multi- and cross-lingual technologies, inclusive\nlanguage research remains scarce and insufficiently supported in current\nresources. To address this gap, we present the multilingual mGeNTe dataset.\nDerived from the bilingual GeNTE (Piergentili et al., 2023), mGeNTE extends the\noriginal corpus to include the English-Italian/German/Spanish language pairs.\nSince each language pair is English-aligned with gendered and neutral sentences\nin the target languages, mGeNTE enables research in both automatic\nGender-Neutral Translation (GNT) and language modelling for three grammatical\ngender languages.\n","authors":["Beatrice Savoldi","Eleonora Cupin","Manjinder Thind","Anne Lauscher","Luisa Bentivogli"],"pdf_url":"https://arxiv.org/pdf/2501.09409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09384v1","updated":"2025-01-16T08:52:50Z","published":"2025-01-16T08:52:50Z","title":"Evaluating LLM Abilities to Understand Tabular Electronic Health\n  Records: A Comprehensive Study of Patient Data Extraction and Retrieval","summary":"  Electronic Health Record (EHR) tables pose unique challenges among which is\nthe presence of hidden contextual dependencies between medical features with a\nhigh level of data dimensionality and sparsity. This study presents the first\ninvestigation into the abilities of LLMs to comprehend EHRs for patient data\nextraction and retrieval. We conduct extensive experiments using the MIMICSQL\ndataset to explore the impact of the prompt structure, instruction, context,\nand demonstration, of two backbone LLMs, Llama2 and Meditron, based on task\nperformance. Through quantitative and qualitative analyses, our findings show\nthat optimal feature selection and serialization methods can enhance task\nperformance by up to 26.79% compared to naive approaches. Similarly, in-context\nlearning setups with relevant example selection improve data extraction\nperformance by 5.95%. Based on our study findings, we propose guidelines that\nwe believe would help the design of LLM-based models to support health search.\n","authors":["Jesus Lovon","Martin Mouysset","Jo Oleiwan","Jose G. Moreno","Christine Damase-Michel","Lynda Tamine"],"pdf_url":"https://arxiv.org/pdf/2501.09384v1.pdf","comment":"To be published as full paper in the Proceedings of the European\n  Conference on Information Retrieval (ECIR) 2025. Preprint"},{"id":"http://arxiv.org/abs/2406.13340v2","updated":"2025-01-16T08:34:36Z","published":"2024-06-19T08:46:29Z","title":"SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond\n  Words","summary":"  Speech encompasses a wealth of information, including but not limited to\ncontent, paralinguistic, and environmental information. This comprehensive\nnature of speech significantly impacts communication and is crucial for\nhuman-computer interaction. Chat-Oriented Large Language Models (LLMs), known\nfor their general-purpose assistance capabilities, have evolved to handle\nmulti-modal inputs, including speech. Although these models can be adept at\nrecognizing and analyzing speech, they often fall short of generating\nappropriate responses. We argue that this is due to the lack of principles on\ntask definition and model development, which requires open-source datasets and\nmetrics suitable for model evaluation. To bridge the gap, we present SD-Eval, a\nbenchmark dataset aimed at multidimensional evaluation of spoken dialogue\nunderstanding and generation. SD-Eval focuses on paralinguistic and\nenvironmental information and includes 7,303 utterances, amounting to 8.76\nhours of speech data. The data is aggregated from eight public datasets,\nrepresenting four perspectives: emotion, accent, age, and background sound. To\nassess the SD-Eval benchmark dataset, we implement three different models and\nconstruct a training set following a process similar to that of SD-Eval. The\ntraining set contains 1,052.72 hours of speech data and 724.4k utterances. We\nalso conduct a comprehensive evaluation using objective evaluation methods\n(e.g. BLEU and ROUGE), subjective evaluations and LLM-based metrics for the\ngenerated responses. Models conditioned with paralinguistic and environmental\ninformation outperform their counterparts in both objective and subjective\nmeasures. Moreover, experiments demonstrate that LLM-based metrics show a\nhigher correlation with human evaluation compared to traditional metrics. We\nopen-source SD-Eval at https://github.com/amphionspace/SD-Eval.\n","authors":["Junyi Ao","Yuancheng Wang","Xiaohai Tian","Dekun Chen","Jun Zhang","Lu Lu","Yuxuan Wang","Haizhou Li","Zhizheng Wu"],"pdf_url":"https://arxiv.org/pdf/2406.13340v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.09349v1","updated":"2025-01-16T08:03:32Z","published":"2025-01-16T08:03:32Z","title":"ChartInsighter: An Approach for Mitigating Hallucination in Time-series\n  Chart Summary Generation with A Benchmark Dataset","summary":"  Effective chart summary can significantly reduce the time and effort decision\nmakers spend interpreting charts, enabling precise and efficient communication\nof data insights. Previous studies have faced challenges in generating accurate\nand semantically rich summaries of time-series data charts. In this paper, we\nidentify summary elements and common hallucination types in the generation of\ntime-series chart summaries, which serve as our guidelines for automatic\ngeneration. We introduce ChartInsighter, which automatically generates chart\nsummaries of time-series data, effectively reducing hallucinations in chart\nsummary generation. Specifically, we assign multiple agents to generate the\ninitial chart summary and collaborate iteratively, during which they invoke\nexternal data analysis modules to extract insights and compile them into a\ncoherent summary. Additionally, we implement a self-consistency test method to\nvalidate and correct our summary. We create a high-quality benchmark of charts\nand summaries, with hallucination types annotated on a sentence-by-sentence\nbasis, facilitating the evaluation of the effectiveness of reducing\nhallucinations. Our evaluations using our benchmark show that our method\nsurpasses state-of-the-art models, and that our summary hallucination rate is\nthe lowest, which effectively reduces various hallucinations and improves\nsummary quality. The benchmark is available at\nhttps://github.com/wangfen01/ChartInsighter.\n","authors":["Fen Wang","Bomiao Wang","Xueli Shu","Zhen Liu","Zekai Shao","Chao Liu","Siming Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03584v2","updated":"2025-01-16T07:56:42Z","published":"2025-01-07T07:17:04Z","title":"Discriminative Representation learning via Attention-Enhanced\n  Contrastive Learning for Short Text Clustering","summary":"  Contrastive learning has gained significant attention in short text\nclustering, yet it has an inherent drawback of mistakenly identifying samples\nfrom the same category as negatives and then separating them in the feature\nspace (false negative separation), which hinders the generation of superior\nrepresentations. To generate more discriminative representations for efficient\nclustering, we propose a novel short text clustering method, called\nDiscriminative Representation learning via \\textbf{A}ttention-\\textbf{E}nhanced\n\\textbf{C}ontrastive \\textbf{L}earning for Short Text Clustering\n(\\textbf{AECL}). The \\textbf{AECL} consists of two modules which are the\npseudo-label generation module and the contrastive learning module. Both\nmodules build a sample-level attention mechanism to capture similarity\nrelationships between samples and aggregate cross-sample features to generate\nconsistent representations. Then, the former module uses the more\ndiscriminative consistent representation to produce reliable supervision\ninformation for assist clustering, while the latter module explores similarity\nrelationships and consistent representations optimize the construction of\npositive samples to perform similarity-guided contrastive learning, effectively\naddressing the false negative separation issue. Experimental results\ndemonstrate that the proposed \\textbf{AECL} outperforms state-of-the-art\nmethods. If the paper is accepted, we will open-source the code.\n","authors":["Zhihao Yao"],"pdf_url":"https://arxiv.org/pdf/2501.03584v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15701v2","updated":"2025-01-16T07:01:37Z","published":"2024-12-20T09:21:15Z","title":"Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent\n  Collaboration","summary":"  Recent advancements in language models (LMs) have sparked growing interest in\ndeveloping LM agents. While fully autonomous agents could excel in many\nscenarios, numerous use cases inherently require them to collaborate with\nhumans due to humans' latent preferences, domain expertise, or need for\ncontrol. To facilitate the study of human-agent collaboration, we present\nCollaborative Gym (Co-Gym), a general framework enabling asynchronous,\ntripartite interaction among agents, humans, and task environments. We\ninstantiate Co-Gym with three representative tasks in both simulated and\nreal-world conditions, and propose an evaluation framework that assesses both\nthe collaboration outcomes and processes. Our findings reveal that\ncollaborative agents consistently outperform their fully autonomous\ncounterparts in task performance within those delivered cases, achieving win\nrates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related\nWork when evaluated by real users. However, our study also highlights\nsignificant challenges in developing collaborative agents, requiring\nadvancements in core aspects of intelligence -- communication capabilities,\nsituational awareness, and balancing autonomy and human control.\n","authors":["Yijia Shao","Vinay Samuel","Yucheng Jiang","John Yang","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2412.15701v2.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2501.09326v1","updated":"2025-01-16T06:51:32Z","published":"2025-01-16T06:51:32Z","title":"Algorithm for Semantic Network Generation from Texts of Low Resource\n  Languages Such as Kiswahili","summary":"  Processing low-resource languages, such as Kiswahili, using machine learning\nis difficult due to lack of adequate training data. However, such low-resource\nlanguages are still important for human communication and are already in daily\nuse and users need practical machine processing tasks such as summarization,\ndisambiguation and even question answering (QA). One method of processing such\nlanguages, while bypassing the need for training data, is the use semantic\nnetworks. Some low resource languages, such as Kiswahili, are of the\nsubject-verb-object (SVO) structure, and similarly semantic networks are a\ntriple of subject-predicate-object, hence SVO parts of speech tags can map into\na semantic network triple. An algorithm to process raw natural language text\nand map it into a semantic network is therefore necessary and desirable in\nstructuring low resource languages texts. This algorithm tested on the\nKiswahili QA task with upto 78.6% exact match.\n","authors":["Barack Wamkaya Wanjawa","Lawrence Muchemi","Evans Miriti"],"pdf_url":"https://arxiv.org/pdf/2501.09326v1.pdf","comment":"18 pages, 3 figures, published in Open Journal for Information\n  Technology"},{"id":"http://arxiv.org/abs/2501.08335v2","updated":"2025-01-16T06:16:43Z","published":"2024-12-21T05:50:48Z","title":"MERaLiON-TextLLM: Cross-Lingual Understanding of Large Language Models\n  in Chinese, Indonesian, Malay, and Singlish","summary":"  Multilingual large language models (MLLMs) have shown impressive capabilities\nacross a variety of languages. However, efficacy can differ greatly between\ndifferent language families, especially for those with limited linguistic\nresources. This report presents MERaLiON-TextLLM, a series of open-source\nlanguage models specifically tailored to improve understanding and generation\nin Chinese, Indonesian, Malay, and Singlish. The initial released model is\nbuilt on Llama-3-8B-Base and refined through a meticulously crafted process of\ncontinued pre-training and weight merging. Our approach achieves performance\nimprovements across benchmarks in these languages, exceeding the capabilities\nof the official Llama-3 models. We provide the model checkpoints as a resource\nto support further research and development in cross-lingual language\nunderstanding.\n","authors":["Xin Huang","Tarun Kumar Vangani","Minh Duc Pham","Xunlong Zou","Bin Wang","Zhengyuan Liu","Ai Ti Aw"],"pdf_url":"https://arxiv.org/pdf/2501.08335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15862v4","updated":"2025-01-16T06:07:12Z","published":"2024-11-24T14:38:59Z","title":"Do LLMs Really Think Step-by-step In Implicit Reasoning?","summary":"  It has been well-known that Chain-of-Thought can remarkably enhance LLMs'\nperformance on complex tasks. However, because it also introduces slower\ninference speeds and higher computational costs, many researches have attempted\nto use implicit CoT, which does not need LLMs to explicitly generate the\nintermediate steps. However, the invisible reasoning process leaves us a doubt\nthat, can implicit CoT really be equal to explicit CoT? Therefore, in this\nstudy, we address this question through experiments. We probe the information\nof intermediate steps from the model's hidden states when it is either trained\nor prompted to perform implicit CoT. The results surprisingly indicate that\nwhen prompted, LLMs hardly think about intermediate steps, suggesting they may\njust rely on experience rather than strict step-by-step reasoning. But when\ntrained, they indeed calculate intermediate steps. Moreover, in both\nsituations, we find the effect of using implicit CoT is susceptible to the\nformat of the problem, reaffirming the current deficiency of implicit CoT.\n","authors":["Yijiong Yu"],"pdf_url":"https://arxiv.org/pdf/2411.15862v4.pdf","comment":"The code is in\n  https://github.com/yuyijiong/if_step_by_step_implicit_CoT"},{"id":"http://arxiv.org/abs/2501.09311v1","updated":"2025-01-16T05:58:32Z","published":"2025-01-16T05:58:32Z","title":"Shape-Based Single Object Classification Using Ensemble Method\n  Classifiers","summary":"  Nowadays, more and more images are available. Annotation and retrieval of the\nimages pose classification problems, where each class is defined as the group\nof database images labelled with a common semantic label. Various systems have\nbeen proposed for content-based retrieval, as well as for image classification\nand indexing. In this paper, a hierarchical classification framework has been\nproposed for bridging the semantic gap effectively and achieving multi-category\nimage classification. A well known pre-processing and post-processing method\nwas used and applied to three problems; image segmentation, object\nidentification and image classification. The method was applied to classify\nsingle object images from Amazon and Google datasets. The classification was\ntested for four different classifiers; BayesNetwork (BN), Random Forest (RF),\nBagging and Vote. The estimated classification accuracies ranged from 20% to\n99% (using 10-fold cross validation). The Bagging classifier presents the best\nperformance, followed by the Random Forest classifier.\n","authors":["Nur Shazwani Kamarudin","Mokhairi Makhtar","Syadiah Nor Wan Shamsuddin","Syed Abdullah Fadzli"],"pdf_url":"https://arxiv.org/pdf/2501.09311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09310v1","updated":"2025-01-16T05:54:59Z","published":"2025-01-16T05:54:59Z","title":"A Study of In-Context-Learning-Based Text-to-SQL Errors","summary":"  Large language models (LLMs) have been adopted to perform text-to-SQL tasks,\nutilizing their in-context learning (ICL) capability to translate natural\nlanguage questions into structured query language (SQL). However, such a\ntechnique faces correctness problems and requires efficient repairing\nsolutions. In this paper, we conduct the first comprehensive study of\ntext-to-SQL errors. Our study covers four representative ICL-based techniques,\nfive basic repairing methods, two benchmarks, and two LLM settings. We find\nthat text-to-SQL errors are widespread and summarize 29 error types of 7\ncategories. We also find that existing repairing attempts have limited\ncorrectness improvement at the cost of high computational overhead with many\nmis-repairs. Based on the findings, we propose MapleRepair, a novel text-to-SQL\nerror detection and repairing framework. The evaluation demonstrates that\nMapleRepair outperforms existing solutions by repairing 13.8% more queries with\nneglectable mis-repairs and 67.4% less overhead.\n","authors":["Jiawei Shen","Chengcheng Wan","Ruoyi Qiao","Jiazhen Zou","Hang Xu","Yuchen Shao","Yueling Zhang","Weikai Miao","Geguang Pu"],"pdf_url":"https://arxiv.org/pdf/2501.09310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09309v1","updated":"2025-01-16T05:46:27Z","published":"2025-01-16T05:46:27Z","title":"Understanding Mental Health Content on Social Media and Its Effect\n  Towards Suicidal Ideation","summary":"  This review underscores the critical need for effective strategies to\nidentify and support individuals with suicidal ideation, exploiting\ntechnological innovations in ML and DL to further suicide prevention efforts.\nThe study details the application of these technologies in analyzing vast\namounts of unstructured social media data to detect linguistic patterns,\nkeywords, phrases, tones, and contextual cues associated with suicidal\nthoughts. It explores various ML and DL models like SVMs, CNNs, LSTM, neural\nnetworks, and their effectiveness in interpreting complex data patterns and\nemotional nuances within text data. The review discusses the potential of these\ntechnologies to serve as a life-saving tool by identifying at-risk individuals\nthrough their digital traces. Furthermore, it evaluates the real-world\neffectiveness, limitations, and ethical considerations of employing these\ntechnologies for suicide prevention, stressing the importance of responsible\ndevelopment and usage. The study aims to fill critical knowledge gaps by\nanalyzing recent studies, methodologies, tools, and techniques in this field.\nIt highlights the importance of synthesizing current literature to inform\npractical tools and suicide prevention efforts, guiding innovation in reliable,\nethical systems for early intervention. This research synthesis evaluates the\nintersection of technology and mental health, advocating for the ethical and\nresponsible application of ML, DL, and NLP to offer life-saving potential\nworldwide while addressing challenges like generalizability, biases, privacy,\nand the need for further research to ensure these technologies do not\nexacerbate existing inequities and harms.\n","authors":["Mohaiminul Islam Bhuiyan","Nur Shazwani Kamarudin","Nur Hafieza Ismail"],"pdf_url":"https://arxiv.org/pdf/2501.09309v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09294v1","updated":"2025-01-16T05:01:30Z","published":"2025-01-16T05:01:30Z","title":"Efficient Few-Shot Medical Image Analysis via Hierarchical Contrastive\n  Vision-Language Learning","summary":"  Few-shot learning in medical image classification presents a significant\nchallenge due to the limited availability of annotated data and the complex\nnature of medical imagery. In this work, we propose Adaptive Vision-Language\nFine-tuning with Hierarchical Contrastive Alignment (HiCA), a novel framework\nthat leverages the capabilities of Large Vision-Language Models (LVLMs) for\nmedical image analysis. HiCA introduces a two-stage fine-tuning strategy,\ncombining domain-specific pretraining and hierarchical contrastive learning to\nalign visual and textual representations at multiple levels. We evaluate our\napproach on two benchmark datasets, Chest X-ray and Breast Ultrasound,\nachieving state-of-the-art performance in both few-shot and zero-shot settings.\nFurther analyses demonstrate the robustness, generalizability, and\ninterpretability of our method, with substantial improvements in performance\ncompared to existing baselines. Our work highlights the potential of\nhierarchical contrastive strategies in adapting LVLMs to the unique challenges\nof medical imaging tasks.\n","authors":["Harrison Fuller","Fernando Gabriela Garcia","Victor Flores"],"pdf_url":"https://arxiv.org/pdf/2501.09294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09292v1","updated":"2025-01-16T04:56:33Z","published":"2025-01-16T04:56:33Z","title":"To Retrieve or Not to Retrieve? Uncertainty Detection for Dynamic\n  Retrieval Augmented Generation","summary":"  Retrieval-Augmented Generation equips large language models with the\ncapability to retrieve external knowledge, thereby mitigating hallucinations by\nincorporating information beyond the model's intrinsic abilities. However, most\nprior works have focused on invoking retrieval deterministically, which makes\nit unsuitable for tasks such as long-form question answering. Instead,\ndynamically performing retrieval by invoking it only when the underlying LLM\nlacks the required knowledge can be more efficient. In this context, we delve\ndeeper into the question, \"To Retrieve or Not to Retrieve?\" by exploring\nmultiple uncertainty detection methods. We evaluate these methods for the task\nof long-form question answering, employing dynamic retrieval, and present our\ncomparisons. Our findings suggest that uncertainty detection metrics, such as\nDegree Matrix Jaccard and Eccentricity, can reduce the number of retrieval\ncalls by almost half, with only a slight reduction in question-answering\naccuracy.\n","authors":["Kaustubh D. Dhole"],"pdf_url":"https://arxiv.org/pdf/2501.09292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09265v1","updated":"2025-01-16T03:30:47Z","published":"2025-01-16T03:30:47Z","title":"Perspective Transition of Large Language Models for Solving Subjective\n  Tasks","summary":"  Large language models (LLMs) have revolutionized the field of natural\nlanguage processing, enabling remarkable progress in various tasks. Different\nfrom objective tasks such as commonsense reasoning and arithmetic\nquestion-answering, the performance of LLMs on subjective tasks is still\nlimited, where the perspective on the specific problem plays crucial roles for\nbetter interpreting the context and giving proper response. For example, in\ncertain scenarios, LLMs may perform better when answering from an expert role\nperspective, potentially eliciting their relevant domain knowledge. In\ncontrast, in some scenarios, LLMs may provide more accurate responses when\nanswering from a third-person standpoint, enabling a more comprehensive\nunderstanding of the problem and potentially mitigating inherent biases. In\nthis paper, we propose Reasoning through Perspective Transition (RPT), a method\nbased on in-context learning that enables LLMs to dynamically select among\ndirect, role, and third-person perspectives for the best way to solve\ncorresponding subjective problem. Through extensive experiments on totally 12\nsubjective tasks by using both closed-source and open-source LLMs including\nGPT-4, GPT-3.5, Llama-3, and Qwen-2, our method outperforms widely used single\nfixed perspective based methods such as chain-of-thought prompting and expert\nprompting, highlights the intricate ways that LLMs can adapt their perspectives\nto provide nuanced and contextually appropriate responses for different\nproblems.\n","authors":["Xiaolong Wang","Yuanchi Zhang","Ziyue Wang","Yuzhuang Xu","Fuwen Luo","Yile Wang","Peng Li","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2501.09265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09818v3","updated":"2025-01-16T03:29:23Z","published":"2024-12-13T03:15:05Z","title":"MERaLiON-AudioLLM: Bridging Audio and Language with Large Language\n  Models","summary":"  We introduce MERaLiON-AudioLLM (Multimodal Empathetic Reasoning and Learning\nin One Network), the first speech-text model tailored for Singapore's\nmultilingual and multicultural landscape. Developed under the National Large\nLanguage Models Funding Initiative, Singapore, MERaLiON-AudioLLM integrates\nadvanced speech and text processing to address the diverse linguistic nuances\nof local accents and dialects, enhancing accessibility and usability in\ncomplex, multilingual environments. Our results demonstrate improvements in\nboth speech recognition and task-specific understanding, positioning\nMERaLiON-AudioLLM as a pioneering solution for region specific AI applications.\nWe envision this release to set a precedent for future models designed to\naddress localised linguistic and cultural contexts in a global framework.\n","authors":["Yingxu He","Zhuohan Liu","Shuo Sun","Bin Wang","Wenyu Zhang","Xunlong Zou","Nancy F. Chen","Ai Ti Aw"],"pdf_url":"https://arxiv.org/pdf/2412.09818v3.pdf","comment":"https://huggingface.co/MERaLiON/MERaLiON-AudioLLM-Whisper-SEA-LION"},{"id":"http://arxiv.org/abs/2406.15477v2","updated":"2025-01-16T03:26:36Z","published":"2024-06-16T23:01:10Z","title":"CrisisSense-LLM: Instruction Fine-Tuned Large Language Model for\n  Multi-label Social Media Text Classification in Disaster Informatics","summary":"  In the field of crisis/disaster informatics, social media is increasingly\nbeing used for improving situational awareness to inform response and relief\nefforts. Efficient and accurate text classification tools have been a focal\narea of investigation in crisis informatics. However, current methods mostly\nrely on single-label text classification models, which fails to capture\ndifferent insights embedded in dynamic and multifaceted disaster-related social\nmedia data. This study introduces a novel approach to disaster text\nclassification by enhancing a pre-trained Large Language Model (LLM) through\ninstruction fine-tuning targeted for multi-label classification of\ndisaster-related tweets. Our methodology involves creating a comprehensive\ninstruction dataset from disaster-related tweets, which is then used to\nfine-tune an open-source LLM, thereby embedding it with disaster-specific\nknowledge. This fine-tuned model can classify multiple aspects of\ndisaster-related information simultaneously, such as the type of event,\ninformativeness, and involvement of human aid, significantly improving the\nutility of social media data for situational awareness in disasters. The\nresults demonstrate that this approach enhances the categorization of critical\ninformation from social media posts, thereby facilitating a more effective\ndeployment for situational awareness during emergencies. This research paves\nthe way for more advanced, adaptable, and robust disaster management tools,\nleveraging the capabilities of LLMs to improve real-time situational awareness\nand response strategies in disaster scenarios.\n","authors":["Kai Yin","Chengkai Liu","Ali Mostafavi","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2406.15477v2.pdf","comment":"Relevant source code and data is available:\n  https://github.com/KaiYin97/CrsisLLM"},{"id":"http://arxiv.org/abs/2501.06848v3","updated":"2025-01-16T03:18:14Z","published":"2025-01-12T15:34:24Z","title":"A General Framework for Inference-time Scaling and Steering of Diffusion\n  Models","summary":"  Diffusion models produce impressive results in modalities ranging from images\nand video to protein design and text. However, generating samples with\nuser-specified properties remains a challenge. Recent research proposes\nfine-tuning models to maximize rewards that capture desired properties, but\nthese methods require expensive training and are prone to mode collapse. In\nthis work, we propose Feynman Kac (FK) steering, an inference-time framework\nfor steering diffusion models with reward functions. FK steering works by\nsampling a system of multiple interacting diffusion processes, called\nparticles, and resampling particles at intermediate steps based on scores\ncomputed using functions called potentials. Potentials are defined using\nrewards for intermediate states and are selected such that a high value\nindicates that the particle will yield a high-reward sample. We explore various\nchoices of potentials, intermediate rewards, and samplers. We evaluate FK\nsteering on text-to-image and text diffusion models. For steering text-to-image\nmodels with a human preference reward, we find that FK steering a 0.8B\nparameter model outperforms a 2.6B parameter fine-tuned model on prompt\nfidelity, with faster sampling and no training. For steering text diffusion\nmodels with rewards for text quality and specific text attributes, we find that\nFK steering generates lower perplexity, more linguistically acceptable outputs\nand enables gradient-free control of attributes like toxicity. Our results\ndemonstrate that inference-time scaling and steering of diffusion models, even\nwith off-the-shelf rewards, can provide significant sample quality gains and\ncontrollability benefits. Code is available at\nhttps://github.com/zacharyhorvitz/Fk-Diffusion-Steering .\n","authors":["Raghav Singhal","Zachary Horvitz","Ryan Teehan","Mengye Ren","Zhou Yu","Kathleen McKeown","Rajesh Ranganath"],"pdf_url":"https://arxiv.org/pdf/2501.06848v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09258v1","updated":"2025-01-16T03:01:50Z","published":"2025-01-16T03:01:50Z","title":"Delayed Fusion: Integrating Large Language Models into First-Pass\n  Decoding in End-to-end Speech Recognition","summary":"  This paper presents an efficient decoding approach for end-to-end automatic\nspeech recognition (E2E-ASR) with large language models (LLMs). Although\nshallow fusion is the most common approach to incorporate language models into\nE2E-ASR decoding, we face two practical problems with LLMs. (1) LLM inference\nis computationally costly. (2) There may be a vocabulary mismatch between the\nASR model and the LLM. To resolve this mismatch, we need to retrain the ASR\nmodel and/or the LLM, which is at best time-consuming and in many cases not\nfeasible. We propose \"delayed fusion,\" which applies LLM scores to ASR\nhypotheses with a delay during decoding and enables easier use of pre-trained\nLLMs in ASR tasks. This method can reduce not only the number of hypotheses\nscored by the LLM but also the number of LLM inference calls. It also allows\nre-tokenizion of ASR hypotheses during decoding if ASR and LLM employ different\ntokenizations. We demonstrate that delayed fusion provides improved decoding\nspeed and accuracy compared to shallow fusion and N-best rescoring using the\nLibriHeavy ASR corpus and three public LLMs, OpenLLaMA 3B & 7B and Mistral 7B.\n","authors":["Takaaki Hori","Martin Kocour","Adnan Haider","Erik McDermott","Xiaodan Zhuang"],"pdf_url":"https://arxiv.org/pdf/2501.09258v1.pdf","comment":"Accepted to ICASSP2025"},{"id":"http://arxiv.org/abs/2404.13885v2","updated":"2025-01-16T02:45:07Z","published":"2024-04-22T05:12:52Z","title":"Surveying Attitudinal Alignment Between Large Language Models Vs. Humans\n  Towards 17 Sustainable Development Goals","summary":"  Large Language Models (LLMs) have emerged as potent tools for advancing the\nUnited Nations' Sustainable Development Goals (SDGs). However, the attitudinal\ndisparities between LLMs and humans towards these goals can pose significant\nchallenges. This study conducts a comprehensive review and analysis of the\nexisting literature on the attitudes of LLMs towards the 17 SDGs, emphasizing\nthe comparison between their attitudes and support for each goal and those of\nhumans. We examine the potential disparities, primarily focusing on aspects\nsuch as understanding and emotions, cultural and regional differences, task\nobjective variations, and factors considered in the decision-making process.\nThese disparities arise from the underrepresentation and imbalance in LLM\ntraining data, historical biases, quality issues, lack of contextual\nunderstanding, and skewed ethical values reflected. The study also investigates\nthe risks and harms that may arise from neglecting the attitudes of LLMs\ntowards the SDGs, including the exacerbation of social inequalities, racial\ndiscrimination, environmental destruction, and resource wastage. To address\nthese challenges, we propose strategies and recommendations to guide and\nregulate the application of LLMs, ensuring their alignment with the principles\nand goals of the SDGs, and therefore creating a more just, inclusive, and\nsustainable future.\n","authors":["Qingyang Wu","Ying Xu","Tingsong Xiao","Yunze Xiao","Yitong Li","Tianyang Wang","Yichi Zhang","Shanghai Zhong","Yuwei Zhang","Wei Lu","Yifan Yang"],"pdf_url":"https://arxiv.org/pdf/2404.13885v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.02797v3","updated":"2025-01-16T02:31:20Z","published":"2024-01-05T13:22:12Z","title":"PeFoMed: Parameter Efficient Fine-tuning of Multimodal Large Language\n  Models for Medical Imaging","summary":"  Multimodal large language models (MLLMs) represent an evolutionary expansion\nin the capabilities of traditional large language models, enabling them to\ntackle challenges that surpass the scope of purely text-based applications. It\nleverages the knowledge previously encoded within these language models,\nthereby enhancing their applicability and functionality in the reign of\nmultimodal contexts. Recent works investigate the adaptation of MLLMs as a\nuniversal solution to address medical multi-modal problems as a generative\ntask. In this paper, we propose a parameter efficient framework for fine-tuning\nMLLMs, specifically validated on medical visual question answering (Med-VQA)\nand medical report generation (MRG) tasks, using public benchmark datasets. We\nalso introduce an evaluation metric using the 5-point Likert scale and its\nweighted average value to measure the quality of the generated reports for MRG\ntasks, where the scale ratings are labelled by both humans manually and the\nGPT-4 model. We further assess the consistency of performance metrics across\ntraditional measures, GPT-4, and human ratings for both VQA and MRG tasks. The\nresults indicate that semantic similarity assessments using GPT-4 align closely\nwith human annotators and provide greater stability, yet they reveal a\ndiscrepancy when compared to conventional lexical similarity measurements. This\nquestions the reliability of lexical similarity metrics for evaluating the\nperformance of generative models in Med-VQA and report generation tasks.\nBesides, our fine-tuned model significantly outperforms GPT-4v. This indicates\nthat without additional fine-tuning, multi-modal models like GPT-4v do not\nperform effectively on medical imaging tasks. The code will be available here:\nhttps://github.com/jinlHe/PeFoMed.\n","authors":["Jinlong He","Pengfei Li","Gang Liu","Genrong He","Zhaolin Chen","Shenjun Zhong"],"pdf_url":"https://arxiv.org/pdf/2401.02797v3.pdf","comment":"12 pages, 8 figures, 12 tables"},{"id":"http://arxiv.org/abs/2406.09948v2","updated":"2025-01-16T01:41:48Z","published":"2024-06-14T11:48:54Z","title":"BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures\n  and Languages","summary":"  Large language models (LLMs) often lack culture-specific knowledge of daily\nlife, especially across diverse regions and non-English languages. Existing\nbenchmarks for evaluating LLMs' cultural sensitivities are limited to a single\nlanguage or collected from online sources such as Wikipedia, which do not\nreflect the mundane everyday lifestyles of diverse regions. That is,\ninformation about the food people eat for their birthday celebrations, spices\nthey typically use, musical instruments youngsters play, or the sports they\npractice in school is common cultural knowledge but uncommon in easily\ncollected online sources, especially for underrepresented cultures. To address\nthis issue, we introduce BLEnD, a hand-crafted benchmark designed to evaluate\nLLMs' everyday knowledge across diverse cultures and languages. BLEnD comprises\n52.6k question-answer pairs from 16 countries/regions, in 13 different\nlanguages, including low-resource ones such as Amharic, Assamese, Azerbaijani,\nHausa, and Sundanese. We construct the benchmark to include two formats of\nquestions: short-answer and multiple-choice. We show that LLMs perform better\nfor cultures that are highly represented online, with a maximum 57.34%\ndifference in GPT-4, the best-performing model, in the short-answer format. For\ncultures represented by mid-to-high-resource languages, LLMs perform better in\ntheir local languages, but for cultures represented by low-resource languages,\nLLMs perform better in English than the local languages. We make our dataset\npublicly available at: https://github.com/nlee0212/BLEnD.\n","authors":["Junho Myung","Nayeon Lee","Yi Zhou","Jiho Jin","Rifki Afina Putri","Dimosthenis Antypas","Hsuvas Borkakoty","Eunsu Kim","Carla Perez-Almendros","Abinew Ali Ayele","Víctor Gutiérrez-Basulto","Yazmín Ibáñez-García","Hwaran Lee","Shamsuddeen Hassan Muhammad","Kiwoong Park","Anar Sabuhi Rzayev","Nina White","Seid Muhie Yimam","Mohammad Taher Pilehvar","Nedjma Ousidhoum","Jose Camacho-Collados","Alice Oh"],"pdf_url":"https://arxiv.org/pdf/2406.09948v2.pdf","comment":"Accepted to NeurIPS 2024 Datasets & Benchmark Track"},{"id":"http://arxiv.org/abs/2501.09223v1","updated":"2025-01-16T01:03:56Z","published":"2025-01-16T01:03:56Z","title":"Foundations of Large Language Models","summary":"  This is a book about large language models. As indicated by the title, it\nprimarily focuses on foundational concepts rather than comprehensive coverage\nof all cutting-edge technologies. The book is structured into four main\nchapters, each exploring a key area: pre-training, generative models, prompting\ntechniques, and alignment methods. It is intended for college students,\nprofessionals, and practitioners in natural language processing and related\nfields, and can serve as a reference for anyone interested in large language\nmodels.\n","authors":["Tong Xiao","Jingbo Zhu"],"pdf_url":"https://arxiv.org/pdf/2501.09223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09219v1","updated":"2025-01-16T00:35:56Z","published":"2025-01-16T00:35:56Z","title":"A Simple Graph Contrastive Learning Framework for Short Text\n  Classification","summary":"  Short text classification has gained significant attention in the information\nage due to its prevalence and real-world applications. Recent advancements in\ngraph learning combined with contrastive learning have shown promising results\nin addressing the challenges of semantic sparsity and limited labeled data in\nshort text classification. However, existing models have certain limitations.\nThey rely on explicit data augmentation techniques to generate contrastive\nviews, resulting in semantic corruption and noise. Additionally, these models\nonly focus on learning the intrinsic consistency between the generated views,\nneglecting valuable discriminative information from other potential views. To\naddress these issues, we propose a Simple graph contrastive learning framework\nfor Short Text Classification (SimSTC). Our approach involves performing graph\nlearning on multiple text-related component graphs to obtain multi-view text\nembeddings. Subsequently, we directly apply contrastive learning on these\nembeddings. Notably, our method eliminates the need for data augmentation\noperations to generate contrastive views while still leveraging the benefits of\nmulti-view contrastive learning. Despite its simplicity, our model achieves\noutstanding performance, surpassing large language models on various datasets.\n","authors":["Yonghao Liu","Fausto Giunchiglia","Lan Huang","Ximing Li","Xiaoyue Feng","Renchu Guan"],"pdf_url":"https://arxiv.org/pdf/2501.09219v1.pdf","comment":"AAAI2025"},{"id":"http://arxiv.org/abs/2501.09214v1","updated":"2025-01-16T00:26:15Z","published":"2025-01-16T00:26:15Z","title":"Boosting Short Text Classification with Multi-Source Information\n  Exploration and Dual-Level Contrastive Learning","summary":"  Short text classification, as a research subtopic in natural language\nprocessing, is more challenging due to its semantic sparsity and insufficient\nlabeled samples in practical scenarios. We propose a novel model named\nMI-DELIGHT for short text classification in this work. Specifically, it first\nperforms multi-source information (i.e., statistical information, linguistic\ninformation, and factual information) exploration to alleviate the sparsity\nissues. Then, the graph learning approach is adopted to learn the\nrepresentation of short texts, which are presented in graph forms. Moreover, we\nintroduce a dual-level (i.e., instance-level and cluster-level) contrastive\nlearning auxiliary task to effectively capture different-grained contrastive\ninformation within massive unlabeled data. Meanwhile, previous models merely\nperform the main task and auxiliary tasks in parallel, without considering the\nrelationship among tasks. Therefore, we introduce a hierarchical architecture\nto explicitly model the correlations between tasks. We conduct extensive\nexperiments across various benchmark datasets, demonstrating that MI-DELIGHT\nsignificantly surpasses previous competitive models. It even outperforms\npopular large language models on several datasets.\n","authors":["Yonghao Liu","Mengyu Li","Wei Pang","Fausto Giunchiglia","Lan Huang","Xiaoyue Feng","Renchu Guan"],"pdf_url":"https://arxiv.org/pdf/2501.09214v1.pdf","comment":"AAAI2025"},{"id":"http://arxiv.org/abs/2501.09213v1","updated":"2025-01-16T00:19:19Z","published":"2025-01-16T00:19:19Z","title":"FineMedLM-o1: Enhancing the Medical Reasoning Ability of LLM from\n  Supervised Fine-Tuning to Test-Time Training","summary":"  Recent advancements in large language models (LLMs) have shown promise in\nmedical applications such as disease diagnosis and treatment planning. However,\nmost existing medical LLMs struggle with the advanced reasoning required for\ncomplex clinical scenarios, such as differential diagnosis or personalized\ntreatment suggestions. We proposed FineMedLM-o1, which leverages high-quality\nsynthetic medical data and long-form reasoning data for Supervised Fine-Tuning\n(SFT) and Direct Preference Optimization (DPO), enabling advanced dialogue and\ndeep reasoning capabilities. Additionally, we introduced Test-Time Training\n(TTT) in the medical domain for the first time, facilitating domain adaptation\nand ensuring reliable, accurate reasoning. Experimental results demonstrate\nthat FineMedLM-o1 achieves a 23% average performance improvement over prior\nmodels on key medical benchmarks. Furthermore, the introduction of TTT provides\nan additional 14% performance boost, highlighting its effectiveness in\nenhancing medical reasoning capabilities. To support this process, we also\nproposed a novel method for synthesizing medical dialogue. Compared to other\nopen-source datasets, our dataset stands out as superior in both quality and\ncomplexity. The project and data will be released on GitHub.\n","authors":["Hongzhou Yu","Tianhao Cheng","Ying Cheng","Rui Feng"],"pdf_url":"https://arxiv.org/pdf/2501.09213v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2411.01332v2","updated":"2025-01-16T23:37:24Z","published":"2024-11-02T18:30:32Z","title":"A Mechanistic Explanatory Strategy for XAI","summary":"  Despite significant advancements in XAI, scholars note a persistent lack of\nsolid conceptual foundations and integration with broader scientific discourse\non explanation. In response, emerging XAI research draws on explanatory\nstrategies from various sciences and philosophy of science literature to fill\nthese gaps. This paper outlines a mechanistic strategy for explaining the\nfunctional organization of deep learning systems, situating recent advancements\nin AI explainability within a broader philosophical context. According to the\nmechanistic approach, the explanation of opaque AI systems involves identifying\nmechanisms that drive decision-making. For deep neural networks, this means\ndiscerning functionally relevant components -- such as neurons, layers,\ncircuits, or activation patterns -- and understanding their roles through\ndecomposition, localization, and recomposition. Proof-of-principle case studies\nfrom image recognition and language modeling align these theoretical approaches\nwith the latest research from AI labs like OpenAI and Anthropic. This research\nsuggests that a systematic approach to studying model organization can reveal\nelements that simpler (or ''more modest'') explainability techniques might\nmiss, fostering more thoroughly explainable AI. The paper concludes with a\ndiscussion on the epistemic relevance of the mechanistic approach positioned in\nthe context of selected philosophical debates on XAI.\n","authors":["Marcin Rabiza"],"pdf_url":"https://arxiv.org/pdf/2411.01332v2.pdf","comment":"Forthcoming in M\\\"uller, V. C., Dewey, A. R., Dung, L., & L\\\"ohr, G.\n  (Eds.), Philosophy of Artificial Intelligence: The State of the Art, Synthese\n  Library, Berlin: Springer Nature. Please cite the published version"},{"id":"http://arxiv.org/abs/2501.09878v1","updated":"2025-01-16T23:28:30Z","published":"2025-01-16T23:28:30Z","title":"ASTRA: A Scene-aware TRAnsformer-based model for trajectory prediction","summary":"  We present ASTRA (A} Scene-aware TRAnsformer-based model for trajectory\nprediction), a light-weight pedestrian trajectory forecasting model that\nintegrates the scene context, spatial dynamics, social inter-agent interactions\nand temporal progressions for precise forecasting. We utilised a U-Net-based\nfeature extractor, via its latent vector representation, to capture scene\nrepresentations and a graph-aware transformer encoder for capturing social\ninteractions. These components are integrated to learn an agent-scene aware\nembedding, enabling the model to learn spatial dynamics and forecast the future\ntrajectory of pedestrians. The model is designed to produce both deterministic\nand stochastic outcomes, with the stochastic predictions being generated by\nincorporating a Conditional Variational Auto-Encoder (CVAE). ASTRA also\nproposes a simple yet effective weighted penalty loss function, which helps to\nyield predictions that outperform a wide array of state-of-the-art\ndeterministic and generative models. ASTRA demonstrates an average improvement\nof 27%/10% in deterministic/stochastic settings on the ETH-UCY dataset, and 26%\nimprovement on the PIE dataset, respectively, along with seven times fewer\nparameters than the existing state-of-the-art model (see Figure 1).\nAdditionally, the model's versatility allows it to generalize across different\nperspectives, such as Bird's Eye View (BEV) and Ego-Vehicle View (EVV).\n","authors":["Izzeddin Teeti","Aniket Thomas","Munish Monga","Sachin Kumar","Uddeshya Singh","Andrew Bradley","Biplab Banerjee","Fabio Cuzzolin"],"pdf_url":"https://arxiv.org/pdf/2501.09878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09858v1","updated":"2025-01-16T22:11:03Z","published":"2025-01-16T22:11:03Z","title":"From Explainability to Interpretability: Interpretable Policies in\n  Reinforcement Learning Via Model Explanation","summary":"  Deep reinforcement learning (RL) has shown remarkable success in complex\ndomains, however, the inherent black box nature of deep neural network policies\nraises significant challenges in understanding and trusting the decision-making\nprocesses. While existing explainable RL methods provide local insights, they\nfail to deliver a global understanding of the model, particularly in\nhigh-stakes applications. To overcome this limitation, we propose a novel\nmodel-agnostic approach that bridges the gap between explainability and\ninterpretability by leveraging Shapley values to transform complex deep RL\npolicies into transparent representations. The proposed approach offers two key\ncontributions: a novel approach employing Shapley values to policy\ninterpretation beyond local explanations and a general framework applicable to\noff-policy and on-policy algorithms. We evaluate our approach with three\nexisting deep RL algorithms and validate its performance in two classic control\nenvironments. The results demonstrate that our approach not only preserves the\noriginal models' performance but also generates more stable interpretable\npolicies.\n","authors":["Peilang Li","Umer Siddique","Yongcan Cao"],"pdf_url":"https://arxiv.org/pdf/2501.09858v1.pdf","comment":"Accepted to Deployable AI (DAI) Workshop at the Thirty-Ninth AAAI\n  Conference on Artificial Intelligence (AAAI-25)"},{"id":"http://arxiv.org/abs/2101.07914v2","updated":"2025-01-16T21:18:48Z","published":"2021-01-20T00:46:52Z","title":"Intelligent Icing Detection Model of Wind Turbine Blades Based on SCADA\n  data","summary":"  Diagnosis of ice accretion on wind turbine blades is all the time a hard nut\nto crack in condition monitoring of wind farms. Existing methods focus on\nmechanism analysis of icing process, deviation degree analysis of feature\nengineering. However, there have not been deep researches of neural networks\napplied in this field at present. Supervisory control and data acquisition\n(SCADA) makes it possible to train networks through continuously providing not\nonly operation parameters and performance parameters of wind turbines but also\nenvironmental parameters and operation modes. This paper explores the\npossibility that using convolutional neural networks (CNNs), generative\nadversarial networks (GANs) and domain adaption learning to establish\nintelligent diagnosis frameworks under different training scenarios.\nSpecifically, PGANC and PGANT are proposed for sufficient and non-sufficient\ntarget wind turbine labeled data, respectively. The basic idea is that we\nconsider a two-stage training with parallel GANs, which are aimed at capturing\nintrinsic features for normal and icing samples, followed by classification CNN\nor domain adaption module in various training cases. Model validation on three\nwind turbine SCADA data shows that two-stage training can effectively improve\nthe model performance. Besides, if there is no sufficient labeled data for a\ntarget turbine, which is an extremely common phenomenon in real industrial\npractices, the addition of domain adaption learning makes the trained model\nshow better performance. Overall, our proposed intelligent diagnosis frameworks\ncan achieve more accurate detection on the same wind turbine and more\ngeneralized capability on a new wind turbine, compared with other machine\nlearning models and conventional CNNs.\n","authors":["Wenqian Jiang","Junyang Jin"],"pdf_url":"https://arxiv.org/pdf/2101.07914v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.07271v2","updated":"2025-01-16T21:09:57Z","published":"2024-11-10T16:28:42Z","title":"Multi-hop Upstream Anticipatory Traffic Signal Control with Deep\n  Reinforcement Learning","summary":"  Coordination in traffic signal control is crucial for managing congestion in\nurban networks. Existing pressure-based control methods focus only on immediate\nupstream links, leading to suboptimal green time allocation and increased\nnetwork delays. However, effective signal control inherently requires\ncoordination across a broader spatial scope, as the effect of upstream traffic\nshould influence signal control decisions at downstream intersections,\nimpacting a large area in the traffic network. Although agent communication\nusing neural network-based feature extraction can implicitly enhance spatial\nawareness, it significantly increases the learning complexity, adding an\nadditional layer of difficulty to the challenging task of control in deep\nreinforcement learning. To address the issue of learning complexity and myopic\ntraffic pressure definition, our work introduces a novel concept based on\nMarkov chain theory, namely \\textit{multi-hop upstream pressure}, which\ngeneralizes the conventional pressure to account for traffic conditions beyond\nthe immediate upstream links. This farsighted and compact metric informs the\ndeep reinforcement learning agent to preemptively clear the multi-hop upstream\nqueues, guiding the agent to optimize signal timings with a broader spatial\nawareness. Simulations on synthetic and realistic (Toronto) scenarios\ndemonstrate controllers utilizing multi-hop upstream pressure significantly\nreduce overall network delay by prioritizing traffic movements based on a\nbroader understanding of upstream congestion.\n","authors":["Xiaocan Li","Xiaoyu Wang","Ilia Smirnov","Scott Sanner","Baher Abdulhai"],"pdf_url":"https://arxiv.org/pdf/2411.07271v2.pdf","comment":"5 tables, 11 figures"},{"id":"http://arxiv.org/abs/2501.06164v2","updated":"2025-01-16T21:07:04Z","published":"2025-01-10T18:39:29Z","title":"Model Alignment Search","summary":"  When can we say that two neural systems are the same? The answer to this\nquestion is goal-dependent, and it is often addressed through correlative\nmethods such as Representational Similarity Analysis (RSA) and Centered Kernel\nAlignment (CKA). What do we miss when we forgo causal explorations, and how can\nwe target specific types of similarity? In this work, we introduce Model\nAlignment Search (MAS), a method for causally exploring distributed\nrepresentational similarity. The method learns invertible linear\ntransformations that align a subspace between two distributed networks'\nrepresentations where causal information can be freely interchanged. We first\nshow that the method can be used to transfer specific causal variables, such as\nthe number of items in a counting task, between networks with different\ntraining seeds. We then explore open questions in number cognition by comparing\ndifferent types of numeric representations in models trained on structurally\ndifferent numeric tasks. We then explore differences between MAS vs preexisting\ncausal similarity methods, and lastly, we introduce a counterfactual latent\nauxiliary loss function that helps shape causally relevant alignments even in\ncases where we do not have causal access to one of the two models for training.\n","authors":["Satchel Grant"],"pdf_url":"https://arxiv.org/pdf/2501.06164v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09838v1","updated":"2025-01-16T20:56:32Z","published":"2025-01-16T20:56:32Z","title":"CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified\n  Intermediate Representation","summary":"  Geospatial imaging leverages data from diverse sensing modalities-such as EO,\nSAR, and LiDAR, ranging from ground-level drones to satellite views. These\nheterogeneous inputs offer significant opportunities for scene understanding\nbut present challenges in interpreting geometry accurately, particularly in the\nabsence of precise ground truth data. To address this, we propose\nCrossModalityDiffusion, a modular framework designed to generate images across\ndifferent modalities and viewpoints without prior knowledge of scene geometry.\nCrossModalityDiffusion employs modality-specific encoders that take multiple\ninput images and produce geometry-aware feature volumes that encode scene\nstructure relative to their input camera positions. The space where the feature\nvolumes are placed acts as a common ground for unifying input modalities. These\nfeature volumes are overlapped and rendered into feature images from novel\nperspectives using volumetric rendering techniques. The rendered feature images\nare used as conditioning inputs for a modality-specific diffusion model,\nenabling the synthesis of novel images for the desired output modality. In this\npaper, we show that jointly training different modules ensures consistent\ngeometric understanding across all modalities within the framework. We validate\nCrossModalityDiffusion's capabilities on the synthetic ShapeNet cars dataset,\ndemonstrating its effectiveness in generating accurate and consistent novel\nviews across multiple imaging modalities and perspectives.\n","authors":["Alex Berian","Daniel Brignac","JhihYang Wu","Natnael Daba","Abhijit Mahalanobis"],"pdf_url":"https://arxiv.org/pdf/2501.09838v1.pdf","comment":"Accepted in the 2025 WACV workshop GeoCV"},{"id":"http://arxiv.org/abs/2409.17400v2","updated":"2025-01-16T20:25:21Z","published":"2024-09-25T22:19:32Z","title":"AgRegNet: A Deep Regression Network for Flower and Fruit Density\n  Estimation, Localization, and Counting in Orchards","summary":"  One of the major challenges for the agricultural industry today is the\nuncertainty in manual labor availability and the associated cost. Automated\nflower and fruit density estimation, localization, and counting could help\nstreamline harvesting, yield estimation, and crop-load management strategies\nsuch as flower and fruitlet thinning. This article proposes a deep\nregression-based network, AgRegNet, to estimate density, count, and location of\nflower and fruit in tree fruit canopies without explicit object detection or\npolygon annotation. Inspired by popular U-Net architecture, AgRegNet is a\nU-shaped network with an encoder-to-decoder skip connection and modified\nConvNeXt-T as an encoder feature extractor. AgRegNet can be trained based on\ninformation from point annotation and leverages segmentation information and\nattention modules (spatial and channel) to highlight relevant flower and fruit\nfeatures while suppressing non-relevant background features. Experimental\nevaluation in apple flower and fruit canopy images under an unstructured\norchard environment showed that AgRegNet achieved promising accuracy as\nmeasured by Structural Similarity Index (SSIM), percentage Mean Absolute Error\n(pMAE) and mean Average Precision (mAP) to estimate flower and fruit density,\ncount, and centroid location, respectively. Specifically, the SSIM, pMAE, and\nmAP values for flower images were 0.938, 13.7%, and 0.81, respectively. For\nfruit images, the corresponding values were 0.910, 5.6%, and 0.93. Since the\nproposed approach relies on information from point annotation, it is suitable\nfor sparsely and densely located objects. This simplified technique will be\nhighly applicable for growers to accurately estimate yields and decide on\noptimal chemical and mechanical flower thinning practices.\n","authors":["Uddhav Bhattarai","Santosh Bhusal","Qin Zhang","Manoj Karkee"],"pdf_url":"https://arxiv.org/pdf/2409.17400v2.pdf","comment":"Published in Computers and Electronics in Agriculture"},{"id":"http://arxiv.org/abs/2501.09825v1","updated":"2025-01-16T20:24:56Z","published":"2025-01-16T20:24:56Z","title":"Bridging Language Barriers in Healthcare: A Study on Arabic LLMs","summary":"  This paper investigates the challenges of developing large language models\n(LLMs) proficient in both multilingual understanding and medical knowledge. We\ndemonstrate that simply translating medical data does not guarantee strong\nperformance on clinical tasks in the target language. Our experiments reveal\nthat the optimal language mix in training data varies significantly across\ndifferent medical tasks. We find that larger models with carefully calibrated\nlanguage ratios achieve superior performance on native-language clinical tasks.\nFurthermore, our results suggest that relying solely on fine-tuning may not be\nthe most effective approach for incorporating new language knowledge into LLMs.\nInstead, data and computationally intensive pretraining methods may still be\nnecessary to achieve optimal performance in multilingual medical settings.\nThese findings provide valuable guidance for building effective and inclusive\nmedical AI systems for diverse linguistic communities.\n","authors":["Nada Saadi","Tathagata Raha","Clément Christophe","Marco AF Pimentel","Ronnie Rajan","Praveen K Kanithi"],"pdf_url":"https://arxiv.org/pdf/2501.09825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09817v1","updated":"2025-01-16T20:09:19Z","published":"2025-01-16T20:09:19Z","title":"Generalized Single-Image-Based Morphing Attack Detection Using Deep\n  Representations from Vision Transformer","summary":"  Face morphing attacks have posed severe threats to Face Recognition Systems\n(FRS), which are operated in border control and passport issuance use cases.\nCorrespondingly, morphing attack detection algorithms (MAD) are needed to\ndefend against such attacks. MAD approaches must be robust enough to handle\nunknown attacks in an open-set scenario where attacks can originate from\nvarious morphing generation algorithms, post-processing and the diversity of\nprinters/scanners. The problem of generalization is further pronounced when the\ndetection has to be made on a single suspected image. In this paper, we propose\na generalized single-image-based MAD (S-MAD) algorithm by learning the encoding\nfrom Vision Transformer (ViT) architecture. Compared to CNN-based\narchitectures, ViT model has the advantage on integrating local and global\ninformation and hence can be suitable to detect the morphing traces widely\ndistributed among the face region. Extensive experiments are carried out on\nface morphing datasets generated using publicly available FRGC face datasets.\nSeveral state-of-the-art (SOTA) MAD algorithms, including representative ones\nthat have been publicly evaluated, have been selected and benchmarked with our\nViT-based approach. Obtained results demonstrate the improved detection\nperformance of the proposed S-MAD method on inter-dataset testing (when\ndifferent data is used for training and testing) and comparable performance on\nintra-dataset testing (when the same data is used for training and testing)\nexperimental protocol.\n","authors":["Haoyu Zhang","Raghavendra Ramachandra","Kiran Raja","Christoph Busch"],"pdf_url":"https://arxiv.org/pdf/2501.09817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09804v1","updated":"2025-01-16T19:23:11Z","published":"2025-01-16T19:23:11Z","title":"Enhancing Generalization in Chain of Thought Reasoning for Smaller\n  Models","summary":"  Chain-of-Thought (CoT) reasoning in smaller language models is a challenging\nnatural language process problem yet highly desirable in many real-life\napplications. Existing CoT knowledge distillation methods often suffer from\noverly conservative memorization in smaller LLMs, leading to low generalization\nconfidence. As fully preserving the CoT ability of teacher model is impossible,\nwe hypothesize that adversarial CoT fine-tuning is crucial for developing\nsmaller LLM with robust CoT generalization. To this end, we propose\n\\textit{PRompt-Assisted Domain-Adversarial fine-tuning} (PRADA), a principled\nfine-tuning framework that integrates diverse CoT domains. Specifically, PRADA\npioneers two CoT improvements in smaller LLM: (1) Recovering the\ndomain-invariant feature insight which typically lost during distillation with\ndomain adversarial fine-tuning; (2) Enhancing the domain adaptability of CoT\nprompt engineering by employing domain-adversarial approaches. We theoretically\ndemonstrate the effectiveness of our approach and empirically show that it\nsignificantly outperforms the state of the arts in a wide range of tasks.\nMoreover, our empirical findings reveal that the smaller LLM, when leveraging\nPRADA, aligns closely with domain knowledge, thereby improving the\nexplainability of our approach.\n","authors":["Maxwell J. Yin","Dingyi Jiang","Yongbing Chen","Boyu Wang","Charles Ling"],"pdf_url":"https://arxiv.org/pdf/2501.09804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09755v1","updated":"2025-01-16T18:59:04Z","published":"2025-01-16T18:59:04Z","title":"Learnings from Scaling Visual Tokenizers for Reconstruction and\n  Generation","summary":"  Visual tokenization via auto-encoding empowers state-of-the-art image and\nvideo generative models by compressing pixels into a latent space. Although\nscaling Transformer-based generators has been central to recent advances, the\ntokenizer component itself is rarely scaled, leaving open questions about how\nauto-encoder design choices influence both its objective of reconstruction and\ndownstream generative performance. Our work aims to conduct an exploration of\nscaling in auto-encoders to fill in this blank. To facilitate this exploration,\nwe replace the typical convolutional backbone with an enhanced Vision\nTransformer architecture for Tokenization (ViTok). We train ViTok on\nlarge-scale image and video datasets far exceeding ImageNet-1K, removing data\nconstraints on tokenizer scaling. We first study how scaling the auto-encoder\nbottleneck affects both reconstruction and generation -- and find that while it\nis highly correlated with reconstruction, its relationship with generation is\nmore complex. We next explored the effect of separately scaling the\nauto-encoders' encoder and decoder on reconstruction and generation\nperformance. Crucially, we find that scaling the encoder yields minimal gains\nfor either reconstruction or generation, while scaling the decoder boosts\nreconstruction but the benefits for generation are mixed. Building on our\nexploration, we design ViTok as a lightweight auto-encoder that achieves\ncompetitive performance with state-of-the-art auto-encoders on ImageNet-1K and\nCOCO reconstruction tasks (256p and 512p) while outperforming existing\nauto-encoders on 16-frame 128p video reconstruction for UCF-101, all with 2-5x\nfewer FLOPs. When integrated with Diffusion Transformers, ViTok demonstrates\ncompetitive performance on image generation for ImageNet-1K and sets new\nstate-of-the-art benchmarks for class-conditional video generation on UCF-101.\n","authors":["Philippe Hansen-Estruch","David Yan","Ching-Yao Chung","Orr Zohar","Jialiang Wang","Tingbo Hou","Tao Xu","Sriram Vishwanath","Peter Vajda","Xinlei Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09755v1.pdf","comment":"28 pages, 25 figures, 7 Tables"},{"id":"http://arxiv.org/abs/2501.09751v1","updated":"2025-01-16T18:58:06Z","published":"2025-01-16T18:58:06Z","title":"OmniThink: Expanding Knowledge Boundaries in Machine Writing through\n  Thinking","summary":"  Machine writing with large language models often relies on\nretrieval-augmented generation. However, these approaches remain confined\nwithin the boundaries of the model's predefined scope, limiting the generation\nof content with rich information. Specifically, vanilla-retrieved information\ntends to lack depth, utility, and suffers from redundancy, which negatively\nimpacts the quality of generated articles, leading to shallow, repetitive, and\nunoriginal outputs. To address these issues, we propose OmniThink, a machine\nwriting framework that emulates the human-like process of iterative expansion\nand reflection. The core idea behind OmniThink is to simulate the cognitive\nbehavior of learners as they progressively deepen their knowledge of the\ntopics. Experimental results demonstrate that OmniThink improves the knowledge\ndensity of generated articles without compromising metrics such as coherence\nand depth. Human evaluations and expert feedback further highlight the\npotential of OmniThink to address real-world challenges in the generation of\nlong-form articles.\n","authors":["Zekun Xi","Wenbiao Yin","Jizhan Fang","Jialong Wu","Runnan Fang","Ningyu Zhang","Jiang Yong","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.08965v3","updated":"2025-01-16T18:56:27Z","published":"2024-05-14T21:12:01Z","title":"Meaning-Typed Programming: Language-level Abstractions and Runtime for\n  GenAI Applications","summary":"  Software is rapidly evolving from being programmed with traditional logical\ncode, to neuro-integrated applications that leverage generative AI and large\nlanguage models (LLMs) for application functionality. This shift increases the\ncomplexity of building applications, as developers now must reasoning about,\nprogram, and prompt LLMs. Despite efforts to create tools to assist with prompt\nengineering, these solutions often introduce additional layers of complexity to\nthe development of neuro-integrated applications. This paper proposes\nmeaning-typed programming (MTP), a novel approach to simplify the creation of\nneuro-integrated applications by introducing new language-level abstractions\nthat hide the complexities of LLM integration. Our key insight is that typical\nconventional code already possesses a high level of semantic richness that can\nbe automatically reasoned about, as it is designed to be readable and\nmaintainable by humans. Leveraging this insight, we conceptualize LLMs as\nmeaning-typed code constructs and introduce a by abstraction at the language\nlevel, MT-IR, a new meaning-based intermediate representation at the compiler\nlevel, and MT Runtime, an automated run-time engine for LLM integration and\noperations. We implement MTP in a production-grade Python super-set language\ncalled Jac and perform an extensive evaluation. Our results demonstrate that\nMTP not only simplifies the development process but also meets or exceeds the\nefficacy of state-of-the-art manual and tool-assisted prompt engineering\ntechniques in terms of accuracy and usability.\n","authors":["Jason Mars","Yiping Kang","Jayanaka L. Dantanarayana","Kugesan Sivasothynathan","Christopher Clarke","Baichuan Li","Krisztian Flautner","Lingjia Tang"],"pdf_url":"https://arxiv.org/pdf/2405.08965v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09744v1","updated":"2025-01-16T18:53:32Z","published":"2025-01-16T18:53:32Z","title":"KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity\n  Recognition and Normalization for Dysmorphology Physical Examination Reports","summary":"  The objective of BioCreative8 Track 3 is to extract phenotypic key medical\nfindings embedded within EHR texts and subsequently normalize these findings to\ntheir Human Phenotype Ontology (HPO) terms. However, the presence of diverse\nsurface forms in phenotypic findings makes it challenging to accurately\nnormalize them to the correct HPO terms. To address this challenge, we explored\nvarious models for named entity recognition and implemented data augmentation\ntechniques such as synonym marginalization to enhance the normalization step.\nOur pipeline resulted in an exact extraction and normalization F1 score 2.6\\%\nhigher than the mean score of all submissions received in response to the\nchallenge. Furthermore, in terms of the normalization F1 score, our approach\nsurpassed the average performance by 1.9\\%. These findings contribute to the\nadvancement of automated medical data extraction and normalization techniques,\nshowcasing potential pathways for future research and application in the\nbiomedical domain.\n","authors":["Hajung Kim","Chanhwi Kim","Jiwoong Sohn","Tim Beck","Marek Rei","Sunkyu Kim","T Ian Simpson","Joram M Posma","Antoine Lain","Mujeen Sung","Jaewoo Kang"],"pdf_url":"https://arxiv.org/pdf/2501.09744v1.pdf","comment":"This article is part of the Proceedings of the BioCreative VIII\n  Challenge and Workshop: Curation and Evaluation in the era of Generative\n  Models"},{"id":"http://arxiv.org/abs/2501.01945v2","updated":"2025-01-16T18:53:23Z","published":"2025-01-03T18:51:18Z","title":"Cold-Start Recommendation towards the Era of Large Language Models\n  (LLMs): A Comprehensive Survey and Roadmap","summary":"  Cold-start problem is one of the long-standing challenges in recommender\nsystems, focusing on accurately modeling new or interaction-limited users or\nitems to provide better recommendations. Due to the diversification of internet\nplatforms and the exponential growth of users and items, the importance of\ncold-start recommendation (CSR) is becoming increasingly evident. At the same\ntime, large language models (LLMs) have achieved tremendous success and possess\nstrong capabilities in modeling user and item information, providing new\npotential for cold-start recommendations. However, the research community on\nCSR still lacks a comprehensive review and reflection in this field. Based on\nthis, in this paper, we stand in the context of the era of large language\nmodels and provide a comprehensive review and discussion on the roadmap,\nrelated literature, and future directions of CSR. Specifically, we have\nconducted an exploration of the development path of how existing CSR utilizes\ninformation, from content features, graph relations, and domain information, to\nthe world knowledge possessed by large language models, aiming to provide new\ninsights for both the research and industrial communities on CSR. Related\nresources of cold-start recommendations are collected and continuously updated\nfor the community in\nhttps://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.\n","authors":["Weizhi Zhang","Yuanchen Bei","Liangwei Yang","Henry Peng Zou","Peilin Zhou","Aiwei Liu","Yinghui Li","Hao Chen","Jianling Wang","Yu Wang","Feiran Huang","Sheng Zhou","Jiajun Bu","Allen Lin","James Caverlee","Fakhri Karray","Irwin King","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2501.01945v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04845v2","updated":"2025-01-16T18:48:36Z","published":"2024-12-06T08:30:01Z","title":"Using Machine Learning to Discover Parsimonious and\n  Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff\n  Dynamics","summary":"  Despite the excellent real-world predictive performance of modern machine\nlearning (ML) methods, many scientists remain hesitant to discard traditional\nphysical-conceptual (PC) approaches due mainly to their relative\ninterpretability, which contributes to credibility during decision-making. In\nthis context, a currently underexplored aspect of ML is how to develop\nminimally-optimal representations that can facilitate better insight regarding\nsystem functioning. Regardless of how this is achieved, it is arguably true\nthat parsimonious representations better support the advancement of scientific\nunderstanding. Our own view is that ML-based modeling of geoscientific systems\nshould be based in the use of computational units that are fundamentally\ninterpretable by design.\n  This paper continues our exploration of how the strengths of ML can be\nexploited in the service of better understanding via scientific investigation.\nHere, we use the Mass Conserving Perceptron (MCP) as the fundamental\ncomputational unit in a generic network architecture consisting of nodes\narranged in series and parallel to explore several generic and important issues\nrelated to the use of observational data for constructing input-state-output\nmodels of dynamical systems. In the context of lumped catchment modeling, we\nshow that physical interpretability and excellent predictive performance can\nboth be achieved using a relatively parsimonious distributed-state\nmultiple-flow-path network with context-dependent gating and information\nsharing across the nodes, suggesting that MCP-based modeling can play a\nsignificant role in application of ML to geoscientific investigation.\n","authors":["Yuan-Heng Wang","Hoshin V. Gupta"],"pdf_url":"https://arxiv.org/pdf/2412.04845v2.pdf","comment":"74 Pages, 4 Tables, 13 Figures, 11 Tables and 11 Figures in\n  Supplementary Materials"},{"id":"http://arxiv.org/abs/2501.09725v1","updated":"2025-01-16T18:16:34Z","published":"2025-01-16T18:16:34Z","title":"Parallel multi-objective metaheuristics for smart communications in\n  vehicular networks","summary":"  This article analyzes the use of two parallel multi-objective soft computing\nalgorithms to automatically search for high-quality settings of the Ad hoc On\nDemand Vector routing protocol for vehicular networks. These methods are based\non an evolutionary algorithm and on a swarm intelligence approach. The\nexperimental analysis demonstrates that the configurations computed by our\noptimization algorithms outperform other state-of-the-art optimized ones. In\nturn, the computational efficiency achieved by all the parallel versions is\ngreater than 87 %. Therefore, the line of work presented in this article\nrepresents an efficient framework to improve vehicular communications.\n","authors":["Jamal Toutouh","Enrique Alba"],"pdf_url":"https://arxiv.org/pdf/2501.09725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09720v1","updated":"2025-01-16T18:09:22Z","published":"2025-01-16T18:09:22Z","title":"A Simple Aerial Detection Baseline of Multimodal Language Models","summary":"  The multimodal language models (MLMs) based on generative pre-trained\nTransformer are considered powerful candidates for unifying various domains and\ntasks. MLMs developed for remote sensing (RS) have demonstrated outstanding\nperformance in multiple tasks, such as visual question answering and visual\ngrounding. In addition to visual grounding that detects specific objects\ncorresponded to given instruction, aerial detection, which detects all objects\nof multiple categories, is also a valuable and challenging task for RS\nfoundation models. However, aerial detection has not been explored by existing\nRS MLMs because the autoregressive prediction mechanism of MLMs differs\nsignificantly from the detection outputs. In this paper, we present a simple\nbaseline for applying MLMs to aerial detection for the first time, named\nLMMRotate. Specifically, we first introduce a normalization method to transform\ndetection outputs into textual outputs to be compatible with the MLM framework.\nThen, we propose a evaluation method, which ensures a fair comparison between\nMLMs and conventional object detection models. We construct the baseline by\nfine-tuning open-source general-purpose MLMs and achieve impressive detection\nperformance comparable to conventional detector. We hope that this baseline\nwill serve as a reference for future MLM development, enabling more\ncomprehensive capabilities for understanding RS images. Code is available at\nhttps://github.com/Li-Qingyun/mllm-mmrotate.\n","authors":["Qingyun Li","Yushi Chen","Xinya Shu","Dong Chen","Xin He","Yi Yu","Xue Yang"],"pdf_url":"https://arxiv.org/pdf/2501.09720v1.pdf","comment":"4 pages, 1 table, 4 figures"},{"id":"http://arxiv.org/abs/2501.09709v1","updated":"2025-01-16T18:00:06Z","published":"2025-01-16T18:00:06Z","title":"CyberMentor: AI Powered Learning Tool Platform to Address Diverse\n  Student Needs in Cybersecurity Education","summary":"  Many non-traditional students in cybersecurity programs often lack access to\nadvice from peers, family members and professors, which can hinder their\neducational experiences. Additionally, these students may not fully benefit\nfrom various LLM-powered AI assistants due to issues like content relevance,\nlocality of advice, minimum expertise, and timing. This paper addresses these\nchallenges by introducing an application designed to provide comprehensive\nsupport by answering questions related to knowledge, skills, and career\npreparation advice tailored to the needs of these students. We developed a\nlearning tool platform, CyberMentor, to address the diverse needs and pain\npoints of students majoring in cybersecurity. Powered by agentic workflow and\nGenerative Large Language Models (LLMs), the platform leverages\nRetrieval-Augmented Generation (RAG) for accurate and contextually relevant\ninformation retrieval to achieve accessibility and personalization. We\ndemonstrated its value in addressing knowledge requirements for cybersecurity\neducation and for career marketability, in tackling skill requirements for\nanalytical and programming assignments, and in delivering real time on demand\nlearning support. Using three use scenarios, we showcased CyberMentor in\nfacilitating knowledge acquisition and career preparation and providing\nseamless skill-based guidance and support. We also employed the LangChain\nprompt-based evaluation methodology to evaluate the platform's impact,\nconfirming its strong performance in helpfulness, correctness, and\ncompleteness. These results underscore the system's ability to support students\nin developing practical cybersecurity skills while improving equity and\nsustainability within higher education. Furthermore, CyberMentor's open-source\ndesign allows for adaptation across other disciplines, fostering educational\ninnovation and broadening its potential impact.\n","authors":["Tianyu Wang","Nianjun Zhou","Zhixiong Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09709v1.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2501.09707v1","updated":"2025-01-16T17:58:58Z","published":"2025-01-16T17:58:58Z","title":"The Goofus & Gallant Story Corpus for Practical Value Alignment","summary":"  Values or principles are key elements of human society that influence people\nto behave and function according to an accepted standard set of social rules to\nmaintain social order. As AI systems are becoming ubiquitous in human society,\nit is a major concern that they could violate these norms or values and\npotentially cause harm. Thus, to prevent intentional or unintentional harm, AI\nsystems are expected to take actions that align with these principles. Training\nsystems to exhibit this type of behavior is difficult and often requires a\nspecialized dataset. This work presents a multi-modal dataset illustrating\nnormative and non-normative behavior in real-life situations described through\nnatural language and artistic images. This training set contains curated sets\nof images that are designed to teach young children about social principles. We\nargue that this is an ideal dataset to use for training socially normative\nagents given this fact.\n","authors":["Md Sultan Al Nahian","Tasmia Tasrin","Spencer Frazier","Mark Riedl","Brent Harrison"],"pdf_url":"https://arxiv.org/pdf/2501.09707v1.pdf","comment":"Accepted by International Conference on Machine Learning and\n  Applications (ICMLA) 2024. Main Conference, Long Paper"},{"id":"http://arxiv.org/abs/2501.09705v1","updated":"2025-01-16T17:57:53Z","published":"2025-01-16T17:57:53Z","title":"Practical Continual Forgetting for Pre-trained Vision Models","summary":"  For privacy and security concerns, the need to erase unwanted information\nfrom pre-trained vision models is becoming evident nowadays. In real-world\nscenarios, erasure requests originate at any time from both users and model\nowners, and these requests usually form a sequence. Therefore, under such a\nsetting, selective information is expected to be continuously removed from a\npre-trained model while maintaining the rest. We define this problem as\ncontinual forgetting and identify three key challenges. (i) For unwanted\nknowledge, efficient and effective deleting is crucial. (ii) For remaining\nknowledge, the impact brought by the forgetting procedure should be minimal.\n(iii) In real-world scenarios, the training samples may be scarce or partially\nmissing during the process of forgetting. To address them, we first propose\nGroup Sparse LoRA (GS-LoRA). Specifically, towards (i), we introduce LoRA\nmodules to fine-tune the FFN layers in Transformer blocks for each forgetting\ntask independently, and towards (ii), a simple group sparse regularization is\nadopted, enabling automatic selection of specific LoRA groups and zeroing out\nthe others. To further extend GS-LoRA to more practical scenarios, we\nincorporate prototype information as additional supervision and introduce a\nmore practical approach, GS-LoRA++. For each forgotten class, we move the\nlogits away from its original prototype. For the remaining classes, we pull the\nlogits closer to their respective prototypes. We conduct extensive experiments\non face recognition, object detection and image classification and demonstrate\nthat our method manages to forget specific classes with minimal impact on other\nclasses. Codes have been released on https://github.com/bjzhb666/GS-LoRA.\n","authors":["Hongbo Zhao","Fei Zhu","Bolin Ni","Feng Zhu","Gaofeng Meng","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.09705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07948v2","updated":"2025-01-16T17:56:53Z","published":"2024-12-10T22:22:19Z","title":"Frechet Music Distance: A Metric For Generative Symbolic Music\n  Evaluation","summary":"  In this paper we introduce the Frechet Music Distance (FMD), a novel\nevaluation metric for generative symbolic music models, inspired by the Frechet\nInception Distance (FID) in computer vision and Frechet Audio Distance (FAD) in\ngenerative audio. FMD calculates the distance between distributions of\nreference and generated symbolic music embeddings, capturing abstract musical\nfeatures. We validate FMD across several datasets and models. Results indicate\nthat FMD effectively differentiates model quality, providing a domain-specific\nmetric for evaluating symbolic music generation, and establishing a\nreproducible standard for future research in symbolic music modeling.\n","authors":["Jan Retkowski","Jakub Stępniak","Mateusz Modrzejewski"],"pdf_url":"https://arxiv.org/pdf/2412.07948v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09700v1","updated":"2025-01-16T17:54:56Z","published":"2025-01-16T17:54:56Z","title":"Cueless EEG imagined speech for subject identification: dataset and\n  benchmarks","summary":"  Electroencephalogram (EEG) signals have emerged as a promising modality for\nbiometric identification. While previous studies have explored the use of\nimagined speech with semantically meaningful words for subject identification,\nmost have relied on additional visual or auditory cues. In this study, we\nintroduce a cueless EEG-based imagined speech paradigm, where subjects imagine\nthe pronunciation of semantically meaningful words without any external cues.\nThis innovative approach addresses the limitations of prior methods by\nrequiring subjects to select and imagine words from a predefined list\nnaturally. The dataset comprises over 4,350 trials from 11 subjects across five\nsessions. We assess a variety of classification methods, including traditional\nmachine learning techniques such as Support Vector Machines (SVM) and XGBoost,\nas well as time-series foundation models and deep learning architectures\nspecifically designed for EEG classification, such as EEG Conformer and Shallow\nConvNet. A session-based hold-out validation strategy was employed to ensure\nreliable evaluation and prevent data leakage. Our results demonstrate\noutstanding classification accuracy, reaching 97.93%. These findings highlight\nthe potential of cueless EEG paradigms for secure and reliable subject\nidentification in real-world applications, such as brain-computer interfaces\n(BCIs).\n","authors":["Ali Derakhshesh","Zahra Dehghanian","Reza Ebrahimpour","Hamid R. Rabiee"],"pdf_url":"https://arxiv.org/pdf/2501.09700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09685v1","updated":"2025-01-16T17:37:35Z","published":"2025-01-16T17:37:35Z","title":"Reward-Guided Controlled Generation for Inference-Time Alignment in\n  Diffusion Models: Tutorial and Review","summary":"  This tutorial provides an in-depth guide on inference-time guidance and\nalignment methods for optimizing downstream reward functions in diffusion\nmodels. While diffusion models are renowned for their generative modeling\ncapabilities, practical applications in fields such as biology often require\nsample generation that maximizes specific metrics (e.g., stability, affinity in\nproteins, closeness to target structures). In these scenarios, diffusion models\ncan be adapted not only to generate realistic samples but also to explicitly\nmaximize desired measures at inference time without fine-tuning. This tutorial\nexplores the foundational aspects of such inference-time algorithms. We review\nthese methods from a unified perspective, demonstrating that current techniques\n-- such as Sequential Monte Carlo (SMC)-based guidance, value-based sampling,\nand classifier guidance -- aim to approximate soft optimal denoising processes\n(a.k.a. policies in RL) that combine pre-trained denoising processes with value\nfunctions serving as look-ahead functions that predict from intermediate states\nto terminal rewards. Within this framework, we present several novel algorithms\nnot yet covered in the literature. Furthermore, we discuss (1) fine-tuning\nmethods combined with inference-time techniques, (2) inference-time algorithms\nbased on search algorithms such as Monte Carlo tree search, which have received\nlimited attention in current research, and (3) connections between\ninference-time algorithms in language models and diffusion models. The code of\nthis tutorial on protein design is available at\nhttps://github.com/masa-ue/AlignInversePro\n","authors":["Masatoshi Uehara","Yulai Zhao","Chenyu Wang","Xiner Li","Aviv Regev","Sergey Levine","Tommaso Biancalani"],"pdf_url":"https://arxiv.org/pdf/2501.09685v1.pdf","comment":"We plan to add more content/codes. Please let us know if there are\n  any comments"},{"id":"http://arxiv.org/abs/2501.09682v1","updated":"2025-01-16T17:34:34Z","published":"2025-01-16T17:34:34Z","title":"Incorporating Quantum Advantage in Quantum Circuit Generation through\n  Genetic Programming","summary":"  Designing efficient quantum circuits that leverage quantum advantage compared\nto classical computing has become increasingly critical. Genetic algorithms\nhave shown potential in generating such circuits through artificial evolution.\nHowever, integrating quantum advantage into the fitness function of these\nalgorithms remains unexplored. In this paper, we aim to enhance the efficiency\nof quantum circuit design by proposing two novel approaches for incorporating\nquantum advantage metrics into the fitness function of genetic algorithms.1 We\nevaluate our approaches based on the Bernstein-Vazirani Problem and the\nUnstructured Database Search Problem as test cases. The results demonstrate\nthat our approaches not only improve the convergence speed of the genetic\nalgorithm but also produce circuits comparable to expert-designed solutions.\nOur findings suggest that automated quantum circuit design using genetic\nalgorithms that incorporate a measure of quantum advantage is a promising\napproach to accelerating the development of quantum algorithms.\n","authors":["Christoph Stein","Michael Färber"],"pdf_url":"https://arxiv.org/pdf/2501.09682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04202v7","updated":"2025-01-16T17:28:26Z","published":"2024-03-07T04:12:24Z","title":"Dynamics of Moral Behavior in Heterogeneous Populations of Learning\n  Agents","summary":"  Growing concerns about safety and alignment of AI systems highlight the\nimportance of embedding moral capabilities in artificial agents: a promising\nsolution is the use of learning from experience, i.e., Reinforcement Learning.\nIn multi-agent (social) environments, complex population-level phenomena may\nemerge from interactions between individual learning agents. Many of the\nexisting studies rely on simulated social dilemma environments to study the\ninteractions of independent learning agents; however, they tend to ignore the\nmoral heterogeneity that is likely to be present in societies of agents in\npractice. For example, at different points in time a single learning agent may\nface opponents who are consequentialist (i.e., focused on maximizing outcomes\nover time), norm-based (i.e., conforming to specific norms), or virtue-based\n(i.e., considering a combination of different virtues). The extent to which\nagents' co-development may be impacted by such moral heterogeneity in\npopulations is not well understood. In this paper, we present a study of the\nlearning dynamics of morally heterogeneous populations interacting in a social\ndilemma setting. Using an Iterated Prisoner's Dilemma environment with a\npartner selection mechanism, we investigate the extent to which the prevalence\nof diverse moral agents in populations affects individual agents' learning\nbehaviors and emergent population-level outcomes. We observe several types of\nnon-trivial interactions between pro-social and anti-social agents, and find\nthat certain types of moral agents are able to steer selfish agents towards\nmore cooperative behavior.\n","authors":["Elizaveta Tennant","Stephen Hailes","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2403.04202v7.pdf","comment":"Presented at AIES 2024 (7th AAAI/ACM Conference on AI, Ethics, and\n  Society - San Jose, CA, USA) - see\n  https://ojs.aaai.org/index.php/AIES/article/view/31736"},{"id":"http://arxiv.org/abs/2501.09674v1","updated":"2025-01-16T17:11:21Z","published":"2025-01-16T17:11:21Z","title":"Authenticated Delegation and Authorized AI Agents","summary":"  The rapid deployment of autonomous AI agents creates urgent challenges around\nauthorization, accountability, and access control in digital spaces. New\nstandards are needed to know whom AI agents act on behalf of and guide their\nuse appropriately, protecting online spaces while unlocking the value of task\ndelegation to autonomous agents. We introduce a novel framework for\nauthenticated, authorized, and auditable delegation of authority to AI agents,\nwhere human users can securely delegate and restrict the permissions and scope\nof agents while maintaining clear chains of accountability. This framework\nbuilds on existing identification and access management protocols, extending\nOAuth 2.0 and OpenID Connect with agent-specific credentials and metadata,\nmaintaining compatibility with established authentication and web\ninfrastructure. Further, we propose a framework for translating flexible,\nnatural language permissions into auditable access control configurations,\nenabling robust scoping of AI agent capabilities across diverse interaction\nmodalities. Taken together, this practical approach facilitates immediate\ndeployment of AI agents while addressing key security and accountability\nconcerns, working toward ensuring agentic AI systems perform only appropriate\nactions and providing a tool for digital service providers to enable AI agent\ninteractions without risking harm from scalable interaction.\n","authors":["Tobin South","Samuele Marro","Thomas Hardjono","Robert Mahari","Cedric Deslandes Whitney","Dazza Greenwood","Alan Chan","Alex Pentland"],"pdf_url":"https://arxiv.org/pdf/2501.09674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09672v1","updated":"2025-01-16T17:08:12Z","published":"2025-01-16T17:08:12Z","title":"Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP\n  Evaluation Benchmark","summary":"  The proliferation of Vision-Language Models (VLMs) in the past several years\ncalls for rigorous and comprehensive evaluation methods and benchmarks. This\nwork analyzes existing VLM evaluation techniques, including automated metrics,\nAI-based assessments, and human evaluations across diverse tasks. We first\nintroduce Robin - a novel suite of VLMs that we built by combining Large\nLanguage Models (LLMs) and Vision Encoders (VEs) at multiple scales, and use\nRobin to identify shortcomings of current evaluation approaches across scales.\nNext, to overcome the identified limitations, we introduce CHIRP - a new long\nform response benchmark we developed for more robust and complete VLM\nevaluation. We provide open access to the Robin training code, model suite, and\nCHIRP benchmark to promote reproducibility and advance VLM research.\n","authors":["Alexis Roger","Prateek Humane","Daniel Z. Kaplan","Kshitij Gupta","Qi Sun","George Adamopoulos","Jonathan Siu Chi Lim","Quentin Anthony","Edwin Fennell","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2501.09672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09653v1","updated":"2025-01-16T16:48:41Z","published":"2025-01-16T16:48:41Z","title":"The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating\n  Large Language Models","summary":"  The recent rise in the popularity of large language models has spurred the\ndevelopment of extensive code datasets needed to train them. This has left\nlimited code available for collection and use in the downstream investigation\nof specific behaviors, or evaluation of large language models without suffering\nfrom data contamination. To address this problem, we release The Heap, a large\nmultilingual dataset covering 57 programming languages that has been\ndeduplicated with respect to other open datasets of code, enabling researchers\nto conduct fair evaluations of large language models without significant data\ncleaning overhead.\n","authors":["Jonathan Katzy","Razvan Mihai Popescu","Arie van Deursen","Maliheh Izadi"],"pdf_url":"https://arxiv.org/pdf/2501.09653v1.pdf","comment":"Pre-Print. Accepted to FORGE 2025 Dataset Track"},{"id":"http://arxiv.org/abs/2501.09649v1","updated":"2025-01-16T16:45:08Z","published":"2025-01-16T16:45:08Z","title":"Monte Carlo Tree Search with Velocity Obstacles for safe and efficient\n  motion planning in dynamic environments","summary":"  Online motion planning is a challenging problem for intelligent robots moving\nin dense environments with dynamic obstacles, e.g., crowds. In this work, we\npropose a novel approach for optimal and safe online motion planning with\nminimal information about dynamic obstacles. Specifically, our approach\nrequires only the current position of the obstacles and their maximum speed,\nbut it does not need any information about their exact trajectories or dynamic\nmodel. The proposed methodology combines Monte Carlo Tree Search (MCTS), for\nonline optimal planning via model simulations, with Velocity Obstacles (VO),\nfor obstacle avoidance. We perform experiments in a cluttered simulated\nenvironment with walls, and up to 40 dynamic obstacles moving with random\nvelocities and directions. With an ablation study, we show the key contribution\nof VO in scaling up the efficiency of MCTS, selecting the safest and most\nrewarding actions in the tree of simulations. Moreover, we show the superiority\nof our methodology with respect to state-of-the-art planners, including\nNon-linear Model Predictive Control (NMPC), in terms of improved collision\nrate, computational and task performance.\n","authors":["Lorenzo Bonanni","Daniele Meli","Alberto Castellini","Alessandro Farinelli"],"pdf_url":"https://arxiv.org/pdf/2501.09649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16600v2","updated":"2025-01-16T16:42:59Z","published":"2024-10-22T00:55:04Z","title":"Convex Markov Games: A Framework for Creativity, Imitation, Fairness,\n  and Safety in Multiagent Learning","summary":"  Behavioral diversity, expert imitation, fairness, safety goals and others\ngive rise to preferences in sequential decision making domains that do not\ndecompose additively across time. We introduce the class of convex Markov games\nthat allow general convex preferences over occupancy measures. Despite infinite\ntime horizon and strictly higher generality than Markov games, pure strategy\nNash equilibria exist. Furthermore, equilibria can be approximated empirically\nby performing gradient descent on an upper bound of exploitability. Our\nexperiments reveal novel solutions to classic repeated normal-form games, find\nfair solutions in a repeated asymmetric coordination game, and prioritize safe\nlong-term behavior in a robot warehouse environment. In the prisoner's dilemma,\nour algorithm leverages transient imitation to find a policy profile that\ndeviates from observed human play only slightly, yet achieves higher per-player\nutility while also being three orders of magnitude less exploitable.\n","authors":["Ian Gemp","Andreas Haupt","Luke Marris","Siqi Liu","Georgios Piliouras"],"pdf_url":"https://arxiv.org/pdf/2410.16600v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09646v1","updated":"2025-01-16T16:38:33Z","published":"2025-01-16T16:38:33Z","title":"NS-Gym: Open-Source Simulation Environments and Benchmarks for\n  Non-Stationary Markov Decision Processes","summary":"  In many real-world applications, agents must make sequential decisions in\nenvironments where conditions are subject to change due to various exogenous\nfactors. These non-stationary environments pose significant challenges to\ntraditional decision-making models, which typically assume stationary dynamics.\nNon-stationary Markov decision processes (NS-MDPs) offer a framework to model\nand solve decision problems under such changing conditions. However, the lack\nof standardized benchmarks and simulation tools has hindered systematic\nevaluation and advance in this field. We present NS-Gym, the first simulation\ntoolkit designed explicitly for NS-MDPs, integrated within the popular\nGymnasium framework. In NS-Gym, we segregate the evolution of the environmental\nparameters that characterize non-stationarity from the agent's decision-making\nmodule, allowing for modular and flexible adaptations to dynamic environments.\nWe review prior work in this domain and present a toolkit encapsulating key\nproblem characteristics and types in NS-MDPs. This toolkit is the first effort\nto develop a set of standardized interfaces and benchmark problems to enable\nconsistent and reproducible evaluation of algorithms under non-stationary\nconditions. We also benchmark six algorithmic approaches from prior work on\nNS-MDPs using NS-Gym. Our vision is that NS-Gym will enable researchers to\nassess the adaptability and robustness of their decision-making algorithms to\nnon-stationary conditions.\n","authors":["Nathaniel S. Keplinger","Baiting Luo","Iliyas Bektas","Yunuo Zhang","Kyle Hollins Wray","Aron Laszka","Abhishek Dubey","Ayan Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2501.09646v1.pdf","comment":"23 pages, 17 figures"},{"id":"http://arxiv.org/abs/2501.09645v1","updated":"2025-01-16T16:37:33Z","published":"2025-01-16T16:37:33Z","title":"CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through\n  Category-Bounding","summary":"  In today's assistant landscape, personalisation enhances interactions,\nfosters long-term relationships, and deepens engagement. However, many systems\nstruggle with retaining user preferences, leading to repetitive user requests\nand disengagement. Furthermore, the unregulated and opaque extraction of user\npreferences in industry applications raises significant concerns about privacy\nand trust, especially in regions with stringent regulations like Europe. In\nresponse to these challenges, we propose a long-term memory system for voice\nassistants, structured around predefined categories. This approach leverages\nLarge Language Models to efficiently extract, store, and retrieve preferences\nwithin these categories, ensuring both personalisation and transparency. We\nalso introduce a synthetic multi-turn, multi-session conversation dataset\n(CarMem), grounded in real industry data, tailored to an in-car voice assistant\nsetting. Benchmarked on the dataset, our system achieves an F1-score of .78 to\n.95 in preference extraction, depending on category granularity. Our\nmaintenance strategy reduces redundant preferences by 95% and contradictory\nones by 92%, while the accuracy of optimal retrieval is at .87. Collectively,\nthe results demonstrate the system's suitability for industrial applications.\n","authors":["Johannes Kirmayr","Lukas Stappen","Phillip Schneider","Florian Matthes","Elisabeth André"],"pdf_url":"https://arxiv.org/pdf/2501.09645v1.pdf","comment":"Accepted for presentation at the International Conference on\n  Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2501.09640v1","updated":"2025-01-16T16:30:02Z","published":"2025-01-16T16:30:02Z","title":"Electronic Health Records: Towards Digital Twins in Healthcare","summary":"  The pivotal shift from traditional paper-based records to sophisticated\nElectronic Health Records (EHR), enabled systematic collection and analysis of\npatient data through descriptive statistics, providing insight into patterns\nand trends across patient populations. This evolution continued toward\npredictive analytics, allowing healthcare providers to anticipate patient\noutcomes and potential complications before they occur. This progression from\nbasic digital record-keeping to sophisticated predictive modelling and digital\ntwins reflects healthcare's broader evolution toward more integrated,\npatient-centred approaches that combine data-driven insights with personalized\ncare delivery. This chapter explores the evolution and significance of\nhealthcare information systems, beginning with an examination of the\nimplementation of EHR in the UK and the USA. It provides a comprehensive\noverview of the International Classification of Diseases (ICD) system, tracing\nits development from ICD-9 to ICD-10. Central to this discussion is the\nMIMIC-III database, a landmark achievement in healthcare data sharing and\narguably the most comprehensive critical care database freely available to\nresearchers worldwide. MIMIC-III has democratized access to high-quality\nhealthcare data, enabling unprecedented opportunities for research and\nanalysis. The chapter examines its structure, clinical outcome analysis\ncapabilities, and practical applications through case studies, with a\nparticular focus on mortality and length of stay metrics, vital signs\nextraction, and ICD coding. Through detailed entity-relationship diagrams and\npractical examples, the text illustrates MIMIC's complex data structure and\ndemonstrates how different querying approaches can lead to subtly different\nresults, emphasizing the critical importance of understanding the database's\narchitecture for accurate data extraction.\n","authors":["Muhammet Alkan","Hester Huijsdens","Yola Jones","Fani Deligianni"],"pdf_url":"https://arxiv.org/pdf/2501.09640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.16641v3","updated":"2025-01-16T16:29:31Z","published":"2024-12-21T14:21:33Z","title":"A Systems Thinking Approach to Algorithmic Fairness","summary":"  Systems thinking provides us with a way to model the algorithmic fairness\nproblem by allowing us to encode prior knowledge and assumptions about where we\nbelieve bias might exist in the data generating process. We can then encode\nthese beliefs as a series of causal graphs, enabling us to link AI/ML systems\nto politics and the law. This allows us to combine techniques from machine\nlearning, causal inference, and system dynamics in order to capture different\nemergent aspects of the fairness problem. We can use systems thinking to help\npolicymakers on both sides of the political aisle to understand the complex\ntrade-offs that exist from different types of fairness policies, providing a\nsociotechnical foundation for designing AI policy that is aligned to their\npolitical agendas.\n","authors":["Chris Lam"],"pdf_url":"https://arxiv.org/pdf/2412.16641v3.pdf","comment":"This paper has been submitted to the 2025 ACM FAccT conference for\n  review"}],"Software Engineering":[{"id":"http://arxiv.org/abs/2501.09879v1","updated":"2025-01-16T23:31:49Z","published":"2025-01-16T23:31:49Z","title":"Testing Refactoring Engine via Historical Bug Report driven LLM","summary":"  Refactoring is the process of restructuring existing code without changing\nits external behavior while improving its internal structure. Refactoring\nengines are integral components of modern Integrated Development Environments\n(IDEs) and can automate or semi-automate this process to enhance code\nreadability, reduce complexity, and improve the maintainability of software\nproducts. Similar to traditional software systems such as compilers,\nrefactoring engines may also contain bugs that can lead to unexpected\nbehaviors. In this paper, we propose a novel approach called RETESTER, a\nLLM-based framework for automated refactoring engine testing. Specifically, by\nusing input program structure templates extracted from historical bug reports\nand input program characteristics that are error-prone, we design\nchain-of-thought (CoT) prompts to perform refactoring-preserving\ntransformations. The generated variants are then tested on the latest version\nof refactoring engines using differential testing. We evaluate RETESTER on two\nmost popular modern refactoring engines (i.e., ECLIPSE, and INTELLIJ IDEA). It\nsuccessfully revealed 18 new bugs in the latest version of those refactoring\nengines. By the time we submit our paper, seven of them were confirmed by their\ndevelopers, and three were fixed.\n","authors":["Haibo Wang","Zhuolin Xu","Shin Hwei Tan"],"pdf_url":"https://arxiv.org/pdf/2501.09879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09872v1","updated":"2025-01-16T22:58:50Z","published":"2025-01-16T22:58:50Z","title":"Automatically Detecting Heterogeneous Bugs in High-Performance Computing\n  Scientific Software","summary":"  Scientific advancements rely on high-performance computing (HPC) applications\nthat model real-world phenomena through simulations. These applications process\nvast amounts of data on specialized accelerators (eg., GPUs) using special\nlibraries. Heterogeneous bugs occur in these applications when managing data\nmovement across different platforms, such as CPUs and GPUs, leading to\ndivergent behavior when using heterogeneous platforms compared to using only\nCPUs. Existing software testing techniques often fail to detect such bugs\nbecause either they do not account for platform-specific characteristics or\ntarget specific platforms. To address this problem, we present HeteroBugDetect,\nan automated approach to detect platform-dependent heterogeneous bugs in HPC\nscientific applications. HeteroBugDetect combines natural-language processing,\noff-target testing, custom fuzzing, and differential testing to provide an\nend-to-end solution for detecting platform-specific bugs in scientific\napplications. We evaluate HeteroBugDetect on LAMMPS, a molecular dynamics\nsimulator, where it detected multiple heterogeneous bugs, enhancing its\nreliability across diverse HPC environments.\n","authors":["Matthew Davis","Aakash Kulkarni","Ziyan Chen","Yunhan Qiao","Christopher Terrazas","Manish Motwani"],"pdf_url":"https://arxiv.org/pdf/2501.09872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09866v1","updated":"2025-01-16T22:36:00Z","published":"2025-01-16T22:36:00Z","title":"Fine-grained Testing for Autonomous Driving Software: a Study on\n  Autoware with LLM-driven Unit Testing","summary":"  Testing autonomous driving systems (ADS) is critical to ensuring their\nreliability and safety. Existing ADS testing works focuses on designing\nscenarios to evaluate system-level behaviors, while fine-grained testing of ADS\nsource code has received comparatively little attention. To address this gap,\nwe present the first study on testing, specifically unit testing, for ADS\nsource code. Our study focuses on an industrial ADS framework, Autoware. We\nanalyze both human-written test cases and those generated by large language\nmodels (LLMs). Our findings reveal that human-written test cases in Autoware\nexhibit limited test coverage, and significant challenges remain in applying\nLLM-generated tests for Autoware unit testing. To overcome these challenges, we\npropose AwTest-LLM, a novel approach to enhance test coverage and improve test\ncase pass rates across Autoware packages.\n","authors":["Wenhan Wang","Xuan Xie","Yuheng Huang","Renzhi Wang","An Ran Chen","Lei Ma"],"pdf_url":"https://arxiv.org/pdf/2501.09866v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09861v1","updated":"2025-01-16T22:20:04Z","published":"2025-01-16T22:20:04Z","title":"Optimization is Better than Generation: Optimizing Commit Message\n  Leveraging Human-written Commit Message","summary":"  Commit messages are crucial in software development, supporting maintenance\ntasks and communication among developers. While Large Language Models (LLMs)\nhave advanced Commit Message Generation (CMG) using various software contexts,\nsome contexts developers consider are often missed by CMG techniques and can't\nbe easily retrieved or even retrieved at all by automated tools. To address\nthis, we propose Commit Message Optimization (CMO), which enhances\nhuman-written messages by leveraging LLMs and search-based optimization. CMO\nstarts with human-written messages and iteratively improves them by integrating\nkey contexts and feedback from external evaluators. Our extensive evaluation\nshows CMO generates commit messages that are significantly more Rational,\nComprehensive, and Expressive while outperforming state-of-the-art CMG methods\nand human messages 88.2%-95.4% of the time.\n","authors":["Jiawei Li","David Faragó","Christian Petrov","Iftekhar Ahmed"],"pdf_url":"https://arxiv.org/pdf/2501.09861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09846v1","updated":"2025-01-16T21:29:34Z","published":"2025-01-16T21:29:34Z","title":"MuFF: Stable and Sensitive Post-training MutationTesting for Deep\n  Learning","summary":"  Rapid adoptions of Deep Learning (DL) in a broad range of fields led to the\ndevelopment of specialised testing techniques for DL systems, including DL\nmutation testing. However, existing post-training DL mutation techniques often\ngenerate unstable mutants across multiple training repetitions and multiple\napplications of the same mutation operator. Additionally, while extremely\nefficient, they generate mutants without taking into account the mutants'\nsensitivity and killability, resulting in a large number of ineffective mutants\ncompared to pre-training mutants. In this paper, we present a new efficient\npost-training DL mutation technique, named MuFF, designed to ensure the\nstability of the mutants and capable of generating killable and sensitive\nmutants. MuFF implements an automated stability check and introduces two\nmutation operators, named weight and neuron inhibitors. Our extensive empirical\nexperiments show that MuFF generates mutants with 60%pt and 25%pt higher\nsensitivity compared to DeepMutation++ and DeepCrime, respectively, while also\nproducing mutants that are more stable than those of DeepMutation++ and\ndifferent from the mutants of DeepCrime. Moreover, MuFF preserves the benefits\nof the post-training mutation technique, being 61 times faster than DeepCrime\nin generating mutants.\n","authors":["Jinhan Kim","Nargiz Humbatova","Gunel Jahangirova","Shin Yoo","Paolo Tonella"],"pdf_url":"https://arxiv.org/pdf/2501.09846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09745v1","updated":"2025-01-16T18:55:38Z","published":"2025-01-16T18:55:38Z","title":"Suggesting Code Edits in Interactive Machine Learning Notebooks Using\n  Large Language Models","summary":"  Machine learning developers frequently use interactive computational\nnotebooks, such as Jupyter notebooks, to host code for data processing and\nmodel training. Jupyter notebooks provide a convenient tool for writing machine\nlearning pipelines and interactively observing outputs, however, maintaining\nJupyter notebooks, e.g., to add new features or fix bugs, can be challenging\ndue to the length and complexity of the notebooks. Moreover, there is no\nexisting benchmark related to developer edits on Jupyter notebooks. To address\nthis, we present the first dataset of 48,398 Jupyter notebook edits derived\nfrom 20,095 revisions of 792 machine learning repositories on GitHub, and\nperform the first study of the using LLMs to predict code edits in Jupyter\nnotebooks. Our dataset captures granular details of cell-level and line-level\nmodifications, offering a foundation for understanding real-world maintenance\npatterns in machine learning workflows. We observed that the edits on Jupyter\nnotebooks are highly localized, with changes averaging only 166 lines of code\nin repositories. While larger models outperform smaller counterparts in code\nediting, all models have low accuracy on our dataset even after finetuning,\ndemonstrating the complexity of real-world machine learning maintenance tasks.\nOur findings emphasize the critical role of contextual information in improving\nmodel performance and point toward promising avenues for advancing large\nlanguage models' capabilities in engineering machine learning code.\n","authors":["Bihui Jin","Jiayue Wang","Pengyu Nie"],"pdf_url":"https://arxiv.org/pdf/2501.09745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09694v1","updated":"2025-01-16T17:47:18Z","published":"2025-01-16T17:47:18Z","title":"Simulated Interactive Debugging","summary":"  Debugging software, i.e., the localization of faults and their repair, is a\nmain activity in software engineering. Therefore, effective and efficient\ndebugging is one of the core skills a software engineer must develop. However,\nthe teaching of debugging techniques is usually very limited or only taught in\nindirect ways, e.g., during software projects. As a result, most Computer\nScience (CS) students learn debugging only in an ad-hoc and unstructured way.\nIn this work, we present our approach called Simulated Interactive Debugging\nthat interactively guides students along the debugging process. The guidance\naims to empower the students to repair their solutions and have a proper\n\"learning\" experience. We envision that such guided debugging techniques can be\nintegrated into programming courses early in the CS education curriculum. To\nperform an initial evaluation, we developed a prototypical implementation using\ntraditional fault localization techniques and large language models. Students\ncan use features like the automated setting of breakpoints or an interactive\nchatbot. We designed and executed a controlled experiment that included this\nIDE-integrated tooling with eight undergraduate CS students. Based on the\nresponses, we conclude that the participants liked the systematic guidance by\nthe assisted debugger. In particular, they rated the automated setting of\nbreakpoints as the most effective, followed by the interactive debugging and\nchatting, and the explanations for how breakpoints were set. In our future\nwork, we will improve our concept and implementation, add new features, and\nperform more intensive user studies.\n","authors":["Yannic Noller","Erick Chandra","Srinidhi HC","Kenny Choo","Cyrille Jegourel","Oka Kurniawan","Christopher M. Poskitt"],"pdf_url":"https://arxiv.org/pdf/2501.09694v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09657v1","updated":"2025-01-16T16:52:55Z","published":"2025-01-16T16:52:55Z","title":"On the Energy Consumption of Test Generation","summary":"  Research in the area of automated test generation has seen remarkable\nprogress in recent years, resulting in several approaches and tools for\neffective and efficient generation of test cases. In particular, the EvoSuite\ntool has been at the forefront of this progress embodying various algorithms\nfor automated test generation of Java programs. EvoSuite has been used to\ngenerate test cases for a wide variety of programs as well. While there are a\nnumber of empirical studies that report results on the effectiveness, in terms\nof code coverage and other related metrics, of the various test generation\nstrategies and algorithms implemented in EvoSuite, there are no studies, to the\nbest of our knowledge, on the energy consumption associated to the automated\ntest generation. In this paper, we set out to investigate this aspect by\nmeasuring the energy consumed by EvoSuite when generating tests. We also\nmeasure the energy consumed in the execution of the test cases generated,\ncomparing them with those manually written by developers. The results show that\nthe different test generation algorithms consumed different amounts of energy,\nin particular on classes with high cyclomatic complexity. Furthermore, we also\nobserve that manual tests tend to consume more energy as compared to\nautomatically generated tests, without necessarily achieving higher code\ncoverage. Our results also give insight into the methods that consume\nsignificantly higher levels of energy, indicating potential points of\nimprovement both for EvoSuite as well as the different programs under test.\n","authors":["Fitsum Kifetew","Davide Prandi","Angelo Susi"],"pdf_url":"https://arxiv.org/pdf/2501.09657v1.pdf","comment":"Accepted for publication at 2025 IEEE Conference on Software Testing,\n  Verification and Validation (ICST)"},{"id":"http://arxiv.org/abs/2410.17907v2","updated":"2025-01-16T16:10:24Z","published":"2024-10-23T14:26:51Z","title":"Adaptive Random Testing with Qgrams: The Illusion Comes True","summary":"  Adaptive Random Testing (ART) has faced criticism, particularly for its\ncomputational inefficiency, as highlighted by Arcuri and Briand. Their analysis\nclarified how ART requires a quadratic number of distance computations as the\nnumber of test executions increases, which limits its scalability in scenarios\nrequiring extensive testing to uncover faults. Simulation results support this,\nshowing that the computational overhead of these distance calculations often\noutweighs ART's benefits. While various ART variants have attempted to reduce\nthese costs, they frequently do so at the expense of fault detection, lack\ncomplexity guarantees, or are restricted to specific input types, such as\nnumerical or discrete data.\n  In this paper, we introduce a novel framework for adaptive random testing\nthat replaces pairwise distance computations with a compact aggregation of past\nexecutions, such as counting the Qgrams observed in previous runs. Test case\nselection then leverages this aggregated data to measure diversity (e.g.,\nentropy of Qgrams), allowing us to reduce the computational complexity from\nquadratic to linear.\n  Experiments with a benchmark of six web applications, show that ART with\nQgrams covers, on average, 4x more unique targets than random testing, and 3.5x\nmore than ART using traditional distance-based methods.\n","authors":["Matteo Biagiola","Robert Feldt","Paolo Tonella"],"pdf_url":"https://arxiv.org/pdf/2410.17907v2.pdf","comment":"Accepted at the ACM International Conference on the Foundations of\n  Software Engineering (FSE) 2025"},{"id":"http://arxiv.org/abs/2410.13187v3","updated":"2025-01-16T12:46:53Z","published":"2024-10-17T03:32:02Z","title":"aiXcoder-7B: A Lightweight and Effective Large Language Model for Code\n  Processing","summary":"  Large Language Models (LLMs) have been widely used in code completion, and\nresearchers are focusing on scaling up LLMs to improve their accuracy. However,\nlarger LLMs have lower inference efficiency, affecting developers' experience\nand productivity. In this paper, we propose a lightweight and effective LLM for\ncode completion named aiXcoder-7B. Compared to existing LLMs, aiXcoder-7B\nachieves higher code completion accuracy while having smaller scales (i.e., 7\nbillion parameters). We attribute the superiority of aiXcoder-7B to three key\nfactors: (1) Multi-objective training. We employ three training objectives, one\nof which is our proposed Structured Fill-In-the-Middle (SFIM). SFIM considers\nthe syntax structures in code and effectively improves the performance of LLMs\nfor code. (2) Diverse data sampling strategies. They consider inter-file\nrelationships and enhance the capability of LLMs in understanding cross-file\ncontexts. (3) Extensive high-quality data. We establish a rigorous data\ncollection pipeline and consume a total of 1.2 trillion unique tokens for\ntraining aiXcoder-7B. This vast volume of data enables aiXcoder-7B to learn a\nbroad distribution of code. We evaluate aiXcoder-7B in five popular code\ncompletion benchmarks and a new benchmark collected by this paper. The results\nshow that aiXcoder-7B outperforms the latest six LLMs with similar sizes and\neven surpasses four larger LLMs (e.g., StarCoder2-15B and CodeLlama-34B),\npositioning aiXcoder-7B as a lightweight and effective LLM for academia and\nindustry. Finally, we summarize three valuable insights for helping\npractitioners train the next generations of LLMs for code. aiXcoder-7B has been\nopen-souced and gained significant attention. Until January 2025, aiXcoder-7B\nhas received 2,226 GitHub Stars.\n","authors":["Siyuan Jiang","Jia Li","He Zong","Huanyu Liu","Hao Zhu","Shukai Hu","Erlu Li","Jiazheng Ding","Yu Han","Wei Ning","Gen Wang","Yihong Dong","Kechi Zhang","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2410.13187v3.pdf","comment":"(1) Accepted by the 47th International Conference on Software\n  Engineering (ICSE 2025). (2) aiXcoder-7B is available at\n  https://github.com/aixcoder-plugin/aiXcoder-7B"},{"id":"http://arxiv.org/abs/2501.09475v1","updated":"2025-01-16T11:27:25Z","published":"2025-01-16T11:27:25Z","title":"Guided Debugging of Auto-Translated Code Using Differential Testing","summary":"  Large Language Models (LLMs) hold great promise in the task of code\ntranslation. However, the lack of explainability complicates the identification\nof the inevitable translation errors. In this paper, we propose tHinter, a\ndebugging tool to locate translation errors in auto-translated code. The core\nidea of tHinter is that correctly translated, the source and translated code\nshould present the same functionalities, giving the same output for the same\ninput. Hence, lines in the translated code responsible for output differences\nare possibly translation errors. First, tHinter employs fuzzing to generate\ndiverse test cases that thoroughly explore the translated code. Then, tHinter\nrelies on a heuristic algorithm to pinpoint translation errors from coverage\ninformation and differential testing execution results of those test cases.\nThis heuristic algorithm is designed to leverage both the statistics and the\nexpertise of developers. Comprehensive experiments with real code show its\neffectiveness. It reduces 71% lines developers need to review during debugging\nand increases the likelihood of the LLM fixing translation errors in a single\nquery by 59%. Developers generally consider it satisfactory and helpful.\n","authors":["Shengnan Wu","Xinyu Sun","Xin Wang","Yangfan Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.09475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04986v2","updated":"2025-01-16T06:55:59Z","published":"2024-10-07T12:34:20Z","title":"Finding Safety Violations of AI-Enabled Control Systems through the Lens\n  of Synthesized Proxy Programs","summary":"  Given the increasing adoption of modern AI-enabled control systems, ensuring\ntheir safety and reliability has become a critical task in software testing.\nOne prevalent approach to testing control systems is falsification, which aims\nto find an input signal that causes the control system to violate a formal\nsafety specification using optimization algorithms. However, applying\nfalsification to AI-enabled control systems poses two significant challenges:\n(1)~it requires the system to execute numerous candidate test inputs, which can\nbe time-consuming, particularly for systems with AI models that have many\nparameters, and (2)~multiple safety requirements are typically defined as a\nconjunctive specification, which is difficult for existing falsification\napproaches to comprehensively cover.\n  This paper introduces Synthify, a falsification framework tailored for\nAI-enabled control systems. Our approach performs falsification in a two-phase\nprocess. At the start, Synthify synthesizes a program that implements one or a\nfew linear controllers to serve as a proxy for the AI controller. This proxy\nprogram mimics the AI controller's functionality but is computationally more\nefficient. Then, Synthify employs the $\\epsilon$-greedy strategy to sample a\npromising sub-specification from the conjunctive safety specification. It then\nuses a Simulated Annealing-based falsification algorithm to find violations of\nthe sampled sub-specification for the control system. To evaluate Synthify, we\ncompare it to PSY-TaLiRo, a state-of-the-art and industrial-strength\nfalsification tool, on 8 publicly available control systems. On average,\nSynthify achieves a 83.5% higher success rate in falsification compared to\nPSY-TaLiRo with the same budget of falsification trials. The safety violations\nfound by Synthify are also more diverse than those found by PSY-TaLiRo,\ncovering 137.7% more sub-specifications.\n","authors":["Jieke Shi","Zhou Yang","Junda He","Bowen Xu","Dongsun Kim","DongGyun Han","David Lo"],"pdf_url":"https://arxiv.org/pdf/2410.04986v2.pdf","comment":"Accepted by ACM Transactions on Software Engineering and Methodology\n  (TOSEM), 35 pages"},{"id":"http://arxiv.org/abs/2501.09319v1","updated":"2025-01-16T06:19:55Z","published":"2025-01-16T06:19:55Z","title":"Modeling Language for Scenario Development of Autonomous Driving Systems","summary":"  Autonomous driving systems are typically verified based on scenarios. To\nrepresent the positions and movements of cars in these scenarios, diagrams that\nutilize icons are typically employed. However, the interpretation of such\ndiagrams is typically ambiguous, which can lead to misunderstandings among\nusers, making them unsuitable for the development of high-reliability systems.\nTo address this issue, this study introduces a notation called the car position\ndiagram (CPD). The CPD allows for the concise representation of numerous\nscenarios and is particularly suitable for scenario analysis and design. In\naddition, we propose a method for converting CPD-based models into\npropositional logic formulas and enumerating all scenarios using a SAT solver.\nA tool for scenario enumeration is implemented, and experiments are conducted\non both typical car behaviors and international standards. The results\ndemonstrate that the CPD enables the concise description of numerous scenarios,\nthereby confirming the effectiveness of our scenario analysis method.\n","authors":["Toshiaki Aoki","Takashi Tomita","Tatsuji Kawai","Daisuke Kawakami","Nobuo Chida"],"pdf_url":"https://arxiv.org/pdf/2501.09319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09310v1","updated":"2025-01-16T05:54:59Z","published":"2025-01-16T05:54:59Z","title":"A Study of In-Context-Learning-Based Text-to-SQL Errors","summary":"  Large language models (LLMs) have been adopted to perform text-to-SQL tasks,\nutilizing their in-context learning (ICL) capability to translate natural\nlanguage questions into structured query language (SQL). However, such a\ntechnique faces correctness problems and requires efficient repairing\nsolutions. In this paper, we conduct the first comprehensive study of\ntext-to-SQL errors. Our study covers four representative ICL-based techniques,\nfive basic repairing methods, two benchmarks, and two LLM settings. We find\nthat text-to-SQL errors are widespread and summarize 29 error types of 7\ncategories. We also find that existing repairing attempts have limited\ncorrectness improvement at the cost of high computational overhead with many\nmis-repairs. Based on the findings, we propose MapleRepair, a novel text-to-SQL\nerror detection and repairing framework. The evaluation demonstrates that\nMapleRepair outperforms existing solutions by repairing 13.8% more queries with\nneglectable mis-repairs and 67.4% less overhead.\n","authors":["Jiawei Shen","Chengcheng Wan","Ruoyi Qiao","Jiazhen Zou","Hang Xu","Yuchen Shao","Yueling Zhang","Weikai Miao","Geguang Pu"],"pdf_url":"https://arxiv.org/pdf/2501.09310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15368v2","updated":"2025-01-16T05:40:08Z","published":"2024-11-22T22:29:37Z","title":"The Power of Types: Exploring the Impact of Type Checking on Neural Bug\n  Detection in Dynamically Typed Languages","summary":"  Motivation: Automated bug detection in dynamically typed languages such as\nPython is essential for maintaining code quality. The lack of mandatory type\nannotations in such languages can lead to errors that are challenging to\nidentify early with traditional static analysis tools. Recent progress in deep\nneural networks has led to increased use of neural bug detectors. In statically\ntyped languages, a type checker is integrated into the compiler and thus taken\ninto consideration when the neural bug detector is designed for these\nlanguages.\n  Problem: However, prior studies overlook this aspect during the training and\ntesting of neural bug detectors for dynamically typed languages. When an\noptional type checker is used, assessing existing neural bug detectors on bugs\neasily detectable by type checkers may impact their performance estimation.\nMoreover, including these bugs in the training set of neural bug detectors can\nshift their detection focus toward the wrong type of bugs.\n  Contribution: We explore the impact of type checking on various neural bug\ndetectors for variable misuse bugs, a common type targeted by neural bug\ndetectors. Existing synthetic and real-world datasets are type-checked to\nevaluate the prevalence of type-related bugs. Then, we investigate how\ntype-related bugs influence the training and testing of the neural bug\ndetectors.\n  Findings: Our findings indicate that existing bug detection datasets contain\na significant proportion of type-related bugs. Building on this insight, we\ndiscover integrating the neural bug detector with a type checker can be\nbeneficial, especially when the code is annotated with types. Further\ninvestigation reveals neural bug detectors perform better on type-related bugs\nthan other bugs. Moreover, removing type-related bugs from the training data\nhelps improve neural bug detectors' ability to identify bugs beyond the scope\nof type checkers.\n","authors":["Boqi Chen","José Antonio Hernández López","Gunter Mussbacher","Dániel Varró"],"pdf_url":"https://arxiv.org/pdf/2411.15368v2.pdf","comment":"Accepted by ICSE'25 Research Track"},{"id":"http://arxiv.org/abs/2411.17274v3","updated":"2025-01-16T04:08:15Z","published":"2024-11-26T09:51:55Z","title":"CleanVul: Automatic Function-Level Vulnerability Detection in Code\n  Commits Using LLM Heuristics","summary":"  Accurate identification of software vulnerabilities is crucial for system\nintegrity. Vulnerability datasets, often derived from the National\nVulnerability Database (NVD) or directly from GitHub, are essential for\ntraining machine learning models to detect these security flaws. However, these\ndatasets frequently suffer from significant noise, typically 40% to 75%, due\nprimarily to the automatic and indiscriminate labeling of all changes in\nvulnerability-fixing commits (VFCs) as vulnerability-related. This\nmisclassification occurs because not all changes in a commit aimed at fixing\nvulnerabilities pertain to security threats; many are routine updates like bug\nfixes or test improvements.\n  This paper introduces the first methodology that uses the Large Language\nModel (LLM) with a heuristic enhancement to automatically identify\nvulnerability-fixing changes from VFCs, achieving an F1-score of 0.82.\nVulSifter was applied to a large-scale study, where we conducted a crawl of\n127,063 repositories on GitHub, resulting in the acquisition of 5,352,105\ncommits. VulSifter involves utilizing an LLM to comprehend code semantics and\ncontextual information, while applying heuristics to filter out unrelated\nchanges. We then developed CleanVul, a high-quality dataset comprising 11,632\nfunctions using our LLM heuristic enhancement approach, demonstrating\nCorrectness (90.6%) comparable to established datasets such as SVEN and\nPrimeVul.\n  To evaluate the CleanVul dataset, we conducted experiments focusing on\nfine-tuning various LLMs on CleanVul and other high-quality datasets.\nEvaluation results reveal that LLMs fine-tuned on CleanVul not only exhibit\nenhanced accuracy but also superior generalization capabilities compared to\nthose trained on uncleaned datasets. Specifically, models trained on CleanVul\nand tested on PrimeVul achieve accuracy higher than those trained and tested\nexclusively on PrimeVul.\n","authors":["Yikun Li","Ting Zhang","Ratnadira Widyasari","Yan Naing Tun","Huu Hung Nguyen","Tan Bui","Ivana Clairine Irsan","Yiran Cheng","Xiang Lan","Han Wei Ang","Frank Liauw","Martin Weyssow","Hong Jin Kang","Eng Lieh Ouh","Lwin Khin Shar","David Lo"],"pdf_url":"https://arxiv.org/pdf/2411.17274v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09236v1","updated":"2025-01-16T01:42:33Z","published":"2025-01-16T01:42:33Z","title":"Exploring the Capabilities of Vision-Language Models to Detect Visual\n  Bugs in HTML5 <canvas> Applications","summary":"  The HyperText Markup Language 5 (HTML5) <canvas> is useful for creating\nvisual-centric web applications. However, unlike traditional web applications,\nHTML5 <canvas> applications render objects onto the <canvas> bitmap without\nrepresenting them in the Document Object Model (DOM). Mismatches between the\nexpected and actual visual output of the <canvas> bitmap are termed visual\nbugs. Due to the visual-centric nature of <canvas> applications, visual bugs\nare important to detect because such bugs can render a <canvas> application\nuseless. As we showed in prior work, Asset-Based graphics can provide the\nground truth for a visual test oracle. However, many <canvas> applications\nprocedurally generate their graphics. In this paper, we investigate how to\ndetect visual bugs in <canvas> applications that use Procedural graphics as\nwell. In particular, we explore the potential of Vision-Language Models (VLMs)\nto automatically detect visual bugs. Instead of defining an exact visual test\noracle, information about the application's expected functionality (the\ncontext) can be provided with the screenshot as input to the VLM. To evaluate\nthis approach, we constructed a dataset containing 80 bug-injected screenshots\nacross four visual bug types (Layout, Rendering, Appearance, and State) plus 20\nbug-free screenshots from 20 <canvas> applications. We ran experiments with a\nstate-of-the-art VLM using several combinations of text and image context to\ndescribe each application's expected functionality. Our results show that by\nproviding the application README(s), a description of visual bug types, and a\nbug-free screenshot as context, VLMs can be leveraged to detect visual bugs\nwith up to 100% per-application accuracy.\n","authors":["Finlay Macklon","Cor-Paul Bezemer"],"pdf_url":"https://arxiv.org/pdf/2501.09236v1.pdf","comment":"Submitted to Empirical Software Engineering (EMSE) journal"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2501.09884v1","updated":"2025-01-16T23:54:54Z","published":"2025-01-16T23:54:54Z","title":"Semi-Supervised Image-Based Narrative Extraction: A Case Study with\n  Historical Photographic Records","summary":"  This paper presents a semi-supervised approach to extracting narratives from\nhistorical photographic records using an adaptation of the narrative maps\nalgorithm. We extend the original unsupervised text-based method to work with\nimage data, leveraging deep learning techniques for visual feature extraction\nand similarity computation. Our method is applied to the ROGER dataset, a\ncollection of photographs from the 1928 Sacambaya Expedition in Bolivia\ncaptured by Robert Gerstmann. We compare our algorithmically extracted visual\nnarratives with expert-curated timelines of varying lengths (5 to 30 images) to\nevaluate the effectiveness of our approach. In particular, we use the Dynamic\nTime Warping (DTW) algorithm to match the extracted narratives with the\nexpert-curated baseline. In addition, we asked an expert on the topic to\nqualitatively evaluate a representative example of the resulting narratives.\nOur findings show that the narrative maps approach generally outperforms random\nsampling for longer timelines (10+ images, p < 0.05), with expert evaluation\nconfirming the historical accuracy and coherence of the extracted narratives.\nThis research contributes to the field of computational analysis of visual\ncultural heritage, offering new tools for historians, archivists, and digital\nhumanities scholars to explore and understand large-scale image collections.\nThe method's ability to generate meaningful narratives from visual data opens\nup new possibilities for the study and interpretation of historical events\nthrough photographic evidence.\n","authors":["Fausto German","Brian Keith","Mauricio Matus","Diego Urrutia","Claudio Meneses"],"pdf_url":"https://arxiv.org/pdf/2501.09884v1.pdf","comment":"This paper has been accepted for oral presentation in the findings\n  track of the 47th European Conference on Information Retrieval (ECIR 2025).\n  Source code and experiments are available at\n  https://github.com/faustogerman/ROGER-Concept-Narratives"},{"id":"http://arxiv.org/abs/2501.09878v1","updated":"2025-01-16T23:28:30Z","published":"2025-01-16T23:28:30Z","title":"ASTRA: A Scene-aware TRAnsformer-based model for trajectory prediction","summary":"  We present ASTRA (A} Scene-aware TRAnsformer-based model for trajectory\nprediction), a light-weight pedestrian trajectory forecasting model that\nintegrates the scene context, spatial dynamics, social inter-agent interactions\nand temporal progressions for precise forecasting. We utilised a U-Net-based\nfeature extractor, via its latent vector representation, to capture scene\nrepresentations and a graph-aware transformer encoder for capturing social\ninteractions. These components are integrated to learn an agent-scene aware\nembedding, enabling the model to learn spatial dynamics and forecast the future\ntrajectory of pedestrians. The model is designed to produce both deterministic\nand stochastic outcomes, with the stochastic predictions being generated by\nincorporating a Conditional Variational Auto-Encoder (CVAE). ASTRA also\nproposes a simple yet effective weighted penalty loss function, which helps to\nyield predictions that outperform a wide array of state-of-the-art\ndeterministic and generative models. ASTRA demonstrates an average improvement\nof 27%/10% in deterministic/stochastic settings on the ETH-UCY dataset, and 26%\nimprovement on the PIE dataset, respectively, along with seven times fewer\nparameters than the existing state-of-the-art model (see Figure 1).\nAdditionally, the model's versatility allows it to generalize across different\nperspectives, such as Bird's Eye View (BEV) and Ego-Vehicle View (EVV).\n","authors":["Izzeddin Teeti","Aniket Thomas","Munish Monga","Sachin Kumar","Uddeshya Singh","Andrew Bradley","Biplab Banerjee","Fabio Cuzzolin"],"pdf_url":"https://arxiv.org/pdf/2501.09878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09863v1","updated":"2025-01-16T22:21:00Z","published":"2025-01-16T22:21:00Z","title":"Detection of Vascular Leukoencephalopathy in CT Images","summary":"  Artificial intelligence (AI) has seen a significant surge in popularity,\nparticularly in its application to medicine. This study explores AI's role in\ndiagnosing leukoencephalopathy, a small vessel disease of the brain, and a\nleading cause of vascular dementia and hemorrhagic strokes. We utilized a\ndataset of approximately 1200 patients with axial brain CT scans to train\nconvolutional neural networks (CNNs) for binary disease classification.\nAddressing the challenge of varying scan dimensions due to different patient\nphysiologies, we processed the data to a uniform size and applied three\npreprocessing methods to improve model accuracy. We compared four neural\nnetwork architectures: ResNet50, ResNet50 3D, ConvNext, and Densenet. The\nConvNext model achieved the highest accuracy of 98.5% without any\npreprocessing, outperforming models with 3D convolutions. To gain insights into\nmodel decision-making, we implemented Grad-CAM heatmaps, which highlighted the\nfocus areas of the models on the scans. Our results demonstrate that AI,\nparticularly the ConvNext architecture, can significantly enhance diagnostic\naccuracy for leukoencephalopathy. This study underscores AI's potential in\nadvancing diagnostic methodologies for brain diseases and highlights the\neffectiveness of CNNs in medical imaging applications.\n","authors":["Z. Cernekova","V. Sisik","F. Jafari"],"pdf_url":"https://arxiv.org/pdf/2501.09863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09838v1","updated":"2025-01-16T20:56:32Z","published":"2025-01-16T20:56:32Z","title":"CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified\n  Intermediate Representation","summary":"  Geospatial imaging leverages data from diverse sensing modalities-such as EO,\nSAR, and LiDAR, ranging from ground-level drones to satellite views. These\nheterogeneous inputs offer significant opportunities for scene understanding\nbut present challenges in interpreting geometry accurately, particularly in the\nabsence of precise ground truth data. To address this, we propose\nCrossModalityDiffusion, a modular framework designed to generate images across\ndifferent modalities and viewpoints without prior knowledge of scene geometry.\nCrossModalityDiffusion employs modality-specific encoders that take multiple\ninput images and produce geometry-aware feature volumes that encode scene\nstructure relative to their input camera positions. The space where the feature\nvolumes are placed acts as a common ground for unifying input modalities. These\nfeature volumes are overlapped and rendered into feature images from novel\nperspectives using volumetric rendering techniques. The rendered feature images\nare used as conditioning inputs for a modality-specific diffusion model,\nenabling the synthesis of novel images for the desired output modality. In this\npaper, we show that jointly training different modules ensures consistent\ngeometric understanding across all modalities within the framework. We validate\nCrossModalityDiffusion's capabilities on the synthetic ShapeNet cars dataset,\ndemonstrating its effectiveness in generating accurate and consistent novel\nviews across multiple imaging modalities and perspectives.\n","authors":["Alex Berian","Daniel Brignac","JhihYang Wu","Natnael Daba","Abhijit Mahalanobis"],"pdf_url":"https://arxiv.org/pdf/2501.09838v1.pdf","comment":"Accepted in the 2025 WACV workshop GeoCV"},{"id":"http://arxiv.org/abs/2501.09833v1","updated":"2025-01-16T20:42:17Z","published":"2025-01-16T20:42:17Z","title":"EraseBench: Understanding The Ripple Effects of Concept Erasure\n  Techniques","summary":"  Concept erasure techniques have recently gained significant attention for\ntheir potential to remove unwanted concepts from text-to-image models. While\nthese methods often demonstrate success in controlled scenarios, their\nrobustness in real-world applications and readiness for deployment remain\nuncertain. In this work, we identify a critical gap in evaluating sanitized\nmodels, particularly in terms of their performance across various concept\ndimensions. We systematically investigate the failure modes of current concept\nerasure techniques, with a focus on visually similar, binomial, and\nsemantically related concepts. We propose that these interconnected\nrelationships give rise to a phenomenon of concept entanglement resulting in\nripple effects and degradation in image quality. To facilitate more\ncomprehensive evaluation, we introduce EraseBENCH, a multi-dimensional\nbenchmark designed to assess concept erasure methods with greater depth. Our\ndataset includes over 100 diverse concepts and more than 1,000 tailored\nprompts, paired with a comprehensive suite of metrics that together offer a\nholistic view of erasure efficacy. Our findings reveal that even\nstate-of-the-art techniques struggle with maintaining quality post-erasure,\nindicating that these approaches are not yet ready for real-world deployment.\nThis highlights the gap in reliability of the concept erasure techniques.\n","authors":["Ibtihel Amara","Ahmed Imtiaz Humayun","Ivana Kajic","Zarana Parekh","Natalie Harris","Sarah Young","Chirag Nagpal","Najoung Kim","Junfeng He","Cristina Nader Vasconcelos","Deepak Ramachandran","Goolnoosh Farnadi","Katherine Heller","Mohammad Havaei","Negar Rostamzadeh"],"pdf_url":"https://arxiv.org/pdf/2501.09833v1.pdf","comment":"11 pages main; 9 pages supplemental material"},{"id":"http://arxiv.org/abs/2501.05880v2","updated":"2025-01-16T20:35:28Z","published":"2025-01-10T11:32:56Z","title":"TakuNet: an Energy-Efficient CNN for Real-Time Inference on Embedded UAV\n  systems in Emergency Response Scenarios","summary":"  Designing efficient neural networks for embedded devices is a critical\nchallenge, particularly in applications requiring real-time performance, such\nas aerial imaging with drones and UAVs for emergency responses. In this work,\nwe introduce TakuNet, a novel light-weight architecture which employs\ntechniques such as depth-wise convolutions and an early downsampling stem to\nreduce computational complexity while maintaining high accuracy. It leverages\ndense connections for fast convergence during training and uses 16-bit\nfloating-point precision for optimization on embedded hardware accelerators.\nExperimental evaluation on two public datasets shows that TakuNet achieves\nnear-state-of-the-art accuracy in classifying aerial images of emergency\nsituations, despite its minimal parameter count. Real-world tests on embedded\ndevices, namely Jetson Orin Nano and Raspberry Pi, confirm TakuNet's\nefficiency, achieving more than 650 fps on the 15W Jetson board, making it\nsuitable for real-time AI processing on resource-constrained platforms and\nadvancing the applicability of drones in emergency scenarios. The code and\nimplementation details are publicly released.\n","authors":["Daniel Rossi","Guido Borghi","Roberto Vezzani"],"pdf_url":"https://arxiv.org/pdf/2501.05880v2.pdf","comment":"This paper has been accepted at WACVW 2025, which will take place on\n  28/02/2025. The official conference proceedings have not yet been published\n  at the time of submission to arXiv. The final version of the paper,\n  incorporating any changes based on feedback received during the conference,\n  will be included in the proceedings once they are made available"},{"id":"http://arxiv.org/abs/2501.09826v1","updated":"2025-01-16T20:26:30Z","published":"2025-01-16T20:26:30Z","title":"PIXELS: Progressive Image Xemplar-based Editing with Latent Surgery","summary":"  Recent advancements in language-guided diffusion models for image editing are\noften bottle-necked by cumbersome prompt engineering to precisely articulate\ndesired changes. An intuitive alternative calls on guidance from in-the-wild\nimage exemplars to help users bring their imagined edits to life. Contemporary\nexemplar-based editing methods shy away from leveraging the rich latent space\nlearnt by pre-existing large text-to-image (TTI) models and fall back on\ntraining with curated objective functions to achieve the task. Though somewhat\neffective, this demands significant computational resources and lacks\ncompatibility with diverse base models and arbitrary exemplar count. On further\ninvestigation, we also find that these techniques restrict user control to only\napplying uniform global changes over the entire edited region. In this paper,\nwe introduce a novel framework for progressive exemplar-driven editing with\noff-the-shelf diffusion models, dubbed PIXELS, to enable customization by\nproviding granular control over edits, allowing adjustments at the pixel or\nregion level. Our method operates solely during inference to facilitate\nimitative editing, enabling users to draw inspiration from a dynamic number of\nreference images, or multimodal prompts, and progressively incorporate all the\ndesired changes without retraining or fine-tuning existing TTI models. This\ncapability of fine-grained control opens up a range of new possibilities,\nincluding selective modification of individual objects and specifying gradual\nspatial changes. We demonstrate that PIXELS delivers high-quality edits\nefficiently, leading to a notable improvement in quantitative metrics as well\nas human evaluation. By making high-quality image editing more accessible,\nPIXELS has the potential to enable professional-grade edits to a wider audience\nwith the ease of using any open-source image generation model.\n","authors":["Shristi Das Biswas","Matthew Shreve","Xuelu Li","Prateek Singhal","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2501.09826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17400v2","updated":"2025-01-16T20:25:21Z","published":"2024-09-25T22:19:32Z","title":"AgRegNet: A Deep Regression Network for Flower and Fruit Density\n  Estimation, Localization, and Counting in Orchards","summary":"  One of the major challenges for the agricultural industry today is the\nuncertainty in manual labor availability and the associated cost. Automated\nflower and fruit density estimation, localization, and counting could help\nstreamline harvesting, yield estimation, and crop-load management strategies\nsuch as flower and fruitlet thinning. This article proposes a deep\nregression-based network, AgRegNet, to estimate density, count, and location of\nflower and fruit in tree fruit canopies without explicit object detection or\npolygon annotation. Inspired by popular U-Net architecture, AgRegNet is a\nU-shaped network with an encoder-to-decoder skip connection and modified\nConvNeXt-T as an encoder feature extractor. AgRegNet can be trained based on\ninformation from point annotation and leverages segmentation information and\nattention modules (spatial and channel) to highlight relevant flower and fruit\nfeatures while suppressing non-relevant background features. Experimental\nevaluation in apple flower and fruit canopy images under an unstructured\norchard environment showed that AgRegNet achieved promising accuracy as\nmeasured by Structural Similarity Index (SSIM), percentage Mean Absolute Error\n(pMAE) and mean Average Precision (mAP) to estimate flower and fruit density,\ncount, and centroid location, respectively. Specifically, the SSIM, pMAE, and\nmAP values for flower images were 0.938, 13.7%, and 0.81, respectively. For\nfruit images, the corresponding values were 0.910, 5.6%, and 0.93. Since the\nproposed approach relies on information from point annotation, it is suitable\nfor sparsely and densely located objects. This simplified technique will be\nhighly applicable for growers to accurately estimate yields and decide on\noptimal chemical and mechanical flower thinning practices.\n","authors":["Uddhav Bhattarai","Santosh Bhusal","Qin Zhang","Manoj Karkee"],"pdf_url":"https://arxiv.org/pdf/2409.17400v2.pdf","comment":"Published in Computers and Electronics in Agriculture"},{"id":"http://arxiv.org/abs/2501.09817v1","updated":"2025-01-16T20:09:19Z","published":"2025-01-16T20:09:19Z","title":"Generalized Single-Image-Based Morphing Attack Detection Using Deep\n  Representations from Vision Transformer","summary":"  Face morphing attacks have posed severe threats to Face Recognition Systems\n(FRS), which are operated in border control and passport issuance use cases.\nCorrespondingly, morphing attack detection algorithms (MAD) are needed to\ndefend against such attacks. MAD approaches must be robust enough to handle\nunknown attacks in an open-set scenario where attacks can originate from\nvarious morphing generation algorithms, post-processing and the diversity of\nprinters/scanners. The problem of generalization is further pronounced when the\ndetection has to be made on a single suspected image. In this paper, we propose\na generalized single-image-based MAD (S-MAD) algorithm by learning the encoding\nfrom Vision Transformer (ViT) architecture. Compared to CNN-based\narchitectures, ViT model has the advantage on integrating local and global\ninformation and hence can be suitable to detect the morphing traces widely\ndistributed among the face region. Extensive experiments are carried out on\nface morphing datasets generated using publicly available FRGC face datasets.\nSeveral state-of-the-art (SOTA) MAD algorithms, including representative ones\nthat have been publicly evaluated, have been selected and benchmarked with our\nViT-based approach. Obtained results demonstrate the improved detection\nperformance of the proposed S-MAD method on inter-dataset testing (when\ndifferent data is used for training and testing) and comparable performance on\nintra-dataset testing (when the same data is used for training and testing)\nexperimental protocol.\n","authors":["Haoyu Zhang","Raghavendra Ramachandra","Kiran Raja","Christoph Busch"],"pdf_url":"https://arxiv.org/pdf/2501.09817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09815v1","updated":"2025-01-16T20:02:13Z","published":"2025-01-16T20:02:13Z","title":"Lossy Compression with Pretrained Diffusion Models","summary":"  We apply the DiffC algorithm (Theis et al. 2022) to Stable Diffusion 1.5,\n2.1, XL, and Flux-dev, and demonstrate that these pretrained models are\nremarkably capable lossy image compressors. A principled algorithm for lossy\ncompression using pretrained diffusion models has been understood since at\nleast Ho et al. 2020, but challenges in reverse-channel coding have prevented\nsuch algorithms from ever being fully implemented. We introduce simple\nworkarounds that lead to the first complete implementation of DiffC, which is\ncapable of compressing and decompressing images using Stable Diffusion in under\n10 seconds. Despite requiring no additional training, our method is competitive\nwith other state-of-the-art generative compression methods at low ultra-low\nbitrates.\n","authors":["Jeremy Vonderfecht","Feng Liu"],"pdf_url":"https://arxiv.org/pdf/2501.09815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09757v1","updated":"2025-01-16T18:59:53Z","published":"2025-01-16T18:59:53Z","title":"Distilling Multi-modal Large Language Models for Autonomous Driving","summary":"  Autonomous driving demands safe motion planning, especially in critical\n\"long-tail\" scenarios. Recent end-to-end autonomous driving systems leverage\nlarge language models (LLMs) as planners to improve generalizability to rare\nevents. However, using LLMs at test time introduces high computational costs.\nTo address this, we propose DiMA, an end-to-end autonomous driving system that\nmaintains the efficiency of an LLM-free (or vision-based) planner while\nleveraging the world knowledge of an LLM. DiMA distills the information from a\nmulti-modal LLM to a vision-based end-to-end planner through a set of specially\ndesigned surrogate tasks. Under a joint training strategy, a scene encoder\ncommon to both networks produces structured representations that are\nsemantically grounded as well as aligned to the final planning objective.\nNotably, the LLM is optional at inference, enabling robust planning without\ncompromising on efficiency. Training with DiMA results in a 37% reduction in\nthe L2 trajectory error and an 80% reduction in the collision rate of the\nvision-based planner, as well as a 44% trajectory error reduction in longtail\nscenarios. DiMA also achieves state-of-the-art performance on the nuScenes\nplanning benchmark.\n","authors":["Deepti Hegde","Rajeev Yasarla","Hong Cai","Shizhong Han","Apratim Bhattacharyya","Shweta Mahajan","Litian Liu","Risheek Garrepalli","Vishal M. Patel","Fatih Porikli"],"pdf_url":"https://arxiv.org/pdf/2501.09757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09756v1","updated":"2025-01-16T18:59:48Z","published":"2025-01-16T18:59:48Z","title":"SynthLight: Portrait Relighting with Diffusion Model by Learning to\n  Re-render Synthetic Faces","summary":"  We introduce SynthLight, a diffusion model for portrait relighting. Our\napproach frames image relighting as a re-rendering problem, where pixels are\ntransformed in response to changes in environmental lighting conditions. Using\na physically-based rendering engine, we synthesize a dataset to simulate this\nlighting-conditioned transformation with 3D head assets under varying lighting.\nWe propose two training and inference strategies to bridge the gap between the\nsynthetic and real image domains: (1) multi-task training that takes advantage\nof real human portraits without lighting labels; (2) an inference time\ndiffusion sampling procedure based on classifier-free guidance that leverages\nthe input portrait to better preserve details. Our method generalizes to\ndiverse real photographs and produces realistic illumination effects, including\nspecular highlights and cast shadows, while preserving the subject's identity.\nOur quantitative experiments on Light Stage data demonstrate results comparable\nto state-of-the-art relighting methods. Our qualitative results on in-the-wild\nimages showcase rich and unprecedented illumination effects. Project Page:\n\\url{https://vrroom.github.io/synthlight/}\n","authors":["Sumit Chaturvedi","Mengwei Ren","Yannick Hold-Geoffroy","Jingyuan Liu","Julie Dorsey","Zhixin Shu"],"pdf_url":"https://arxiv.org/pdf/2501.09756v1.pdf","comment":"27 pages, 25 figures, Project Page\n  https://vrroom.github.io/synthlight/"},{"id":"http://arxiv.org/abs/2501.09782v1","updated":"2025-01-16T18:59:46Z","published":"2025-01-16T18:59:46Z","title":"SMPLest-X: Ultimate Scaling for Expressive Human Pose and Shape\n  Estimation","summary":"  Expressive human pose and shape estimation (EHPS) unifies body, hands, and\nface motion capture with numerous applications. Despite encouraging progress,\ncurrent state-of-the-art methods focus on training innovative architectural\ndesigns on confined datasets. In this work, we investigate the impact of\nscaling up EHPS towards a family of generalist foundation models. 1) For data\nscaling, we perform a systematic investigation on 40 EHPS datasets,\nencompassing a wide range of scenarios that a model trained on any single\ndataset cannot handle. More importantly, capitalizing on insights obtained from\nthe extensive benchmarking process, we optimize our training scheme and select\ndatasets that lead to a significant leap in EHPS capabilities. Ultimately, we\nachieve diminishing returns at 10M training instances from diverse data\nsources. 2) For model scaling, we take advantage of vision transformers (up to\nViT-Huge as the backbone) to study the scaling law of model sizes in EHPS. To\nexclude the influence of algorithmic design, we base our experiments on two\nminimalist architectures: SMPLer-X, which consists of an intermediate step for\nhand and face localization, and SMPLest-X, an even simpler version that reduces\nthe network to its bare essentials and highlights significant advances in the\ncapture of articulated hands. With big data and the large model, the foundation\nmodels exhibit strong performance across diverse test benchmarks and excellent\ntransferability to even unseen environments. Moreover, our finetuning strategy\nturns the generalist into specialist models, allowing them to achieve further\nperformance boosts. Notably, our foundation models consistently deliver\nstate-of-the-art results on seven benchmarks such as AGORA, UBody, EgoBody, and\nour proposed SynHand dataset for comprehensive hand evaluation. (Code is\navailable at: https://github.com/wqyin/SMPLest-X).\n","authors":["Wanqi Yin","Zhongang Cai","Ruisi Wang","Ailing Zeng","Chen Wei","Qingping Sun","Haiyi Mei","Yanjun Wang","Hui En Pang","Mingyuan Zhang","Lei Zhang","Chen Change Loy","Atsushi Yamashita","Lei Yang","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2501.09782v1.pdf","comment":"An extension of SMPLer-X [arXiv:2309.17448]. Homepage:\n  https://caizhongang.com/projects/SMPLer-X/"},{"id":"http://arxiv.org/abs/2501.09781v1","updated":"2025-01-16T18:59:10Z","published":"2025-01-16T18:59:10Z","title":"VideoWorld: Exploring Knowledge Learning from Unlabeled Videos","summary":"  This work explores whether a deep generative model can learn complex\nknowledge solely from visual input, in contrast to the prevalent focus on\ntext-based models like large language models (LLMs). We develop VideoWorld, an\nauto-regressive video generation model trained on unlabeled video data, and\ntest its knowledge acquisition abilities in video-based Go and robotic control\ntasks. Our experiments reveal two key findings: (1) video-only training\nprovides sufficient information for learning knowledge, including rules,\nreasoning and planning capabilities, and (2) the representation of visual\nchange is crucial for knowledge acquisition. To improve both the efficiency and\nefficacy of this process, we introduce the Latent Dynamics Model (LDM) as a key\ncomponent of VideoWorld. Remarkably, VideoWorld reaches a 5-dan professional\nlevel in the Video-GoBench with just a 300-million-parameter model, without\nrelying on search algorithms or reward mechanisms typical in reinforcement\nlearning. In robotic tasks, VideoWorld effectively learns diverse control\noperations and generalizes across environments, approaching the performance of\noracle models in CALVIN and RLBench. This study opens new avenues for knowledge\nacquisition from visual data, with all code, data, and models open-sourced for\nfurther research.\n","authors":["Zhongwei Ren","Yunchao Wei","Xun Guo","Yao Zhao","Bingyi Kang","Jiashi Feng","Xiaojie Jin"],"pdf_url":"https://arxiv.org/pdf/2501.09781v1.pdf","comment":"Code and models are released at:\n  https://maverickren.github.io/VideoWorld.github.io/"},{"id":"http://arxiv.org/abs/2501.09755v1","updated":"2025-01-16T18:59:04Z","published":"2025-01-16T18:59:04Z","title":"Learnings from Scaling Visual Tokenizers for Reconstruction and\n  Generation","summary":"  Visual tokenization via auto-encoding empowers state-of-the-art image and\nvideo generative models by compressing pixels into a latent space. Although\nscaling Transformer-based generators has been central to recent advances, the\ntokenizer component itself is rarely scaled, leaving open questions about how\nauto-encoder design choices influence both its objective of reconstruction and\ndownstream generative performance. Our work aims to conduct an exploration of\nscaling in auto-encoders to fill in this blank. To facilitate this exploration,\nwe replace the typical convolutional backbone with an enhanced Vision\nTransformer architecture for Tokenization (ViTok). We train ViTok on\nlarge-scale image and video datasets far exceeding ImageNet-1K, removing data\nconstraints on tokenizer scaling. We first study how scaling the auto-encoder\nbottleneck affects both reconstruction and generation -- and find that while it\nis highly correlated with reconstruction, its relationship with generation is\nmore complex. We next explored the effect of separately scaling the\nauto-encoders' encoder and decoder on reconstruction and generation\nperformance. Crucially, we find that scaling the encoder yields minimal gains\nfor either reconstruction or generation, while scaling the decoder boosts\nreconstruction but the benefits for generation are mixed. Building on our\nexploration, we design ViTok as a lightweight auto-encoder that achieves\ncompetitive performance with state-of-the-art auto-encoders on ImageNet-1K and\nCOCO reconstruction tasks (256p and 512p) while outperforming existing\nauto-encoders on 16-frame 128p video reconstruction for UCF-101, all with 2-5x\nfewer FLOPs. When integrated with Diffusion Transformers, ViTok demonstrates\ncompetitive performance on image generation for ImageNet-1K and sets new\nstate-of-the-art benchmarks for class-conditional video generation on UCF-101.\n","authors":["Philippe Hansen-Estruch","David Yan","Ching-Yao Chung","Orr Zohar","Jialiang Wang","Tingbo Hou","Tao Xu","Sriram Vishwanath","Peter Vajda","Xinlei Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09755v1.pdf","comment":"28 pages, 25 figures, 7 Tables"},{"id":"http://arxiv.org/abs/2501.09754v1","updated":"2025-01-16T18:59:03Z","published":"2025-01-16T18:59:03Z","title":"Lost in Translation, Found in Context: Sign Language Translation with\n  Contextual Cues","summary":"  Our objective is to translate continuous sign language into spoken language\ntext. Inspired by the way human interpreters rely on context for accurate\ntranslation, we incorporate additional contextual cues together with the\nsigning video, into a new translation framework. Specifically, besides visual\nsign recognition features that encode the input video, we integrate\ncomplementary textual information from (i) captions describing the background\nshow, (ii) translation of previous sentences, as well as (iii) pseudo-glosses\ntranscribing the signing. These are automatically extracted and inputted along\nwith the visual features to a pre-trained large language model (LLM), which we\nfine-tune to generate spoken language translations in text form. Through\nextensive ablation studies, we show the positive contribution of each input cue\nto the translation performance. We train and evaluate our approach on BOBSL --\nthe largest British Sign Language dataset currently available. We show that our\ncontextual approach significantly enhances the quality of the translations\ncompared to previously reported results on BOBSL, and also to state-of-the-art\nmethods that we implement as baselines. Furthermore, we demonstrate the\ngenerality of our approach by applying it also to How2Sign, an American Sign\nLanguage dataset, and achieve competitive results.\n","authors":["Youngjoon Jang","Haran Raajesh","Liliane Momeni","Gül Varol","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2501.09754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09753v1","updated":"2025-01-16T18:59:02Z","published":"2025-01-16T18:59:02Z","title":"SRE-Conv: Symmetric Rotation Equivariant Convolution for Biomedical\n  Image Classification","summary":"  Convolutional neural networks (CNNs) are essential tools for computer vision\ntasks, but they lack traditionally desired properties of extracted features\nthat could further improve model performance, e.g., rotational equivariance.\nSuch properties are ubiquitous in biomedical images, which often lack explicit\norientation. While current work largely relies on data augmentation or explicit\nmodules to capture orientation information, this comes at the expense of\nincreased training costs or ineffective approximations of the desired\nequivariance. To overcome these challenges, we propose a novel and efficient\nimplementation of the Symmetric Rotation-Equivariant (SRE) Convolution\n(SRE-Conv) kernel, designed to learn rotation-invariant features while\nsimultaneously compressing the model size. The SRE-Conv kernel can easily be\nincorporated into any CNN backbone. We validate the ability of a deep SRE-CNN\nto capture equivariance to rotation using the public MedMNISTv2 dataset (16\ntotal tasks). SRE-Conv-CNN demonstrated improved rotated image classification\nperformance accuracy on all 16 test datasets in both 2D and 3D images, all\nwhile increasing efficiency with fewer parameters and reduced memory footprint.\nThe code is available at https://github.com/XYPB/SRE-Conv.\n","authors":["Yuexi Du","Jiazhen Zhang","Tal Zeevi","Nicha C. Dvornek","John A. Onofrey"],"pdf_url":"https://arxiv.org/pdf/2501.09753v1.pdf","comment":"Accepted by IEEE ISBI 2025 4-page paper"},{"id":"http://arxiv.org/abs/2403.12953v2","updated":"2025-01-16T18:58:31Z","published":"2024-03-19T17:55:22Z","title":"FutureDepth: Learning to Predict the Future Improves Video Depth\n  Estimation","summary":"  In this paper, we propose a novel video depth estimation approach,\nFutureDepth, which enables the model to implicitly leverage multi-frame and\nmotion cues to improve depth estimation by making it learn to predict the\nfuture at training. More specifically, we propose a future prediction network,\nF-Net, which takes the features of multiple consecutive frames and is trained\nto predict multi-frame features one time step ahead iteratively. In this way,\nF-Net learns the underlying motion and correspondence information, and we\nincorporate its features into the depth decoding process. Additionally, to\nenrich the learning of multiframe correspondence cues, we further leverage a\nreconstruction network, R-Net, which is trained via adaptively masked\nauto-encoding of multiframe feature volumes. At inference time, both F-Net and\nR-Net are used to produce queries to work with the depth decoder, as well as a\nfinal refinement network. Through extensive experiments on several benchmarks,\ni.e., NYUDv2, KITTI, DDAD, and Sintel, which cover indoor, driving, and\nopen-domain scenarios, we show that FutureDepth significantly improves upon\nbaseline models, outperforms existing video depth estimation methods, and sets\nnew state-of-the-art (SOTA) accuracy. Furthermore, FutureDepth is more\nefficient than existing SOTA video depth estimation models and has similar\nlatencies when comparing to monocular models\n","authors":["Rajeev Yasarla","Manish Kumar Singh","Hong Cai","Yunxiao Shi","Jisoo Jeong","Yinhao Zhu","Shizhong Han","Risheek Garrepalli","Fatih Porikli"],"pdf_url":"https://arxiv.org/pdf/2403.12953v2.pdf","comment":"ECCV 2024"},{"id":"http://arxiv.org/abs/2307.14336v3","updated":"2025-01-16T18:55:36Z","published":"2023-07-26T17:55:32Z","title":"MAMo: Leveraging Memory and Attention for Monocular Video Depth\n  Estimation","summary":"  We propose MAMo, a novel memory and attention frame-work for monocular video\ndepth estimation. MAMo can augment and improve any single-image depth\nestimation networks into video depth estimation models, enabling them to take\nadvantage of the temporal information to predict more accurate depth. In MAMo,\nwe augment model with memory which aids the depth prediction as the model\nstreams through the video. Specifically, the memory stores learned visual and\ndisplacement tokens of the previous time instances. This allows the depth\nnetwork to cross-reference relevant features from the past when predicting\ndepth on the current frame. We introduce a novel scheme to continuously update\nthe memory, optimizing it to keep tokens that correspond with both the past and\nthe present visual information. We adopt attention-based approach to process\nmemory features where we first learn the spatio-temporal relation among the\nresultant visual and displacement memory tokens using self-attention module.\nFurther, the output features of self-attention are aggregated with the current\nvisual features through cross-attention. The cross-attended features are\nfinally given to a decoder to predict depth on the current frame. Through\nextensive experiments on several benchmarks, including KITTI, NYU-Depth V2, and\nDDAD, we show that MAMo consistently improves monocular depth estimation\nnetworks and sets new state-of-the-art (SOTA) accuracy. Notably, our MAMo video\ndepth estimation provides higher accuracy with lower latency, when omparing to\nSOTA cost-volume-based video depth models.\n","authors":["Rajeev Yasarla","Hong Cai","Jisoo Jeong","Yunxiao Shi","Risheek Garrepalli","Fatih Porikli"],"pdf_url":"https://arxiv.org/pdf/2307.14336v3.pdf","comment":"Accepted at ICCV 2023"},{"id":"http://arxiv.org/abs/2501.09733v1","updated":"2025-01-16T18:35:45Z","published":"2025-01-16T18:35:45Z","title":"ComplexVAD: Detecting Interaction Anomalies in Video","summary":"  Existing video anomaly detection datasets are inadequate for representing\ncomplex anomalies that occur due to the interactions between objects. The\nabsence of complex anomalies in previous video anomaly detection datasets\naffects research by shifting the focus onto simple anomalies. To address this\nproblem, we introduce a new large-scale dataset: ComplexVAD. In addition, we\npropose a novel method to detect complex anomalies via modeling the\ninteractions between objects using a scene graph with spatio-temporal\nattributes. With our proposed method and two other state-of-the-art video\nanomaly detection methods, we obtain baseline scores on ComplexVAD and\ndemonstrate that our new method outperforms existing works.\n","authors":["Furkan Mumcu","Michael J. Jones","Yasin Yilmaz","Anoop Cherian"],"pdf_url":"https://arxiv.org/pdf/2501.09733v1.pdf","comment":"16 pages, 11 figures, to appear in WACV Workshop ASTAD 2025"},{"id":"http://arxiv.org/abs/2501.09732v1","updated":"2025-01-16T18:30:37Z","published":"2025-01-16T18:30:37Z","title":"Inference-Time Scaling for Diffusion Models beyond Scaling Denoising\n  Steps","summary":"  Generative models have made significant impacts across various domains,\nlargely due to their ability to scale during training by increasing data,\ncomputational resources, and model size, a phenomenon characterized by the\nscaling laws. Recent research has begun to explore inference-time scaling\nbehavior in Large Language Models (LLMs), revealing how performance can further\nimprove with additional computation during inference. Unlike LLMs, diffusion\nmodels inherently possess the flexibility to adjust inference-time computation\nvia the number of denoising steps, although the performance gains typically\nflatten after a few dozen. In this work, we explore the inference-time scaling\nbehavior of diffusion models beyond increasing denoising steps and investigate\nhow the generation performance can further improve with increased computation.\nSpecifically, we consider a search problem aimed at identifying better noises\nfor the diffusion sampling process. We structure the design space along two\naxes: the verifiers used to provide feedback, and the algorithms used to find\nbetter noise candidates. Through extensive experiments on class-conditioned and\ntext-conditioned image generation benchmarks, our findings reveal that\nincreasing inference-time compute leads to substantial improvements in the\nquality of samples generated by diffusion models, and with the complicated\nnature of images, combinations of the components in the framework can be\nspecifically chosen to conform with different application scenario.\n","authors":["Nanye Ma","Shangyuan Tong","Haolin Jia","Hexiang Hu","Yu-Chuan Su","Mingda Zhang","Xuan Yang","Yandong Li","Tommi Jaakkola","Xuhui Jia","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2501.09732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09720v1","updated":"2025-01-16T18:09:22Z","published":"2025-01-16T18:09:22Z","title":"A Simple Aerial Detection Baseline of Multimodal Language Models","summary":"  The multimodal language models (MLMs) based on generative pre-trained\nTransformer are considered powerful candidates for unifying various domains and\ntasks. MLMs developed for remote sensing (RS) have demonstrated outstanding\nperformance in multiple tasks, such as visual question answering and visual\ngrounding. In addition to visual grounding that detects specific objects\ncorresponded to given instruction, aerial detection, which detects all objects\nof multiple categories, is also a valuable and challenging task for RS\nfoundation models. However, aerial detection has not been explored by existing\nRS MLMs because the autoregressive prediction mechanism of MLMs differs\nsignificantly from the detection outputs. In this paper, we present a simple\nbaseline for applying MLMs to aerial detection for the first time, named\nLMMRotate. Specifically, we first introduce a normalization method to transform\ndetection outputs into textual outputs to be compatible with the MLM framework.\nThen, we propose a evaluation method, which ensures a fair comparison between\nMLMs and conventional object detection models. We construct the baseline by\nfine-tuning open-source general-purpose MLMs and achieve impressive detection\nperformance comparable to conventional detector. We hope that this baseline\nwill serve as a reference for future MLM development, enabling more\ncomprehensive capabilities for understanding RS images. Code is available at\nhttps://github.com/Li-Qingyun/mllm-mmrotate.\n","authors":["Qingyun Li","Yushi Chen","Xinya Shu","Dong Chen","Xin He","Yi Yu","Xue Yang"],"pdf_url":"https://arxiv.org/pdf/2501.09720v1.pdf","comment":"4 pages, 1 table, 4 figures"},{"id":"http://arxiv.org/abs/2501.09718v1","updated":"2025-01-16T18:06:09Z","published":"2025-01-16T18:06:09Z","title":"FLOL: Fast Baselines for Real-World Low-Light Enhancement","summary":"  Low-Light Image Enhancement (LLIE) is a key task in computational photography\nand imaging. The problem of enhancing images captured during night or in dark\nenvironments has been well-studied in the image signal processing literature.\nHowever, current deep learning-based solutions struggle with efficiency and\nrobustness in real-world scenarios (e.g. scenes with noise, saturated pixels,\nbad illumination). We propose a lightweight neural network that combines image\nprocessing in the frequency and spatial domains. Our method, FLOL+, is one of\nthe fastest models for this task, achieving state-of-the-art results on popular\nreal scenes datasets such as LOL and LSRW. Moreover, we are able to process\n1080p images under 12ms. Code and models at https://github.com/cidautai/FLOL\n","authors":["Juan C. Benito","Daniel Feijoo","Alvaro Garcia","Marcos V. Conde"],"pdf_url":"https://arxiv.org/pdf/2501.09718v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2501.09705v1","updated":"2025-01-16T17:57:53Z","published":"2025-01-16T17:57:53Z","title":"Practical Continual Forgetting for Pre-trained Vision Models","summary":"  For privacy and security concerns, the need to erase unwanted information\nfrom pre-trained vision models is becoming evident nowadays. In real-world\nscenarios, erasure requests originate at any time from both users and model\nowners, and these requests usually form a sequence. Therefore, under such a\nsetting, selective information is expected to be continuously removed from a\npre-trained model while maintaining the rest. We define this problem as\ncontinual forgetting and identify three key challenges. (i) For unwanted\nknowledge, efficient and effective deleting is crucial. (ii) For remaining\nknowledge, the impact brought by the forgetting procedure should be minimal.\n(iii) In real-world scenarios, the training samples may be scarce or partially\nmissing during the process of forgetting. To address them, we first propose\nGroup Sparse LoRA (GS-LoRA). Specifically, towards (i), we introduce LoRA\nmodules to fine-tune the FFN layers in Transformer blocks for each forgetting\ntask independently, and towards (ii), a simple group sparse regularization is\nadopted, enabling automatic selection of specific LoRA groups and zeroing out\nthe others. To further extend GS-LoRA to more practical scenarios, we\nincorporate prototype information as additional supervision and introduce a\nmore practical approach, GS-LoRA++. For each forgotten class, we move the\nlogits away from its original prototype. For the remaining classes, we pull the\nlogits closer to their respective prototypes. We conduct extensive experiments\non face recognition, object detection and image classification and demonstrate\nthat our method manages to forget specific classes with minimal impact on other\nclasses. Codes have been released on https://github.com/bjzhb666/GS-LoRA.\n","authors":["Hongbo Zhao","Fei Zhu","Bolin Ni","Feng Zhu","Gaofeng Meng","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.09705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09695v1","updated":"2025-01-16T17:48:03Z","published":"2025-01-16T17:48:03Z","title":"Mitigating Hallucinations in Large Vision-Language Models via DPO:\n  On-Policy Data Hold the Key","summary":"  Hallucination remains a major challenge for Large Vision-Language Models\n(LVLMs). Direct Preference Optimization (DPO) has gained increasing attention\nas a simple solution to hallucination issues. It directly learns from\nconstructed preference pairs that reflect the severity of hallucinations in\nresponses to the same prompt and image. Nonetheless, different data\nconstruction methods in existing works bring notable performance variations. We\nidentify a crucial factor here: outcomes are largely contingent on whether the\nconstructed data aligns on-policy w.r.t the initial (reference) policy of DPO.\nTheoretical analysis suggests that learning from off-policy data is impeded by\nthe presence of KL-divergence between the updated policy and the reference\npolicy. From the perspective of dataset distribution, we systematically\nsummarize the inherent flaws in existing algorithms that employ DPO to address\nhallucination issues. To alleviate the problems, we propose On-Policy Alignment\n(OPA)-DPO framework, which uniquely leverages expert feedback to correct\nhallucinated responses and aligns both the original and expert-revised\nresponses in an on-policy manner. Notably, with only 4.8k data, OPA-DPO\nachieves an additional reduction in the hallucination rate of LLaVA-1.5-7B:\n13.26% on the AMBER benchmark and 5.39% on the Object-Hal benchmark, compared\nto the previous SOTA algorithm trained with 16k samples.\n","authors":["Zhihe Yang","Xufang Luo","Dongqi Han","Yunjian Xu","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2501.09695v1.pdf","comment":"18 pages, 15 figures"},{"id":"http://arxiv.org/abs/2501.09688v1","updated":"2025-01-16T17:40:19Z","published":"2025-01-16T17:40:19Z","title":"Fine-Grained Image-Text Correspondence with Cost Aggregation for\n  Open-Vocabulary Part Segmentation","summary":"  Open-Vocabulary Part Segmentation (OVPS) is an emerging field for recognizing\nfine-grained parts in unseen categories. We identify two primary challenges in\nOVPS: (1) the difficulty in aligning part-level image-text correspondence, and\n(2) the lack of structural understanding in segmenting object parts. To address\nthese issues, we propose PartCATSeg, a novel framework that integrates\nobject-aware part-level cost aggregation, compositional loss, and structural\nguidance from DINO. Our approach employs a disentangled cost aggregation\nstrategy that handles object and part-level costs separately, enhancing the\nprecision of part-level segmentation. We also introduce a compositional loss to\nbetter capture part-object relationships, compensating for the limited part\nannotations. Additionally, structural guidance from DINO features improves\nboundary delineation and inter-part understanding. Extensive experiments on\nPascal-Part-116, ADE20K-Part-234, and PartImageNet datasets demonstrate that\nour method significantly outperforms state-of-the-art approaches, setting a new\nbaseline for robust generalization to unseen part categories.\n","authors":["Jiho Choi","Seonho Lee","Minhyun Lee","Seungho Lee","Hyunjung Shim"],"pdf_url":"https://arxiv.org/pdf/2501.09688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.01184v2","updated":"2025-01-16T17:11:06Z","published":"2025-01-02T10:21:34Z","title":"Vulnerability-Aware Spatio-Temporal Learning for Generalizable and\n  Interpretable Deepfake Video Detection","summary":"  Detecting deepfake videos is highly challenging due to the complex\nintertwined spatial and temporal artifacts in forged sequences. Most recent\napproaches rely on binary classifiers trained on both real and fake data.\nHowever, such methods may struggle to focus on important artifacts, which can\nhinder their generalization capability. Additionally, these models often lack\ninterpretability, making it difficult to understand how predictions are made.\nTo address these issues, we propose FakeSTormer, offering two key\ncontributions. First, we introduce a multi-task learning framework with\nadditional spatial and temporal branches that enable the model to focus on\nsubtle spatio-temporal artifacts. These branches also provide interpretability\nby highlighting video regions that may contain artifacts. Second, we propose a\nvideo-level data synthesis algorithm that generates pseudo-fake videos with\nsubtle artifacts, providing the model with high-quality samples and ground\ntruth data for our spatial and temporal branches. Extensive experiments on\nseveral challenging benchmarks demonstrate the competitiveness of our approach\ncompared to recent state-of-the-art methods. The code is available at\nhttps://github.com/10Ring/FakeSTormer.\n","authors":["Dat Nguyen","Marcella Astrid","Anis Kacem","Enjie Ghorbel","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2501.01184v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05728v2","updated":"2025-01-16T17:09:57Z","published":"2025-01-10T05:53:32Z","title":"Super-class guided Transformer for Zero-Shot Attribute Classification","summary":"  Attribute classification is crucial for identifying specific characteristics\nwithin image regions. Vision-Language Models (VLMs) have been effective in\nzero-shot tasks by leveraging their general knowledge from large-scale\ndatasets. Recent studies demonstrate that transformer-based models with\nclass-wise queries can effectively address zero-shot multi-label\nclassification. However, poor utilization of the relationship between seen and\nunseen attributes makes the model lack generalizability. Additionally,\nattribute classification generally involves many attributes, making maintaining\nthe model's scalability difficult. To address these issues, we propose\nSuper-class guided transFormer (SugaFormer), a novel framework that leverages\nsuper-classes to enhance scalability and generalizability for zero-shot\nattribute classification. SugaFormer employs Super-class Query Initialization\n(SQI) to reduce the number of queries, utilizing common semantic information\nfrom super-classes, and incorporates Multi-context Decoding (MD) to handle\ndiverse visual cues. To strengthen generalizability, we introduce two knowledge\ntransfer strategies that utilize VLMs. During training, Super-class guided\nConsistency Regularization (SCR) aligns model's features with VLMs using\nsuper-class guided prompts, and during inference, Zero-shot Retrieval-based\nScore Enhancement (ZRSE) refines predictions for unseen attributes. Extensive\nexperiments demonstrate that SugaFormer achieves state-of-the-art performance\nacross three widely-used attribute classification benchmarks under zero-shot,\nand cross-dataset transfer settings. Our code is available at\nhttps://github.com/mlvlab/SugaFormer.\n","authors":["Sehyung Kim","Chanhyeong Yang","Jihwan Park","Taehoon Song","Hyunwoo J. Kim"],"pdf_url":"https://arxiv.org/pdf/2501.05728v2.pdf","comment":"AAAI25"},{"id":"http://arxiv.org/abs/2501.09672v1","updated":"2025-01-16T17:08:12Z","published":"2025-01-16T17:08:12Z","title":"Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP\n  Evaluation Benchmark","summary":"  The proliferation of Vision-Language Models (VLMs) in the past several years\ncalls for rigorous and comprehensive evaluation methods and benchmarks. This\nwork analyzes existing VLM evaluation techniques, including automated metrics,\nAI-based assessments, and human evaluations across diverse tasks. We first\nintroduce Robin - a novel suite of VLMs that we built by combining Large\nLanguage Models (LLMs) and Vision Encoders (VEs) at multiple scales, and use\nRobin to identify shortcomings of current evaluation approaches across scales.\nNext, to overcome the identified limitations, we introduce CHIRP - a new long\nform response benchmark we developed for more robust and complete VLM\nevaluation. We provide open access to the Robin training code, model suite, and\nCHIRP benchmark to promote reproducibility and advance VLM research.\n","authors":["Alexis Roger","Prateek Humane","Daniel Z. Kaplan","Kshitij Gupta","Qi Sun","George Adamopoulos","Jonathan Siu Chi Lim","Quentin Anthony","Edwin Fennell","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2501.09672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01034v2","updated":"2025-01-16T16:45:29Z","published":"2024-02-01T21:45:12Z","title":"VIS-MAE: An Efficient Self-supervised Learning Approach on Medical Image\n  Segmentation and Classification","summary":"  Artificial Intelligence (AI) has the potential to revolutionize diagnosis and\nsegmentation in medical imaging. However, development and clinical\nimplementation face multiple challenges including limited data availability,\nlack of generalizability, and the necessity to incorporate multi-modal data\neffectively. A foundation model, which is a large-scale pre-trained AI model,\noffers a versatile base that can be adapted to a variety of specific tasks and\ncontexts. Here, we present VIsualization and Segmentation Masked AutoEncoder\n(VIS-MAE), novel model weights specifically designed for medical imaging.\nSpecifically, VIS-MAE is trained on a dataset of 2.5 million unlabeled images\nfrom various modalities (CT, MR, PET,X-rays, and ultrasound), using\nself-supervised learning techniques. It is then adapted to classification and\nsegmentation tasks using explicit labels. VIS-MAE has high label efficiency,\noutperforming several benchmark models in both in-domain and out-of-domain\napplications. In addition, VIS-MAE has improved label efficiency as it can\nachieve similar performance to other models with a reduced amount of labeled\ntraining data (50% or 80%) compared to other pre-trained weights. VIS-MAE\nrepresents a significant advancement in medical imaging AI, offering a\ngeneralizable and robust solution for improving segmentation and classification\ntasks while reducing the data annotation workload. The source code of this work\nis available at https://github.com/lzl199704/VIS-MAE.\n","authors":["Zelong Liu","Andrew Tieu","Nikhil Patel","Georgios Soultanidis","Louisa Deyer","Ying Wang","Sean Huver","Alexander Zhou","Yunhao Mei","Zahi A. Fayad","Timothy Deyer","Xueyan Mei"],"pdf_url":"https://arxiv.org/pdf/2402.01034v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17097v2","updated":"2025-01-16T16:27:33Z","published":"2024-05-27T12:12:26Z","title":"A Comparative Study on Multi-task Uncertainty Quantification in Semantic\n  Segmentation and Monocular Depth Estimation","summary":"  Deep neural networks excel in perception tasks such as semantic segmentation\nand monocular depth estimation, making them indispensable in safety-critical\napplications like autonomous driving and industrial inspection. However, they\noften suffer from overconfidence and poor explainability, especially for\nout-of-domain data. While uncertainty quantification has emerged as a promising\nsolution to these challenges, multi-task settings have yet to be explored. In\nan effort to shed light on this, we evaluate Monte Carlo Dropout, Deep\nSub-Ensembles, and Deep Ensembles for joint semantic segmentation and monocular\ndepth estimation. Thereby, we reveal that Deep Ensembles stand out as the\npreferred choice, particularly in out-of-domain scenarios, and show the\npotential benefit of multi-task learning with regard to the uncertainty quality\nin comparison to solving both tasks separately. Additionally, we highlight the\nimpact of employing different uncertainty thresholds to classify pixels as\ncertain or uncertain, with the median uncertainty emerging as a robust default.\n","authors":["Steven Landgraf","Markus Hillemann","Theodor Kapler","Markus Ulrich"],"pdf_url":"https://arxiv.org/pdf/2405.17097v2.pdf","comment":"This manuscript is an extended version of a previously published\n  conference paper and is currently in review for a journal"},{"id":"http://arxiv.org/abs/2501.09635v1","updated":"2025-01-16T16:24:21Z","published":"2025-01-16T16:24:21Z","title":"Unified Face Matching and Physical-Digital Spoofing Attack Detection","summary":"  Face recognition technology has dramatically transformed the landscape of\nsecurity, surveillance, and authentication systems, offering a user-friendly\nand non-invasive biometric solution. However, despite its significant\nadvantages, face recognition systems face increasing threats from physical and\ndigital spoofing attacks. Current research typically treats face recognition\nand attack detection as distinct classification challenges. This approach\nnecessitates the implementation of separate models for each task, leading to\nconsiderable computational complexity, particularly on devices with limited\nresources. Such inefficiencies can stifle scalability and hinder performance.\nIn response to these challenges, this paper introduces an innovative unified\nmodel designed for face recognition and detection of physical and digital\nattacks. By leveraging the advanced Swin Transformer backbone and incorporating\nHiLo attention in a convolutional neural network framework, we address unified\nface recognition and spoof attack detection more effectively. Moreover, we\nintroduce augmentation techniques that replicate the traits of physical and\ndigital spoofing cues, significantly enhancing our model robustness. Through\ncomprehensive experimental evaluation across various datasets, we showcase the\neffectiveness of our model in unified face recognition and spoof detection.\nAdditionally, we confirm its resilience against unseen physical and digital\nspoofing attacks, underscoring its potential for real-world applications.\n","authors":["Arun Kunwar","Ajita Rattani"],"pdf_url":"https://arxiv.org/pdf/2501.09635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10729v3","updated":"2025-01-16T16:04:07Z","published":"2024-06-15T20:04:06Z","title":"A Comprehensive Survey of Foundation Models in Medicine","summary":"  Foundation models (FMs) are large-scale deep learning models trained on\nmassive datasets, often using self-supervised learning techniques. These models\nserve as a versatile base for a wide range of downstream tasks, including those\nin medicine and healthcare. FMs have demonstrated remarkable success across\nmultiple healthcare domains. However, existing surveys in this field do not\ncomprehensively cover all areas where FMs have made significant strides. In\nthis survey, we present a comprehensive review of FMs in medicine, focusing on\ntheir evolution, learning strategies, flagship models, applications, and\nassociated challenges. We examine how prominent FMs, such as the BERT and GPT\nfamilies, are transforming various aspects of healthcare, including clinical\nlarge language models, medical image analysis, and omics research.\nAdditionally, we provide a detailed taxonomy of FM-enabled healthcare\napplications, spanning clinical natural language processing, medical computer\nvision, graph learning, and other biology- and omics- related tasks. Despite\nthe transformative potentials of FMs, they also pose unique challenges. This\nsurvey delves into these challenges and highlights open research questions and\nlessons learned to guide researchers and practitioners. Our goal is to provide\nvaluable insights into the capabilities of FMs in health, facilitating\nresponsible deployment and mitigating associated risks.\n","authors":["Wasif Khan","Seowung Leem","Kyle B. See","Joshua K. Wong","Shaoting Zhang","Ruogu Fang"],"pdf_url":"https://arxiv.org/pdf/2406.10729v3.pdf","comment":"Currently under review in IEEE REVIEWS IN BIOMEDICAL ENGINEERING"},{"id":"http://arxiv.org/abs/2501.05555v2","updated":"2025-01-16T16:00:37Z","published":"2025-01-09T20:02:10Z","title":"Improving Zero-Shot Object-Level Change Detection by Incorporating\n  Visual Correspondence","summary":"  Detecting object-level changes between two images across possibly different\nviews is a core task in many applications that involve visual inspection or\ncamera surveillance. Existing change-detection approaches suffer from three\nmajor limitations: (1) lack of evaluation on image pairs that contain no\nchanges, leading to unreported false positive rates; (2) lack of\ncorrespondences (i.e., localizing the regions before and after a change); and\n(3) poor zero-shot generalization across different domains. To address these\nissues, we introduce a novel method that leverages change correspondences (a)\nduring training to improve change detection accuracy, and (b) at test time, to\nminimize false positives. That is, we harness the supervision labels of where\nan object is added or removed to supervise change detectors, improving their\naccuracy over previous work by a large margin. Our work is also the first to\npredict correspondences between pairs of detected changes using estimated\nhomography and the Hungarian algorithm. Our model demonstrates superior\nperformance over existing methods, achieving state-of-the-art results in change\ndetection and change correspondence accuracy across both in-distribution and\nzero-shot benchmarks.\n","authors":["Hung Huy Nguyen","Pooyan Rahmanzadehgervi","Long Mai","Anh Totti Nguyen"],"pdf_url":"https://arxiv.org/pdf/2501.05555v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09617v1","updated":"2025-01-16T15:44:24Z","published":"2025-01-16T15:44:24Z","title":"WMamba: Wavelet-based Mamba for Face Forgery Detection","summary":"  With the rapid advancement of deepfake generation technologies, the demand\nfor robust and accurate face forgery detection algorithms has become\nincreasingly critical. Recent studies have demonstrated that wavelet analysis\ncan uncover subtle forgery artifacts that remain imperceptible in the spatial\ndomain. Wavelets effectively capture important facial contours, which are often\nslender, fine-grained, and global in nature. However, existing wavelet-based\napproaches fail to fully leverage these unique characteristics, resulting in\nsub-optimal feature extraction and limited generalizability. To address this\nchallenge, we introduce WMamba, a novel wavelet-based feature extractor built\nupon the Mamba architecture. WMamba maximizes the utility of wavelet\ninformation through two key innovations. First, we propose Dynamic Contour\nConvolution (DCConv), which employs specially crafted deformable kernels to\nadaptively model slender facial contours. Second, by leveraging the Mamba\narchitecture, our method captures long-range spatial relationships with linear\ncomputational complexity. This efficiency allows for the extraction of\nfine-grained, global forgery artifacts from small image patches. Extensive\nexperimental results show that WMamba achieves state-of-the-art (SOTA)\nperformance, highlighting its effectiveness and superiority in face forgery\ndetection.\n","authors":["Siran Peng","Tianshuo Zhang","Li Gao","Xiangyu Zhu","Haoyuan Zhang","Kai Pang","Zhen Lei"],"pdf_url":"https://arxiv.org/pdf/2501.09617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09608v1","updated":"2025-01-16T15:32:41Z","published":"2025-01-16T15:32:41Z","title":"Metric Learning with Progressive Self-Distillation for Audio-Visual\n  Embedding Learning","summary":"  Metric learning projects samples into an embedded space, where similarities\nand dissimilarities are quantified based on their learned representations.\nHowever, existing methods often rely on label-guided representation learning,\nwhere representations of different modalities, such as audio and visual data,\nare aligned based on annotated labels. This approach tends to underutilize\nlatent complex features and potential relationships inherent in the\ndistributions of audio and visual data that are not directly tied to the\nlabels, resulting in suboptimal performance in audio-visual embedding learning.\nTo address this issue, we propose a novel architecture that integrates\ncross-modal triplet loss with progressive self-distillation. Our method\nenhances representation learning by leveraging inherent distributions and\ndynamically refining soft audio-visual alignments -- probabilistic alignments\nbetween audio and visual data that capture the inherent relationships beyond\nexplicit labels. Specifically, the model distills audio-visual\ndistribution-based knowledge from annotated labels in a subset of each batch.\nThis self-distilled knowledge is used t\n","authors":["Donghuo Zeng","Kazushi Ikeda"],"pdf_url":"https://arxiv.org/pdf/2501.09608v1.pdf","comment":"5 pages, 3 figures, 2 tables. Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.01957v2","updated":"2025-01-16T15:00:16Z","published":"2025-01-03T18:59:52Z","title":"VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction","summary":"  Recent Multimodal Large Language Models (MLLMs) have typically focused on\nintegrating visual and textual modalities, with less emphasis placed on the\nrole of speech in enhancing interaction. However, speech plays a crucial role\nin multimodal dialogue systems, and implementing high-performance in both\nvision and speech tasks remains a significant challenge due to the fundamental\nmodality differences. In this paper, we propose a carefully designed\nmulti-stage training methodology that progressively trains LLM to understand\nboth visual and speech information, ultimately enabling fluent vision and\nspeech interaction. Our approach not only preserves strong vision-language\ncapacity, but also enables efficient speech-to-speech dialogue capabilities\nwithout separate ASR and TTS modules, significantly accelerating multimodal\nend-to-end response speed. By comparing our method against state-of-the-art\ncounterparts across benchmarks for image, video, and speech tasks, we\ndemonstrate that our model is equipped with both strong visual and speech\ncapabilities, making near real-time vision and speech interaction.\n","authors":["Chaoyou Fu","Haojia Lin","Xiong Wang","Yi-Fan Zhang","Yunhang Shen","Xiaoyu Liu","Yangze Li","Zuwei Long","Heting Gao","Ke Li","Long Ma","Xiawu Zheng","Rongrong Ji","Xing Sun","Caifeng Shan","Ran He"],"pdf_url":"https://arxiv.org/pdf/2501.01957v2.pdf","comment":"https://github.com/VITA-MLLM/VITA"},{"id":"http://arxiv.org/abs/2501.09579v1","updated":"2025-01-16T14:56:41Z","published":"2025-01-16T14:56:41Z","title":"Sequential PatchCore: Anomaly Detection for Surface Inspection using\n  Synthetic Impurities","summary":"  The appearance of surface impurities (e.g., water stains, fingerprints,\nstickers) is an often-mentioned issue that causes degradation of automated\nvisual inspection systems. At the same time, synthetic data generation\ntechniques for visual surface inspection have focused primarily on generating\nperfect examples and defects, disregarding impurities. This study highlights\nthe importance of considering impurities when generating synthetic data. We\nintroduce a procedural method to include photorealistic water stains in\nsynthetic data. The synthetic datasets are generated to correspond to real\ndatasets and are further used to train an anomaly detection model and\ninvestigate the influence of water stains. The high-resolution images used for\nsurface inspection lead to memory bottlenecks during anomaly detection\ntraining. To address this, we introduce Sequential PatchCore - a method to\nbuild coresets sequentially and make training on large images using\nconsumer-grade hardware tractable. This allows us to perform transfer learning\nusing coresets pre-trained on different dataset versions. Our results show the\nbenefits of using synthetic data for pre-training an explicit coreset anomaly\nmodel and the extended performance benefits of finetuning the coreset using\nreal data. We observed how the impurities and labelling ambiguity lower the\nmodel performance and have additionally reported the defect-wise recall to\nprovide an industrially relevant perspective on model performance.\n","authors":["Runzhou Mao","Juraj Fulir","Christoph Garth","Petra Gospodnetić"],"pdf_url":"https://arxiv.org/pdf/2501.09579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20891v4","updated":"2025-01-16T14:45:36Z","published":"2024-07-30T15:07:13Z","title":"Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian\n  Neural Networks","summary":"  Computational complexity of Bayesian learning is impeding its adoption in\npractical, large-scale tasks. Despite demonstrations of significant merits such\nas improved robustness and resilience to unseen or out-of-distribution inputs\nover their non- Bayesian counterparts, their practical use has faded to near\ninsignificance. In this study, we introduce an innovative framework to mitigate\nthe computational burden of Bayesian neural networks (BNNs). Our approach\nfollows the principle of Bayesian techniques based on deep ensembles, but\nsignificantly reduces their cost via multiple low-rank perturbations of\nparameters arising from a pre-trained neural network. Both vanilla version of\nensembles as well as more sophisticated schemes such as Bayesian learning with\nStein Variational Gradient Descent (SVGD), previously deemed impractical for\nlarge models, can be seamlessly implemented within the proposed framework,\ncalled Bayesian Low-Rank LeArning (Bella). In a nutshell, i) Bella achieves a\ndramatic reduction in the number of trainable parameters required to\napproximate a Bayesian posterior; and ii) it not only maintains, but in some\ninstances, surpasses the performance of conventional Bayesian learning methods\nand non-Bayesian baselines. Our results with large-scale tasks such as\nImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA demonstrate the\neffectiveness and versatility of Bella in building highly scalable and\npractical Bayesian deep models for real-world applications.\n","authors":["Bao Gia Doan","Afshar Shamsi","Xiao-Yu Guo","Arash Mohammadi","Hamid Alinejad-Rokny","Dino Sejdinovic","Damien Teney","Damith C. Ranasinghe","Ehsan Abbasnejad"],"pdf_url":"https://arxiv.org/pdf/2407.20891v4.pdf","comment":"This paper is accepted in AAAI'2025"},{"id":"http://arxiv.org/abs/2412.04755v2","updated":"2025-01-16T14:44:39Z","published":"2024-12-06T03:40:21Z","title":"Latent Space Characterization of Autoencoder Variants","summary":"  Understanding the latent spaces learned by deep learning models is crucial in\nexploring how they represent and generate complex data. Autoencoders (AEs) have\nplayed a key role in the area of representation learning, with numerous\nregularization techniques and training principles developed not only to enhance\ntheir ability to learn compact and robust representations, but also to reveal\nhow different architectures influence the structure and smoothness of the\nlower-dimensional non-linear manifold. We strive to characterize the structure\nof the latent spaces learned by different autoencoders including convolutional\nautoencoders (CAEs), denoising autoencoders (DAEs), and variational\nautoencoders (VAEs) and how they change with the perturbations in the input. By\ncharacterizing the matrix manifolds corresponding to the latent spaces, we\nprovide an explanation for the well-known observation that the latent spaces of\nCAE and DAE form non-smooth manifolds, while that of VAE forms a smooth\nmanifold. We also map the points of the matrix manifold to a Hilbert space\nusing distance preserving transforms and provide an alternate view in terms of\nthe subspaces generated in the Hilbert space as a function of the distortion in\nthe input. The results show that the latent manifolds of CAE and DAE are\nstratified with each stratum being a smooth product manifold, while the\nmanifold of VAE is a smooth product manifold of two symmetric positive definite\nmatrices and a symmetric positive semi-definite matrix.\n","authors":["Anika Shrivastava","Renu Rameshan","Samar Agnihotri"],"pdf_url":"https://arxiv.org/pdf/2412.04755v2.pdf","comment":"9 pages, 6 figures, and 1 table"},{"id":"http://arxiv.org/abs/2501.09565v1","updated":"2025-01-16T14:40:02Z","published":"2025-01-16T14:40:02Z","title":"A New Teacher-Reviewer-Student Framework for Semi-supervised 2D Human\n  Pose Estimation","summary":"  Conventional 2D human pose estimation methods typically require extensive\nlabeled annotations, which are both labor-intensive and expensive. In contrast,\nsemi-supervised 2D human pose estimation can alleviate the above problems by\nleveraging a large amount of unlabeled data along with a small portion of\nlabeled data. Existing semi-supervised 2D human pose estimation methods update\nthe network through backpropagation, ignoring crucial historical information\nfrom the previous training process. Therefore, we propose a novel\nsemi-supervised 2D human pose estimation method by utilizing a newly designed\nTeacher-Reviewer-Student framework. Specifically, we first mimic the phenomenon\nthat human beings constantly review previous knowledge for consolidation to\ndesign our framework, in which the teacher predicts results to guide the\nstudent's learning and the reviewer stores important historical parameters to\nprovide additional supervision signals. Secondly, we introduce a Multi-level\nFeature Learning strategy, which utilizes the outputs from different stages of\nthe backbone to estimate the heatmap to guide network training, enriching the\nsupervisory information while effectively capturing keypoint relationships.\nFinally, we design a data augmentation strategy, i.e., Keypoint-Mix, to perturb\npose information by mixing different keypoints, thus enhancing the network's\nability to discern keypoints. Extensive experiments on publicly available\ndatasets, demonstrate our method achieves significant improvements compared to\nthe existing methods.\n","authors":["Wulian Yun","Mengshi Qi","Fei Peng","Huadong Ma"],"pdf_url":"https://arxiv.org/pdf/2501.09565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09555v1","updated":"2025-01-16T14:18:06Z","published":"2025-01-16T14:18:06Z","title":"Text-driven Adaptation of Foundation Models for Few-shot Surgical\n  Workflow Analysis","summary":"  Purpose: Surgical workflow analysis is crucial for improving surgical\nefficiency and safety. However, previous studies rely heavily on large-scale\nannotated datasets, posing challenges in cost, scalability, and reliance on\nexpert annotations. To address this, we propose Surg-FTDA (Few-shot Text-driven\nAdaptation), designed to handle various surgical workflow analysis tasks with\nminimal paired image-label data.\n  Methods: Our approach has two key components. First, Few-shot selection-based\nmodality alignment selects a small subset of images and aligns their embeddings\nwith text embeddings from the downstream task, bridging the modality gap.\nSecond, Text-driven adaptation leverages only text data to train a decoder,\neliminating the need for paired image-text data. This decoder is then applied\nto aligned image embeddings, enabling image-related tasks without explicit\nimage-text pairs.\n  Results: We evaluate our approach to generative tasks (image captioning) and\ndiscriminative tasks (triplet recognition and phase recognition). Results show\nthat Surg-FTDA outperforms baselines and generalizes well across downstream\ntasks.\n  Conclusion: We propose a text-driven adaptation approach that mitigates the\nmodality gap and handles multiple downstream tasks in surgical workflow\nanalysis, with minimal reliance on large annotated datasets. The code and\ndataset will be released in https://github.com/TingxuanSix/Surg-FTDA.\n","authors":["Tingxuan Chen","Kun Yuan","Vinkle Srivastav","Nassir Navab","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2501.09555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09552v1","updated":"2025-01-16T14:12:33Z","published":"2025-01-16T14:12:33Z","title":"Exploring AI-based System Design for Pixel-level Protected Health\n  Information Detection in Medical Images","summary":"  De-identification of medical images is a critical step to ensure privacy\nduring data sharing in research and clinical settings. The initial step in this\nprocess involves detecting Protected Health Information (PHI), which can be\nfound in image metadata or imprinted within image pixels. Despite the\nimportance of such systems, there has been limited evaluation of existing\nAI-based solutions, creating barriers to the development of reliable and robust\ntools. In this study, we present an AI-based pipeline for PHI detection,\ncomprising three key components: text detection, text extraction, and analysis\nof PHI content in medical images. By experimenting with exchanging roles of\nvision and language models within the pipeline, we evaluate the performance and\nrecommend the best setup for the PHI detection task.\n","authors":["Tuan Truong","Ivo M. Baltruschat","Mark Klemens","Grit Werner","Matthias Lenga"],"pdf_url":"https://arxiv.org/pdf/2501.09552v1.pdf","comment":"In progress"},{"id":"http://arxiv.org/abs/2404.14388v3","updated":"2025-01-16T14:02:26Z","published":"2024-04-22T17:46:29Z","title":"STROOBnet Optimization via GPU-Accelerated Proximal Recurrence\n  Strategies","summary":"  Spatiotemporal networks' observational capabilities are crucial for accurate\ndata gathering and informed decisions across multiple sectors. This study\nfocuses on the Spatiotemporal Ranged Observer-Observable Bipartite Network\n(STROOBnet), linking observational nodes (e.g., surveillance cameras) to events\nwithin defined geographical regions, enabling efficient monitoring. Using data\nfrom Real-Time Crime Camera (RTCC) systems and Calls for Service (CFS) in New\nOrleans, where RTCC combats rising crime amidst reduced police presence, we\naddress the network's initial observational imbalances. Aiming for uniform\nobservational efficacy, we propose the Proximal Recurrence approach. It\noutperformed traditional clustering methods like k-means and DBSCAN by offering\nholistic event frequency and spatial consideration, enhancing observational\ncoverage.\n","authors":["Ted Edward Holmberg","Mahdi Abdelguerfi","Elias Ioup"],"pdf_url":"https://arxiv.org/pdf/2404.14388v3.pdf","comment":"10 pages, 17 figures, 2023 IEEE International Conference on Big Data\n  (BigData)"},{"id":"http://arxiv.org/abs/2409.07989v2","updated":"2025-01-16T14:01:58Z","published":"2024-09-12T12:34:29Z","title":"Enhancing Few-Shot Image Classification through Learnable Multi-Scale\n  Embedding and Attention Mechanisms","summary":"  In the context of few-shot classification, the goal is to train a classifier\nusing a limited number of samples while maintaining satisfactory performance.\nHowever, traditional metric-based methods exhibit certain limitations in\nachieving this objective. These methods typically rely on a single distance\nvalue between the query feature and support feature, thereby overlooking the\ncontribution of shallow features. To overcome this challenge, we propose a\nnovel approach in this paper. Our approach involves utilizing a multi-output\nembedding network that maps samples into distinct feature spaces. The proposed\nmethod extracts feature vectors at different stages, enabling the model to\ncapture both global and abstract features. By utilizing these diverse feature\nspaces, our model enhances its performance. Moreover, employing a\nself-attention mechanism improves the refinement of features at each stage,\nleading to even more robust representations and improved overall performance.\nFurthermore, assigning learnable weights to each stage significantly improved\nperformance and results. We conducted comprehensive evaluations on the\nMiniImageNet and FC100 datasets, specifically in the 5-way 1-shot and 5-way\n5-shot scenarios. Additionally, we performed cross-domain tasks across eight\nbenchmark datasets, achieving high accuracy in the testing domains. These\nevaluations demonstrate the efficacy of our proposed method in comparison to\nstate-of-the-art approaches. https://github.com/FatemehAskari/MSENet\n","authors":["Fatemeh Askari","Amirreza Fateh","Mohammad Reza Mohammadi"],"pdf_url":"https://arxiv.org/pdf/2409.07989v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09532v1","updated":"2025-01-16T13:34:33Z","published":"2025-01-16T13:34:33Z","title":"AdaFV: Accelerating VLMs with Self-Adaptive Cross-Modality Attention\n  Mixture","summary":"  The success of VLMs often relies on the dynamic high-resolution schema that\nadaptively augments the input images to multiple crops, so that the details of\nthe images can be retained. However, such approaches result in a large number\nof redundant visual tokens, thus significantly reducing the efficiency of the\nVLMs. To improve the VLMs' efficiency without introducing extra training costs,\nmany research works are proposed to reduce the visual tokens by filtering the\nuninformative visual tokens or aggregating their information. Some approaches\npropose to reduce the visual tokens according to the self-attention of VLMs,\nwhich are biased, to result in inaccurate responses. The token reduction\napproaches solely rely on visual cues are text-agnostic, and fail to focus on\nthe areas that are most relevant to the question, especially when the queried\nobjects are non-salient to the image. In this work, we first conduct\nexperiments to show that the original text embeddings are aligned with the\nvisual tokens, without bias on the tailed visual tokens. We then propose a\nself-adaptive cross-modality attention mixture mechanism that dynamically\nleverages the effectiveness of visual saliency and text-to-image similarity in\nthe pre-LLM layers to select the visual tokens that are informative. Extensive\nexperiments demonstrate that the proposed approach achieves state-of-the-art\ntraining-free VLM acceleration performance, especially when the reduction rate\nis sufficiently large.\n","authors":["Jiayi Han","Liang Du","Yiwen Wu","Xiangguo Zhou","Hongwei Du","Weibo Zheng"],"pdf_url":"https://arxiv.org/pdf/2501.09532v1.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.24031v3","updated":"2025-01-16T13:20:56Z","published":"2024-10-31T15:29:51Z","title":"A Multi-Modal Approach for Face Anti-Spoofing in Non-Calibrated Systems\n  using Disparity Maps","summary":"  Face recognition technologies are increasingly used in various applications,\nyet they are vulnerable to face spoofing attacks. These spoofing attacks often\ninvolve unique 3D structures, such as printed papers or mobile device screens.\nAlthough stereo-depth cameras can detect such attacks effectively, their\nhigh-cost limits their widespread adoption. Conversely, two-sensor systems\nwithout extrinsic calibration offer a cost-effective alternative but are unable\nto calculate depth using stereo techniques. In this work, we propose a method\nto overcome this challenge by leveraging facial attributes to derive disparity\ninformation and estimate relative depth for anti-spoofing purposes, using\nnon-calibrated systems. We introduce a multi-modal anti-spoofing model, coined\nDisparity Model, that incorporates created disparity maps as a third modality\nalongside the two original sensor modalities. We demonstrate the effectiveness\nof the Disparity Model in countering various spoof attacks using a\ncomprehensive dataset collected from the Intel RealSense ID Solution F455. Our\nmethod outperformed existing methods in the literature, achieving an Equal\nError Rate (EER) of 1.71% and a False Negative Rate (FNR) of 2.77% at a False\nPositive Rate (FPR) of 1%. These errors are lower by 2.45% and 7.94% than the\nerrors of the best comparison method, respectively. Additionally, we introduce\na model ensemble that addresses 3D spoof attacks as well, achieving an EER of\n2.04% and an FNR of 3.83% at an FPR of 1%. Overall, our work provides a\nstate-of-the-art solution for the challenging task of anti-spoofing in\nnon-calibrated systems that lack depth information.\n","authors":["Ariel Larey","Eyal Rond","Omer Achrack"],"pdf_url":"https://arxiv.org/pdf/2410.24031v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09504v1","updated":"2025-01-16T12:33:48Z","published":"2025-01-16T12:33:48Z","title":"HydraMix: Multi-Image Feature Mixing for Small Data Image Classification","summary":"  Training deep neural networks requires datasets with a large number of\nannotated examples. The collection and annotation of these datasets is not only\nextremely expensive but also faces legal and privacy problems. These factors\nare a significant limitation for many real-world applications. To address this,\nwe introduce HydraMix, a novel architecture that generates new image\ncompositions by mixing multiple different images from the same class. HydraMix\nlearns the fusion of the content of various images guided by a\nsegmentation-based mixing mask in feature space and is optimized via a\ncombination of unsupervised and adversarial training. Our data augmentation\nscheme allows the creation of models trained from scratch on very small\ndatasets. We conduct extensive experiments on ciFAIR-10, STL-10, and\nciFAIR-100. Additionally, we introduce a novel text-image metric to assess the\ngenerality of the augmented datasets. Our results show that HydraMix\noutperforms existing state-of-the-art methods for image classification on small\ndatasets.\n","authors":["Christoph Reinders","Frederik Schubert","Bodo Rosenhahn"],"pdf_url":"https://arxiv.org/pdf/2501.09504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09503v1","updated":"2025-01-16T12:28:39Z","published":"2025-01-16T12:28:39Z","title":"AnyStory: Towards Unified Single and Multiple Subject Personalization in\n  Text-to-Image Generation","summary":"  Recently, large-scale generative models have demonstrated outstanding\ntext-to-image generation capabilities. However, generating high-fidelity\npersonalized images with specific subjects still presents challenges,\nespecially in cases involving multiple subjects. In this paper, we propose\nAnyStory, a unified approach for personalized subject generation. AnyStory not\nonly achieves high-fidelity personalization for single subjects, but also for\nmultiple subjects, without sacrificing subject fidelity. Specifically, AnyStory\nmodels the subject personalization problem in an \"encode-then-route\" manner. In\nthe encoding step, AnyStory utilizes a universal and powerful image encoder,\ni.e., ReferenceNet, in conjunction with CLIP vision encoder to achieve\nhigh-fidelity encoding of subject features. In the routing step, AnyStory\nutilizes a decoupled instance-aware subject router to accurately perceive and\npredict the potential location of the corresponding subject in the latent\nspace, and guide the injection of subject conditions. Detailed experimental\nresults demonstrate the excellent performance of our method in retaining\nsubject details, aligning text descriptions, and personalizing for multiple\nsubjects. The project page is at https://aigcdesigngroup.github.io/AnyStory/ .\n","authors":["Junjie He","Yuxiang Tuo","Binghui Chen","Chongyang Zhong","Yifeng Geng","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2501.09503v1.pdf","comment":"Tech report; Project page:\n  https://aigcdesigngroup.github.io/AnyStory/"},{"id":"http://arxiv.org/abs/2501.09502v1","updated":"2025-01-16T12:27:05Z","published":"2025-01-16T12:27:05Z","title":"Omni-Emotion: Extending Video MLLM with Detailed Face and Audio Modeling\n  for Multimodal Emotion Analysis","summary":"  Understanding emotions accurately is essential for fields like human-computer\ninteraction. Due to the complexity of emotions and their multi-modal nature\n(e.g., emotions are influenced by facial expressions and audio), researchers\nhave turned to using multi-modal models to understand human emotions rather\nthan single-modality. However, current video multi-modal large language models\n(MLLMs) encounter difficulties in effectively integrating audio and identifying\nsubtle facial micro-expressions. Furthermore, the lack of detailed emotion\nanalysis datasets also limits the development of multimodal emotion analysis.\nTo address these issues, we introduce a self-reviewed dataset and a\nhuman-reviewed dataset, comprising 24,137 coarse-grained samples and 3,500\nmanually annotated samples with detailed emotion annotations, respectively.\nThese datasets allow models to learn from diverse scenarios and better\ngeneralize to real-world applications. Moreover, in addition to the audio\nmodeling, we propose to explicitly integrate facial encoding models into the\nexisting advanced Video MLLM, enabling the MLLM to effectively unify audio and\nthe subtle facial cues for emotion understanding. By aligning these features\nwithin a unified space and employing instruction tuning in our proposed\ndatasets, our Omni-Emotion achieves state-of-the-art performance in both\nemotion recognition and reasoning tasks.\n","authors":["Qize Yang","Detao Bai","Yi-Xing Peng","Xihan Wei"],"pdf_url":"https://arxiv.org/pdf/2501.09502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09499v1","updated":"2025-01-16T12:20:40Z","published":"2025-01-16T12:20:40Z","title":"VanGogh: A Unified Multimodal Diffusion-based Framework for Video\n  Colorization","summary":"  Video colorization aims to transform grayscale videos into vivid color\nrepresentations while maintaining temporal consistency and structural\nintegrity. Existing video colorization methods often suffer from color bleeding\nand lack comprehensive control, particularly under complex motion or diverse\nsemantic cues. To this end, we introduce VanGogh, a unified multimodal\ndiffusion-based framework for video colorization. VanGogh tackles these\nchallenges using a Dual Qformer to align and fuse features from multiple\nmodalities, complemented by a depth-guided generation process and an optical\nflow loss, which help reduce color overflow. Additionally, a color injection\nstrategy and luma channel replacement are implemented to improve generalization\nand mitigate flickering artifacts. Thanks to this design, users can exercise\nboth global and local control over the generation process, resulting in\nhigher-quality colorized videos. Extensive qualitative and quantitative\nevaluations, and user studies, demonstrate that VanGogh achieves superior\ntemporal consistency and color fidelity.Project page:\nhttps://becauseimbatman0.github.io/VanGogh.\n","authors":["Zixun Fang","Zhiheng Liu","Kai Zhu","Yu Liu","Ka Leong Cheng","Wei Zhai","Yang Cao","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2501.09499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09377v3","updated":"2025-01-16T12:12:24Z","published":"2023-06-15T08:18:29Z","title":"Evaluating alignment between humans and neural network representations\n  in image-based learning tasks","summary":"  Humans represent scenes and objects in rich feature spaces, carrying\ninformation that allows us to generalise about category memberships and\nabstract functions with few examples. What determines whether a neural network\nmodel generalises like a human? We tested how well the representations of $86$\npretrained neural network models mapped to human learning trajectories across\ntwo tasks where humans had to learn continuous relationships and categories of\nnatural images. In these tasks, both human participants and neural networks\nsuccessfully identified the relevant stimulus features within a few trials,\ndemonstrating effective generalisation. We found that while training dataset\nsize was a core determinant of alignment with human choices, contrastive\ntraining with multi-modal data (text and imagery) was a common feature of\ncurrently publicly available models that predicted human generalisation.\nIntrinsic dimensionality of representations had different effects on alignment\nfor different model types. Lastly, we tested three sets of human-aligned\nrepresentations and found no consistent improvements in predictive accuracy\ncompared to the baselines. In conclusion, pretrained neural networks can serve\nto extract representations for cognitive models, as they appear to capture some\nfundamental aspects of cognition that are transferable across tasks. Both our\nparadigms and modelling approach offer a novel way to quantify alignment\nbetween neural networks and humans and extend cognitive science into more\nnaturalistic domains.\n","authors":["Can Demircan","Tankred Saanum","Leonardo Pettini","Marcel Binz","Blazej M Baczkowski","Christian F Doeller","Mona M Garvert","Eric Schulz"],"pdf_url":"https://arxiv.org/pdf/2306.09377v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09490v1","updated":"2025-01-16T12:01:44Z","published":"2025-01-16T12:01:44Z","title":"Comparison of Various SLAM Systems for Mobile Robot in an Indoor\n  Environment","summary":"  This article presents a comparative analysis of a mobile robot trajectories\ncomputed by various ROS-based SLAM systems. For this reason we developed a\nprototype of a mobile robot with common sensors: 2D lidar, a monocular and ZED\nstereo cameras. Then we conducted experiments in a typical office environment\nand collected data from all sensors, running all tested SLAM systems based on\nthe acquired dataset. We studied the following SLAM systems: (a) 2D\nlidar-based: GMapping, Hector SLAM, Cartographer; (b) monocular camera-based:\nLarge Scale Direct monocular SLAM (LSD SLAM), ORB SLAM, Direct Sparse Odometry\n(DSO); and (c) stereo camera-based: ZEDfu, Real-Time Appearance-Based Mapping\n(RTAB map), ORB SLAM, Stereo Parallel Tracking and Mapping (S-PTAM). Since all\nSLAM methods were tested on the same dataset we compared results for different\nSLAM systems with appropriate metrics, demonstrating encouraging results for\nlidar-based Cartographer SLAM, Monocular ORB SLAM and Stereo RTAB Map methods.\n","authors":["Maksim Filipenko","Ilya Afanasyev"],"pdf_url":"https://arxiv.org/pdf/2501.09490v1.pdf","comment":"6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2501.09485v1","updated":"2025-01-16T11:44:29Z","published":"2025-01-16T11:44:29Z","title":"The Devil is in the Details: Simple Remedies for Image-to-LiDAR\n  Representation Learning","summary":"  LiDAR is a crucial sensor in autonomous driving, commonly used alongside\ncameras. By exploiting this camera-LiDAR setup and recent advances in image\nrepresentation learning, prior studies have shown the promising potential of\nimage-to-LiDAR distillation. These prior arts focus on the designs of their own\nlosses to effectively distill the pre-trained 2D image representations into a\n3D model. However, the other parts of the designs have been surprisingly\nunexplored. We find that fundamental design elements, e.g., the LiDAR\ncoordinate system, quantization according to the existing input interface, and\ndata utilization, are more critical than developing loss functions, which have\nbeen overlooked in prior works. In this work, we show that simple fixes to\nthese designs notably outperform existing methods by 16% in 3D semantic\nsegmentation on the nuScenes dataset and 13% in 3D object detection on the\nKITTI dataset in downstream task performance. We focus on overlooked design\nchoices along the spatial and temporal axes. Spatially, prior work has used\ncylindrical coordinate and voxel sizes without considering their side effects\nyielded with a commonly deployed sparse convolution layer input interface,\nleading to spatial quantization errors in 3D models. Temporally, existing work\nhas avoided cumbersome data curation by discarding unsynced data, limiting the\nuse to only the small portion of data that is temporally synced across sensors.\nWe analyze these effects and propose simple solutions for each overlooked\naspect.\n","authors":["Wonjun Jo","Kwon Byung-Ki","Kim Ji-Yeon","Hawook Jeong","Kyungdon Joo","Tae-Hyun Oh"],"pdf_url":"https://arxiv.org/pdf/2501.09485v1.pdf","comment":"Accepted to ACCV2024"},{"id":"http://arxiv.org/abs/2501.09481v1","updated":"2025-01-16T11:35:22Z","published":"2025-01-16T11:35:22Z","title":"MonoSOWA: Scalable monocular 3D Object detector Without human\n  Annotations","summary":"  Detecting the three-dimensional position and orientation of objects using a\nsingle RGB camera is a foundational task in computer vision with many important\napplications. Traditionally, 3D object detection methods are trained in a\nfully-supervised setup, requiring vast amounts of human annotations, which are\nlaborious, costly, and do not scale well with the ever-increasing amounts of\ndata being captured.\n  In this paper, we present the first method to train 3D object detectors for\nmonocular RGB cameras without domain-specific human annotations, thus making\norders of magnitude more data available for training. Thanks to newly proposed\nCanonical Object Space, the method can not only exploit data across a variety\nof datasets and camera setups to train a single 3D detector, but unlike\nprevious work it also works out of the box in previously unseen camera setups.\nAll this is crucial for practical applications, where the data and cameras are\nextremely heterogeneous.\n  The method is evaluated on two standard autonomous driving datasets, where it\noutperforms previous works, which, unlike our method, still rely on 2D human\nannotations.\n","authors":["Jan Skvrna","Lukas Neumann"],"pdf_url":"https://arxiv.org/pdf/2501.09481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04747v6","updated":"2025-01-16T11:17:04Z","published":"2022-09-10T22:00:30Z","title":"Diffusion Models in Vision: A Survey","summary":"  Denoising diffusion models represent a recent emerging topic in computer\nvision, demonstrating remarkable results in the area of generative modeling. A\ndiffusion model is a deep generative model that is based on two stages, a\nforward diffusion stage and a reverse diffusion stage. In the forward diffusion\nstage, the input data is gradually perturbed over several steps by adding\nGaussian noise. In the reverse stage, a model is tasked at recovering the\noriginal input data by learning to gradually reverse the diffusion process,\nstep by step. Diffusion models are widely appreciated for the quality and\ndiversity of the generated samples, despite their known computational burdens,\ni.e. low speeds due to the high number of steps involved during sampling. In\nthis survey, we provide a comprehensive review of articles on denoising\ndiffusion models applied in vision, comprising both theoretical and practical\ncontributions in the field. First, we identify and present three generic\ndiffusion modeling frameworks, which are based on denoising diffusion\nprobabilistic models, noise conditioned score networks, and stochastic\ndifferential equations. We further discuss the relations between diffusion\nmodels and other deep generative models, including variational auto-encoders,\ngenerative adversarial networks, energy-based models, autoregressive models and\nnormalizing flows. Then, we introduce a multi-perspective categorization of\ndiffusion models applied in computer vision. Finally, we illustrate the current\nlimitations of diffusion models and envision some interesting directions for\nfuture research.\n","authors":["Florinel-Alin Croitoru","Vlad Hondru","Radu Tudor Ionescu","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2209.04747v6.pdf","comment":"Accepted in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence. 25 pages, 3 figures"},{"id":"http://arxiv.org/abs/2501.09466v1","updated":"2025-01-16T10:59:29Z","published":"2025-01-16T10:59:29Z","title":"DEFOM-Stereo: Depth Foundation Model Based Stereo Matching","summary":"  Stereo matching is a key technique for metric depth estimation in computer\nvision and robotics. Real-world challenges like occlusion and non-texture\nhinder accurate disparity estimation from binocular matching cues. Recently,\nmonocular relative depth estimation has shown remarkable generalization using\nvision foundation models. Thus, to facilitate robust stereo matching with\nmonocular depth cues, we incorporate a robust monocular relative depth model\ninto the recurrent stereo-matching framework, building a new framework for\ndepth foundation model-based stereo-matching, DEFOM-Stereo. In the feature\nextraction stage, we construct the combined context and matching feature\nencoder by integrating features from conventional CNNs and DEFOM. In the update\nstage, we use the depth predicted by DEFOM to initialize the recurrent\ndisparity and introduce a scale update module to refine the disparity at the\ncorrect scale. DEFOM-Stereo is verified to have comparable performance on the\nScene Flow dataset with state-of-the-art (SOTA) methods and notably shows much\nstronger zero-shot generalization. Moreover, DEFOM-Stereo achieves SOTA\nperformance on the KITTI 2012, KITTI 2015, Middlebury, and ETH3D benchmarks,\nranking 1st on many metrics. In the joint evaluation under the robust vision\nchallenge, our model simultaneously outperforms previous models on the\nindividual benchmarks. Both results demonstrate the outstanding capabilities of\nthe proposed model.\n","authors":["Hualie Jiang","Zhiqiang Lou","Laiyan Ding","Rui Xu","Minglang Tan","Wenjie Jiang","Rui Huang"],"pdf_url":"https://arxiv.org/pdf/2501.09466v1.pdf","comment":"Code: https://github.com/Insta360-Research-Team/DEFOM-Stereo"},{"id":"http://arxiv.org/abs/2312.14150v3","updated":"2025-01-16T10:57:44Z","published":"2023-12-21T18:59:12Z","title":"DriveLM: Driving with Graph Visual Question Answering","summary":"  We study how vision-language models (VLMs) trained on web-scale data can be\nintegrated into end-to-end driving systems to boost generalization and enable\ninteractivity with human users. While recent approaches adapt VLMs to driving\nvia single-round visual question answering (VQA), human drivers reason about\ndecisions in multiple steps. Starting from the localization of key objects,\nhumans estimate object interactions before taking actions. The key insight is\nthat with our proposed task, Graph VQA, where we model graph-structured\nreasoning through perception, prediction and planning question-answer pairs, we\nobtain a suitable proxy task to mimic the human reasoning process. We\ninstantiate datasets (DriveLM-Data) built upon nuScenes and CARLA, and propose\na VLM-based baseline approach (DriveLM-Agent) for jointly performing Graph VQA\nand end-to-end driving. The experiments demonstrate that Graph VQA provides a\nsimple, principled framework for reasoning about a driving scene, and\nDriveLM-Data provides a challenging benchmark for this task. Our DriveLM-Agent\nbaseline performs end-to-end autonomous driving competitively in comparison to\nstate-of-the-art driving-specific architectures. Notably, its benefits are\npronounced when it is evaluated zero-shot on unseen objects or sensor\nconfigurations. We hope this work can be the starting point to shed new light\non how to apply VLMs for autonomous driving. To facilitate future research, all\ncode, data, and models are available to the public.\n","authors":["Chonghao Sima","Katrin Renz","Kashyap Chitta","Li Chen","Hanxue Zhang","Chengen Xie","Jens Beißwenger","Ping Luo","Andreas Geiger","Hongyang Li"],"pdf_url":"https://arxiv.org/pdf/2312.14150v3.pdf","comment":"Accepted to ECCV 2024 as Oral paper"},{"id":"http://arxiv.org/abs/2501.09465v1","updated":"2025-01-16T10:56:45Z","published":"2025-01-16T10:56:45Z","title":"RE-POSE: Synergizing Reinforcement Learning-Based Partitioning and\n  Offloading for Edge Object Detection","summary":"  Object detection plays a crucial role in smart video analysis, with\napplications ranging from autonomous driving and security to smart cities.\nHowever, achieving real-time object detection on edge devices presents\nsignificant challenges due to their limited computational resources and the\nhigh demands of deep neural network (DNN)-based detection models, particularly\nwhen processing high-resolution video. Conventional strategies, such as input\ndown-sampling and network up-scaling, often compromise detection accuracy for\nfaster performance or lead to higher inference latency. To address these\nissues, this paper introduces RE-POSE, a Reinforcement Learning (RL)-Driven\nPartitioning and Edge Offloading framework designed to optimize the\naccuracy-latency trade-off in resource-constrained edge environments. Our\napproach features an RL-Based Dynamic Clustering Algorithm (RL-DCA) that\npartitions video frames into non-uniform blocks based on object distribution\nand the computational characteristics of DNNs. Furthermore, a parallel edge\noffloading scheme is implemented to distribute these blocks across multiple\nedge servers for concurrent processing. Experimental evaluations show that\nRE-POSE significantly enhances detection accuracy and reduces inference\nlatency, surpassing existing methods.\n","authors":["Jianrui Shi","Yong Zhao","Zeyang Cui","Xiaoming Shen","Minhang Zeng","Xiaojie Liu"],"pdf_url":"https://arxiv.org/pdf/2501.09465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08258v2","updated":"2025-01-16T10:55:41Z","published":"2025-01-14T17:10:02Z","title":"Towards an End-to-End (E2E) Adversarial Learning and Application in the\n  Physical World","summary":"  The traditional learning process of patch-based adversarial attacks,\nconducted in the digital domain and then applied in the physical domain (e.g.,\nvia printed stickers), may suffer from reduced performance due to adversarial\npatches' limited transferability from the digital domain to the physical\ndomain. Given that previous studies have considered using projectors to apply\nadversarial attacks, we raise the following question: can adversarial learning\n(i.e., patch generation) be performed entirely in the physical domain with a\nprojector? In this work, we propose the Physical-domain Adversarial Patch\nLearning Augmentation (PAPLA) framework, a novel end-to-end (E2E) framework\nthat converts adversarial learning from the digital domain to the physical\ndomain using a projector. We evaluate PAPLA across multiple scenarios,\nincluding controlled laboratory settings and realistic outdoor environments,\ndemonstrating its ability to ensure attack success compared to conventional\ndigital learning-physical application (DL-PA) methods. We also analyze the\nimpact of environmental factors, such as projection surface color, projector\nstrength, ambient light, distance, and angle of the target object relative to\nthe camera, on the effectiveness of projected patches. Finally, we demonstrate\nthe feasibility of the attack against a parked car and a stop sign in a\nreal-world outdoor environment. Our results show that under specific\nconditions, E2E adversarial learning in the physical domain eliminates the\ntransferability issue and ensures evasion by object detectors. Finally, we\nprovide insights into the challenges and opportunities of applying adversarial\nlearning in the physical domain and explain where such an approach is more\neffective than using a sticker.\n","authors":["Dudi Biton","Jacob Shams","Satoru Koda","Asaf Shabtai","Yuval Elovici","Ben Nassi"],"pdf_url":"https://arxiv.org/pdf/2501.08258v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09460v1","updated":"2025-01-16T10:42:29Z","published":"2025-01-16T10:42:29Z","title":"Normal-NeRF: Ambiguity-Robust Normal Estimation for Highly Reflective\n  Scenes","summary":"  Neural Radiance Fields (NeRF) often struggle with reconstructing and\nrendering highly reflective scenes. Recent advancements have developed various\nreflection-aware appearance models to enhance NeRF's capability to render\nspecular reflections. However, the robust reconstruction of highly reflective\nscenes is still hindered by the inherent shape ambiguity on specular surfaces.\nExisting methods typically rely on additional geometry priors to regularize the\nshape prediction, but this can lead to oversmoothed geometry in complex scenes.\nObserving the critical role of surface normals in parameterizing reflections,\nwe introduce a transmittance-gradient-based normal estimation technique that\nremains robust even under ambiguous shape conditions. Furthermore, we propose a\ndual activated densities module that effectively bridges the gap between smooth\nsurface normals and sharp object boundaries. Combined with a reflection-aware\nappearance model, our proposed method achieves robust reconstruction and\nhigh-fidelity rendering of scenes featuring both highly specular reflections\nand intricate geometric structures. Extensive experiments demonstrate that our\nmethod outperforms existing state-of-the-art methods on various datasets.\n","authors":["Ji Shi","Xianghua Ying","Ruohao Guo","Bowei Xing","Wenzhen Yue"],"pdf_url":"https://arxiv.org/pdf/2501.09460v1.pdf","comment":"AAAI 2025, code available at https://github.com/sjj118/Normal-NeRF"},{"id":"http://arxiv.org/abs/2501.09456v1","updated":"2025-01-16T10:31:51Z","published":"2025-01-16T10:31:51Z","title":"On the Relation between Optical Aperture and Automotive Object Detection","summary":"  We explore the impact of aperture size and shape on automotive camera systems\nfor deep-learning-based tasks like traffic sign recognition and light state\ndetection. A method is proposed to simulate optical effects using the point\nspread function (PSF), enhancing realism and reducing the domain gap between\nsynthetic and real-world images. Computer-generated scenes are refined with\nthis technique to model optical distortions and improve simulation accuracy.\n","authors":["Ofer Bar-Shalom","Tzvi Philipp","Eran Kishon"],"pdf_url":"https://arxiv.org/pdf/2501.09456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09446v1","updated":"2025-01-16T10:20:48Z","published":"2025-01-16T10:20:48Z","title":"Double Visual Defense: Adversarial Pre-training and Instruction Tuning\n  for Improving Vision-Language Model Robustness","summary":"  This paper investigates the robustness of vision-language models against\nadversarial visual perturbations and introduces a novel ``double visual\ndefense\" to enhance this robustness. Unlike previous approaches that resort to\nlightweight adversarial fine-tuning of a pre-trained CLIP model, we perform\nlarge-scale adversarial vision-language pre-training from scratch using\nweb-scale data. We then strengthen the defense by incorporating adversarial\nvisual instruction tuning. The resulting models from each stage, $\\Delta$CLIP\nand $\\Delta^2$LLaVA, show substantially enhanced zero-shot robustness and set a\nnew state-of-the-art in adversarial defense for vision-language models. For\nexample, the adversarial robustness of $\\Delta$CLIP surpasses that of the\nprevious best models on ImageNet-1k by ~20%. %For example, $\\Delta$CLIP\nsurpasses the previous best models on ImageNet-1k by ~20% in terms of\nadversarial robustness. Similarly, compared to prior art, $\\Delta^2$LLaVA\nbrings a ~30% robustness improvement to image captioning task and a ~20%\nrobustness improvement to visual question answering task. Furthermore, our\nmodels exhibit stronger zero-shot recognition capability, fewer hallucinations,\nand superior reasoning performance compared to baselines. Our project page is\nhttps://doublevisualdefense.github.io/.\n","authors":["Zeyu Wang","Cihang Xie","Brian Bartoldson","Bhavya Kailkhura"],"pdf_url":"https://arxiv.org/pdf/2501.09446v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15500v4","updated":"2025-01-16T10:20:32Z","published":"2024-07-22T09:31:30Z","title":"TextureCrop: Enhancing Synthetic Image Detection through Texture-based\n  Cropping","summary":"  Generative AI technologies produce increasingly realistic imagery, which,\ndespite its potential for creative applications, can also be misused to produce\nmisleading and harmful content. This renders Synthetic Image Detection (SID)\nmethods essential for identifying AI-generated content online. State-of-the-art\nSID methods typically resize or center-crop input images due to architectural\nor computational constraints, which hampers the detection of artifacts that\nappear in high-resolution images. To address this limitation, we propose\nTextureCrop, an image pre-processing component that can be plugged in any\npre-trained SID model to improve its performance. By focusing on high-frequency\nimage parts where generative artifacts are prevalent, TextureCrop enhances SID\nperformance with manageable memory requirements. Experimental results\ndemonstrate a consistent improvement in AUC across various detectors by 6.1%\ncompared to center cropping and by 15% compared to resizing, across\nhigh-resolution images from the Forensynths, Synthbuster and TWIGMA datasets.\nCode available at https : //github.com/mever-team/texture-crop.\n","authors":["Despina Konstantinidou","Christos Koutlis","Symeon Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2407.15500v4.pdf","comment":"10 pages, 7 images"},{"id":"http://arxiv.org/abs/2501.09436v1","updated":"2025-01-16T10:07:44Z","published":"2025-01-16T10:07:44Z","title":"Scaling up self-supervised learning for improved surgical foundation\n  models","summary":"  Foundation models have revolutionized computer vision by achieving vastly\nsuperior performance across diverse tasks through large-scale pretraining on\nextensive datasets. However, their application in surgical computer vision has\nbeen limited. This study addresses this gap by introducing SurgeNetXL, a novel\nsurgical foundation model that sets a new benchmark in surgical computer\nvision. Trained on the largest reported surgical dataset to date, comprising\nover 4.7 million video frames, SurgeNetXL achieves consistent top-tier\nperformance across six datasets spanning four surgical procedures and three\ntasks, including semantic segmentation, phase recognition, and critical view of\nsafety (CVS) classification. Compared with the best-performing surgical\nfoundation models, SurgeNetXL shows mean improvements of 2.4, 9.0, and 12.6\npercent for semantic segmentation, phase recognition, and CVS classification,\nrespectively. Additionally, SurgeNetXL outperforms the best-performing\nImageNet-based variants by 14.4, 4.0, and 1.6 percent in the respective tasks.\nIn addition to advancing model performance, this study provides key insights\ninto scaling pretraining datasets, extending training durations, and optimizing\nmodel architectures specifically for surgical computer vision. These findings\npave the way for improved generalizability and robustness in data-scarce\nscenarios, offering a comprehensive framework for future research in this\ndomain. All models and a subset of the SurgeNetXL dataset, including over 2\nmillion video frames, are publicly available at:\nhttps://github.com/TimJaspers0801/SurgeNet.\n","authors":["Tim J. M. Jaspers","Ronald L. P. D. de Jong","Yiping Li","Carolus H. J. Kusters","Franciscus H. A. Bakker","Romy C. van Jaarsveld","Gino M. Kuiper","Richard van Hillegersberg","Jelle P. Ruurda","Willem M. Brinkman","Josien P. W. Pluim","Peter H. N. de With","Marcel Breeuwer","Yasmina Al Khalil","Fons van der Sommen"],"pdf_url":"https://arxiv.org/pdf/2501.09436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09433v1","updated":"2025-01-16T10:03:15Z","published":"2025-01-16T10:03:15Z","title":"CaPa: Carve-n-Paint Synthesis for Efficient 4K Textured Mesh Generation","summary":"  The synthesis of high-quality 3D assets from textual or visual inputs has\nbecome a central objective in modern generative modeling. Despite the\nproliferation of 3D generation algorithms, they frequently grapple with\nchallenges such as multi-view inconsistency, slow generation times, low\nfidelity, and surface reconstruction problems. While some studies have\naddressed some of these issues, a comprehensive solution remains elusive. In\nthis paper, we introduce \\textbf{CaPa}, a carve-and-paint framework that\ngenerates high-fidelity 3D assets efficiently. CaPa employs a two-stage\nprocess, decoupling geometry generation from texture synthesis. Initially, a 3D\nlatent diffusion model generates geometry guided by multi-view inputs, ensuring\nstructural consistency across perspectives. Subsequently, leveraging a novel,\nmodel-agnostic Spatially Decoupled Attention, the framework synthesizes\nhigh-resolution textures (up to 4K) for a given geometry. Furthermore, we\npropose a 3D-aware occlusion inpainting algorithm that fills untextured\nregions, resulting in cohesive results across the entire model. This pipeline\ngenerates high-quality 3D assets in less than 30 seconds, providing\nready-to-use outputs for commercial applications. Experimental results\ndemonstrate that CaPa excels in both texture fidelity and geometric stability,\nestablishing a new standard for practical, scalable 3D asset generation.\n","authors":["Hwan Heo","Jangyeong Kim","Seongyeong Lee","Jeong A Wi","Junyoung Choi","Sangjun Ahn"],"pdf_url":"https://arxiv.org/pdf/2501.09433v1.pdf","comment":"project page: https://ncsoft.github.io/CaPa/"},{"id":"http://arxiv.org/abs/2501.09428v1","updated":"2025-01-16T09:57:40Z","published":"2025-01-16T09:57:40Z","title":"AugRefer: Advancing 3D Visual Grounding via Cross-Modal Augmentation and\n  Spatial Relation-based Referring","summary":"  3D visual grounding (3DVG), which aims to correlate a natural language\ndescription with the target object within a 3D scene, is a significant yet\nchallenging task. Despite recent advancements in this domain, existing\napproaches commonly encounter a shortage: a limited amount and diversity of\ntext3D pairs available for training. Moreover, they fall short in effectively\nleveraging different contextual clues (e.g., rich spatial relations within the\n3D visual space) for grounding. To address these limitations, we propose\nAugRefer, a novel approach for advancing 3D visual grounding. AugRefer\nintroduces cross-modal augmentation designed to extensively generate diverse\ntext-3D pairs by placing objects into 3D scenes and creating accurate and\nsemantically rich descriptions using foundation models. Notably, the resulting\npairs can be utilized by any existing 3DVG methods for enriching their training\ndata. Additionally, AugRefer presents a language-spatial adaptive decoder that\neffectively adapts the potential referring objects based on the language\ndescription and various 3D spatial relations. Extensive experiments on three\nbenchmark datasets clearly validate the effectiveness of AugRefer.\n","authors":["Xinyi Wang","Na Zhao","Zhiyuan Han","Dan Guo","Xun Yang"],"pdf_url":"https://arxiv.org/pdf/2501.09428v1.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2501.09425v1","updated":"2025-01-16T09:55:42Z","published":"2025-01-16T09:55:42Z","title":"Vision-Language Models Do Not Understand Negation","summary":"  Many practical vision-language applications require models that understand\nnegation, e.g., when using natural language to retrieve images which contain\ncertain objects but not others. Despite advancements in vision-language models\n(VLMs) through large-scale training, their ability to comprehend negation\nremains underexplored. This study addresses the question: how well do current\nVLMs understand negation? We introduce NegBench, a new benchmark designed to\nevaluate negation understanding across 18 task variations and 79k examples\nspanning image, video, and medical datasets. The benchmark consists of two core\ntasks designed to evaluate negation understanding in diverse multimodal\nsettings: Retrieval with Negation and Multiple Choice Questions with Negated\nCaptions. Our evaluation reveals that modern VLMs struggle significantly with\nnegation, often performing at chance level. To address these shortcomings, we\nexplore a data-centric approach wherein we finetune CLIP models on large-scale\nsynthetic datasets containing millions of negated captions. We show that this\napproach can result in a 10% increase in recall on negated queries and a 40%\nboost in accuracy on multiple-choice questions with negated captions.\n","authors":["Kumail Alhamoud","Shaden Alshammari","Yonglong Tian","Guohao Li","Philip Torr","Yoon Kim","Marzyeh Ghassemi"],"pdf_url":"https://arxiv.org/pdf/2501.09425v1.pdf","comment":"Project page: https://negbench.github.io"},{"id":"http://arxiv.org/abs/2501.09420v1","updated":"2025-01-16T09:47:18Z","published":"2025-01-16T09:47:18Z","title":"Dynamic Neural Style Transfer for Artistic Image Generation using VGG19","summary":"  Throughout history, humans have created remarkable works of art, but\nartificial intelligence has only recently started to make strides in generating\nvisually compelling art. Breakthroughs in the past few years have focused on\nusing convolutional neural networks (CNNs) to separate and manipulate the\ncontent and style of images, applying texture synthesis techniques.\nNevertheless, a number of current techniques continue to encounter obstacles,\nincluding lengthy processing times, restricted choices of style images, and the\ninability to modify the weight ratio of styles. We proposed a neural style\ntransfer system that can add various artistic styles to a desired image to\naddress these constraints allowing flexible adjustments to style weight ratios\nand reducing processing time. The system uses the VGG19 model for feature\nextraction, ensuring high-quality, flexible stylization without compromising\ncontent integrity.\n","authors":["Kapil Kashyap","Mehak Garg","Sean Fargose","Sindhu Nair"],"pdf_url":"https://arxiv.org/pdf/2501.09420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09411v1","updated":"2025-01-16T09:38:22Z","published":"2025-01-16T09:38:22Z","title":"Towards Robust and Realistic Human Pose Estimation via WiFi Signals","summary":"  Robust WiFi-based human pose estimation is a challenging task that bridges\ndiscrete and subtle WiFi signals to human skeletons. This paper revisits this\nproblem and reveals two critical yet overlooked issues: 1) cross-domain gap,\ni.e., due to significant variations between source-target domain pose\ndistributions; and 2) structural fidelity gap, i.e., predicted skeletal poses\nmanifest distorted topology, usually with misplaced joints and disproportionate\nbone lengths. This paper fills these gaps by reformulating the task into a\nnovel two-phase framework dubbed DT-Pose: Domain-consistent representation\nlearning and Topology-constrained Pose decoding. Concretely, we first propose a\ntemporal-consistent contrastive learning strategy with uniformity\nregularization, coupled with self-supervised masking-reconstruction operations,\nto enable robust learning of domain-consistent and motion-discriminative\nWiFi-specific representations. Beyond this, we introduce a simple yet effective\npose decoder with task prompts, which integrates Graph Convolution Network\n(GCN) and Transformer layers to constrain the topology structure of the\ngenerated skeleton by exploring the adjacent-overarching relationships among\nhuman joints. Extensive experiments conducted on various benchmark datasets\nhighlight the superior performance of our method in tackling these fundamental\nchallenges in both 2D/3D human pose estimation tasks.\n","authors":["Yang Chen","Jingcai Guo","Song Guo","Jingren Zhou","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2501.09411v1.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2501.09403v1","updated":"2025-01-16T09:18:59Z","published":"2025-01-16T09:18:59Z","title":"PISCO: Self-Supervised k-Space Regularization for Improved Neural\n  Implicit k-Space Representations of Dynamic MRI","summary":"  Neural implicit k-space representations (NIK) have shown promising results\nfor dynamic magnetic resonance imaging (MRI) at high temporal resolutions. Yet,\nreducing acquisition time, and thereby available training data, results in\nsevere performance drops due to overfitting. To address this, we introduce a\nnovel self-supervised k-space loss function $\\mathcal{L}_\\mathrm{PISCO}$,\napplicable for regularization of NIK-based reconstructions. The proposed loss\nfunction is based on the concept of parallel imaging-inspired self-consistency\n(PISCO), enforcing a consistent global k-space neighborhood relationship\nwithout requiring additional data. Quantitative and qualitative evaluations on\nstatic and dynamic MR reconstructions show that integrating PISCO significantly\nimproves NIK representations. Particularly for high acceleration factors\n(R$\\geq$54), NIK with PISCO achieves superior spatio-temporal reconstruction\nquality compared to state-of-the-art methods. Furthermore, an extensive\nanalysis of the loss assumptions and stability shows PISCO's potential as\nversatile self-supervised k-space loss function for further applications and\narchitectures. Code is available at:\nhttps://github.com/compai-lab/2025-pisco-spieker\n","authors":["Veronika Spieker","Hannah Eichhorn","Wenqi Huang","Jonathan K. Stelter","Tabita Catalan","Rickmer F. Braren","Daniel Rueckert","Francisco Sahli Costabal","Kerstin Hammernik","Dimitrios C. Karampinos","Claudia Prieto","Julia A. Schnabel"],"pdf_url":"https://arxiv.org/pdf/2501.09403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09396v1","updated":"2025-01-16T09:07:01Z","published":"2025-01-16T09:07:01Z","title":"Joint Transmission and Deblurring: A Semantic Communication Approach\n  Using Events","summary":"  Deep learning-based joint source-channel coding (JSCC) is emerging as a\npromising technology for effective image transmission. However, most existing\napproaches focus on transmitting clear images, overlooking real-world\nchallenges such as motion blur caused by camera shaking or fast-moving objects.\nMotion blur often degrades image quality, making transmission and\nreconstruction more challenging. Event cameras, which asynchronously record\npixel intensity changes with extremely low latency, have shown great potential\nfor motion deblurring tasks. However, the efficient transmission of the\nabundant data generated by event cameras remains a significant challenge. In\nthis work, we propose a novel JSCC framework for the joint transmission of\nblurry images and events, aimed at achieving high-quality reconstructions under\nlimited channel bandwidth. This approach is designed as a deblurring\ntask-oriented JSCC system. Since RGB cameras and event cameras capture the same\nscene through different modalities, their outputs contain both shared and\ndomain-specific information. To avoid repeatedly transmitting the shared\ninformation, we extract and transmit their shared information and\ndomain-specific information, respectively. At the receiver, the received\nsignals are processed by a deblurring decoder to generate clear images.\nAdditionally, we introduce a multi-stage training strategy to train the\nproposed model. Simulation results demonstrate that our method significantly\noutperforms existing JSCC-based image transmission schemes, addressing motion\nblur effectively.\n","authors":["Pujing Yang","Guangyi Zhang","Yunlong Cai","Lei Yu","Guanding Yu"],"pdf_url":"https://arxiv.org/pdf/2501.09396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09393v1","updated":"2025-01-16T09:05:46Z","published":"2025-01-16T09:05:46Z","title":"SVIA: A Street View Image Anonymization Framework for Self-Driving\n  Applications","summary":"  In recent years, there has been an increasing interest in image\nanonymization, particularly focusing on the de-identification of faces and\nindividuals. However, for self-driving applications, merely de-identifying\nfaces and individuals might not provide sufficient privacy protection since\nstreet views like vehicles and buildings can still disclose locations,\ntrajectories, and other sensitive information. Therefore, it remains crucial to\nextend anonymization techniques to street view images to fully preserve the\nprivacy of users, pedestrians, and vehicles. In this paper, we propose a Street\nView Image Anonymization (SVIA) framework for self-driving applications. The\nSVIA framework consists of three integral components: a semantic segmenter to\nsegment an input image into functional regions, an inpainter to generate\nalternatives to privacy-sensitive regions, and a harmonizer to seamlessly\nstitch modified regions to guarantee visual coherence. Compared to existing\nmethods, SVIA achieves a much better trade-off between image generation quality\nand privacy protection, as evidenced by experimental results for five common\nmetrics on two widely used public datasets.\n","authors":["Dongyu Liu","Xuhong Wang","Cen Chen","Yanhao Wang","Shengyue Yao","Yilun Lin"],"pdf_url":"https://arxiv.org/pdf/2501.09393v1.pdf","comment":"8 pages, 6 figures, 3 tables. Accepted by IEEE ITSC 2024"},{"id":"http://arxiv.org/abs/2410.20986v2","updated":"2025-01-16T08:58:44Z","published":"2024-10-28T13:04:44Z","title":"Skinned Motion Retargeting with Dense Geometric Interaction Perception","summary":"  Capturing and maintaining geometric interactions among different body parts\nis crucial for successful motion retargeting in skinned characters. Existing\napproaches often overlook body geometries or add a geometry correction stage\nafter skeletal motion retargeting. This results in conflicts between skeleton\ninteraction and geometry correction, leading to issues such as jittery,\ninterpenetration, and contact mismatches. To address these challenges, we\nintroduce a new retargeting framework, MeshRet, which directly models the dense\ngeometric interactions in motion retargeting. Initially, we establish dense\nmesh correspondences between characters using semantically consistent sensors\n(SCS), effective across diverse mesh topologies. Subsequently, we develop a\nnovel spatio-temporal representation called the dense mesh interaction (DMI)\nfield. This field, a collection of interacting SCS feature vectors, skillfully\ncaptures both contact and non-contact interactions between body geometries. By\naligning the DMI field during retargeting, MeshRet not only preserves motion\nsemantics but also prevents self-interpenetration and ensures contact\npreservation. Extensive experiments on the public Mixamo dataset and our\nnewly-collected ScanRet dataset demonstrate that MeshRet achieves\nstate-of-the-art performance. Code available at\nhttps://github.com/abcyzj/MeshRet.\n","authors":["Zijie Ye","Jia-Wei Liu","Jia Jia","Shikun Sun","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2410.20986v2.pdf","comment":"NeurIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2407.03653v3","updated":"2025-01-16T08:55:49Z","published":"2024-07-04T05:48:28Z","title":"reBEN: Refined BigEarthNet Dataset for Remote Sensing Image Analysis","summary":"  This paper presents refined BigEarthNet (reBEN) that is a large-scale,\nmulti-modal remote sensing dataset constructed to support deep learning (DL)\nstudies for remote sensing image analysis. The reBEN dataset consists of\n549,488 pairs of Sentinel-1 and Sentinel-2 image patches. To construct reBEN,\nwe initially consider the Sentinel-1 and Sentinel-2 tiles used to construct the\nBigEarthNet dataset and then divide them into patches of size 1200 m x 1200 m.\nWe apply atmospheric correction to the Sentinel-2 patches using the latest\nversion of the sen2cor tool, resulting in higher-quality patches compared to\nthose present in BigEarthNet. Each patch is then associated with a pixel-level\nreference map and scene-level multi-labels. This makes reBEN suitable for\npixel- and scene-based learning tasks. The labels are derived from the most\nrecent CORINE Land Cover (CLC) map of 2018 by utilizing the 19-class\nnomenclature as in BigEarthNet. The use of the most recent CLC map results in\novercoming the label noise present in BigEarthNet. Furthermore, we introduce a\nnew geographical-based split assignment algorithm that significantly reduces\nthe spatial correlation among the train, validation, and test sets with respect\nto those present in BigEarthNet. This increases the reliability of the\nevaluation of DL models. To minimize the DL model training time, we introduce\nsoftware tools that convert the reBEN dataset into a DL-optimized data format.\nIn our experiments, we show the potential of reBEN for multi-modal multi-label\nimage classification problems by considering several state-of-the-art DL\nmodels. The pre-trained model weights, associated code, and complete dataset\nare available at https://bigearth.net.\n","authors":["Kai Norman Clasen","Leonard Hackel","Tom Burgert","Gencer Sumbul","Begüm Demir","Volker Markl"],"pdf_url":"https://arxiv.org/pdf/2407.03653v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09372v1","updated":"2025-01-16T08:34:39Z","published":"2025-01-16T08:34:39Z","title":"Image Segmentation with transformers: An Overview, Challenges and Future","summary":"  Image segmentation, a key task in computer vision, has traditionally relied\non convolutional neural networks (CNNs), yet these models struggle with\ncapturing complex spatial dependencies, objects with varying scales, need for\nmanually crafted architecture components and contextual information. This paper\nexplores the shortcomings of CNN-based models and the shift towards transformer\narchitectures -to overcome those limitations. This work reviews\nstate-of-the-art transformer-based segmentation models, addressing\nsegmentation-specific challenges and their solutions. The paper discusses\ncurrent challenges in transformer-based segmentation and outlines promising\nfuture trends, such as lightweight architectures and enhanced data efficiency.\nThis survey serves as a guide for understanding the impact of transformers in\nadvancing segmentation capabilities and overcoming the limitations of\ntraditional models.\n","authors":["Deepjyoti Chetia","Debasish Dutta","Sanjib Kr Kalita"],"pdf_url":"https://arxiv.org/pdf/2501.09372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03659v3","updated":"2025-01-16T08:20:15Z","published":"2025-01-07T09:47:46Z","title":"DehazeGS: Seeing Through Fog with 3D Gaussian Splatting","summary":"  Current novel view synthesis tasks primarily rely on high-quality and clear\nimages. However, in foggy scenes, scattering and attenuation can significantly\ndegrade the reconstruction and rendering quality. Although NeRF-based dehazing\nreconstruction algorithms have been developed, their use of deep fully\nconnected neural networks and per-ray sampling strategies leads to high\ncomputational costs. Moreover, NeRF's implicit representation struggles to\nrecover fine details from hazy scenes. In contrast, recent advancements in 3D\nGaussian Splatting achieve high-quality 3D scene reconstruction by explicitly\nmodeling point clouds into 3D Gaussians. In this paper, we propose leveraging\nthe explicit Gaussian representation to explain the foggy image formation\nprocess through a physically accurate forward rendering process. We introduce\nDehazeGS, a method capable of decomposing and rendering a fog-free background\nfrom participating media using only muti-view foggy images as input. We model\nthe transmission within each Gaussian distribution to simulate the formation of\nfog. During this process, we jointly learn the atmospheric light and scattering\ncoefficient while optimizing the Gaussian representation of the hazy scene. In\nthe inference stage, we eliminate the effects of scattering and attenuation on\nthe Gaussians and directly project them onto a 2D plane to obtain a clear view.\nExperiments on both synthetic and real-world foggy datasets demonstrate that\nDehazeGS achieves state-of-the-art performance in terms of both rendering\nquality and computational efficiency. visualizations are available at\nhttps://dehazegs.github.io/\n","authors":["Jinze Yu","Yiqun Wang","Zhengda Lu","Jianwei Guo","Yong Li","Hongxing Qin","Xiaopeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.03659v3.pdf","comment":"9 pages,4 figures"},{"id":"http://arxiv.org/abs/2501.05777v2","updated":"2025-01-16T08:20:11Z","published":"2025-01-10T08:18:37Z","title":"StructSR: Refuse Spurious Details in Real-World Image Super-Resolution","summary":"  Diffusion-based models have shown great promise in real-world image\nsuper-resolution (Real-ISR), but often generate content with structural errors\nand spurious texture details due to the empirical priors and illusions of these\nmodels. To address this issue, we introduce StructSR, a simple, effective, and\nplug-and-play method that enhances structural fidelity and suppresses spurious\ndetails for diffusion-based Real-ISR. StructSR operates without the need for\nadditional fine-tuning, external model priors, or high-level semantic\nknowledge. At its core is the Structure-Aware Screening (SAS) mechanism, which\nidentifies the image with the highest structural similarity to the\nlow-resolution (LR) input in the early inference stage, allowing us to leverage\nit as a historical structure knowledge to suppress the generation of spurious\ndetails. By intervening in the diffusion inference process, StructSR seamlessly\nintegrates with existing diffusion-based Real-ISR models. Our experimental\nresults demonstrate that StructSR significantly improves the fidelity of\nstructure and texture, improving the PSNR and SSIM metrics by an average of\n5.27% and 9.36% on a synthetic dataset (DIV2K-Val) and 4.13% and 8.64% on two\nreal-world datasets (RealSR and DRealSR) when integrated with four\nstate-of-the-art diffusion-based Real-ISR methods.\n","authors":["Yachao Li","Dong Liang","Tianyu Ding","Sheng-Jun Huang"],"pdf_url":"https://arxiv.org/pdf/2501.05777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09363v1","updated":"2025-01-16T08:18:03Z","published":"2025-01-16T08:18:03Z","title":"Identification of Traditional Medicinal Plant Leaves Using an effective\n  Deep Learning model and Self-Curated Dataset","summary":"  Medicinal plants have been a key component in producing traditional and\nmodern medicines, especially in the field of Ayurveda, an ancient Indian\nmedical system. Producing these medicines and collecting and extracting the\nright plant is a crucial step due to the visually similar nature of some\nplants. The extraction of these plants from nonmedicinal plants requires human\nexpert intervention. To solve the issue of accurate plant identification and\nreduce the need for a human expert in the collection process; employing\ncomputer vision methods will be efficient and beneficial. In this paper, we\nhave proposed a model that solves such issues. The proposed model is a custom\nconvolutional neural network (CNN) architecture with 6 convolution layers,\nmax-pooling layers, and dense layers. The model was tested on three different\ndatasets named Indian Medicinal Leaves Image Dataset,MED117 Medicinal Plant\nLeaf Dataset, and the self-curated dataset by the authors. The proposed model\nachieved respective accuracies of 99.5%, 98.4%, and 99.7% using various\noptimizers including Adam, RMSprop, and SGD with momentum.\n","authors":["Deepjyoti Chetia","Sanjib Kr Kalita","Prof Partha Pratim Baruah","Debasish Dutta","Tanaz Akhter"],"pdf_url":"https://arxiv.org/pdf/2501.09363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09361v1","updated":"2025-01-16T08:17:32Z","published":"2025-01-16T08:17:32Z","title":"Strategic Base Representation Learning via Feature Augmentations for\n  Few-Shot Class Incremental Learning","summary":"  Few-shot class incremental learning implies the model to learn new classes\nwhile retaining knowledge of previously learned classes with a small number of\ntraining instances. Existing frameworks typically freeze the parameters of the\npreviously learned classes during the incorporation of new classes. However,\nthis approach often results in suboptimal class separation of previously\nlearned classes, leading to overlap between old and new classes. Consequently,\nthe performance of old classes degrades on new classes. To address these\nchallenges, we propose a novel feature augmentation driven contrastive learning\nframework designed to enhance the separation of previously learned classes to\naccommodate new classes. Our approach involves augmenting feature vectors and\nassigning proxy labels to these vectors. This strategy expands the feature\nspace, ensuring seamless integration of new classes within the expanded space.\nAdditionally, we employ a self-supervised contrastive loss to improve the\nseparation between previous classes. We validate our framework through\nexperiments on three FSCIL benchmark datasets: CIFAR100, miniImageNet, and\nCUB200. The results demonstrate that our Feature Augmentation driven\nContrastive Learning framework significantly outperforms other approaches,\nachieving state-of-the-art performance.\n","authors":["Parinita Nema","Vinod K Kurmi"],"pdf_url":"https://arxiv.org/pdf/2501.09361v1.pdf","comment":"Accepted at WACV 2025"},{"id":"http://arxiv.org/abs/2407.21035v2","updated":"2025-01-16T08:08:57Z","published":"2024-07-17T08:19:11Z","title":"Direct Unlearning Optimization for Robust and Safe Text-to-Image Models","summary":"  Recent advancements in text-to-image (T2I) models have unlocked a wide range\nof applications but also present significant risks, particularly in their\npotential to generate unsafe content. To mitigate this issue, researchers have\ndeveloped unlearning techniques to remove the model's ability to generate\npotentially harmful content. However, these methods are easily bypassed by\nadversarial attacks, making them unreliable for ensuring the safety of\ngenerated images. In this paper, we propose Direct Unlearning Optimization\n(DUO), a novel framework for removing Not Safe For Work (NSFW) content from T2I\nmodels while preserving their performance on unrelated topics. DUO employs a\npreference optimization approach using curated paired image data, ensuring that\nthe model learns to remove unsafe visual concepts while retaining unrelated\nfeatures. Furthermore, we introduce an output-preserving regularization term to\nmaintain the model's generative capabilities on safe content. Extensive\nexperiments demonstrate that DUO can robustly defend against various\nstate-of-the-art red teaming methods without significant performance\ndegradation on unrelated topics, as measured by FID and CLIP scores. Our work\ncontributes to the development of safer and more reliable T2I models, paving\nthe way for their responsible deployment in both closed-source and open-source\nscenarios.\n","authors":["Yong-Hyun Park","Sangdoo Yun","Jin-Hwa Kim","Junho Kim","Geonhui Jang","Yonghyun Jeong","Junghyo Jo","Gayoung Lee"],"pdf_url":"https://arxiv.org/pdf/2407.21035v2.pdf","comment":"This paper has been accepted for NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.10869v2","updated":"2025-01-16T08:06:16Z","published":"2024-06-16T09:38:33Z","title":"Geometric Distortion Guided Transformer for Omnidirectional Image\n  Super-Resolution","summary":"  As virtual and augmented reality applications gain popularity,\nomnidirectional image (ODI) super-resolution has become increasingly important.\nUnlike 2D plain images that are formed on a plane, ODIs are projected onto\nspherical surfaces. Applying established image super-resolution methods to\nODIs, therefore, requires performing equirectangular projection (ERP) to map\nthe ODIs onto a plane. ODI super-resolution needs to take into account\ngeometric distortion resulting from ERP. However, without considering such\ngeometric distortion of ERP images, previous deep-learning-based methods only\nutilize a limited range of pixels and may easily miss self-similar textures for\nreconstruction. In this paper, we introduce a novel Geometric Distortion Guided\nTransformer for Omnidirectional image Super-Resolution (GDGT-OSR).\nSpecifically, a distortion modulated rectangle-window self-attention mechanism,\nintegrated with deformable self-attention, is proposed to better perceive the\ndistortion and thus involve more self-similar textures. Distortion modulation\nis achieved through a newly devised distortion guidance generator that produces\nguidance by exploiting the variability of distortion across latitudes.\nFurthermore, we propose a dynamic feature aggregation scheme to adaptively fuse\nthe features from different self-attention modules. We present extensive\nexperimental results on public datasets and show that the new GDGT-OSR\noutperforms methods in existing literature.\n","authors":["Cuixin Yang","Rongkang Dong","Jun Xiao","Cong Zhang","Kin-Man Lam","Fei Zhou","Guoping Qiu"],"pdf_url":"https://arxiv.org/pdf/2406.10869v2.pdf","comment":"13 pages, 12 figures, journal"},{"id":"http://arxiv.org/abs/2501.09355v1","updated":"2025-01-16T08:06:02Z","published":"2025-01-16T08:06:02Z","title":"YETI (YET to Intervene) Proactive Interventions by Multimodal AI Agents\n  in Augmented Reality Tasks","summary":"  Multimodal AI Agents are AI models that have the capability of interactively\nand cooperatively assisting human users to solve day-to-day tasks. Augmented\nReality (AR) head worn devices can uniquely improve the user experience of\nsolving procedural day-to-day tasks by providing egocentric multimodal (audio\nand video) observational capabilities to AI Agents. Such AR capabilities can\nhelp AI Agents see and listen to actions that users take which can relate to\nmultimodal capabilities of human users. Existing AI Agents, either Large\nLanguage Models (LLMs) or Multimodal Vision-Language Models (VLMs) are reactive\nin nature, which means that models cannot take an action without reading or\nlistening to the human user's prompts. Proactivity of AI Agents on the other\nhand can help the human user detect and correct any mistakes in agent observed\ntasks, encourage users when they do tasks correctly or simply engage in\nconversation with the user - akin to a human teaching or assisting a user. Our\nproposed YET to Intervene (YETI) multimodal agent focuses on the research\nquestion of identifying circumstances that may require the agent to intervene\nproactively. This allows the agent to understand when it can intervene in a\nconversation with human users that can help the user correct mistakes on tasks,\nlike cooking, using AR. Our YETI Agent learns scene understanding signals based\non interpretable notions of Structural Similarity (SSIM) on consecutive video\nframes. We also define the alignment signal which the AI Agent can learn to\nidentify if the video frames corresponding to the user's actions on the task\nare consistent with expected actions. These signals are used by our AI Agent to\ndetermine when it should proactively intervene. We compare our results on the\ninstances of proactive intervention in the HoloAssist multimodal benchmark for\nan expert agent guiding a user to complete procedural tasks.\n","authors":["Saptarashmi Bandyopadhyay","Vikas Bahirwani","Lavisha Aggarwal","Bhanu Guda","Lin Li","Andrea Colaco"],"pdf_url":"https://arxiv.org/pdf/2501.09355v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2501.09350v1","updated":"2025-01-16T08:03:49Z","published":"2025-01-16T08:03:49Z","title":"Making Your Dreams A Reality: Decoding the Dreams into a Coherent Video\n  Story from fMRI Signals","summary":"  This paper studies the brave new idea for Multimedia community, and proposes\na novel framework to convert dreams into coherent video narratives using fMRI\ndata. Essentially, dreams have intrigued humanity for centuries, offering\nglimpses into our subconscious minds. Recent advancements in brain imaging,\nparticularly functional magnetic resonance imaging (fMRI), have provided new\nways to explore the neural basis of dreaming. By combining subjective dream\nexperiences with objective neurophysiological data, we aim to understand the\nvisual aspects of dreams and create complete video narratives. Our process\ninvolves three main steps: reconstructing visual perception, decoding dream\nimagery, and integrating dream stories. Using innovative techniques in fMRI\nanalysis and language modeling, we seek to push the boundaries of dream\nresearch and gain deeper insights into visual experiences during sleep. This\ntechnical report introduces a novel approach to visually decoding dreams using\nfMRI signals and weaving dream visuals into narratives using language models.\nWe gather a dataset of dreams along with descriptions to assess the\neffectiveness of our framework.\n","authors":["Yanwei Fu","Jianxiong Gao","Baofeng Yang","Jianfeng Feng"],"pdf_url":"https://arxiv.org/pdf/2501.09350v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2501.09347v1","updated":"2025-01-16T08:00:17Z","published":"2025-01-16T08:00:17Z","title":"UVRM: A Scalable 3D Reconstruction Model from Unposed Videos","summary":"  Large Reconstruction Models (LRMs) have recently become a popular method for\ncreating 3D foundational models. Training 3D reconstruction models with 2D\nvisual data traditionally requires prior knowledge of camera poses for the\ntraining samples, a process that is both time-consuming and prone to errors.\nConsequently, 3D reconstruction training has been confined to either synthetic\n3D datasets or small-scale datasets with annotated poses. In this study, we\ninvestigate the feasibility of 3D reconstruction using unposed video data of\nvarious objects. We introduce UVRM, a novel 3D reconstruction model capable of\nbeing trained and evaluated on monocular videos without requiring any\ninformation about the pose. UVRM uses a transformer network to implicitly\naggregate video frames into a pose-invariant latent feature space, which is\nthen decoded into a tri-plane 3D representation. To obviate the need for\nground-truth pose annotations during training, UVRM employs a combination of\nthe score distillation sampling (SDS) method and an analysis-by-synthesis\napproach, progressively synthesizing pseudo novel-views using a pre-trained\ndiffusion model. We qualitatively and quantitatively evaluate UVRM's\nperformance on the G-Objaverse and CO3D datasets without relying on pose\ninformation. Extensive experiments show that UVRM is capable of effectively and\nefficiently reconstructing a wide range of 3D objects from unposed videos.\n","authors":["Shiu-hong Kao","Xiao Li","Jinglu Wang","Chi-Keung Tang","Yu-Wing Tai","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2501.09347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04390v2","updated":"2025-01-16T07:58:06Z","published":"2025-01-08T10:08:09Z","title":"iFADIT: Invertible Face Anonymization via Disentangled Identity\n  Transform","summary":"  Face anonymization aims to conceal the visual identity of a face to safeguard\nthe individual's privacy. Traditional methods like blurring and pixelation can\nlargely remove identifying features, but these techniques significantly degrade\nimage quality and are vulnerable to deep reconstruction attacks. Generative\nmodels have emerged as a promising solution for anonymizing faces while\npreserving a natural appearance. However, many still face limitations in visual\nquality and often overlook the potential to recover the original face from the\nanonymized version, which can be valuable in specific contexts such as image\nforensics. This paper proposes a novel framework named iFADIT, an acronym for\nInvertible Face Anonymization via Disentangled Identity Transform. The\nframework features a disentanglement architecture coupled with a secure\nflow-based model: the former decouples identity information from\nnon-identifying attributes, while the latter transforms the decoupled identity\ninto an anonymized version in an invertible manner controlled by a secret key.\nThe anonymized face can then be reconstructed based on a pre-trained StyleGAN\nthat ensures high image quality and realistic facial details. Recovery of the\noriginal face (aka de-anonymization) is possible upon the availability of the\nmatching secret, by inverting the anonymization process based on the same set\nof model parameters. Furthermore, a dedicated secret-key mechanism along with a\ndual-phase training strategy is devised to ensure the desired properties of\nface anonymization. Qualitative and quantitative experiments demonstrate the\nsuperiority of the proposed approach in anonymity, reversibility, security,\ndiversity, and interpretability over competing methods.\n","authors":["Lin Yuan","Kai Liang","Xiong Li","Tao Wu","Nannan Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2501.04390v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09341v1","updated":"2025-01-16T07:50:56Z","published":"2025-01-16T07:50:56Z","title":"SE-BSFV: Online Subspace Learning based Shadow Enhancement and\n  Background Suppression for ViSAR under Complex Background","summary":"  Video synthetic aperture radar (ViSAR) has attracted substantial attention in\nthe moving target detection (MTD) field due to its ability to continuously\nmonitor changes in the target area. In ViSAR, the moving targets' shadows will\nnot offset and defocus, which is widely used as a feature for MTD. However, the\nshadows are difficult to distinguish from the low scattering region in the\nbackground, which will cause more missing and false alarms. Therefore, it is\nworth investigating how to enhance the distinction between the shadows and\nbackground. In this study, we proposed the Shadow Enhancement and Background\nSuppression for ViSAR (SE-BSFV) algorithm. The SE-BSFV algorithm is based on\nthe low-rank representation (LRR) theory and adopts online subspace learning\ntechnique to enhance shadows and suppress background for ViSAR images. Firstly,\nwe use a registration algorithm to register the ViSAR images and utilize\nGaussian mixture distribution (GMD) to model the ViSAR data. Secondly, the\nknowledge learned from the previous frames is leveraged to estimate the GMD\nparameters of the current frame, and the Expectation-maximization (EM)\nalgorithm is used to estimate the subspace parameters. Then, the foreground\nmatrix of the current frame can be obtained. Finally, the alternating direction\nmethod of multipliers (ADMM) is used to eliminate strong scattering objects in\nthe foreground matrix to obtain the final results. The experimental results\nindicate that the SE-BSFV algorithm significantly enhances the shadows'\nsaliency and greatly improves the detection performance while ensuring\nefficiency compared with several other advanced pre-processing algorithms.\n","authors":["Shangqu Yan","Chenyang Luo","Yaowen Fu","Wenpeng Zhang","Wei Yang","Ruofeng Yu"],"pdf_url":"https://arxiv.org/pdf/2501.09341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08331v2","updated":"2025-01-16T07:43:19Z","published":"2025-01-14T18:59:10Z","title":"Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using\n  Real-Time Warped Noise","summary":"  Generative modeling aims to transform random noise into structured outputs.\nIn this work, we enhance video diffusion models by allowing motion control via\nstructured latent noise sampling. This is achieved by just a change in data: we\npre-process training videos to yield structured noise. Consequently, our method\nis agnostic to diffusion model design, requiring no changes to model\narchitectures or training pipelines. Specifically, we propose a novel noise\nwarping algorithm, fast enough to run in real time, that replaces random\ntemporal Gaussianity with correlated warped noise derived from optical flow\nfields, while preserving the spatial Gaussianity. The efficiency of our\nalgorithm enables us to fine-tune modern video diffusion base models using\nwarped noise with minimal overhead, and provide a one-stop solution for a wide\nrange of user-friendly motion control: local object motion control, global\ncamera movement control, and motion transfer. The harmonization between\ntemporal coherence and spatial Gaussianity in our warped noise leads to\neffective motion control while maintaining per-frame pixel quality. Extensive\nexperiments and user studies demonstrate the advantages of our method, making\nit a robust and scalable approach for controlling motion in video diffusion\nmodels. Video results are available on our webpage:\nhttps://vgenai-netflix-eyeline-research.github.io/Go-with-the-Flow. Source code\nand model checkpoints are available on GitHub:\nhttps://github.com/VGenAI-Netflix-Eyeline-Research/Go-with-the-Flow.\n","authors":["Ryan Burgert","Yuancheng Xu","Wenqi Xian","Oliver Pilarski","Pascal Clausen","Mingming He","Li Ma","Yitong Deng","Lingxiao Li","Mohsen Mousavi","Michael Ryoo","Paul Debevec","Ning Yu"],"pdf_url":"https://arxiv.org/pdf/2501.08331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20406v3","updated":"2025-01-16T07:26:52Z","published":"2024-10-27T10:35:47Z","title":"Point-PRC: A Prompt Learning Based Regulation Framework for\n  Generalizable Point Cloud Analysis","summary":"  This paper investigates the 3D domain generalization (3DDG) ability of large\n3D models based on prevalent prompt learning. Recent works demonstrate the\nperformances of 3D point cloud recognition can be boosted remarkably by\nparameter-efficient prompt tuning. However, we observe that the improvement on\ndownstream tasks comes at the expense of a severe drop in 3D domain\ngeneralization. To resolve this challenge, we present a comprehensive\nregulation framework that allows the learnable prompts to actively interact\nwith the well-learned general knowledge in large 3D models to maintain good\ngeneralization. Specifically, the proposed framework imposes multiple explicit\nconstraints on the prompt learning trajectory by maximizing the mutual\nagreement between task-specific predictions and task-agnostic knowledge. We\ndesign the regulation framework as a plug-and-play module to embed into\nexisting representative large 3D models. Surprisingly, our method not only\nrealizes consistently increasing generalization ability but also enhances\ntask-specific 3D recognition performances across various 3DDG benchmarks by a\nclear margin. Considering the lack of study and evaluation on 3DDG, we also\ncreate three new benchmarks, namely base-to-new, cross-dataset and few-shot\ngeneralization benchmarks, to enrich the field and inspire future research.\nCode and benchmarks are available at\n\\url{https://github.com/auniquesun/Point-PRC}.\n","authors":["Hongyu Sun","Qiuhong Ke","Yongcai Wang","Wang Chen","Kang Yang","Deying Li","Jianfei Cai"],"pdf_url":"https://arxiv.org/pdf/2410.20406v3.pdf","comment":"5 figures, 14 tables; accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.09333v1","updated":"2025-01-16T07:07:41Z","published":"2025-01-16T07:07:41Z","title":"Prompt-CAM: A Simpler Interpretable Transformer for Fine-Grained\n  Analysis","summary":"  We present a simple usage of pre-trained Vision Transformers (ViTs) for\nfine-grained analysis, aiming to identify and localize the traits that\ndistinguish visually similar categories, such as different bird species or dog\nbreeds. Pre-trained ViTs such as DINO have shown remarkable capabilities to\nextract localized, informative features. However, using saliency maps like\nGrad-CAM can hardly point out the traits: they often locate the whole object by\na blurred, coarse heatmap, not traits. We propose a novel approach Prompt Class\nAttention Map (Prompt-CAM) to the rescue. Prompt-CAM learns class-specific\nprompts to a pre-trained ViT and uses the corresponding outputs for\nclassification. To classify an image correctly, the true-class prompt must\nattend to the unique image patches not seen in other classes' images, i.e.,\ntraits. As such, the true class's multi-head attention maps reveal traits and\ntheir locations. Implementation-wise, Prompt-CAM is almost a free lunch by\nsimply modifying the prediction head of Visual Prompt Tuning (VPT). This makes\nPrompt-CAM fairly easy to train and apply, sharply contrasting other\ninterpretable methods that design specific models and training processes. It is\neven simpler than the recently published INterpretable TRansformer (INTR),\nwhose encoder-decoder architecture prevents it from leveraging pre-trained\nViTs. Extensive empirical studies on a dozen datasets from various domains\n(e.g., birds, fishes, insects, fungi, flowers, food, and cars) validate\nPrompt-CAM superior interpretation capability.\n","authors":["Arpita Chowdhury","Dipanjyoti Paul","Zheda Mai","Jianyang Gu","Ziheng Zhang","Kazi Sajeed Mehrab","Elizabeth G. Campolongo","Daniel Rubenstein","Charles V. Stewart","Anuj Karpatne","Tanya Berger-Wolf","Yu Su","Wei-Lun Chao"],"pdf_url":"https://arxiv.org/pdf/2501.09333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19043v2","updated":"2025-01-16T06:46:18Z","published":"2024-06-27T09:50:20Z","title":"CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting\n  Universal Machine Learning for Accelerated Cardiac MRI","summary":"  Cardiac magnetic resonance imaging (MRI) has emerged as a clinically\ngold-standard technique for diagnosing cardiac diseases, thanks to its ability\nto provide diverse information with multiple modalities and anatomical views.\nAccelerated cardiac MRI is highly expected to achieve time-efficient and\npatient-friendly imaging, and then advanced image reconstruction approaches are\nrequired to recover high-quality, clinically interpretable images from\nundersampled measurements. However, the lack of publicly available cardiac MRI\nk-space dataset in terms of both quantity and diversity has severely hindered\nsubstantial technological progress, particularly for data-driven artificial\nintelligence. Here, we provide a standardized, diverse, and high-quality\nCMRxRecon2024 dataset to facilitate the technical development, fair evaluation,\nand clinical transfer of cardiac MRI reconstruction approaches, towards\npromoting the universal frameworks that enable fast and robust reconstructions\nacross different cardiac MRI protocols in clinical practice. To the best of our\nknowledge, the CMRxRecon2024 dataset is the largest and most protocal-diverse\npublicly available cardiac k-space dataset. It is acquired from 330 healthy\nvolunteers, covering commonly used modalities, anatomical views, and\nacquisition trajectories in clinical cardiac MRI workflows. Besides, an open\nplatform with tutorials, benchmarks, and data processing tools is provided to\nfacilitate data usage, advanced method development, and fair performance\nevaluation.\n","authors":["Zi Wang","Fanwen Wang","Chen Qin","Jun Lyu","Cheng Ouyang","Shuo Wang","Yan Li","Mengyao Yu","Haoyu Zhang","Kunyuan Guo","Zhang Shi","Qirong Li","Ziqiang Xu","Yajing Zhang","Hao Li","Sha Hua","Binghua Chen","Longyu Sun","Mengting Sun","Qin Li","Ying-Hua Chu","Wenjia Bai","Jing Qin","Xiahai Zhuang","Claudia Prieto","Alistair Young","Michael Markl","He Wang","Lianming Wu","Guang Yang","Xiaobo Qu","Chengyan Wang"],"pdf_url":"https://arxiv.org/pdf/2406.19043v2.pdf","comment":"23 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2501.09321v1","updated":"2025-01-16T06:25:56Z","published":"2025-01-16T06:25:56Z","title":"Soft Knowledge Distillation with Multi-Dimensional Cross-Net Attention\n  for Image Restoration Models Compression","summary":"  Transformer-based encoder-decoder models have achieved remarkable success in\nimage-to-image transfer tasks, particularly in image restoration. However,\ntheir high computational complexity-manifested in elevated FLOPs and parameter\ncounts-limits their application in real-world scenarios. Existing knowledge\ndistillation methods in image restoration typically employ lightweight student\nmodels that directly mimic the intermediate features and reconstruction results\nof the teacher, overlooking the implicit attention relationships between them.\nTo address this, we propose a Soft Knowledge Distillation (SKD) strategy that\nincorporates a Multi-dimensional Cross-net Attention (MCA) mechanism for\ncompressing image restoration models. This mechanism facilitates interaction\nbetween the student and teacher across both channel and spatial dimensions,\nenabling the student to implicitly learn the attention matrices. Additionally,\nwe employ a Gaussian kernel function to measure the distance between student\nand teacher features in kernel space, ensuring stable and efficient feature\nlearning. To further enhance the quality of reconstructed images, we replace\nthe commonly used L1 or KL divergence loss with a contrastive learning loss at\nthe image level. Experiments on three tasks-image deraining, deblurring, and\ndenoising-demonstrate that our SKD strategy significantly reduces computational\ncomplexity while maintaining strong image restoration capabilities.\n","authors":["Yongheng Zhang","Danfeng Yan"],"pdf_url":"https://arxiv.org/pdf/2501.09321v1.pdf","comment":"Accepted by ICASSP2025"},{"id":"http://arxiv.org/abs/2501.09311v1","updated":"2025-01-16T05:58:32Z","published":"2025-01-16T05:58:32Z","title":"Shape-Based Single Object Classification Using Ensemble Method\n  Classifiers","summary":"  Nowadays, more and more images are available. Annotation and retrieval of the\nimages pose classification problems, where each class is defined as the group\nof database images labelled with a common semantic label. Various systems have\nbeen proposed for content-based retrieval, as well as for image classification\nand indexing. In this paper, a hierarchical classification framework has been\nproposed for bridging the semantic gap effectively and achieving multi-category\nimage classification. A well known pre-processing and post-processing method\nwas used and applied to three problems; image segmentation, object\nidentification and image classification. The method was applied to classify\nsingle object images from Amazon and Google datasets. The classification was\ntested for four different classifiers; BayesNetwork (BN), Random Forest (RF),\nBagging and Vote. The estimated classification accuracies ranged from 20% to\n99% (using 10-fold cross validation). The Bagging classifier presents the best\nperformance, followed by the Random Forest classifier.\n","authors":["Nur Shazwani Kamarudin","Mokhairi Makhtar","Syadiah Nor Wan Shamsuddin","Syed Abdullah Fadzli"],"pdf_url":"https://arxiv.org/pdf/2501.09311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01432v3","updated":"2025-01-16T05:42:28Z","published":"2024-07-18T19:44:44Z","title":"VLG-CBM: Training Concept Bottleneck Models with Vision-Language\n  Guidance","summary":"  Concept Bottleneck Models (CBMs) provide interpretable prediction by\nintroducing an intermediate Concept Bottleneck Layer (CBL), which encodes\nhuman-understandable concepts to explain models' decision. Recent works\nproposed to utilize Large Language Models and pre-trained Vision-Language\nModels to automate the training of CBMs, making it more scalable and automated.\nHowever, existing approaches still fall short in two aspects: First, the\nconcepts predicted by CBL often mismatch the input image, raising doubts about\nthe faithfulness of interpretation. Second, it has been shown that concept\nvalues encode unintended information: even a set of random concepts could\nachieve comparable test accuracy to state-of-the-art CBMs. To address these\ncritical limitations, in this work, we propose a novel framework called\nVision-Language-Guided Concept Bottleneck Model (VLG-CBM) to enable faithful\ninterpretability with the benefits of boosted performance. Our method leverages\noff-the-shelf open-domain grounded object detectors to provide visually\ngrounded concept annotation, which largely enhances the faithfulness of concept\nprediction while further improving the model performance. In addition, we\npropose a new metric called Number of Effective Concepts (NEC) to control the\ninformation leakage and provide better interpretability. Extensive evaluations\nacross five standard benchmarks show that our method, VLG-CBM, outperforms\nexisting methods by at least 4.27% and up to 51.09% on Accuracy at NEC=5\n(denoted as ANEC-5), and by at least 0.45% and up to 29.78% on average accuracy\n(denoted as ANEC-avg), while preserving both faithfulness and interpretability\nof the learned concepts as demonstrated in extensive experiments.\n","authors":["Divyansh Srivastava","Ge Yan","Tsui-Wei Weng"],"pdf_url":"https://arxiv.org/pdf/2408.01432v3.pdf","comment":"Appeared at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.09305v1","updated":"2025-01-16T05:39:50Z","published":"2025-01-16T05:39:50Z","title":"Domain-conditioned and Temporal-guided Diffusion Modeling for\n  Accelerated Dynamic MRI Reconstruction","summary":"  Purpose: To propose a domain-conditioned and temporal-guided diffusion\nmodeling method, termed dynamic Diffusion Modeling (dDiMo), for accelerated\ndynamic MRI reconstruction, enabling diffusion process to characterize\nspatiotemporal information for time-resolved multi-coil Cartesian and\nnon-Cartesian data. Methods: The dDiMo framework integrates temporal\ninformation from time-resolved dimensions, allowing for the concurrent capture\nof intra-frame spatial features and inter-frame temporal dynamics in diffusion\nmodeling. It employs additional spatiotemporal ($x$-$t$) and self-consistent\nfrequency-temporal ($k$-$t$) priors to guide the diffusion process. This\napproach ensures precise temporal alignment and enhances the recovery of fine\nimage details. To facilitate a smooth diffusion process, the nonlinear\nconjugate gradient algorithm is utilized during the reverse diffusion steps.\nThe proposed model was tested on two types of MRI data: Cartesian-acquired\nmulti-coil cardiac MRI and Golden-Angle-Radial-acquired multi-coil\nfree-breathing lung MRI, across various undersampling rates. Results: dDiMo\nachieved high-quality reconstructions at various acceleration factors,\ndemonstrating improved temporal alignment and structural recovery compared to\nother competitive reconstruction methods, both qualitatively and\nquantitatively. This proposed diffusion framework exhibited robust performance\nin handling both Cartesian and non-Cartesian acquisitions, effectively\nreconstructing dynamic datasets in cardiac and lung MRI under different imaging\nconditions. Conclusion: This study introduces a novel diffusion modeling method\nfor dynamic MRI reconstruction.\n","authors":["Liping Zhang","Iris Yuwen Zhou","Sydney B. Montesi","Li Feng","Fang Liu"],"pdf_url":"https://arxiv.org/pdf/2501.09305v1.pdf","comment":"21 pages, 15 figures, 2 tables"},{"id":"http://arxiv.org/abs/2501.09304v1","updated":"2025-01-16T05:39:28Z","published":"2025-01-16T05:39:28Z","title":"Finding the Trigger: Causal Abductive Reasoning on Video Events","summary":"  This paper introduces a new problem, Causal Abductive Reasoning on Video\nEvents (CARVE), which involves identifying causal relationships between events\nin a video and generating hypotheses about causal chains that account for the\noccurrence of a target event. To facilitate research in this direction, we\ncreate two new benchmark datasets with both synthetic and realistic videos,\naccompanied by trigger-target labels generated through a novel counterfactual\nsynthesis approach. To explore the challenge of solving CARVE, we present a\nCausal Event Relation Network (CERN) that examines the relationships between\nvideo events in temporal and semantic spaces to efficiently determine the\nroot-cause trigger events. Through extensive experiments, we demonstrate the\ncritical roles of event relational representation learning and interaction\nmodeling in solving video causal reasoning challenges. The introduction of the\nCARVE task, along with the accompanying datasets and the CERN framework, will\nadvance future research on video causal reasoning and significantly facilitate\nvarious applications, including video surveillance, root-cause analysis and\nmovie content management.\n","authors":["Thao Minh Le","Vuong Le","Kien Do","Sunil Gupta","Svetha Venkatesh","Truyen Tran"],"pdf_url":"https://arxiv.org/pdf/2501.09304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09302v1","updated":"2025-01-16T05:37:29Z","published":"2025-01-16T05:37:29Z","title":"Creating Virtual Environments with 3D Gaussian Splatting: A Comparative\n  Study","summary":"  3D Gaussian Splatting (3DGS) has recently emerged as an innovative and\nefficient 3D representation technique. While its potential for extended reality\n(XR) applications is frequently highlighted, its practical effectiveness\nremains underexplored. In this work, we examine three distinct 3DGS-based\napproaches for virtual environment (VE) creation, leveraging their unique\nstrengths for efficient and visually compelling scene representation. By\nconducting a comparable study, we evaluate the feasibility of 3DGS in creating\nimmersive VEs, identify its limitations in XR applications, and discuss future\nresearch and development opportunities.\n","authors":["Shi Qiu","Binzhu Xie","Qixuan Liu","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2501.09302v1.pdf","comment":"IEEE VR 2025 Posters"},{"id":"http://arxiv.org/abs/2501.09294v1","updated":"2025-01-16T05:01:30Z","published":"2025-01-16T05:01:30Z","title":"Efficient Few-Shot Medical Image Analysis via Hierarchical Contrastive\n  Vision-Language Learning","summary":"  Few-shot learning in medical image classification presents a significant\nchallenge due to the limited availability of annotated data and the complex\nnature of medical imagery. In this work, we propose Adaptive Vision-Language\nFine-tuning with Hierarchical Contrastive Alignment (HiCA), a novel framework\nthat leverages the capabilities of Large Vision-Language Models (LVLMs) for\nmedical image analysis. HiCA introduces a two-stage fine-tuning strategy,\ncombining domain-specific pretraining and hierarchical contrastive learning to\nalign visual and textual representations at multiple levels. We evaluate our\napproach on two benchmark datasets, Chest X-ray and Breast Ultrasound,\nachieving state-of-the-art performance in both few-shot and zero-shot settings.\nFurther analyses demonstrate the robustness, generalizability, and\ninterpretability of our method, with substantial improvements in performance\ncompared to existing baselines. Our work highlights the potential of\nhierarchical contrastive strategies in adapting LVLMs to the unique challenges\nof medical imaging tasks.\n","authors":["Harrison Fuller","Fernando Gabriela Garcia","Victor Flores"],"pdf_url":"https://arxiv.org/pdf/2501.09294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03789v3","updated":"2025-01-16T04:13:10Z","published":"2023-07-07T18:28:44Z","title":"Synthesizing Forestry Images Conditioned on Plant Phenotype Using a\n  Generative Adversarial Network","summary":"  Plant phenology and phenotype prediction using remote sensing data are\nincreasingly gaining attention within the plant science community as a\npromising approach to enhance agricultural productivity. This work focuses on\ngenerating synthetic forestry images that satisfy certain phenotypic\nattributes, viz. canopy greenness. We harness a Generative Adversarial Network\n(GAN) to synthesize biologically plausible and phenotypically stable forestry\nimages conditioned on the greenness of vegetation (a continuous attribute) over\na specific region of interest, describing a particular vegetation type in a\nmixed forest. The training data is based on the automated digital camera\nimagery provided by the National Ecological Observatory Network (NEON) and\nprocessed by the PhenoCam Network. Our method helps render the appearance of\nforest sites specific to a greenness value. The synthetic images are\nsubsequently utilized to predict another phenotypic attribute, viz., redness of\nplants. The quality of the synthetic images is assessed using the Structural\nSIMilarity (SSIM) index and Fr\\'echet Inception Distance (FID). Further, the\ngreenness and redness indices of the synthetic images are compared against\nthose of the original images using Root Mean Squared Percentage Error (RMSPE)\nto evaluate their accuracy and integrity. The generalizability and scalability\nof our proposed GAN model are established by effectively transforming it to\ngenerate synthetic images for other forest sites and vegetation types. From a\nbroader perspective, this approach could be leveraged to visualize forestry\nbased on different phenotypic attributes in the context of various\nenvironmental parameters.\n","authors":["Debasmita Pal","Arun Ross"],"pdf_url":"https://arxiv.org/pdf/2307.03789v3.pdf","comment":"Accepted to Pattern Recognition journal"},{"id":"http://arxiv.org/abs/2501.09281v1","updated":"2025-01-16T04:06:59Z","published":"2025-01-16T04:06:59Z","title":"SoccerSynth-Detection: A Synthetic Dataset for Soccer Player Detection","summary":"  In soccer video analysis, player detection is essential for identifying key\nevents and reconstructing tactical positions. The presence of numerous players\nand frequent occlusions, combined with copyright restrictions, severely\nrestricts the availability of datasets, leaving limited options such as\nSoccerNet-Tracking and SportsMOT. These datasets suffer from a lack of\ndiversity, which hinders algorithms from adapting effectively to varied soccer\nvideo contexts. To address these challenges, we developed\nSoccerSynth-Detection, the first synthetic dataset designed for the detection\nof synthetic soccer players. It includes a broad range of random lighting and\ntextures, as well as simulated camera motion blur. We validated its efficacy\nusing the object detection model (Yolov8n) against real-world datasets\n(SoccerNet-Tracking and SportsMoT). In transfer tests, it matched the\nperformance of real datasets and significantly outperformed them in images with\nmotion blur; in pre-training tests, it demonstrated its efficacy as a\npre-training dataset, significantly enhancing the algorithm's overall\nperformance. Our work demonstrates the potential of synthetic datasets to\nreplace real datasets for algorithm training in the field of soccer video\nanalysis.\n","authors":["Haobin Qin","Calvin Yeung","Rikuhei Umemoto","Keisuke Fujii"],"pdf_url":"https://arxiv.org/pdf/2501.09281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08659v2","updated":"2025-01-16T03:51:49Z","published":"2025-01-15T08:50:52Z","title":"BRIGHT-VO: Brightness-Guided Hybrid Transformer for Visual Odometry with\n  Multi-modality Refinement Module","summary":"  Visual odometry (VO) plays a crucial role in autonomous driving, robotic\nnavigation, and other related tasks by estimating the position and orientation\nof a camera based on visual input. Significant progress has been made in\ndata-driven VO methods, particularly those leveraging deep learning techniques\nto extract image features and estimate camera poses. However, these methods\noften struggle in low-light conditions because of the reduced visibility of\nfeatures and the increased difficulty of matching keypoints. To address this\nlimitation, we introduce BrightVO, a novel VO model based on Transformer\narchitecture, which not only performs front-end visual feature extraction, but\nalso incorporates a multi-modality refinement module in the back-end that\nintegrates Inertial Measurement Unit (IMU) data. Using pose graph optimization,\nthis module iteratively refines pose estimates to reduce errors and improve\nboth accuracy and robustness. Furthermore, we create a synthetic low-light\ndataset, KiC4R, which includes a variety of lighting conditions to facilitate\nthe training and evaluation of VO frameworks in challenging environments.\nExperimental results demonstrate that BrightVO achieves state-of-the-art\nperformance on both the KiC4R dataset and the KITTI benchmarks. Specifically,\nit provides an average improvement of 20% in pose estimation accuracy in normal\noutdoor environments and 259% in low-light conditions, outperforming existing\nmethods. For widespread use and further development, the research work is fully\nopen-source at https://github.com/Anastasiawd/BrightVO.\n","authors":["Dongzhihan Wang","Yang Yang","Liang Xu"],"pdf_url":"https://arxiv.org/pdf/2501.08659v2.pdf","comment":"We have identified significant issues in the methodology and data\n  analysis that impact the validity of our conclusions"},{"id":"http://arxiv.org/abs/2501.09277v1","updated":"2025-01-16T03:47:25Z","published":"2025-01-16T03:47:25Z","title":"Bias for Action: Video Implicit Neural Representations with Bias\n  Modulation","summary":"  We propose a new continuous video modeling framework based on implicit neural\nrepresentations (INRs) called ActINR. At the core of our approach is the\nobservation that INRs can be considered as a learnable dictionary, with the\nshapes of the basis functions governed by the weights of the INR, and their\nlocations governed by the biases. Given compact non-linear activation\nfunctions, we hypothesize that an INR's biases are suitable to capture motion\nacross images, and facilitate compact representations for video sequences.\nUsing these observations, we design ActINR to share INR weights across frames\nof a video sequence, while using unique biases for each frame. We further model\nthe biases as the output of a separate INR conditioned on time index to promote\nsmoothness. By training the video INR and this bias INR together, we\ndemonstrate unique capabilities, including $10\\times$ video slow motion,\n$4\\times$ spatial super resolution along with $2\\times$ slow motion, denoising,\nand video inpainting. ActINR performs remarkably well across numerous video\nprocessing tasks (often achieving more than 6dB improvement), setting a new\nstandard for continuous modeling of videos.\n","authors":["Alper Kayabasi","Anil Kumar Vadathya","Guha Balakrishnan","Vishwanath Saragadam"],"pdf_url":"https://arxiv.org/pdf/2501.09277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09268v1","updated":"2025-01-16T03:35:23Z","published":"2025-01-16T03:35:23Z","title":"Knowledge Distillation for Image Restoration : Simultaneous Learning\n  from Degraded and Clean Images","summary":"  Model compression through knowledge distillation has seen extensive\napplication in classification and segmentation tasks. However, its potential in\nimage-to-image translation, particularly in image restoration, remains\nunderexplored. To address this gap, we propose a Simultaneous Learning\nKnowledge Distillation (SLKD) framework tailored for model compression in image\nrestoration tasks. SLKD employs a dual-teacher, single-student architecture\nwith two distinct learning strategies: Degradation Removal Learning (DRL) and\nImage Reconstruction Learning (IRL), simultaneously. In DRL, the student\nencoder learns from Teacher A to focus on removing degradation factors, guided\nby a novel BRISQUE extractor. In IRL, the student decoder learns from Teacher B\nto reconstruct clean images, with the assistance of a proposed PIQE extractor.\nThese strategies enable the student to learn from degraded and clean images\nsimultaneously, ensuring high-quality compression of image restoration models.\nExperimental results across five datasets and three tasks demonstrate that SLKD\nachieves substantial reductions in FLOPs and parameters, exceeding 80\\%, while\nmaintaining strong image restoration performance.\n","authors":["Yongheng Zhang","Danfeng Yan"],"pdf_url":"https://arxiv.org/pdf/2501.09268v1.pdf","comment":"Accepted by ICASSP2025"},{"id":"http://arxiv.org/abs/2501.09267v1","updated":"2025-01-16T03:34:36Z","published":"2025-01-16T03:34:36Z","title":"Are Open-Vocabulary Models Ready for Detection of MEP Elements on\n  Construction Sites","summary":"  The construction industry has long explored robotics and computer vision, yet\ntheir deployment on construction sites remains very limited. These technologies\nhave the potential to revolutionize traditional workflows by enhancing\naccuracy, efficiency, and safety in construction management. Ground robots\nequipped with advanced vision systems could automate tasks such as monitoring\nmechanical, electrical, and plumbing (MEP) systems. The present research\nevaluates the applicability of open-vocabulary vision-language models compared\nto fine-tuned, lightweight, closed-set object detectors for detecting MEP\ncomponents using a mobile ground robotic platform. A dataset collected with\ncameras mounted on a ground robot was manually annotated and analyzed to\ncompare model performance. The results demonstrate that, despite the\nversatility of vision-language models, fine-tuned lightweight models still\nlargely outperform them in specialized environments and for domain-specific\ntasks.\n","authors":["Abdalwhab Abdalwhab","Ali Imran","Sina Heydarian","Ivanka Iordanova","David St-Onge"],"pdf_url":"https://arxiv.org/pdf/2501.09267v1.pdf","comment":"4 pages, 3 figures"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2501.09862v1","updated":"2025-01-16T22:20:40Z","published":"2025-01-16T22:20:40Z","title":"A Tale of Two Models: Understanding Data Workers' Internal and External\n  Representations of Complex Data","summary":"  Data workers may have a a different mental model of their data that the one\nreified in code. Understanding the organization of their data is necessary for\nanalyzing data, be it through scripting, visualization or abstract thought.\nMore complicated organizations, such as tables with attached hierarchies, may\ntax people's ability to think about and interact with data. To better\nunderstand and ultimately design for these situations, we conduct a study\nacross a team of ten people work ing with the same reified data model. Through\ninterviews and sketching, we conduct a study across a team of ten people\nworking with the same reified data model. Through interviews and sketching, we\nprobed their conception of the data model and developed themes through\nreflexive data analysis. Participants had diverse data models that differed\nfrom the reified data model, even among team members who had designed the\nmodel, resulting in parallel hazards limiting their ability to reason about the\ndata. From these observations, we suggest potential design interventions for\ndata analysis processes and tools.\n","authors":["Connor Scully-Allison","Katy Williams","Stephanie Brink","Olga Pearce","Katherine E. Isaacs"],"pdf_url":"https://arxiv.org/pdf/2501.09862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09824v1","updated":"2025-01-16T20:23:20Z","published":"2025-01-16T20:23:20Z","title":"Improving Automated Feedback Systems for Tutor Training in Low-Resource\n  Scenarios through Data Augmentation","summary":"  Tutoring is an effective instructional method for enhancing student learning,\nyet its success relies on the skill and experience of the tutors. This reliance\npresents challenges for the widespread implementation of tutoring, particularly\nin training novice tutors. To support tutor training programs, real-time\nautomated feedback systems are essential for efficiently training large numbers\nof tutors. Lin et al.'s previous study employed Generative Pre-Trained\nTransformers (GPT) for sequence labeling to identify desirable and undesirable\npraise components in a tutor training dataset, providing explanatory feedback.\nHowever, this approach requires a significant amount of labeled data for\nfine-tuning, which is both labor-intensive and dependent on expert input. To\naddress the challenges associated with extensive data labeling, the current\nstudy explores the use of prompting more advanced GPT models like GPT-4o to\ngenerate synthetic datasets for augmenting labeled response data, followed by\nfine-tuning a GPT-3.5 model. Our results demonstrate that our data augmentation\napproach generalizes effectively to identify other types of praise, compared to\nthe same model fine-tuned without augmentation. These findings suggest that for\ndata-intensive tasks, synthetic data generated through GPT model prompting can\nsubstantially enhance fine-tuned model performance in low-resource scenarios.\n","authors":["Chentianye Xu","Jionghao Lin","Tongshuang Wu","Vincent Aleven","Kenneth R. Koedinger"],"pdf_url":"https://arxiv.org/pdf/2501.09824v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2501.09782v1","updated":"2025-01-16T18:59:46Z","published":"2025-01-16T18:59:46Z","title":"SMPLest-X: Ultimate Scaling for Expressive Human Pose and Shape\n  Estimation","summary":"  Expressive human pose and shape estimation (EHPS) unifies body, hands, and\nface motion capture with numerous applications. Despite encouraging progress,\ncurrent state-of-the-art methods focus on training innovative architectural\ndesigns on confined datasets. In this work, we investigate the impact of\nscaling up EHPS towards a family of generalist foundation models. 1) For data\nscaling, we perform a systematic investigation on 40 EHPS datasets,\nencompassing a wide range of scenarios that a model trained on any single\ndataset cannot handle. More importantly, capitalizing on insights obtained from\nthe extensive benchmarking process, we optimize our training scheme and select\ndatasets that lead to a significant leap in EHPS capabilities. Ultimately, we\nachieve diminishing returns at 10M training instances from diverse data\nsources. 2) For model scaling, we take advantage of vision transformers (up to\nViT-Huge as the backbone) to study the scaling law of model sizes in EHPS. To\nexclude the influence of algorithmic design, we base our experiments on two\nminimalist architectures: SMPLer-X, which consists of an intermediate step for\nhand and face localization, and SMPLest-X, an even simpler version that reduces\nthe network to its bare essentials and highlights significant advances in the\ncapture of articulated hands. With big data and the large model, the foundation\nmodels exhibit strong performance across diverse test benchmarks and excellent\ntransferability to even unseen environments. Moreover, our finetuning strategy\nturns the generalist into specialist models, allowing them to achieve further\nperformance boosts. Notably, our foundation models consistently deliver\nstate-of-the-art results on seven benchmarks such as AGORA, UBody, EgoBody, and\nour proposed SynHand dataset for comprehensive hand evaluation. (Code is\navailable at: https://github.com/wqyin/SMPLest-X).\n","authors":["Wanqi Yin","Zhongang Cai","Ruisi Wang","Ailing Zeng","Chen Wei","Qingping Sun","Haiyi Mei","Yanjun Wang","Hui En Pang","Mingyuan Zhang","Lei Zhang","Chen Change Loy","Atsushi Yamashita","Lei Yang","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2501.09782v1.pdf","comment":"An extension of SMPLer-X [arXiv:2309.17448]. Homepage:\n  https://caizhongang.com/projects/SMPLer-X/"},{"id":"http://arxiv.org/abs/2501.09751v1","updated":"2025-01-16T18:58:06Z","published":"2025-01-16T18:58:06Z","title":"OmniThink: Expanding Knowledge Boundaries in Machine Writing through\n  Thinking","summary":"  Machine writing with large language models often relies on\nretrieval-augmented generation. However, these approaches remain confined\nwithin the boundaries of the model's predefined scope, limiting the generation\nof content with rich information. Specifically, vanilla-retrieved information\ntends to lack depth, utility, and suffers from redundancy, which negatively\nimpacts the quality of generated articles, leading to shallow, repetitive, and\nunoriginal outputs. To address these issues, we propose OmniThink, a machine\nwriting framework that emulates the human-like process of iterative expansion\nand reflection. The core idea behind OmniThink is to simulate the cognitive\nbehavior of learners as they progressively deepen their knowledge of the\ntopics. Experimental results demonstrate that OmniThink improves the knowledge\ndensity of generated articles without compromising metrics such as coherence\nand depth. Human evaluations and expert feedback further highlight the\npotential of OmniThink to address real-world challenges in the generation of\nlong-form articles.\n","authors":["Zekun Xi","Wenbiao Yin","Jizhan Fang","Jialong Wu","Runnan Fang","Ningyu Zhang","Jiang Yong","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13036v2","updated":"2025-01-16T17:22:56Z","published":"2024-10-16T20:51:42Z","title":"Uncovering the Internet's Hidden Values: An Empirical Study of Desirable\n  Behavior Using Highly-Upvoted Content on Reddit","summary":"  A major task for moderators of online spaces is norm-setting, essentially\ncreating shared norms for user behavior in their communities. Platform design\nprinciples emphasize the importance of highlighting norm-adhering examples and\nexplicitly stating community norms. However, norms and values vary between\ncommunities and go beyond content-level attributes, making it challenging for\nplatforms and researchers to provide automated ways to identify desirable\nbehavior to be highlighted. Current automated approaches to detect desirability\nare limited to measures of prosocial behavior, but we do not know whether these\nmeasures fully capture the spectrum of what communities value. In this paper,\nwe use upvotes, which express community approval, as a proxy for desirability\nand examine 16,000 highly-upvoted comments across 80 popular sub-communities on\nReddit. Using a large language model, we extract values from these comments\nacross two years (2016 and 2022) and compile 64 and 72 $\\textit{macro}$,\n$\\textit{meso}$, and $\\textit{micro}$ values for 2016 and 2022 respectively,\nbased on their frequency across communities. Furthermore, we find that existing\ncomputational models for measuring prosociality were inadequate to capture on\naverage $82\\%$ of the values we extracted. Finally, we show that our approach\ncan not only extract most of the qualitatively-identified values from prior\ntaxonomies, but also uncover new values that are actually encouraged in\npractice. Our findings highlight the need for nuanced models of desirability\nthat go beyond preexisting prosocial measures. This work has implications for\nimproving moderator understanding of their community values and provides a\nframework that can supplement qualitative approaches with larger-scale content\nanalyses.\n","authors":["Agam Goyal","Charlotte Lambert","Yoshee Jain","Eshwar Chandrasekharan"],"pdf_url":"https://arxiv.org/pdf/2410.13036v2.pdf","comment":"Preprint: 14 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2501.09645v1","updated":"2025-01-16T16:37:33Z","published":"2025-01-16T16:37:33Z","title":"CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through\n  Category-Bounding","summary":"  In today's assistant landscape, personalisation enhances interactions,\nfosters long-term relationships, and deepens engagement. However, many systems\nstruggle with retaining user preferences, leading to repetitive user requests\nand disengagement. Furthermore, the unregulated and opaque extraction of user\npreferences in industry applications raises significant concerns about privacy\nand trust, especially in regions with stringent regulations like Europe. In\nresponse to these challenges, we propose a long-term memory system for voice\nassistants, structured around predefined categories. This approach leverages\nLarge Language Models to efficiently extract, store, and retrieve preferences\nwithin these categories, ensuring both personalisation and transparency. We\nalso introduce a synthetic multi-turn, multi-session conversation dataset\n(CarMem), grounded in real industry data, tailored to an in-car voice assistant\nsetting. Benchmarked on the dataset, our system achieves an F1-score of .78 to\n.95 in preference extraction, depending on category granularity. Our\nmaintenance strategy reduces redundant preferences by 95% and contradictory\nones by 92%, while the accuracy of optimal retrieval is at .87. Collectively,\nthe results demonstrate the system's suitability for industrial applications.\n","authors":["Johannes Kirmayr","Lukas Stappen","Phillip Schneider","Florian Matthes","Elisabeth André"],"pdf_url":"https://arxiv.org/pdf/2501.09645v1.pdf","comment":"Accepted for presentation at the International Conference on\n  Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2407.12105v3","updated":"2025-01-16T15:23:19Z","published":"2024-07-16T18:23:10Z","title":"AeroHaptix: A Wearable Vibrotactile Feedback System for Enhancing\n  Collision Avoidance in UAV Teleoperation","summary":"  Haptic feedback enhances collision avoidance by providing directional\nobstacle information to operators during unmanned aerial vehicle (UAV)\nteleoperation. However, such feedback is often rendered via haptic joysticks,\nwhich are unfamiliar to UAV operators and limited to single-direction force\nfeedback. Additionally, the direct coupling between the input device and the\nfeedback method diminishes operators' sense of control and induces oscillatory\nmovements. To overcome these limitations, we propose AeroHaptix, a wearable\nhaptic feedback system that uses spatial vibrations to simultaneously\ncommunicate multiple obstacle directions to operators, without interfering with\ntheir input control. The layout of vibrotactile actuators was optimized via a\nperceptual study to eliminate perceptual biases and achieve uniform spatial\ncoverage. A novel rendering algorithm, MultiCBF, extended control barrier\nfunctions to support multi-directional feedback. Our system evaluation showed\nthat compared to a no-feedback condition, AeroHaptix effectively reduced the\nnumber of collisions and input disagreement. Furthermore, operators reported\nthat AeroHaptix was more helpful than force feedback, with improved situational\nawareness and comparable workload.\n","authors":["Bingjian Huang","Zhecheng Wang","Qilong Cheng","Siyi Ren","Hanfeng Cai","Antonio Alvarez Valdivia","Karthik Mahadevan","Daniel Wigdor"],"pdf_url":"https://arxiv.org/pdf/2407.12105v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09530v1","updated":"2025-01-16T13:28:40Z","published":"2025-01-16T13:28:40Z","title":"Make yourself comfortable: Nudging urban heat and noise mitigation with\n  smartwatch-based Just-in-time Adaptive Interventions (JITAI)","summary":"  Humans can play a more active role in improving their comfort in the built\nenvironment if given the right information at the right place and time. This\npaper outlines the use of Just-in-Time Adaptive Interventions (JITAI)\nimplemented in the context of the built environment to provide information that\nhelps humans minimize the impact of heat and noise on their daily lives. This\nframework builds upon the open-source Cozie iOS smartwatch platform. It\nincludes data collection through micro-surveys and intervention messages\ntriggered by environmental, contextual, and personal history conditions. An\neight-month deployment of the method was completed in Singapore with 103\nparticipants who submitted over 12,000 micro-surveys and delivered over 3,600\nJITAI intervention messages. A weekly survey conducted during two deployment\nphases revealed an overall increase in perceived usefulness ranging from 8-19%\nover the first three weeks of data collection. For noise-related interventions,\nparticipants showed an overall increase in location changes ranging from 4-11%\nand a 2-17% increase in earphone use to mitigate noise distractions. For\nthermal comfort-related interventions, participants demonstrated a 3-13%\nincrease in adjustments to their location or thermostat to feel more\ncomfortable. The analysis found evidence that personality traits (such as\nconscientiousness), gender, and environmental preferences could be factors in\ndetermining the perceived helpfulness of JITAIs and influencing behavior\nchange. These findings underscore the importance of tailoring intervention\nstrategies to individual traits and environmental conditions, setting the stage\nfor future research to refine the delivery, timing, and content of intervention\nmessages.\n","authors":["Clayton Miller","Yun Xuan Chua","Matias Quintana","Binyu Lei","Filip Biljecki","Mario Frei"],"pdf_url":"https://arxiv.org/pdf/2501.09530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09521v1","updated":"2025-01-16T13:16:37Z","published":"2025-01-16T13:16:37Z","title":"Augmenting a Large Language Model with a Combination of Text and Visual\n  Data for Conversational Visualization of Global Geospatial Data","summary":"  We present a method for augmenting a Large Language Model (LLM) with a\ncombination of text and visual data to enable accurate question answering in\nvisualization of scientific data, making conversational visualization possible.\nLLMs struggle with tasks like visual data interaction, as they lack contextual\nvisual information. We address this problem by merging a text description of a\nvisualization and dataset with snapshots of the visualization. We extract their\nessential features into a structured text file, highly compact, yet descriptive\nenough to appropriately augment the LLM with contextual information, without\nany fine-tuning. This approach can be applied to any visualization that is\nalready finally rendered, as long as it is associated with some textual\ndescription.\n","authors":["Omar Mena","Alexandre Kouyoumdjian","Lonni Besançon","Michael Gleicher","Ivan Viola","Anders Ynnerman"],"pdf_url":"https://arxiv.org/pdf/2501.09521v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09457v1","updated":"2025-01-16T10:33:42Z","published":"2025-01-16T10:33:42Z","title":"\"A Great Start, But...\": Evaluating LLM-Generated Mind Maps for\n  Information Mapping in Video-Based Design","summary":"  Extracting concepts and understanding relationships from videos is essential\nin Video-Based Design (VBD), where videos serve as a primary medium for\nexploration but require significant effort in managing meta-information. Mind\nmaps, with their ability to visually organize complex data, offer a promising\napproach for structuring and analysing video content. Recent advancements in\nLarge Language Models (LLMs) provide new opportunities for meta-information\nprocessing and visual understanding in VBD, yet their application remains\nunderexplored. This study recruited 28 VBD practitioners to investigate the use\nof prompt-tuned LLMs for generating mind maps from ethnographic videos.\nComparing LLM-generated mind maps with those created by professional designers,\nwe evaluated rated scores, design effectiveness, and user experience across two\ncontexts. Findings reveal that LLMs effectively capture central concepts but\nstruggle with hierarchical organization and contextual grounding. We discuss\ntrust, customization, and workflow integration as key factors to guide future\nresearch on LLM-supported information mapping in VBD.\n","authors":["Tianhao He","Karthi Saravanan","Evangelos Niforatos","Gerd Kortuem"],"pdf_url":"https://arxiv.org/pdf/2501.09457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.20770v2","updated":"2025-01-16T10:24:32Z","published":"2024-12-30T07:41:01Z","title":"Humanoid Robot RHP Friends: Seamless Combination of Autonomous and\n  Teleoperated Tasks in a Nursing Context","summary":"  This paper describes RHP Friends, a social humanoid robot developed to enable\nassistive robotic deployments in human-coexisting environments. As a use-case\napplication, we present its potential use in nursing by extending its\ncapabilities to operate human devices and tools according to the task and by\nenabling remote assistance operations. To meet a wide variety of tasks and\nsituations in environments designed by and for humans, we developed a system\nthat seamlessly integrates the slim and lightweight robot and several\ntechnologies: locomanipulation, multi-contact motion, teleoperation, and object\ndetection and tracking. We demonstrated the system's usage in a nursing\napplication. The robot efficiently performed the daily task of patient transfer\nand a non-routine task, represented by a request to operate a circuit breaker.\nThis demonstration, held at the 2023 International Robot Exhibition (IREX),\nconducted three times a day over three days.\n","authors":["Mehdi Benallegue","Guillaume Lorthioir","Antonin Dallard","Rafael Cisneros-Limón","Iori Kumagai","Mitsuharu Morisawa","Hiroshi Kaminaga","Masaki Murooka","Antoine Andre","Pierre Gergondet","Kenji Kaneko","Guillaume Caron","Fumio Kanehiro","Abderrahmane Kheddar","Soh Yukizaki","Junichi Karasuyama","Junichi Murakami","Masayuki Kamon"],"pdf_url":"https://arxiv.org/pdf/2412.20770v2.pdf","comment":"IEEE Robotics and Automation Magazine, In press"},{"id":"http://arxiv.org/abs/2501.09442v1","updated":"2025-01-16T10:15:41Z","published":"2025-01-16T10:15:41Z","title":"Effects of Social Contextual Variation Using Partner Avatars on Memory\n  Acquisition and Retention","summary":"  This study investigates how partner avatar design affects learning and memory\nwhen an avatar serves as a lecturer. Based on earlier research on the\nenvironmental context dependency of memory, we hypothesize that the use of\ndiverse partner avatars results in a slower learning rate but better memory\nretention than that of a constant partner avatar. Accordingly, participants\nwere tasked with memorizing Tagalog--Japanese word pairs. On the first day of\nthe experiment, they repeatedly learned the pairs over six sessions from a\npartner avatar in an immersive virtual environment. One week later, on the\nsecond day of the experiment, they underwent a recall test in a real\nenvironment. We employed a between-participants design to compare the following\nconditions: the varied avatar condition, in which each repetition used a\ndifferent avatar, and the constant avatar condition, in which the same avatar\nwas used throughout the experiment. Results showed that, compared to the\nconstant avatar condition, the varied avatar condition resulted in\nsignificantly lower recall performance in the repeated learning trials\nconducted on the first day. However, the avatar conditions showed no\nsignificant differences in the final recall test on the second day. We discuss\nthese effects in relation to the social presence of the partner avatar. This\nstudy opens up a novel approach to optimizing the effectiveness of instructor\navatars in immersive virtual environments.\n","authors":["Takato Mizuho","Takuji Narumi","Hideaki Kuzuoka"],"pdf_url":"https://arxiv.org/pdf/2501.09442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02623v3","updated":"2025-01-16T08:18:01Z","published":"2024-11-04T21:31:04Z","title":"Learning to Assist Humans without Inferring Rewards","summary":"  Assistive agents should make humans' lives easier. Classically, such\nassistance is studied through the lens of inverse reinforcement learning, where\nan assistive agent (e.g., a chatbot, a robot) infers a human's intention and\nthen selects actions to help the human reach that goal. This approach requires\ninferring intentions, which can be difficult in high-dimensional settings. We\nbuild upon prior work that studies assistance through the lens of empowerment:\nan assistive agent aims to maximize the influence of the human's actions such\nthat they exert a greater control over the environmental outcomes and can solve\ntasks in fewer steps. We lift the major limitation of prior work in this\narea--scalability to high-dimensional settings--with contrastive successor\nrepresentations. We formally prove that these representations estimate a\nsimilar notion of empowerment to that studied by prior work and provide a\nready-made mechanism for optimizing it. Empirically, our proposed method\noutperforms prior methods on synthetic benchmarks, and scales to Overcooked, a\ncooperative game setting. Theoretically, our work connects ideas from\ninformation theory, neuroscience, and reinforcement learning, and charts a path\nfor representations to play a critical role in solving assistive problems.\n","authors":["Vivek Myers","Evan Ellis","Sergey Levine","Benjamin Eysenbach","Anca Dragan"],"pdf_url":"https://arxiv.org/pdf/2411.02623v3.pdf","comment":"Conference on Neural Information Processing Systems (NeurIPS), 2024"},{"id":"http://arxiv.org/abs/2501.09349v1","updated":"2025-01-16T08:03:32Z","published":"2025-01-16T08:03:32Z","title":"ChartInsighter: An Approach for Mitigating Hallucination in Time-series\n  Chart Summary Generation with A Benchmark Dataset","summary":"  Effective chart summary can significantly reduce the time and effort decision\nmakers spend interpreting charts, enabling precise and efficient communication\nof data insights. Previous studies have faced challenges in generating accurate\nand semantically rich summaries of time-series data charts. In this paper, we\nidentify summary elements and common hallucination types in the generation of\ntime-series chart summaries, which serve as our guidelines for automatic\ngeneration. We introduce ChartInsighter, which automatically generates chart\nsummaries of time-series data, effectively reducing hallucinations in chart\nsummary generation. Specifically, we assign multiple agents to generate the\ninitial chart summary and collaborate iteratively, during which they invoke\nexternal data analysis modules to extract insights and compile them into a\ncoherent summary. Additionally, we implement a self-consistency test method to\nvalidate and correct our summary. We create a high-quality benchmark of charts\nand summaries, with hallucination types annotated on a sentence-by-sentence\nbasis, facilitating the evaluation of the effectiveness of reducing\nhallucinations. Our evaluations using our benchmark show that our method\nsurpasses state-of-the-art models, and that our summary hallucination rate is\nthe lowest, which effectively reduces various hallucinations and improves\nsummary quality. The benchmark is available at\nhttps://github.com/wangfen01/ChartInsighter.\n","authors":["Fen Wang","Bomiao Wang","Xueli Shu","Zhen Liu","Zekai Shao","Chao Liu","Siming Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03337v4","updated":"2025-01-16T07:40:27Z","published":"2024-07-22T07:19:12Z","title":"PsyDI: Towards a Personalized and Progressively In-depth Chatbot for\n  Psychological Measurements","summary":"  In the field of psychology, traditional assessment methods, such as\nstandardized scales, are frequently critiqued for their static nature, lack of\npersonalization, and reduced participant engagement, while comprehensive\ncounseling evaluations are often inaccessible. The complexity of quantifying\npsychological traits further limits these methods. Despite advances with large\nlanguage models (LLMs), many still depend on single-round Question-and-Answer\ninteractions. To bridge this gap, we introduce PsyDI, a personalized and\nprogressively in-depth chatbot designed for psychological measurements,\nexemplified by its application in the Myers-Briggs Type Indicator (MBTI)\nframework. PsyDI leverages user-related multi-modal information and engages in\ncustomized, multi-turn interactions to provide personalized, easily accessible\nmeasurements, while ensuring precise MBTI type determination. To address the\nchallenge of unquantifiable psychological traits, we introduce a novel training\nparadigm that involves learning the ranking of proxy variables associated with\nthese traits, culminating in a robust score model for MBTI measurements. The\nscore model enables PsyDI to conduct comprehensive and precise measurements\nthrough multi-turn interactions within a unified estimation context. Through\nvarious experiments, we validate the efficacy of both the score model and the\nPsyDI pipeline, demonstrating its potential to serve as a general framework for\npsychological measurements. Furthermore, the online deployment of PsyDI has\ngarnered substantial user engagement, with over 3,000 visits, resulting in the\ncollection of numerous multi-turn dialogues annotated with MBTI types, which\nfacilitates further research. The source code for the training and web service\ncomponents is publicly available as a part of OpenDILab at:\nhttps://github.com/opendilab/PsyDI\n","authors":["Xueyan Li","Xinyan Chen","Yazhe Niu","Shuai Hu","Yu Liu"],"pdf_url":"https://arxiv.org/pdf/2408.03337v4.pdf","comment":"29 pages, 15 figures"},{"id":"http://arxiv.org/abs/2412.15701v2","updated":"2025-01-16T07:01:37Z","published":"2024-12-20T09:21:15Z","title":"Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent\n  Collaboration","summary":"  Recent advancements in language models (LMs) have sparked growing interest in\ndeveloping LM agents. While fully autonomous agents could excel in many\nscenarios, numerous use cases inherently require them to collaborate with\nhumans due to humans' latent preferences, domain expertise, or need for\ncontrol. To facilitate the study of human-agent collaboration, we present\nCollaborative Gym (Co-Gym), a general framework enabling asynchronous,\ntripartite interaction among agents, humans, and task environments. We\ninstantiate Co-Gym with three representative tasks in both simulated and\nreal-world conditions, and propose an evaluation framework that assesses both\nthe collaboration outcomes and processes. Our findings reveal that\ncollaborative agents consistently outperform their fully autonomous\ncounterparts in task performance within those delivered cases, achieving win\nrates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related\nWork when evaluated by real users. However, our study also highlights\nsignificant challenges in developing collaborative agents, requiring\nadvancements in core aspects of intelligence -- communication capabilities,\nsituational awareness, and balancing autonomy and human control.\n","authors":["Yijia Shao","Vinay Samuel","Yucheng Jiang","John Yang","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2412.15701v2.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2304.06872v2","updated":"2025-01-16T05:46:02Z","published":"2023-04-14T00:26:34Z","title":"Submerse: Visualizing Storm Surge Flooding Simulations in Immersive\n  Display Ecologies","summary":"  We present Submerse, an end-to-end framework for visualizing flooding\nscenarios on large and immersive display ecologies. Specifically, we\nreconstruct a surface mesh from input flood simulation data and generate a\nto-scale 3D virtual scene by incorporating geographical data such as terrain,\ntextures, buildings, and additional scene objects. To optimize computation and\nmemory performance for large simulation datasets, we discretize the data on an\nadaptive grid using dynamic quadtrees and support level-of-detail based\nrendering. Moreover, to provide a perception of flooding direction for a time\ninstance, we animate the surface mesh by synthesizing water waves. As\ninteraction is key for effective decision-making and analysis, we introduce two\nnovel techniques for flood visualization in immersive systems: (1) an automatic\nscene-navigation method using optimal camera viewpoints generated for marked\npoints-of-interest based on the display layout, and (2) an AR-based\nfocus+context technique using an auxiliary display system. Submerse is\ndeveloped in collaboration between computer scientists and atmospheric\nscientists. We evaluate the effectiveness of our system and application by\nconducting workshops with emergency managers, domain experts, and concerned\nstakeholders in the Stony Brook Reality Deck, an immersive gigapixel facility,\nto visualize a superstorm flooding scenario in New York City.\n","authors":["Saeed Boorboor","Yoonsang Kim","Ping Hu","Josef M. Moses","Brian A. Colle","Arie E. Kaufman"],"pdf_url":"https://arxiv.org/pdf/2304.06872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09302v1","updated":"2025-01-16T05:37:29Z","published":"2025-01-16T05:37:29Z","title":"Creating Virtual Environments with 3D Gaussian Splatting: A Comparative\n  Study","summary":"  3D Gaussian Splatting (3DGS) has recently emerged as an innovative and\nefficient 3D representation technique. While its potential for extended reality\n(XR) applications is frequently highlighted, its practical effectiveness\nremains underexplored. In this work, we examine three distinct 3DGS-based\napproaches for virtual environment (VE) creation, leveraging their unique\nstrengths for efficient and visually compelling scene representation. By\nconducting a comparable study, we evaluate the feasibility of 3DGS in creating\nimmersive VEs, identify its limitations in XR applications, and discuss future\nresearch and development opportunities.\n","authors":["Shi Qiu","Binzhu Xie","Qixuan Liu","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2501.09302v1.pdf","comment":"IEEE VR 2025 Posters"},{"id":"http://arxiv.org/abs/2303.13397v6","updated":"2025-01-16T02:48:38Z","published":"2023-03-23T16:15:18Z","title":"DiffMesh: A Motion-aware Diffusion Framework for Human Mesh Recovery\n  from Videos","summary":"  Human mesh recovery (HMR) provides rich human body information for various\nreal-world applications. While image-based HMR methods have achieved impressive\nresults, they often struggle to recover humans in dynamic scenarios, leading to\ntemporal inconsistencies and non-smooth 3D motion predictions due to the\nabsence of human motion. In contrast, video-based approaches leverage temporal\ninformation to mitigate this issue. In this paper, we present DiffMesh, an\ninnovative motion-aware Diffusion-like framework for video-based HMR. DiffMesh\nestablishes a bridge between diffusion models and human motion, efficiently\ngenerating accurate and smooth output mesh sequences by incorporating human\nmotion within the forward process and reverse process in the diffusion model.\nExtensive experiments are conducted on the widely used datasets (Human3.6M\n\\cite{h36m_pami} and 3DPW \\cite{pw3d2018}), which demonstrate the effectiveness\nand efficiency of our DiffMesh. Visual comparisons in real-world scenarios\nfurther highlight DiffMesh's suitability for practical applications.\n","authors":["Ce Zheng","Xianpeng Liu","Qucheng Peng","Tianfu Wu","Pu Wang","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2303.13397v6.pdf","comment":"WACV 2025"},{"id":"http://arxiv.org/abs/2501.08736v2","updated":"2025-01-16T02:24:48Z","published":"2025-01-15T11:29:26Z","title":"Holoview: Interactive 3D visualization of medical data in AR","summary":"  We introduce HoloView, an innovative augmented reality (AR) system that\nenhances interactive learning of human anatomical structures through immersive\nvisualization. Combining advanced rendering techniques with intuitive\ngesture-based interactions, HoloView provides a comprehensive technical\nsolution for medical education. The system architecture features a distributed\nrendering pipeline that offloads stereoscopic computations to a remote server,\noptimizing performance and enabling high-quality visualization on less powerful\ndevices. To prioritize visual quality in the user's direct line of sight while\nreducing computational load, we implement foveated rendering optimization,\nenhancing the immersive experience. Additionally, a hybrid surface-volume\nrendering technique is used to achieve faster rendering speeds without\nsacrificing visual fidelity. Complemented by a carefully designed user\ninterface and gesture-based interaction system, HoloView allows users to\nnaturally manipulate holographic content and seamlessly navigate the learning\nenvironment. HoloView significantly facilitates anatomical structure\nvisualization and promotes an engaging, user-centric learning experience.\n","authors":["Pankaj Kaushik","Anshul Goswami","Ojaswa Sharma"],"pdf_url":"https://arxiv.org/pdf/2501.08736v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.00689v4","updated":"2025-01-16T02:12:45Z","published":"2023-11-01T17:45:22Z","title":"Collaboration in Immersive Environments: Challenges and Solutions","summary":"  Virtual Reality (VR) and Augmented Reality (AR) tools have been applied in\nall engineering fields in order to avoid the use of physical prototypes, to\ntrain in high-risk situations, and to interpret real or simulated results. In\norder to complete a shared task or assign tasks to the agents in such immersive\nenvironments, collaboration or Shared Cooperative Activities are a necessity.\nCollaboration in immersive environments is an emerging field of research that\naims to study and enhance the ways in which people interact and work together\nin Virtual and Augmented Reality settings. Collaboration in immersive\nenvironments is a complex process that involves different factors such as\ncommunication, coordination, and social presence. This paper provides an\noverview of the current state of research on collaboration in immersive\nenvironments. It discusses the different types of immersive environments,\nincluding VR and AR, and the different forms of collaboration that can occur in\nthese environments. The paper also highlights the challenges and limitations of\ncollaboration in immersive environments, such as the lack of physical cues,\ncost and usability and the need for further research in this area. Overall,\ncollaboration in immersive environments is a promising field with a wide range\nof potential applications, from education to industry, and it can benefit both\nindividuals and groups by enhancing their ability to work together effectively.\n","authors":["Shahin Doroudian"],"pdf_url":"https://arxiv.org/pdf/2311.00689v4.pdf","comment":"Added new references in Networking section"},{"id":"http://arxiv.org/abs/2501.09235v1","updated":"2025-01-16T01:40:55Z","published":"2025-01-16T01:40:55Z","title":"The Spread of Virtual Gifting in Live Streaming: The Case of Twitch","summary":"  This paper examines how gifting spreads among viewers on Twitch, one of the\nlargest live streaming platforms worldwide. Twitch users can give gift\nsubscriptions to other viewers in the chat room, with the majority of gifters\nopting for community gifting, which is gifting to randomly selected viewers. We\nidentify the random nature of gift-receiving in our data as a natural\nexperiment setting. We investigate whether gift recipients pay it forward,\nconsidering various gift types that may either promote or deter the spread of\ngifting. Our findings reveal that Twitch viewers who receive gift subscriptions\nare generally more likely to pay it forward than non-recipients, and the\npositive impact of gift-receiving becomes stronger when the recipient is the\nsole beneficiary of the giver's gifting behavior. However, we found that gifts\nfrom frequent gifters discourage recipients from paying it forward, and gifts\nfrom anonymous gifters do not influence the likelihood of viewers becoming\nfuture gifters. This research contributes to the existing literature on the\nspread of online prosocial behavior by providing robust evidence and suggests\npractical strategies for promoting online gifting.\n","authors":["Ji Eun Kim","Seura Ha","Sangmi Kim","Libby Hemphill"],"pdf_url":"https://arxiv.org/pdf/2501.09235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09210v1","updated":"2025-01-16T00:05:20Z","published":"2025-01-16T00:05:20Z","title":"Personalized Parsons Puzzles as Scaffolding Enhance Practice Engagement\n  Over Just Showing LLM-Powered Solutions","summary":"  As generative AI products could generate code and assist students with\nprogramming learning seamlessly, integrating AI into programming education\ncontexts has driven much attention. However, one emerging concern is that\nstudents might get answers without learning from the LLM-generated content. In\nthis work, we deployed the LLM-powered personalized Parsons puzzles as\nscaffolding to write-code practice in a Python learning classroom (PC\ncondition) and conducted an 80-minute randomized between-subjects study. Both\nconditions received the same practice problems. The only difference was that\nwhen requesting help, the control condition showed students a complete solution\n(CC condition), simulating the most traditional LLM output. Results indicated\nthat students who received personalized Parsons puzzles as scaffolding engaged\nin practicing significantly longer than those who received complete solutions\nwhen struggling.\n","authors":["Xinying Hou","Zihan Wu","Xu Wang","Barbara J. Ericson"],"pdf_url":"https://arxiv.org/pdf/2501.09210v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2409.15922v4","updated":"2025-01-16T23:59:18Z","published":"2024-09-24T09:45:20Z","title":"The Dark Side of Rich Rewards: Understanding and Mitigating Noise in VLM\n  Rewards","summary":"  While Vision-Language Models (VLMs) are increasingly used to generate reward\nsignals for training embodied agents to follow instructions, our research\nreveals that agents guided by VLM rewards often underperform compared to those\nemploying only intrinsic (exploration-driven) rewards, contradicting\nexpectations set by recent work. We hypothesize that false positive rewards --\ninstances where unintended trajectories are incorrectly rewarded -- are more\ndetrimental than false negatives. Our analysis confirms this hypothesis,\nrevealing that the widely used cosine similarity metric is prone to false\npositive reward estimates. To address this, we introduce BiMI ({Bi}nary\n{M}utual {I}nformation), a novel reward function designed to mitigate noise.\nBiMI significantly enhances learning efficiency across diverse and challenging\nembodied navigation environments. Our findings offer a nuanced understanding of\nhow different types of reward noise impact agent learning and highlight the\nimportance of addressing multimodal reward signal noise when training embodied\nagents\n","authors":["Sukai Huang","Shu-Wei Liu","Nir Lipovetzky","Trevor Cohn"],"pdf_url":"https://arxiv.org/pdf/2409.15922v4.pdf","comment":"11 main body pages, 21 appendix pages"},{"id":"http://arxiv.org/abs/2411.01332v2","updated":"2025-01-16T23:37:24Z","published":"2024-11-02T18:30:32Z","title":"A Mechanistic Explanatory Strategy for XAI","summary":"  Despite significant advancements in XAI, scholars note a persistent lack of\nsolid conceptual foundations and integration with broader scientific discourse\non explanation. In response, emerging XAI research draws on explanatory\nstrategies from various sciences and philosophy of science literature to fill\nthese gaps. This paper outlines a mechanistic strategy for explaining the\nfunctional organization of deep learning systems, situating recent advancements\nin AI explainability within a broader philosophical context. According to the\nmechanistic approach, the explanation of opaque AI systems involves identifying\nmechanisms that drive decision-making. For deep neural networks, this means\ndiscerning functionally relevant components -- such as neurons, layers,\ncircuits, or activation patterns -- and understanding their roles through\ndecomposition, localization, and recomposition. Proof-of-principle case studies\nfrom image recognition and language modeling align these theoretical approaches\nwith the latest research from AI labs like OpenAI and Anthropic. This research\nsuggests that a systematic approach to studying model organization can reveal\nelements that simpler (or ''more modest'') explainability techniques might\nmiss, fostering more thoroughly explainable AI. The paper concludes with a\ndiscussion on the epistemic relevance of the mechanistic approach positioned in\nthe context of selected philosophical debates on XAI.\n","authors":["Marcin Rabiza"],"pdf_url":"https://arxiv.org/pdf/2411.01332v2.pdf","comment":"Forthcoming in M\\\"uller, V. C., Dewey, A. R., Dung, L., & L\\\"ohr, G.\n  (Eds.), Philosophy of Artificial Intelligence: The State of the Art, Synthese\n  Library, Berlin: Springer Nature. Please cite the published version"},{"id":"http://arxiv.org/abs/2501.09877v1","updated":"2025-01-16T23:22:17Z","published":"2025-01-16T23:22:17Z","title":"CLAP-S: Support Set Based Adaptation for Downstream Fiber-optic Acoustic\n  Recognition","summary":"  Contrastive Language-Audio Pretraining (CLAP) models have demonstrated\nunprecedented performance in various acoustic signal recognition tasks.\nFiber-optic-based acoustic recognition is one of the most important downstream\ntasks and plays a significant role in environmental sensing. Adapting CLAP for\nfiber-optic acoustic recognition has become an active research area. As a\nnon-conventional acoustic sensor, fiber-optic acoustic recognition presents a\nchallenging, domain-specific, low-shot deployment environment with significant\ndomain shifts due to unique frequency response and noise characteristics. To\naddress these challenges, we propose a support-based adaptation method, CLAP-S,\nwhich linearly interpolates a CLAP Adapter with the Support Set, leveraging\nboth implicit knowledge through fine-tuning and explicit knowledge retrieved\nfrom memory for cross-domain generalization. Experimental results show that our\nmethod delivers competitive performance on both laboratory-recorded fiber-optic\nESC-50 datasets and a real-world fiber-optic gunshot-firework dataset. Our\nresearch also provides valuable insights for other downstream acoustic\nrecognition tasks. The code and gunshot-firework dataset are available at\nhttps://github.com/Jingchensun/clap-s.\n","authors":["Jingchen Sun","Shaobo Han","Wataru Kohno","Changyou Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09877v1.pdf","comment":"Accepted to ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.09876v1","updated":"2025-01-16T23:14:34Z","published":"2025-01-16T23:14:34Z","title":"Geometry-Preserving Encoder/Decoder in Latent Generative Models","summary":"  Generative modeling aims to generate new data samples that resemble a given\ndataset, with diffusion models recently becoming the most popular generative\nmodel. One of the main challenges of diffusion models is solving the problem in\nthe input space, which tends to be very high-dimensional. Recently, solving\ndiffusion models in the latent space through an encoder that maps from the data\nspace to a lower-dimensional latent space has been considered to make the\ntraining process more efficient and has shown state-of-the-art results. The\nvariational autoencoder (VAE) is the most commonly used encoder/decoder\nframework in this domain, known for its ability to learn latent representations\nand generate data samples. In this paper, we introduce a novel encoder/decoder\nframework with theoretical properties distinct from those of the VAE,\nspecifically designed to preserve the geometric structure of the data\ndistribution. We demonstrate the significant advantages of this\ngeometry-preserving encoder in the training process of both the encoder and\ndecoder. Additionally, we provide theoretical results proving convergence of\nthe training process, including convergence guarantees for encoder training,\nand results showing faster convergence of decoder training when using the\ngeometry-preserving encoder.\n","authors":["Wonjun Lee","Riley C. W. O'Neill","Dongmian Zou","Jeff Calder","Gilad Lerman"],"pdf_url":"https://arxiv.org/pdf/2501.09876v1.pdf","comment":"41 pages"},{"id":"http://arxiv.org/abs/2501.09870v1","updated":"2025-01-16T22:54:12Z","published":"2025-01-16T22:54:12Z","title":"An LLM-Guided Tutoring System for Social Skills Training","summary":"  Social skills training targets behaviors necessary for success in social\ninteractions. However, traditional classroom training for such skills is often\ninsufficient to teach effective communication -- one-to-one interaction in\nreal-world scenarios is preferred to lecture-style information delivery. This\npaper introduces a framework that allows instructors to collaborate with large\nlanguage models to dynamically design realistic scenarios for students to\ncommunicate. Our framework uses these scenarios to enable student rehearsal,\nprovide immediate feedback, and visualize performance for both students and\ninstructors. Unlike traditional intelligent tutoring systems, instructors can\neasily co-create scenarios with a large language model without technical\nskills. Additionally, the system generates new scenario branches in real time\nwhen existing options do not fit the student's response.\n","authors":["Michael Guevarra","Indronil Bhattacharjee","Srijita Das","Christabel Wayllace","Carrie Demmans Epp","Matthew E. Taylor","Alan Tay"],"pdf_url":"https://arxiv.org/pdf/2501.09870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02988v2","updated":"2025-01-16T22:16:11Z","published":"2024-12-04T03:02:55Z","title":"Preference-based Pure Exploration","summary":"  We study the preference-based pure exploration problem for bandits with\nvector-valued rewards. The rewards are ordered using a (given) preference cone\n$\\mathcal{C}$ and our goal is to identify the set of Pareto optimal arms.\nFirst, to quantify the impact of preferences, we derive a novel lower bound on\nsample complexity for identifying the most preferred policy with a confidence\nlevel $1-\\delta$. Our lower bound elicits the role played by the geometry of\nthe preference cone and punctuates the difference in hardness compared to\nexisting best-arm identification variants of the problem. We further explicate\nthis geometry when the rewards follow Gaussian distributions. We then provide a\nconvex relaxation of the lower bound and leverage it to design the\nPreference-based Track and Stop (PreTS) algorithm that identifies the most\npreferred policy. Finally, we show that the sample complexity of PreTS is\nasymptotically tight by deriving a new concentration inequality for\nvector-valued rewards.\n","authors":["Apurv Shukla","Debabrota Basu"],"pdf_url":"https://arxiv.org/pdf/2412.02988v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09858v1","updated":"2025-01-16T22:11:03Z","published":"2025-01-16T22:11:03Z","title":"From Explainability to Interpretability: Interpretable Policies in\n  Reinforcement Learning Via Model Explanation","summary":"  Deep reinforcement learning (RL) has shown remarkable success in complex\ndomains, however, the inherent black box nature of deep neural network policies\nraises significant challenges in understanding and trusting the decision-making\nprocesses. While existing explainable RL methods provide local insights, they\nfail to deliver a global understanding of the model, particularly in\nhigh-stakes applications. To overcome this limitation, we propose a novel\nmodel-agnostic approach that bridges the gap between explainability and\ninterpretability by leveraging Shapley values to transform complex deep RL\npolicies into transparent representations. The proposed approach offers two key\ncontributions: a novel approach employing Shapley values to policy\ninterpretation beyond local explanations and a general framework applicable to\noff-policy and on-policy algorithms. We evaluate our approach with three\nexisting deep RL algorithms and validate its performance in two classic control\nenvironments. The results demonstrate that our approach not only preserves the\noriginal models' performance but also generates more stable interpretable\npolicies.\n","authors":["Peilang Li","Umer Siddique","Yongcan Cao"],"pdf_url":"https://arxiv.org/pdf/2501.09858v1.pdf","comment":"Accepted to Deployable AI (DAI) Workshop at the Thirty-Ninth AAAI\n  Conference on Artificial Intelligence (AAAI-25)"},{"id":"http://arxiv.org/abs/2501.09851v1","updated":"2025-01-16T21:46:53Z","published":"2025-01-16T21:46:53Z","title":"Learning Noisy Halfspaces with a Margin: Massart is No Harder than\n  Random","summary":"  We study the problem of PAC learning $\\gamma$-margin halfspaces with Massart\nnoise. We propose a simple proper learning algorithm, the Perspectron, that has\nsample complexity $\\widetilde{O}((\\epsilon\\gamma)^{-2})$ and achieves\nclassification error at most $\\eta+\\epsilon$ where $\\eta$ is the Massart noise\nrate. Prior works [DGT19,CKMY20] came with worse sample complexity guarantees\n(in both $\\epsilon$ and $\\gamma$) or could only handle random classification\nnoise [DDK+23,KIT+23] -- a much milder noise assumption. We also show that our\nresults extend to the more challenging setting of learning generalized linear\nmodels with a known link function under Massart noise, achieving a similar\nsample complexity to the halfspace case. This significantly improves upon the\nprior state-of-the-art in this setting due to [CKMY20], who introduced this\nmodel.\n","authors":["Gautam Chandrasekaran","Vasilis Kontonis","Konstantinos Stavropoulos","Kevin Tian"],"pdf_url":"https://arxiv.org/pdf/2501.09851v1.pdf","comment":"Appeared in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2501.09849v1","updated":"2025-01-16T21:33:47Z","published":"2025-01-16T21:33:47Z","title":"Coded Deep Learning: Framework and Algorithm","summary":"  The success of deep learning (DL) is often achieved with large models and\nhigh complexity during both training and post-training inferences, hindering\ntraining in resource-limited settings. To alleviate these issues, this paper\nintroduces a new framework dubbed ``coded deep learning'' (CDL), which\nintegrates information-theoretic coding concepts into the inner workings of DL,\nto significantly compress model weights and activations, reduce computational\ncomplexity at both training and post-training inference stages, and enable\nefficient model/data parallelism. Specifically, within CDL, (i) we first\npropose a novel probabilistic method for quantizing both model weights and\nactivations, and its soft differentiable variant which offers an analytic\nformula for gradient calculation during training; (ii) both the forward and\nbackward passes during training are executed over quantized weights and\nactivations, eliminating most floating-point operations and reducing training\ncomplexity; (iii) during training, both weights and activations are entropy\nconstrained so that they are compressible in an information-theoretic sense\nthroughout training, thus reducing communication costs in model/data\nparallelism; and (iv) the trained model in CDL is by default in a quantized\nformat with compressible quantized weights, reducing post-training inference\nand storage complexity. Additionally, a variant of CDL, namely relaxed CDL\n(R-CDL), is presented to further improve the trade-off between validation\naccuracy and compression though requiring full precision in training with other\nadvantageous features of CDL intact. Extensive empirical results show that CDL\nand R-CDL outperform the state-of-the-art algorithms in DNN compression in the\nliterature.\n","authors":["En-hui Yang","Shayan Mohajer Hamidi"],"pdf_url":"https://arxiv.org/pdf/2501.09849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.07914v2","updated":"2025-01-16T21:18:48Z","published":"2021-01-20T00:46:52Z","title":"Intelligent Icing Detection Model of Wind Turbine Blades Based on SCADA\n  data","summary":"  Diagnosis of ice accretion on wind turbine blades is all the time a hard nut\nto crack in condition monitoring of wind farms. Existing methods focus on\nmechanism analysis of icing process, deviation degree analysis of feature\nengineering. However, there have not been deep researches of neural networks\napplied in this field at present. Supervisory control and data acquisition\n(SCADA) makes it possible to train networks through continuously providing not\nonly operation parameters and performance parameters of wind turbines but also\nenvironmental parameters and operation modes. This paper explores the\npossibility that using convolutional neural networks (CNNs), generative\nadversarial networks (GANs) and domain adaption learning to establish\nintelligent diagnosis frameworks under different training scenarios.\nSpecifically, PGANC and PGANT are proposed for sufficient and non-sufficient\ntarget wind turbine labeled data, respectively. The basic idea is that we\nconsider a two-stage training with parallel GANs, which are aimed at capturing\nintrinsic features for normal and icing samples, followed by classification CNN\nor domain adaption module in various training cases. Model validation on three\nwind turbine SCADA data shows that two-stage training can effectively improve\nthe model performance. Besides, if there is no sufficient labeled data for a\ntarget turbine, which is an extremely common phenomenon in real industrial\npractices, the addition of domain adaption learning makes the trained model\nshow better performance. Overall, our proposed intelligent diagnosis frameworks\ncan achieve more accurate detection on the same wind turbine and more\ngeneralized capability on a new wind turbine, compared with other machine\nlearning models and conventional CNNs.\n","authors":["Wenqian Jiang","Junyang Jin"],"pdf_url":"https://arxiv.org/pdf/2101.07914v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.07271v2","updated":"2025-01-16T21:09:57Z","published":"2024-11-10T16:28:42Z","title":"Multi-hop Upstream Anticipatory Traffic Signal Control with Deep\n  Reinforcement Learning","summary":"  Coordination in traffic signal control is crucial for managing congestion in\nurban networks. Existing pressure-based control methods focus only on immediate\nupstream links, leading to suboptimal green time allocation and increased\nnetwork delays. However, effective signal control inherently requires\ncoordination across a broader spatial scope, as the effect of upstream traffic\nshould influence signal control decisions at downstream intersections,\nimpacting a large area in the traffic network. Although agent communication\nusing neural network-based feature extraction can implicitly enhance spatial\nawareness, it significantly increases the learning complexity, adding an\nadditional layer of difficulty to the challenging task of control in deep\nreinforcement learning. To address the issue of learning complexity and myopic\ntraffic pressure definition, our work introduces a novel concept based on\nMarkov chain theory, namely \\textit{multi-hop upstream pressure}, which\ngeneralizes the conventional pressure to account for traffic conditions beyond\nthe immediate upstream links. This farsighted and compact metric informs the\ndeep reinforcement learning agent to preemptively clear the multi-hop upstream\nqueues, guiding the agent to optimize signal timings with a broader spatial\nawareness. Simulations on synthetic and realistic (Toronto) scenarios\ndemonstrate controllers utilizing multi-hop upstream pressure significantly\nreduce overall network delay by prioritizing traffic movements based on a\nbroader understanding of upstream congestion.\n","authors":["Xiaocan Li","Xiaoyu Wang","Ilia Smirnov","Scott Sanner","Baher Abdulhai"],"pdf_url":"https://arxiv.org/pdf/2411.07271v2.pdf","comment":"5 tables, 11 figures"},{"id":"http://arxiv.org/abs/2501.06164v2","updated":"2025-01-16T21:07:04Z","published":"2025-01-10T18:39:29Z","title":"Model Alignment Search","summary":"  When can we say that two neural systems are the same? The answer to this\nquestion is goal-dependent, and it is often addressed through correlative\nmethods such as Representational Similarity Analysis (RSA) and Centered Kernel\nAlignment (CKA). What do we miss when we forgo causal explorations, and how can\nwe target specific types of similarity? In this work, we introduce Model\nAlignment Search (MAS), a method for causally exploring distributed\nrepresentational similarity. The method learns invertible linear\ntransformations that align a subspace between two distributed networks'\nrepresentations where causal information can be freely interchanged. We first\nshow that the method can be used to transfer specific causal variables, such as\nthe number of items in a counting task, between networks with different\ntraining seeds. We then explore open questions in number cognition by comparing\ndifferent types of numeric representations in models trained on structurally\ndifferent numeric tasks. We then explore differences between MAS vs preexisting\ncausal similarity methods, and lastly, we introduce a counterfactual latent\nauxiliary loss function that helps shape causally relevant alignments even in\ncases where we do not have causal access to one of the two models for training.\n","authors":["Satchel Grant"],"pdf_url":"https://arxiv.org/pdf/2501.06164v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09822v1","updated":"2025-01-16T20:16:49Z","published":"2025-01-16T20:16:49Z","title":"pFedWN: A Personalized Federated Learning Framework for D2D Wireless\n  Networks with Heterogeneous Data","summary":"  Traditional Federated Learning (FL) approaches often struggle with data\nheterogeneity across clients, leading to suboptimal model performance for\nindividual clients. To address this issue, Personalized Federated Learning\n(PFL) emerges as a solution to the challenges posed by non-independent and\nidentically distributed (non-IID) and unbalanced data across clients.\nFurthermore, in most existing decentralized machine learning works, a perfect\ncommunication channel is considered for model parameter transmission between\nclients and servers. However, decentralized PFL over wireless links introduces\nnew challenges, such as resource allocation and interference management. To\novercome these challenges, we formulate a joint optimization problem that\nincorporates the underlying device-to-device (D2D) wireless channel conditions\ninto a server-free PFL approach. The proposed method, dubbed pFedWN, optimizes\nthe learning performance for each client while accounting for the variability\nin D2D wireless channels. To tackle the formulated problem, we divide it into\ntwo sub-problems: PFL neighbor selection and PFL weight assignment. The PFL\nneighbor selection is addressed through channel-aware neighbor selection within\nunlicensed spectrum bands such as ISM bands. Next, to assign PFL weights, we\nutilize the Expectation-Maximization (EM) method to evaluate the similarity\nbetween clients' data and obtain optimal weight distribution among the chosen\nPFL neighbors. Empirical results show that pFedWN provides efficient and\npersonalized learning performance with non-IID and unbalanced datasets.\nFurthermore, it outperforms the existing FL and PFL methods in terms of\nlearning efficacy and robustness, particularly under dynamic and unpredictable\nwireless channel conditions.\n","authors":["Zhou Ni","Masoud Ghazikor","Morteza Hashemi"],"pdf_url":"https://arxiv.org/pdf/2501.09822v1.pdf","comment":"16 pages, 9 figures, 3 tables, submitted to Transactions on\n  Networking"},{"id":"http://arxiv.org/abs/2501.09821v1","updated":"2025-01-16T20:15:12Z","published":"2025-01-16T20:15:12Z","title":"BN-Pool: a Bayesian Nonparametric Approach to Graph Pooling","summary":"  We introduce BN-Pool, the first clustering-based pooling method for Graph\nNeural Networks (GNNs) that adaptively determines the number of supernodes in a\ncoarsened graph. By leveraging a Bayesian non-parametric framework, BN-Pool\nemploys a generative model capable of partitioning graph nodes into an\nunbounded number of clusters. During training, we learn the node-to-cluster\nassignments by combining the supervised loss of the downstream task with an\nunsupervised auxiliary term, which encourages the reconstruction of the\noriginal graph topology while penalizing unnecessary proliferation of clusters.\nThis adaptive strategy allows BN-Pool to automatically discover an optimal\ncoarsening level, offering enhanced flexibility and removing the need to\nspecify sensitive pooling ratios. We show that BN-Pool achieves superior\nperformance across diverse benchmarks.\n","authors":["Daniele Castellana","Filippo Maria Bianchi"],"pdf_url":"https://arxiv.org/pdf/2501.09821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11335v3","updated":"2025-01-16T19:43:21Z","published":"2023-10-17T15:13:33Z","title":"Reinforcement learning with non-ergodic reward increments: robustness\n  via ergodicity transformations","summary":"  Envisioned application areas for reinforcement learning (RL) include\nautonomous driving, precision agriculture, and finance, which all require RL\nagents to make decisions in the real world. A significant challenge hindering\nthe adoption of RL methods in these domains is the non-robustness of\nconventional algorithms. In particular, the focus of RL is typically on the\nexpected value of the return. The expected value is the average over the\nstatistical ensemble of infinitely many trajectories, which can be\nuninformative about the performance of the average individual. For instance,\nwhen we have a heavy-tailed return distribution, the ensemble average can be\ndominated by rare extreme events. Consequently, optimizing the expected value\ncan lead to policies that yield exceptionally high returns with a probability\nthat approaches zero but almost surely result in catastrophic outcomes in\nsingle long trajectories. In this paper, we develop an algorithm that lets RL\nagents optimize the long-term performance of individual trajectories. The\nalgorithm enables the agents to learn robust policies, which we show in an\ninstructive example with a heavy-tailed return distribution and standard RL\nbenchmarks. The key element of the algorithm is a transformation that we learn\nfrom data. This transformation turns the time series of collected returns into\none for whose increments expected value and the average over a long trajectory\ncoincide. Optimizing these increments results in robust policies.\n","authors":["Dominik Baumann","Erfaun Noorani","James Price","Ole Peters","Colm Connaughton","Thomas B. Schön"],"pdf_url":"https://arxiv.org/pdf/2310.11335v3.pdf","comment":"Accepted final version to appear in the Transactions on Machine\n  Learning Research"},{"id":"http://arxiv.org/abs/2501.09804v1","updated":"2025-01-16T19:23:11Z","published":"2025-01-16T19:23:11Z","title":"Enhancing Generalization in Chain of Thought Reasoning for Smaller\n  Models","summary":"  Chain-of-Thought (CoT) reasoning in smaller language models is a challenging\nnatural language process problem yet highly desirable in many real-life\napplications. Existing CoT knowledge distillation methods often suffer from\noverly conservative memorization in smaller LLMs, leading to low generalization\nconfidence. As fully preserving the CoT ability of teacher model is impossible,\nwe hypothesize that adversarial CoT fine-tuning is crucial for developing\nsmaller LLM with robust CoT generalization. To this end, we propose\n\\textit{PRompt-Assisted Domain-Adversarial fine-tuning} (PRADA), a principled\nfine-tuning framework that integrates diverse CoT domains. Specifically, PRADA\npioneers two CoT improvements in smaller LLM: (1) Recovering the\ndomain-invariant feature insight which typically lost during distillation with\ndomain adversarial fine-tuning; (2) Enhancing the domain adaptability of CoT\nprompt engineering by employing domain-adversarial approaches. We theoretically\ndemonstrate the effectiveness of our approach and empirically show that it\nsignificantly outperforms the state of the arts in a wide range of tasks.\nMoreover, our empirical findings reveal that the smaller LLM, when leveraging\nPRADA, aligns closely with domain knowledge, thereby improving the\nexplainability of our approach.\n","authors":["Maxwell J. Yin","Dingyi Jiang","Yongbing Chen","Boyu Wang","Charles Ling"],"pdf_url":"https://arxiv.org/pdf/2501.09804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09803v1","updated":"2025-01-16T19:22:50Z","published":"2025-01-16T19:22:50Z","title":"Graph Neural Networks for Travel Distance Estimation and Route\n  Recommendation Under Probabilistic Hazards","summary":"  Estimating the shortest travel time and providing route recommendation\nbetween different locations in a city or region can quantitatively measure the\nconditions of the transportation network during or after extreme events. One\ncommon approach is to use Dijkstra's Algorithm, which produces the shortest\npath as well as the shortest distance. However, this option is computationally\nexpensive when applied to large-scale networks. This paper proposes a novel\nfast framework based on graph neural networks (GNNs) which approximate the\nsingle-source shortest distance between pairs of locations, and predict the\nsingle-source shortest path subsequently. We conduct multiple experiments on\nsynthetic graphs of different size to demonstrate the feasibility and\ncomputational efficiency of the proposed model. In real-world case studies, we\nalso applied the proposed method of flood risk analysis of coastal urban areas\nto calculate delays in evacuation to public shelters during hurricanes. The\nresults indicate the accuracy and computational efficiency of the GNN model,\nand its potential for effective implementation in emergency planning and\nmanagement.\n","authors":["Tong Liu","Hadi Meidani"],"pdf_url":"https://arxiv.org/pdf/2501.09803v1.pdf","comment":"17 pages, 11 figures"},{"id":"http://arxiv.org/abs/2404.04269v2","updated":"2025-01-16T18:59:53Z","published":"2024-03-19T23:27:15Z","title":"Algorithmic Collective Action in Recommender Systems: Promoting Songs by\n  Reordering Playlists","summary":"  We investigate algorithmic collective action in transformer-based recommender\nsystems. Our use case is a music streaming platform where a collective of fans\naims to promote the visibility of an underrepresented artist by strategically\nplacing one of their songs in the existing playlists they control. We introduce\ntwo easily implementable strategies to select the position at which to insert\nthe song with the goal to boost recommendations at test time. The strategies\nexploit statistical properties of the learner by targeting discontinuities in\nthe recommendations, and leveraging the long-tail nature of song distributions.\nWe evaluate the efficacy of our strategies using a publicly available\nrecommender system model released by a major music streaming platform. Our\nfindings reveal that through strategic placement even small collectives\n(controlling less than 0.01\\% of the training data) can achieve up to\n$40\\times$ more test time recommendations than an average song with the same\nnumber of training set occurrences. Focusing on the externalities of the\nstrategy, we find that the recommendations of other songs are largely\npreserved, and the newly gained recommendations are distributed across various\nartists. Together, our findings demonstrate how carefully designed collective\naction strategies can be effective while not necessarily being adversarial.\n","authors":["Joachim Baumann","Celestine Mendler-Dünner"],"pdf_url":"https://arxiv.org/pdf/2404.04269v2.pdf","comment":"Published at NeurIPS 2024, camera-ready updates"},{"id":"http://arxiv.org/abs/2501.09753v1","updated":"2025-01-16T18:59:02Z","published":"2025-01-16T18:59:02Z","title":"SRE-Conv: Symmetric Rotation Equivariant Convolution for Biomedical\n  Image Classification","summary":"  Convolutional neural networks (CNNs) are essential tools for computer vision\ntasks, but they lack traditionally desired properties of extracted features\nthat could further improve model performance, e.g., rotational equivariance.\nSuch properties are ubiquitous in biomedical images, which often lack explicit\norientation. While current work largely relies on data augmentation or explicit\nmodules to capture orientation information, this comes at the expense of\nincreased training costs or ineffective approximations of the desired\nequivariance. To overcome these challenges, we propose a novel and efficient\nimplementation of the Symmetric Rotation-Equivariant (SRE) Convolution\n(SRE-Conv) kernel, designed to learn rotation-invariant features while\nsimultaneously compressing the model size. The SRE-Conv kernel can easily be\nincorporated into any CNN backbone. We validate the ability of a deep SRE-CNN\nto capture equivariance to rotation using the public MedMNISTv2 dataset (16\ntotal tasks). SRE-Conv-CNN demonstrated improved rotated image classification\nperformance accuracy on all 16 test datasets in both 2D and 3D images, all\nwhile increasing efficiency with fewer parameters and reduced memory footprint.\nThe code is available at https://github.com/XYPB/SRE-Conv.\n","authors":["Yuexi Du","Jiazhen Zhang","Tal Zeevi","Nicha C. Dvornek","John A. Onofrey"],"pdf_url":"https://arxiv.org/pdf/2501.09753v1.pdf","comment":"Accepted by IEEE ISBI 2025 4-page paper"},{"id":"http://arxiv.org/abs/2501.09751v1","updated":"2025-01-16T18:58:06Z","published":"2025-01-16T18:58:06Z","title":"OmniThink: Expanding Knowledge Boundaries in Machine Writing through\n  Thinking","summary":"  Machine writing with large language models often relies on\nretrieval-augmented generation. However, these approaches remain confined\nwithin the boundaries of the model's predefined scope, limiting the generation\nof content with rich information. Specifically, vanilla-retrieved information\ntends to lack depth, utility, and suffers from redundancy, which negatively\nimpacts the quality of generated articles, leading to shallow, repetitive, and\nunoriginal outputs. To address these issues, we propose OmniThink, a machine\nwriting framework that emulates the human-like process of iterative expansion\nand reflection. The core idea behind OmniThink is to simulate the cognitive\nbehavior of learners as they progressively deepen their knowledge of the\ntopics. Experimental results demonstrate that OmniThink improves the knowledge\ndensity of generated articles without compromising metrics such as coherence\nand depth. Human evaluations and expert feedback further highlight the\npotential of OmniThink to address real-world challenges in the generation of\nlong-form articles.\n","authors":["Zekun Xi","Wenbiao Yin","Jizhan Fang","Jialong Wu","Runnan Fang","Ningyu Zhang","Jiang Yong","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09747v1","updated":"2025-01-16T18:57:04Z","published":"2025-01-16T18:57:04Z","title":"FAST: Efficient Action Tokenization for Vision-Language-Action Models","summary":"  Autoregressive sequence models, such as Transformer-based vision-language\naction (VLA) policies, can be tremendously effective for capturing complex and\ngeneralizable robotic behaviors. However, such models require us to choose a\ntokenization of our continuous action signals, which determines how the\ndiscrete symbols predicted by the model map to continuous robot actions. We\nfind that current approaches for robot action tokenization, based on simple\nper-dimension, per-timestep binning schemes, typically perform poorly when\nlearning dexterous skills from high-frequency robot data. To address this\nchallenge, we propose a new compression-based tokenization scheme for robot\nactions, based on the discrete cosine transform. Our tokenization approach,\nFrequency-space Action Sequence Tokenization (FAST), enables us to train\nautoregressive VLAs for highly dexterous and high-frequency tasks where\nstandard discretization methods fail completely. Based on FAST, we release\nFAST+, a universal robot action tokenizer, trained on 1M real robot action\ntrajectories. It can be used as a black-box tokenizer for a wide range of robot\naction sequences, with diverse action spaces and control frequencies. Finally,\nwe show that, when combined with the pi0 VLA, our method can scale to training\non 10k hours of robot data and match the performance of diffusion VLAs, while\nreducing training time by up to 5x.\n","authors":["Karl Pertsch","Kyle Stachowicz","Brian Ichter","Danny Driess","Suraj Nair","Quan Vuong","Oier Mees","Chelsea Finn","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2501.09747v1.pdf","comment":"Website: https://www.pi.website/research/fast"},{"id":"http://arxiv.org/abs/2501.09745v1","updated":"2025-01-16T18:55:38Z","published":"2025-01-16T18:55:38Z","title":"Suggesting Code Edits in Interactive Machine Learning Notebooks Using\n  Large Language Models","summary":"  Machine learning developers frequently use interactive computational\nnotebooks, such as Jupyter notebooks, to host code for data processing and\nmodel training. Jupyter notebooks provide a convenient tool for writing machine\nlearning pipelines and interactively observing outputs, however, maintaining\nJupyter notebooks, e.g., to add new features or fix bugs, can be challenging\ndue to the length and complexity of the notebooks. Moreover, there is no\nexisting benchmark related to developer edits on Jupyter notebooks. To address\nthis, we present the first dataset of 48,398 Jupyter notebook edits derived\nfrom 20,095 revisions of 792 machine learning repositories on GitHub, and\nperform the first study of the using LLMs to predict code edits in Jupyter\nnotebooks. Our dataset captures granular details of cell-level and line-level\nmodifications, offering a foundation for understanding real-world maintenance\npatterns in machine learning workflows. We observed that the edits on Jupyter\nnotebooks are highly localized, with changes averaging only 166 lines of code\nin repositories. While larger models outperform smaller counterparts in code\nediting, all models have low accuracy on our dataset even after finetuning,\ndemonstrating the complexity of real-world machine learning maintenance tasks.\nOur findings emphasize the critical role of contextual information in improving\nmodel performance and point toward promising avenues for advancing large\nlanguage models' capabilities in engineering machine learning code.\n","authors":["Bihui Jin","Jiayue Wang","Pengyu Nie"],"pdf_url":"https://arxiv.org/pdf/2501.09745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04845v2","updated":"2025-01-16T18:48:36Z","published":"2024-12-06T08:30:01Z","title":"Using Machine Learning to Discover Parsimonious and\n  Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff\n  Dynamics","summary":"  Despite the excellent real-world predictive performance of modern machine\nlearning (ML) methods, many scientists remain hesitant to discard traditional\nphysical-conceptual (PC) approaches due mainly to their relative\ninterpretability, which contributes to credibility during decision-making. In\nthis context, a currently underexplored aspect of ML is how to develop\nminimally-optimal representations that can facilitate better insight regarding\nsystem functioning. Regardless of how this is achieved, it is arguably true\nthat parsimonious representations better support the advancement of scientific\nunderstanding. Our own view is that ML-based modeling of geoscientific systems\nshould be based in the use of computational units that are fundamentally\ninterpretable by design.\n  This paper continues our exploration of how the strengths of ML can be\nexploited in the service of better understanding via scientific investigation.\nHere, we use the Mass Conserving Perceptron (MCP) as the fundamental\ncomputational unit in a generic network architecture consisting of nodes\narranged in series and parallel to explore several generic and important issues\nrelated to the use of observational data for constructing input-state-output\nmodels of dynamical systems. In the context of lumped catchment modeling, we\nshow that physical interpretability and excellent predictive performance can\nboth be achieved using a relatively parsimonious distributed-state\nmultiple-flow-path network with context-dependent gating and information\nsharing across the nodes, suggesting that MCP-based modeling can play a\nsignificant role in application of ML to geoscientific investigation.\n","authors":["Yuan-Heng Wang","Hoshin V. Gupta"],"pdf_url":"https://arxiv.org/pdf/2412.04845v2.pdf","comment":"74 Pages, 4 Tables, 13 Figures, 11 Tables and 11 Figures in\n  Supplementary Materials"},{"id":"http://arxiv.org/abs/2501.09734v1","updated":"2025-01-16T18:37:59Z","published":"2025-01-16T18:37:59Z","title":"Random Subspace Cubic-Regularization Methods, with Applications to\n  Low-Rank Functions","summary":"  We propose and analyze random subspace variants of the second-order Adaptive\nRegularization using Cubics (ARC) algorithm. These methods iteratively restrict\nthe search space to some random subspace of the parameters, constructing and\nminimizing a local model only within this subspace. Thus, our variants only\nrequire access to (small-dimensional) projections of first- and second-order\nproblem derivatives and calculate a reduced step inexpensively. Under suitable\nassumptions, the ensuing methods maintain the optimal first-order, and\nsecond-order, global rates of convergence of (full-dimensional) cubic\nregularization, while showing improved scalability both theoretically and\nnumerically, particularly when applied to low-rank functions. When applied to\nthe latter, our adaptive variant naturally adapts the subspace size to the true\nrank of the function, without knowing it a priori.\n","authors":["Coralia Cartis","Zhen Shao","Edward Tansley"],"pdf_url":"https://arxiv.org/pdf/2501.09734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09731v1","updated":"2025-01-16T18:30:33Z","published":"2025-01-16T18:30:33Z","title":"Predictions as Surrogates: Revisiting Surrogate Outcomes in the Age of\n  AI","summary":"  We establish a formal connection between the decades-old surrogate outcome\nmodel in biostatistics and economics and the emerging field of\nprediction-powered inference (PPI). The connection treats predictions from\npre-trained models, prevalent in the age of AI, as cost-effective surrogates\nfor expensive outcomes. Building on the surrogate outcomes literature, we\ndevelop recalibrated prediction-powered inference, a more efficient approach to\nstatistical inference than existing PPI proposals. Our method departs from the\nexisting proposals by using flexible machine learning techniques to learn the\noptimal ``imputed loss'' through a step we call recalibration. Importantly, the\nmethod always improves upon the estimator that relies solely on the data with\navailable true outcomes, even when the optimal imputed loss is estimated\nimperfectly, and it achieves the smallest asymptotic variance among PPI\nestimators if the estimate is consistent. Computationally, our optimization\nobjective is convex whenever the loss function that defines the target\nparameter is convex. We further analyze the benefits of recalibration, both\ntheoretically and numerically, in several common scenarios where machine\nlearning predictions systematically deviate from the outcome of interest. We\ndemonstrate significant gains in effective sample size over existing PPI\nproposals via three applications leveraging state-of-the-art machine\nlearning/AI models.\n","authors":["Wenlong Ji","Lihua Lei","Tijana Zrnic"],"pdf_url":"https://arxiv.org/pdf/2501.09731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09729v1","updated":"2025-01-16T18:25:50Z","published":"2025-01-16T18:25:50Z","title":"Generating particle physics Lagrangians with transformers","summary":"  In physics, Lagrangians provide a systematic way to describe laws governing\nphysical systems. In the context of particle physics, they encode the\ninteractions and behavior of the fundamental building blocks of our universe.\nBy treating Lagrangians as complex, rule-based constructs similar to linguistic\nexpressions, we trained a transformer model -- proven to be effective in\nnatural language tasks -- to predict the Lagrangian corresponding to a given\nlist of particles. We report on the transformer's performance in constructing\nLagrangians respecting the Standard Model $\\mathrm{SU}(3)\\times\n\\mathrm{SU}(2)\\times \\mathrm{U}(1)$ gauge symmetries. The resulting model is\nshown to achieve high accuracies (over 90\\%) with Lagrangians up to six matter\nfields, with the capacity to generalize beyond the training distribution,\nalbeit within architectural constraints. We show through an analysis of input\nembeddings that the model has internalized concepts such as group\nrepresentations and conjugation operations as it learned to generate\nLagrangians. We make the model and training datasets available to the\ncommunity. An interactive demonstration can be found at:\n\\url{https://huggingface.co/spaces/JoseEliel/generate-lagrangians}.\n","authors":["Yong Sheng Koay","Rikard Enberg","Stefano Moretti","Eliel Camargo-Molina"],"pdf_url":"https://arxiv.org/pdf/2501.09729v1.pdf","comment":"32 pages, 11 figues, 18 tables"},{"id":"http://arxiv.org/abs/2501.09722v1","updated":"2025-01-16T18:10:37Z","published":"2025-01-16T18:10:37Z","title":"Attention based Bidirectional GRU hybrid model for inappropriate content\n  detection in Urdu language","summary":"  With the increased use of the internet and social networks for online\ndiscussions, the spread of toxic and inappropriate content on social networking\nsites has also increased. Several studies have been conducted in different\nlanguages. However, there is less work done for South Asian languages for\ninappropriate content identification using deep learning techniques. In Urdu\nlanguage, the spellings are not unique, and people write different common\nspellings for the same word, while mixing it other languages, like English in\nthe text makes it more challenging, and limited research work is available to\nprocess such language with the finest algorithms. The use of attention layer\nwith a deep learning model can help handling the long-term dependencies and\nincrease its efficiency . To explore the effects of the attention layer, this\nstudy proposes attention-based Bidirectional GRU hybrid model for identifying\ninappropriate content in Urdu Unicode text language. Four different baseline\ndeep learning models; LSTM, Bi-LSTM, GRU, and TCN, are used to compare the\nperformance of the proposed model. The results of these models were compared\nbased on evaluation metrics, dataset size, and impact of the word embedding\nlayer. The pre-trained Urdu word2Vec embeddings were utilized for our case. Our\nproposed model BiGRU-A outperformed all other baseline models by yielding 84\\%\naccuracy without using pre-trained word2Vec layer. From our experiments, we\nhave established that the attention layer improves the model's efficiency, and\npre-trained word2Vec embedding does not work well with an inappropriate content\ndataset.\n","authors":["Ezzah Shoukat","Rabia Irfan","Iqra Basharat","Muhammad Ali Tahir","Sameen Shaukat"],"pdf_url":"https://arxiv.org/pdf/2501.09722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09705v1","updated":"2025-01-16T17:57:53Z","published":"2025-01-16T17:57:53Z","title":"Practical Continual Forgetting for Pre-trained Vision Models","summary":"  For privacy and security concerns, the need to erase unwanted information\nfrom pre-trained vision models is becoming evident nowadays. In real-world\nscenarios, erasure requests originate at any time from both users and model\nowners, and these requests usually form a sequence. Therefore, under such a\nsetting, selective information is expected to be continuously removed from a\npre-trained model while maintaining the rest. We define this problem as\ncontinual forgetting and identify three key challenges. (i) For unwanted\nknowledge, efficient and effective deleting is crucial. (ii) For remaining\nknowledge, the impact brought by the forgetting procedure should be minimal.\n(iii) In real-world scenarios, the training samples may be scarce or partially\nmissing during the process of forgetting. To address them, we first propose\nGroup Sparse LoRA (GS-LoRA). Specifically, towards (i), we introduce LoRA\nmodules to fine-tune the FFN layers in Transformer blocks for each forgetting\ntask independently, and towards (ii), a simple group sparse regularization is\nadopted, enabling automatic selection of specific LoRA groups and zeroing out\nthe others. To further extend GS-LoRA to more practical scenarios, we\nincorporate prototype information as additional supervision and introduce a\nmore practical approach, GS-LoRA++. For each forgotten class, we move the\nlogits away from its original prototype. For the remaining classes, we pull the\nlogits closer to their respective prototypes. We conduct extensive experiments\non face recognition, object detection and image classification and demonstrate\nthat our method manages to forget specific classes with minimal impact on other\nclasses. Codes have been released on https://github.com/bjzhb666/GS-LoRA.\n","authors":["Hongbo Zhao","Fei Zhu","Bolin Ni","Feng Zhu","Gaofeng Meng","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.09705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09700v1","updated":"2025-01-16T17:54:56Z","published":"2025-01-16T17:54:56Z","title":"Cueless EEG imagined speech for subject identification: dataset and\n  benchmarks","summary":"  Electroencephalogram (EEG) signals have emerged as a promising modality for\nbiometric identification. While previous studies have explored the use of\nimagined speech with semantically meaningful words for subject identification,\nmost have relied on additional visual or auditory cues. In this study, we\nintroduce a cueless EEG-based imagined speech paradigm, where subjects imagine\nthe pronunciation of semantically meaningful words without any external cues.\nThis innovative approach addresses the limitations of prior methods by\nrequiring subjects to select and imagine words from a predefined list\nnaturally. The dataset comprises over 4,350 trials from 11 subjects across five\nsessions. We assess a variety of classification methods, including traditional\nmachine learning techniques such as Support Vector Machines (SVM) and XGBoost,\nas well as time-series foundation models and deep learning architectures\nspecifically designed for EEG classification, such as EEG Conformer and Shallow\nConvNet. A session-based hold-out validation strategy was employed to ensure\nreliable evaluation and prevent data leakage. Our results demonstrate\noutstanding classification accuracy, reaching 97.93%. These findings highlight\nthe potential of cueless EEG paradigms for secure and reliable subject\nidentification in real-world applications, such as brain-computer interfaces\n(BCIs).\n","authors":["Ali Derakhshesh","Zahra Dehghanian","Reza Ebrahimpour","Hamid R. Rabiee"],"pdf_url":"https://arxiv.org/pdf/2501.09700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09691v1","updated":"2025-01-16T17:44:18Z","published":"2025-01-16T17:44:18Z","title":"A Near-optimal Algorithm for Learning Margin Halfspaces with Massart\n  Noise","summary":"  We study the problem of PAC learning $\\gamma$-margin halfspaces in the\npresence of Massart noise. Without computational considerations, the sample\ncomplexity of this learning problem is known to be\n$\\widetilde{\\Theta}(1/(\\gamma^2 \\epsilon))$. Prior computationally efficient\nalgorithms for the problem incur sample complexity $\\tilde{O}(1/(\\gamma^4\n\\epsilon^3))$ and achieve 0-1 error of $\\eta+\\epsilon$, where $\\eta<1/2$ is the\nupper bound on the noise rate. Recent work gave evidence of an\ninformation-computation tradeoff, suggesting that a quadratic dependence on\n$1/\\epsilon$ is required for computationally efficient algorithms. Our main\nresult is a computationally efficient learner with sample complexity\n$\\widetilde{\\Theta}(1/(\\gamma^2 \\epsilon^2))$, nearly matching this lower\nbound. In addition, our algorithm is simple and practical, relying on online\nSGD on a carefully selected sequence of convex losses.\n","authors":["Ilias Diakonikolas","Nikos Zarifis"],"pdf_url":"https://arxiv.org/pdf/2501.09691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09687v1","updated":"2025-01-16T17:39:25Z","published":"2025-01-16T17:39:25Z","title":"U-Fair: Uncertainty-based Multimodal Multitask Learning for Fairer\n  Depression Detection","summary":"  Machine learning bias in mental health is becoming an increasingly pertinent\nchallenge. Despite promising efforts indicating that multitask approaches often\nwork better than unitask approaches, there is minimal work investigating the\nimpact of multitask learning on performance and fairness in depression\ndetection nor leveraged it to achieve fairer prediction outcomes. In this work,\nwe undertake a systematic investigation of using a multitask approach to\nimprove performance and fairness for depression detection. We propose a novel\ngender-based task-reweighting method using uncertainty grounded in how the\nPHQ-8 questionnaire is structured. Our results indicate that, although a\nmultitask approach improves performance and fairness compared to a unitask\napproach, the results are not always consistent and we see evidence of negative\ntransfer and a reduction in the Pareto frontier, which is concerning given the\nhigh-stake healthcare setting. Our proposed approach of gender-based\nreweighting with uncertainty improves performance and fairness and alleviates\nboth challenges to a certain extent. Our findings on each PHQ-8 subitem task\ndifficulty are also in agreement with the largest study conducted on the PHQ-8\nsubitem discrimination capacity, thus providing the very first tangible\nevidence linking ML findings with large-scale empirical population studies\nconducted on the PHQ-8.\n","authors":["Jiaee Cheong","Aditya Bangar","Sinan Kalkan","Hatice Gunes"],"pdf_url":"https://arxiv.org/pdf/2501.09687v1.pdf","comment":"To appear at the Proceedings of Machine Learning Research 259, 1-14,\n  2024 as part of the Machine Learning for Health (ML4H) Symposium 2024"},{"id":"http://arxiv.org/abs/2501.09685v1","updated":"2025-01-16T17:37:35Z","published":"2025-01-16T17:37:35Z","title":"Reward-Guided Controlled Generation for Inference-Time Alignment in\n  Diffusion Models: Tutorial and Review","summary":"  This tutorial provides an in-depth guide on inference-time guidance and\nalignment methods for optimizing downstream reward functions in diffusion\nmodels. While diffusion models are renowned for their generative modeling\ncapabilities, practical applications in fields such as biology often require\nsample generation that maximizes specific metrics (e.g., stability, affinity in\nproteins, closeness to target structures). In these scenarios, diffusion models\ncan be adapted not only to generate realistic samples but also to explicitly\nmaximize desired measures at inference time without fine-tuning. This tutorial\nexplores the foundational aspects of such inference-time algorithms. We review\nthese methods from a unified perspective, demonstrating that current techniques\n-- such as Sequential Monte Carlo (SMC)-based guidance, value-based sampling,\nand classifier guidance -- aim to approximate soft optimal denoising processes\n(a.k.a. policies in RL) that combine pre-trained denoising processes with value\nfunctions serving as look-ahead functions that predict from intermediate states\nto terminal rewards. Within this framework, we present several novel algorithms\nnot yet covered in the literature. Furthermore, we discuss (1) fine-tuning\nmethods combined with inference-time techniques, (2) inference-time algorithms\nbased on search algorithms such as Monte Carlo tree search, which have received\nlimited attention in current research, and (3) connections between\ninference-time algorithms in language models and diffusion models. The code of\nthis tutorial on protein design is available at\nhttps://github.com/masa-ue/AlignInversePro\n","authors":["Masatoshi Uehara","Yulai Zhao","Chenyu Wang","Xiner Li","Aviv Regev","Sergey Levine","Tommaso Biancalani"],"pdf_url":"https://arxiv.org/pdf/2501.09685v1.pdf","comment":"We plan to add more content/codes. Please let us know if there are\n  any comments"}]},"2025-01-15T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2406.17967v3","updated":"2025-01-15T22:20:15Z","published":"2024-06-25T22:49:17Z","title":"Unmasking the Imposters: How Censorship and Domain Adaptation Affect the\n  Detection of Machine-Generated Tweets","summary":"  The rapid development of large language models (LLMs) has significantly\nimproved the generation of fluent and convincing text, raising concerns about\ntheir potential misuse on social media platforms. We present a comprehensive\nmethodology for creating nine Twitter datasets to examine the generative\ncapabilities of four prominent LLMs: Llama 3, Mistral, Qwen2, and GPT4o. These\ndatasets encompass four censored and five uncensored model configurations,\nincluding 7B and 8B parameter base-instruction models of the three open-source\nLLMs. Additionally, we perform a data quality analysis to assess the\ncharacteristics of textual outputs from human, \"censored,\" and \"uncensored\"\nmodels, employing semantic meaning, lexical richness, structural patterns,\ncontent characteristics, and detector performance metrics to identify\ndifferences and similarities. Our evaluation demonstrates that \"uncensored\"\nmodels significantly undermine the effectiveness of automated detection\nmethods. This study addresses a critical gap by exploring smaller open-source\nmodels and the ramifications of \"uncensoring,\" providing valuable insights into\nhow domain adaptation and content moderation strategies influence both the\ndetectability and structural characteristics of machine-generated text.\n","authors":["Bryan E. Tuck","Rakesh M. Verma"],"pdf_url":"https://arxiv.org/pdf/2406.17967v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09164v1","updated":"2025-01-15T21:30:03Z","published":"2025-01-15T21:30:03Z","title":"The Veln(ia)s is in the Details: Evaluating LLM Judgment on Latvian and\n  Lithuanian Short Answer Matching","summary":"  In this work, we address the challenge of evaluating large language models\n(LLMs) on the short answer matching task for Latvian and Lithuanian languages.\nWe introduce novel datasets consisting of 502 Latvian and 690 Lithuanian\nquestion-answer pairs. For each question-answer pair, we generated matched and\nnon-matched answers using a set of alteration rules specifically designed to\nintroduce small but meaningful changes in the text. These generated answers\nserve as test cases to assess the ability of LLMs to detect subtle differences\nin matching of the original answers. A subset of the datasets was manually\nverified for quality and accuracy. Our results show that while larger LLMs,\nsuch as QWEN2.5 72b and LLaMa3.1 70b, demonstrate near-perfect performance in\ndistinguishing matched and non-matched answers, smaller models show more\nvariance. For instance, LLaMa3.1 8b and EuroLLM 9b benefited from few-shot\nexamples, while Mistral Nemo 12b underperformed on detection of subtle text\nalteration, particularly in Lithuanian, even with additional examples. QWEN2.5\n7b and Mistral 7b were able to obtain a strong and comparable performance to\nthe larger 70b models in zero and few shot experiments. Moreover, the\nperformance of Mistral 7b was weaker in few shot experiments.\n","authors":["Yevhen Kostiuk","Oxana Vitman","Łukasz Gagała","Artur Kiulian"],"pdf_url":"https://arxiv.org/pdf/2501.09164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09158v1","updated":"2025-01-15T21:19:01Z","published":"2025-01-15T21:19:01Z","title":"Evaluating GenAI for Simplifying Texts for Education: Improving Accuracy\n  and Consistency for Enhanced Readability","summary":"  Generative artificial intelligence (GenAI) holds great promise as a tool to\nsupport personalized learning. Teachers need tools to efficiently and\neffectively enhance content readability of educational texts so that they are\nmatched to individual students reading levels, while retaining key details.\nLarge Language Models (LLMs) show potential to fill this need, but previous\nresearch notes multiple shortcomings in current approaches. In this study, we\nintroduced a generalized approach and metrics for the systematic evaluation of\nthe accuracy and consistency in which LLMs, prompting techniques, and a novel\nmulti-agent architecture to simplify sixty informational reading passages,\nreducing each from the twelfth grade level down to the eighth, sixth, and\nfourth grade levels. We calculated the degree to which each LLM and prompting\ntechnique accurately achieved the targeted grade level for each passage,\npercentage change in word count, and consistency in maintaining keywords and\nkey phrases (semantic similarity). One-sample t-tests and multiple regression\nmodels revealed significant differences in the best performing LLM and prompt\ntechnique for each of the four metrics. Both LLMs and prompting techniques\ndemonstrated variable utility in grade level accuracy and consistency of\nkeywords and key phrases when attempting to level content down to the fourth\ngrade reading level. These results demonstrate the promise of the application\nof LLMs for efficient and precise automated text simplification, the\nshortcomings of current models and prompting methods in attaining an ideal\nbalance across various evaluation criteria, and a generalizable method to\nevaluate future systems.\n","authors":["Stephanie L. Day","Jacapo Cirica","Steven R. Clapp","Veronika Penkova","Amy E. Giroux","Abbey Banta","Catherine Bordeau","Poojitha Mutteneni","Ben D. Sawyer"],"pdf_url":"https://arxiv.org/pdf/2501.09158v1.pdf","comment":"64 pages, 9 tables, 6 figures, and supplemental materials"},{"id":"http://arxiv.org/abs/2501.09155v1","updated":"2025-01-15T21:14:36Z","published":"2025-01-15T21:14:36Z","title":"VCRScore: Image captioning metric based on V\\&L Transformers, CLIP, and\n  precision-recall","summary":"  Image captioning has become an essential Vision & Language research task. It\nis about predicting the most accurate caption given a specific image or video.\nThe research community has achieved impressive results by continuously\nproposing new models and approaches to improve the overall model's performance.\nNevertheless, despite increasing proposals, the performance metrics used to\nmeasure their advances have remained practically untouched through the years. A\nprobe of that, nowadays metrics like BLEU, METEOR, CIDEr, and ROUGE are still\nvery used, aside from more sophisticated metrics such as BertScore and\nClipScore.\n  Hence, it is essential to adjust how are measure the advances, limitations,\nand scopes of the new image captioning proposals, as well as to adapt new\nmetrics to these new advanced image captioning approaches.\n  This work proposes a new evaluation metric for the image captioning problem.\nTo do that, first, it was generated a human-labeled dataset to assess to which\ndegree the captions correlate with the image's content. Taking these human\nscores as ground truth, we propose a new metric, and compare it with several\nwell-known metrics, from classical to newer ones. Outperformed results were\nalso found, and interesting insights were presented and discussed.\n","authors":["Guillermo Ruiz","Tania Ramírez","Daniela Moctezuma"],"pdf_url":"https://arxiv.org/pdf/2501.09155v1.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2501.09154v1","updated":"2025-01-15T21:14:09Z","published":"2025-01-15T21:14:09Z","title":"Towards Multilingual LLM Evaluation for Baltic and Nordic languages: A\n  study on Lithuanian History","summary":"  In this work, we evaluated Lithuanian and general history knowledge of\nmultilingual Large Language Models (LLMs) on a multiple-choice\nquestion-answering task. The models were tested on a dataset of Lithuanian\nnational and general history questions translated into Baltic, Nordic, and\nother languages (English, Ukrainian, Arabic) to assess the knowledge sharing\nfrom culturally and historically connected groups. We evaluated GPT-4o,\nLLaMa3.1 8b and 70b, QWEN2.5 7b and 72b, Mistral Nemo 12b, LLaMa3 8b, Mistral\n7b, LLaMa3.2 3b, and Nordic fine-tuned models (GPT-SW3 and LLaMa3 8b).\n  Our results show that GPT-4o consistently outperformed all other models\nacross language groups, with slightly better results for Baltic and Nordic\nlanguages. Larger open-source models like QWEN2.5 72b and LLaMa3.1 70b\nperformed well but showed weaker alignment with Baltic languages. Smaller\nmodels (Mistral Nemo 12b, LLaMa3.2 3b, QWEN 7B, LLaMa3.1 8B, and LLaMa3 8b)\ndemonstrated gaps with LT-related alignment with Baltic languages while\nperforming better on Nordic and other languages. The Nordic fine-tuned models\ndid not surpass multilingual models, indicating that shared cultural or\nhistorical context alone does not guarantee better performance.\n","authors":["Yevhen Kostiuk","Oxana Vitman","Łukasz Gagała","Artur Kiulian"],"pdf_url":"https://arxiv.org/pdf/2501.09154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06497v2","updated":"2025-01-15T20:43:44Z","published":"2025-01-11T10:22:04Z","title":"PASS: Presentation Automation for Slide Generation and Speech","summary":"  In today's fast-paced world, effective presentations have become an essential\ntool for communication in both online and offline meetings. The crafting of a\ncompelling presentation requires significant time and effort, from gathering\nkey insights to designing slides that convey information clearly and concisely.\nHowever, despite the wealth of resources available, people often find\nthemselves manually extracting crucial points, analyzing data, and organizing\ncontent in a way that ensures clarity and impact. Furthermore, a successful\npresentation goes beyond just the slides; it demands rehearsal and the ability\nto weave a captivating narrative to fully engage the audience. Although there\nhas been some exploration of automating document-to-slide generation, existing\nresearch is largely centered on converting research papers. In addition,\nautomation of the delivery of these presentations has yet to be addressed. We\nintroduce PASS, a pipeline used to generate slides from general Word documents,\ngoing beyond just research papers, which also automates the oral delivery of\nthe generated slides. PASS analyzes user documents to create a dynamic,\nengaging presentation with an AI-generated voice. Additionally, we developed an\nLLM-based evaluation metric to assess our pipeline across three critical\ndimensions of presentations: relevance, coherence, and redundancy. The data and\ncodes are available at https://github.com/AggarwalTushar/PASS.\n","authors":["Tushar Aggarwal","Aarohi Bhand"],"pdf_url":"https://arxiv.org/pdf/2501.06497v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09136v1","updated":"2025-01-15T20:40:25Z","published":"2025-01-15T20:40:25Z","title":"Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG","summary":"  Large Language Models (LLMs) have revolutionized artificial intelligence (AI)\nby enabling human like text generation and natural language understanding.\nHowever, their reliance on static training data limits their ability to respond\nto dynamic, real time queries, resulting in outdated or inaccurate outputs.\nRetrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs\nby integrating real time data retrieval to provide contextually relevant and\nup-to-date responses. Despite its promise, traditional RAG systems are\nconstrained by static workflows and lack the adaptability required for\nmultistep reasoning and complex task management.\n  Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these\nlimitations by embedding autonomous AI agents into the RAG pipeline. These\nagents leverage agentic design patterns reflection, planning, tool use, and\nmultiagent collaboration to dynamically manage retrieval strategies,\niteratively refine contextual understanding, and adapt workflows to meet\ncomplex task requirements. This integration enables Agentic RAG systems to\ndeliver unparalleled flexibility, scalability, and context awareness across\ndiverse applications.\n  This survey provides a comprehensive exploration of Agentic RAG, beginning\nwith its foundational principles and the evolution of RAG paradigms. It\npresents a detailed taxonomy of Agentic RAG architectures, highlights key\napplications in industries such as healthcare, finance, and education, and\nexamines practical implementation strategies. Additionally, it addresses\nchallenges in scaling these systems, ensuring ethical decision making, and\noptimizing performance for real-world applications, while providing detailed\ninsights into frameworks and tools for implementing Agentic RAG\n","authors":["Aditi Singh","Abul Ehtesham","Saket Kumar","Tala Talaei Khoei"],"pdf_url":"https://arxiv.org/pdf/2501.09136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09134v1","updated":"2025-01-15T20:37:04Z","published":"2025-01-15T20:37:04Z","title":"Benchmarking Robustness of Contrastive Learning Models for Medical\n  Image-Report Retrieval","summary":"  Medical images and reports offer invaluable insights into patient health. The\nheterogeneity and complexity of these data hinder effective analysis. To bridge\nthis gap, we investigate contrastive learning models for cross-domain\nretrieval, which associates medical images with their corresponding clinical\nreports. This study benchmarks the robustness of four state-of-the-art\ncontrastive learning models: CLIP, CXR-RePaiR, MedCLIP, and CXR-CLIP. We\nintroduce an occlusion retrieval task to evaluate model performance under\nvarying levels of image corruption. Our findings reveal that all evaluated\nmodels are highly sensitive to out-of-distribution data, as evidenced by the\nproportional decrease in performance with increasing occlusion levels. While\nMedCLIP exhibits slightly more robustness, its overall performance remains\nsignificantly behind CXR-CLIP and CXR-RePaiR. CLIP, trained on a\ngeneral-purpose dataset, struggles with medical image-report retrieval,\nhighlighting the importance of domain-specific training data. The evaluation of\nthis work suggests that more effort needs to be spent on improving the\nrobustness of these models. By addressing these limitations, we can develop\nmore reliable cross-domain retrieval models for medical applications.\n","authors":["Demetrio Deanda","Yuktha Priya Masupalli","Jeong Yang","Young Lee","Zechun Cao","Gongbo Liang"],"pdf_url":"https://arxiv.org/pdf/2501.09134v1.pdf","comment":"This work is accepted to AAAI 2025 Workshop -- the 9th International\n  Workshop on Health Intelligence"},{"id":"http://arxiv.org/abs/2501.09127v1","updated":"2025-01-15T20:22:35Z","published":"2025-01-15T20:22:35Z","title":"Multilingual LLMs Struggle to Link Orthography and Semantics in\n  Bilingual Word Processing","summary":"  Bilingual lexical processing is shaped by the complex interplay of\nphonological, orthographic, and semantic features of two languages within an\nintegrated mental lexicon. In humans, this is evident in the ease with which\ncognate words - words similar in both orthographic form and meaning (e.g.,\nblind, meaning \"sightless\" in both English and German) - are processed,\ncompared to the challenges posed by interlingual homographs, which share\northographic form but differ in meaning (e.g., gift, meaning \"present\" in\nEnglish but \"poison\" in German). We investigate how multilingual Large Language\nModels (LLMs) handle such phenomena, focusing on English-Spanish,\nEnglish-French, and English-German cognates, non-cognate, and interlingual\nhomographs. Specifically, we evaluate their ability to disambiguate meanings\nand make semantic judgments, both when these word types are presented in\nisolation or within sentence contexts. Our findings reveal that while certain\nLLMs demonstrate strong performance in recognizing cognates and non-cognates in\nisolation, they exhibit significant difficulty in disambiguating interlingual\nhomographs, often performing below random baselines. This suggests LLMs tend to\nrely heavily on orthographic similarities rather than semantic understanding\nwhen interpreting interlingual homographs. Further, we find LLMs exhibit\ndifficulty in retrieving word meanings, with performance in isolative\ndisambiguation tasks having no correlation with semantic understanding.\nFinally, we study how the LLM processes interlingual homographs in incongruent\nsentences. We find models to opt for different strategies in understanding\nEnglish and non-English homographs, highlighting a lack of a unified approach\nto handling cross-lingual ambiguities.\n","authors":["Eshaan Tanwar","Gayatri Oke","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2501.09127v1.pdf","comment":"Code available at:\n  https://github.com/EshaanT/Bilingual_processing_LLMs"},{"id":"http://arxiv.org/abs/2501.09126v1","updated":"2025-01-15T20:13:46Z","published":"2025-01-15T20:13:46Z","title":"Augmenting Human-Annotated Training Data with Large Language Model\n  Generation and Distillation in Open-Response Assessment","summary":"  Large Language Models (LLMs) like GPT-4o can help automate text\nclassification tasks at low cost and scale. However, there are major concerns\nabout the validity and reliability of LLM outputs. By contrast, human coding is\ngenerally more reliable but expensive to procure at scale. In this study, we\npropose a hybrid solution to leverage the strengths of both. We combine\nhuman-coded data and synthetic LLM-produced data to fine-tune a classical\nmachine learning classifier, distilling both into a smaller BERT model. We\nevaluate our method on a human-coded test set as a validity measure for LLM\noutput quality. In three experiments, we systematically vary LLM-generated\nsamples' size, variety, and consistency, informed by best practices in LLM\ntuning. Our findings indicate that augmenting datasets with synthetic samples\nimproves classifier performance, with optimal results achieved at an 80%\nsynthetic to 20% human-coded data ratio. Lower temperature settings of 0.3,\ncorresponding to less variability in LLM generations, produced more stable\nimprovements but also limited model learning from augmented samples. In\ncontrast, higher temperature settings (0.7 and above) introduced greater\nvariability in performance estimates and, at times, lower performance. Hence,\nLLMs may produce more uniform output that classifiers overfit to earlier or\nproduce more diverse output that runs the risk of deteriorating model\nperformance through information irrelevant to the prediction task. Filtering\nout inconsistent synthetic samples did not enhance performance. We conclude\nthat integrating human and LLM-generated data to improve text classification\nmodels in assessment offers a scalable solution that leverages both the\naccuracy of human coding and the variety of LLM outputs.\n","authors":["Conrad Borchers","Danielle R. Thomas","Jionghao Lin","Ralph Abboud","Kenneth R. Koedinger"],"pdf_url":"https://arxiv.org/pdf/2501.09126v1.pdf","comment":"Manuscript accepted to the Second Workshop on Generative AI for\n  Learning Analytics (GenAI-LA) at LAK25"},{"id":"http://arxiv.org/abs/2501.09092v1","updated":"2025-01-15T19:24:48Z","published":"2025-01-15T19:24:48Z","title":"SteLLA: A Structured Grading System Using LLMs with RAG","summary":"  Large Language Models (LLMs) have shown strong general capabilities in many\napplications. However, how to make them reliable tools for some specific tasks\nsuch as automated short answer grading (ASAG) remains a challenge. We present\nSteLLA (Structured Grading System Using LLMs with RAG) in which a) Retrieval\nAugmented Generation (RAG) approach is used to empower LLMs specifically on the\nASAG task by extracting structured information from the highly relevant and\nreliable external knowledge based on the instructor-provided reference answer\nand rubric, b) an LLM performs a structured and question-answering-based\nevaluation of student answers to provide analytical grades and feedback. A\nreal-world dataset that contains students' answers in an exam was collected\nfrom a college-level Biology course. Experiments show that our proposed system\ncan achieve substantial agreement with the human grader while providing\nbreak-down grades and feedback on all the knowledge points examined in the\nproblem. A qualitative and error analysis of the feedback generated by GPT4\nshows that GPT4 is good at capturing facts while may be prone to inferring too\nmuch implication from the given text in the grading task which provides\ninsights into the usage of LLMs in the ASAG system.\n","authors":["Hefei Qiu","Brian White","Ashley Ding","Reinaldo Costa","Ali Hachem","Wei Ding","Ping Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09012v1","updated":"2025-01-15T18:56:22Z","published":"2025-01-15T18:56:22Z","title":"Multimodal LLMs Can Reason about Aesthetics in Zero-Shot","summary":"  We present the first study on how Multimodal LLMs' (MLLMs) reasoning ability\nshall be elicited to evaluate the aesthetics of artworks. To facilitate this\ninvestigation, we construct MM-StyleBench, a novel high-quality dataset for\nbenchmarking artistic stylization. We then develop a principled method for\nhuman preference modeling and perform a systematic correlation analysis between\nMLLMs' responses and human preference. Our experiments reveal an inherent\nhallucination issue of MLLMs in art evaluation, associated with response\nsubjectivity. ArtCoT is proposed, demonstrating that art-specific task\ndecomposition and the use of concrete language boost MLLMs' reasoning ability\nfor aesthetics. Our findings offer valuable insights into MLLMs for art and can\nbenefit a wide range of downstream applications, such as style transfer and\nartistic image generation. Code available at\nhttps://github.com/songrise/MLLM4Art.\n","authors":["Ruixiang Jiang","Changwen Chen"],"pdf_url":"https://arxiv.org/pdf/2501.09012v1.pdf","comment":"WIP, Homepage https://github.com/songrise/MLLM4Art"},{"id":"http://arxiv.org/abs/2409.09201v3","updated":"2025-01-15T18:52:52Z","published":"2024-09-13T21:28:54Z","title":"Contextual Evaluation of Large Language Models for Classifying Tropical\n  and Infectious Diseases","summary":"  While large language models (LLMs) have shown promise for medical question\nanswering, there is limited work focused on tropical and infectious\ndisease-specific exploration. We build on an opensource tropical and infectious\ndiseases (TRINDs) dataset, expanding it to include demographic and semantic\nclinical and consumer augmentations yielding 11000+ prompts. We evaluate LLM\nperformance on these, comparing generalist and medical LLMs, as well as LLM\noutcomes to human experts. We demonstrate through systematic experimentation,\nthe benefit of contextual information such as demographics, location, gender,\nrisk factors for optimal LLM response. Finally we develop a prototype of\nTRINDs-LM, a research tool that provides a playground to navigate how context\nimpacts LLM outputs for health.\n","authors":["Mercy Asiedu","Nenad Tomasev","Chintan Ghate","Tiya Tiyasirichokchai","Awa Dieng","Oluwatosin Akande","Geoffrey Siwo","Steve Adudans","Sylvanus Aitkins","Odianosen Ehiakhamen","Eric Ndombi","Katherine Heller"],"pdf_url":"https://arxiv.org/pdf/2409.09201v3.pdf","comment":"Accepted at 2 NeurIPS 2024 workshops: Generative AI for Health\n  Workshop and Workshop on Advancements In Medical Foundation Models:\n  Explainability, Robustness, Security, and Beyond"},{"id":"http://arxiv.org/abs/2501.09056v1","updated":"2025-01-15T18:44:01Z","published":"2025-01-15T18:44:01Z","title":"Decompose-ToM: Enhancing Theory of Mind Reasoning in Large Language\n  Models through Simulation and Task Decomposition","summary":"  Theory of Mind (ToM) is the ability to understand and reflect on the mental\nstates of others. Although this capability is crucial for human interaction,\ntesting on Large Language Models (LLMs) reveals that they possess only a\nrudimentary understanding of it. Although the most capable closed-source LLMs\nhave come close to human performance on some ToM tasks, they still perform\npoorly on complex variations of the task that involve more structured\nreasoning. In this work, we utilize the concept of \"pretend-play\", or\n``Simulation Theory'' from cognitive psychology to propose ``Decompose-ToM'':\nan LLM-based inference algorithm that improves model performance on complex ToM\ntasks. We recursively simulate user perspectives and decompose the ToM task\ninto a simpler set of functions: subject identification, question-reframing,\nworld model updation, and knowledge availability. We test the algorithm on\nhigher-order ToM tasks and a task testing for ToM capabilities in a\nconversational setting, demonstrating that our approach shows significant\nimprovement across models compared to baseline methods while requiring minimal\nprompt tuning across tasks and no additional model training.\n","authors":["Sneheel Sarangi","Maha Elgarf","Hanan Salam"],"pdf_url":"https://arxiv.org/pdf/2501.09056v1.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2501.09004v1","updated":"2025-01-15T18:37:08Z","published":"2025-01-15T18:37:08Z","title":"Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment\n  of LLM Guardrails","summary":"  As Large Language Models (LLMs) and generative AI become increasingly\nwidespread, concerns about content safety have grown in parallel. Currently,\nthere is a clear lack of high-quality, human-annotated datasets that address\nthe full spectrum of LLM-related safety risks and are usable for commercial\napplications. To bridge this gap, we propose a comprehensive and adaptable\ntaxonomy for categorizing safety risks, structured into 12 top-level hazard\ncategories with an extension to 9 fine-grained subcategories. This taxonomy is\ndesigned to meet the diverse requirements of downstream users, offering more\ngranular and flexible tools for managing various risk types. Using a hybrid\ndata generation pipeline that combines human annotations with a multi-LLM\n\"jury\" system to assess the safety of responses, we obtain Aegis 2.0, a\ncarefully curated collection of 34,248 samples of human-LLM interactions,\nannotated according to our proposed taxonomy. To validate its effectiveness, we\ndemonstrate that several lightweight models, trained using parameter-efficient\ntechniques on Aegis 2.0, achieve performance competitive with leading safety\nmodels fully fine-tuned on much larger, non-commercial datasets. In addition,\nwe introduce a novel training blend that combines safety with topic following\ndata.This approach enhances the adaptability of guard models, enabling them to\ngeneralize to new risk categories defined during inference. We plan to\nopen-source Aegis 2.0 data and models to the research community to aid in the\nsafety guardrailing of LLMs.\n","authors":["Shaona Ghosh","Prasoon Varshney","Makesh Narsimhan Sreedhar","Aishwarya Padmakumar","Traian Rebedea","Jibin Rajan Varghese","Christopher Parisien"],"pdf_url":"https://arxiv.org/pdf/2501.09004v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2404.05993"},{"id":"http://arxiv.org/abs/2501.08102v2","updated":"2025-01-15T18:10:00Z","published":"2025-01-14T13:19:47Z","title":"Consistency of Responses and Continuations Generated by Large Language\n  Models on Social Media","summary":"  Large Language Models (LLMs) demonstrate remarkable capabilities in text\ngeneration, yet their emotional consistency and semantic coherence in social\nmedia contexts remain insufficiently understood. This study investigates how\nLLMs handle emotional content and maintain semantic relationships through\ncontinuation and response tasks using two open-source models: Gemma and Llama.\nBy analyzing climate change discussions from Twitter and Reddit, we examine\nemotional transitions, intensity patterns, and semantic similarity between\nhuman-authored and LLM-generated content. Our findings reveal that while both\nmodels maintain high semantic coherence, they exhibit distinct emotional\npatterns: Gemma shows a tendency toward negative emotion amplification,\nparticularly anger, while maintaining certain positive emotions like optimism.\nLlama demonstrates superior emotional preservation across a broader spectrum of\naffects. Both models systematically generate responses with attenuated\nemotional intensity compared to human-authored content and show a bias toward\npositive emotions in response tasks. Additionally, both models maintain strong\nsemantic similarity with original texts, though performance varies between\ncontinuation and response tasks. These findings provide insights into LLMs'\nemotional and semantic processing capabilities, with implications for their\ndeployment in social media contexts and human-AI interaction design.\n","authors":["Wenlu Fan","Yuqi Zhu","Chenyang Wang","Bin Wang","Wentao Xu"],"pdf_url":"https://arxiv.org/pdf/2501.08102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08985v1","updated":"2025-01-15T18:04:21Z","published":"2025-01-15T18:04:21Z","title":"Personality Modeling for Persuasion of Misinformation using AI Agent","summary":"  The proliferation of misinformation on social media platforms has highlighted\nthe need to understand how individual personality traits influence\nsusceptibility to and propagation of misinformation. This study employs an\ninnovative agent-based modeling approach to investigate the relationship\nbetween personality traits and misinformation dynamics. Using six AI agents\nembodying different dimensions of the Big Five personality traits\n(Extraversion, Agreeableness, and Neuroticism), we simulated interactions\nacross six diverse misinformation topics. The experiment, implemented through\nthe AgentScope framework using the GLM-4-Flash model, generated 90 unique\ninteractions, revealing complex patterns in how personality combinations affect\npersuasion and resistance to misinformation. Our findings demonstrate that\nanalytical and critical personality traits enhance effectiveness in\nevidence-based discussions, while non-aggressive persuasion strategies show\nunexpected success in misinformation correction. Notably, agents with critical\ntraits achieved a 59.4% success rate in HIV-related misinformation discussions,\nwhile those employing non-aggressive approaches maintained consistent\npersuasion rates above 40% across different personality combinations. The study\nalso revealed a non-transitive pattern in persuasion effectiveness, challenging\nconventional assumptions about personality-based influence. These results\nprovide crucial insights for developing personality-aware interventions in\ndigital environments and suggest that effective misinformation countermeasures\nshould prioritize emotional connection and trust-building over confrontational\napproaches. The findings contribute to both theoretical understanding of\npersonality-misinformation dynamics and practical strategies for combating\nmisinformation in social media contexts.\n","authors":["Qianmin Lou","Wentao Xu"],"pdf_url":"https://arxiv.org/pdf/2501.08985v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08974v1","updated":"2025-01-15T17:36:56Z","published":"2025-01-15T17:36:56Z","title":"Learning to Extract Cross-Domain Aspects and Understanding Sentiments\n  Using Large Language Models","summary":"  Aspect-based sentiment analysis (ASBA) is a refined approach to sentiment\nanalysis that aims to extract and classify sentiments based on specific aspects\nor features of a product, service, or entity. Unlike traditional sentiment\nanalysis, which assigns a general sentiment score to entire reviews or texts,\nABSA focuses on breaking down the text into individual components or aspects\n(e.g., quality, price, service) and evaluating the sentiment towards each. This\nallows for a more granular level of understanding of customer opinions,\nenabling businesses to pinpoint specific areas of strength and improvement. The\nprocess involves several key steps, including aspect extraction, sentiment\nclassification, and aspect-level sentiment aggregation for a review paragraph\nor any other form that the users have provided. ABSA has significant\napplications in areas such as product reviews, social media monitoring,\ncustomer feedback analysis, and market research. By leveraging techniques from\nnatural language processing (NLP) and machine learning, ABSA facilitates the\nextraction of valuable insights, enabling companies to make data-driven\ndecisions that enhance customer satisfaction and optimize offerings. As ABSA\nevolves, it holds the potential to greatly improve personalized customer\nexperiences by providing a deeper understanding of sentiment across various\nproduct aspects. In this work, we have analyzed the strength of LLMs for a\ncomplete cross-domain aspect-based sentiment analysis with the aim of defining\nthe framework for certain products and using it for other similar situations.\nWe argue that it is possible to that at an effectiveness of 92\\% accuracy for\nthe Aspect Based Sentiment Analysis dataset of SemEval-2015 Task 12.\n","authors":["Karukriti Kaushik Ghosh","Chiranjib Sur"],"pdf_url":"https://arxiv.org/pdf/2501.08974v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08946v1","updated":"2025-01-15T16:49:22Z","published":"2025-01-15T16:49:22Z","title":"Applying General Turn-taking Models to Conversational Human-Robot\n  Interaction","summary":"  Turn-taking is a fundamental aspect of conversation, but current Human-Robot\nInteraction (HRI) systems often rely on simplistic, silence-based models,\nleading to unnatural pauses and interruptions. This paper investigates, for the\nfirst time, the application of general turn-taking models, specifically TurnGPT\nand Voice Activity Projection (VAP), to improve conversational dynamics in HRI.\nThese models are trained on human-human dialogue data using self-supervised\nlearning objectives, without requiring domain-specific fine-tuning. We propose\nmethods for using these models in tandem to predict when a robot should begin\npreparing responses, take turns, and handle potential interruptions. We\nevaluated the proposed system in a within-subject study against a traditional\nbaseline system, using the Furhat robot with 39 adults in a conversational\nsetting, in combination with a large language model for autonomous response\ngeneration. The results show that participants significantly prefer the\nproposed system, and it significantly reduces response delays and\ninterruptions.\n","authors":["Gabriel Skantze","Bahar Irfan"],"pdf_url":"https://arxiv.org/pdf/2501.08946v1.pdf","comment":"Accepted at HRI 2025 (the IEEE/ACM International Conference on\n  Human-Robot Interaction)"},{"id":"http://arxiv.org/abs/2501.08925v1","updated":"2025-01-15T16:30:29Z","published":"2025-01-15T16:30:29Z","title":"Disentangling Exploration of Large Language Models by Optimal\n  Exploitation","summary":"  Exploration is a crucial skill for self-improvement and open-ended\nproblem-solving. However, it remains uncertain whether large language models\ncan effectively explore the state-space. Existing evaluations predominantly\nfocus on the trade-off between exploration and exploitation, often assessed in\nmulti-armed bandit problems. In contrast, this work isolates exploration as the\nsole objective, tasking the agent with delivering information that enhances\nfuture returns. For the evaluation, we propose to decompose missing rewards\ninto exploration and exploitation components by measuring the optimal\nachievable return for the states already explored. Our experiments with various\nLLMs reveal that most models struggle to sufficiently explore the state-space\nand that weak exploration is insufficient. We observe a positive correlation\nbetween model size and exploration performance, with larger models\ndemonstrating superior capabilities. Furthermore, we show that our\ndecomposition provides insights into differences in behaviors driven by agent\ninstructions during prompt engineering, offering a valuable tool for refining\nLLM performance in exploratory tasks.\n","authors":["Tim Grams","Patrick Betz","Christian Bartelt"],"pdf_url":"https://arxiv.org/pdf/2501.08925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08913v1","updated":"2025-01-15T16:21:09Z","published":"2025-01-15T16:21:09Z","title":"GenAI Content Detection Task 3: Cross-Domain Machine-Generated Text\n  Detection Challenge","summary":"  Recently there have been many shared tasks targeting the detection of\ngenerated text from Large Language Models (LLMs). However, these shared tasks\ntend to focus either on cases where text is limited to one particular domain or\ncases where text can be from many domains, some of which may not be seen during\ntest time. In this shared task, using the newly released RAID benchmark, we aim\nto answer whether or not models can detect generated text from a large, yet\nfixed, number of domains and LLMs, all of which are seen during training. Over\nthe course of three months, our task was attempted by 9 teams with 23 detector\nsubmissions. We find that multiple participants were able to obtain accuracies\nof over 99% on machine-generated text from RAID while maintaining a 5% False\nPositive Rate -- suggesting that detectors are able to robustly detect text\nfrom many domains and models simultaneously. We discuss potential\ninterpretations of this result and provide directions for future research.\n","authors":["Liam Dugan","Andrew Zhu","Firoj Alam","Preslav Nakov","Marianna Apidianaki","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2501.08913v1.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2411.18152v2","updated":"2025-01-15T15:34:13Z","published":"2024-11-27T09:01:08Z","title":"MSA-ASR: Efficient Multilingual Speaker Attribution with frozen ASR\n  Models","summary":"  Speaker-attributed automatic speech recognition (SA-ASR) aims to transcribe\nspeech while assigning transcripts to the corresponding speakers accurately.\nExisting methods often rely on complex modular systems or require extensive\nfine-tuning of joint modules, limiting their adaptability and general\nefficiency. This paper introduces a novel approach, leveraging a frozen\nmultilingual ASR model to incorporate speaker attribution into the\ntranscriptions, using only standard monolingual ASR datasets. Our method\ninvolves training a speaker module to predict speaker embeddings based on weak\nlabels without requiring additional ASR model modifications. Despite being\ntrained exclusively with non-overlapping monolingual data, our approach\neffectively extracts speaker attributes across diverse multilingual datasets,\nincluding those with overlapping speech. Experimental results demonstrate\ncompetitive performance compared to strong baselines, highlighting the model's\nrobustness and potential for practical applications.\n","authors":["Thai-Binh Nguyen","Alexander Waibel"],"pdf_url":"https://arxiv.org/pdf/2411.18152v2.pdf","comment":"Accepted at ICASSP 2025"},{"id":"http://arxiv.org/abs/2501.08838v1","updated":"2025-01-15T14:47:02Z","published":"2025-01-15T14:47:02Z","title":"ToMATO: Verbalizing the Mental States of Role-Playing LLMs for\n  Benchmarking Theory of Mind","summary":"  Existing Theory of Mind (ToM) benchmarks diverge from real-world scenarios in\nthree aspects: 1) they assess a limited range of mental states such as beliefs,\n2) false beliefs are not comprehensively explored, and 3) the diverse\npersonality traits of characters are overlooked. To address these challenges,\nwe introduce ToMATO, a new ToM benchmark formulated as multiple-choice QA over\nconversations. ToMATO is generated via LLM-LLM conversations featuring\ninformation asymmetry. By employing a prompting method that requires\nrole-playing LLMs to verbalize their thoughts before each utterance, we capture\nboth first- and second-order mental states across five categories: belief,\nintention, desire, emotion, and knowledge. These verbalized thoughts serve as\nanswers to questions designed to assess the mental states of characters within\nconversations. Furthermore, the information asymmetry introduced by hiding\nthoughts from others induces the generation of false beliefs about various\nmental states. Assigning distinct personality traits to LLMs further\ndiversifies both utterances and thoughts. ToMATO consists of 5.4k questions,\n753 conversations, and 15 personality trait patterns. Our analysis shows that\nthis dataset construction approach frequently generates false beliefs due to\nthe information asymmetry between role-playing LLMs, and effectively reflects\ndiverse personalities. We evaluate nine LLMs on ToMATO and find that even\nGPT-4o mini lags behind human performance, especially in understanding false\nbeliefs, and lacks robustness to various personality traits.\n","authors":["Kazutoshi Shinoda","Nobukatsu Hojo","Kyosuke Nishida","Saki Mizuno","Keita Suzuki","Ryo Masumura","Hiroaki Sugiyama","Kuniko Saito"],"pdf_url":"https://arxiv.org/pdf/2501.08838v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2406.11192v2","updated":"2025-01-15T14:38:01Z","published":"2024-06-17T03:57:35Z","title":"Beyond Boundaries: Learning a Universal Entity Taxonomy across Datasets\n  and Languages for Open Named Entity Recognition","summary":"  Open Named Entity Recognition (NER), which involves identifying arbitrary\ntypes of entities from arbitrary domains, remains challenging for Large\nLanguage Models (LLMs). Recent studies suggest that fine-tuning LLMs on\nextensive NER data can boost their performance. However, training directly on\nexisting datasets neglects their inconsistent entity definitions and redundant\ndata, limiting LLMs to dataset-specific learning and hindering out-of-domain\nadaptation. To address this, we present B2NERD, a compact dataset designed to\nguide LLMs' generalization in Open NER under a universal entity taxonomy.\nB2NERD is refined from 54 existing English and Chinese datasets using a\ntwo-step process. First, we detect inconsistent entity definitions across\ndatasets and clarify them by distinguishable label names to construct a\nuniversal taxonomy of 400+ entity types. Second, we address redundancy using a\ndata pruning strategy that selects fewer samples with greater category and\nsemantic diversity. Comprehensive evaluation shows that B2NERD significantly\nenhances LLMs' Open NER capabilities. Our B2NER models, trained on B2NERD,\noutperform GPT-4 by 6.8-12.0 F1 points and surpass previous methods in 3\nout-of-domain benchmarks across 15 datasets and 6 languages. The data, models,\nand code are publicly available at https://github.com/UmeanNever/B2NER.\n","authors":["Yuming Yang","Wantong Zhao","Caishuang Huang","Junjie Ye","Xiao Wang","Huiyuan Zheng","Yang Nan","Yuran Wang","Xueying Xu","Kaixin Huang","Yunke Zhang","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2406.11192v2.pdf","comment":"Accepted at COLING 2025. Camera-ready version updated. Project page:\n  https://github.com/UmeanNever/B2NER"},{"id":"http://arxiv.org/abs/2501.08828v1","updated":"2025-01-15T14:30:13Z","published":"2025-01-15T14:30:13Z","title":"MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents","summary":"  Multi-modal document retrieval is designed to identify and retrieve various\nforms of multi-modal content, such as figures, tables, charts, and layout\ninformation from extensive documents. Despite its significance, there is a\nnotable lack of a robust benchmark to effectively evaluate the performance of\nsystems in multi-modal document retrieval. To address this gap, this work\nintroduces a new benchmark, named as MMDocIR, encompassing two distinct tasks:\npage-level and layout-level retrieval. The former focuses on localizing the\nmost relevant pages within a long document, while the latter targets the\ndetection of specific layouts, offering a more fine-grained granularity than\nwhole-page analysis. A layout can refer to a variety of elements such as\ntextual paragraphs, equations, figures, tables, or charts. The MMDocIR\nbenchmark comprises a rich dataset featuring expertly annotated labels for\n1,685 questions and bootstrapped labels for 173,843 questions, making it a\npivotal resource for advancing multi-modal document retrieval for both training\nand evaluation. Through rigorous experiments, we reveal that (i) visual\nretrievers significantly outperform their text counterparts, (ii) MMDocIR train\nset can effectively benefit the training process of multi-modal document\nretrieval and (iii) text retrievers leveraging on VLM-text perform much better\nthan those using OCR-text. These findings underscores the potential advantages\nof integrating visual elements for multi-modal document retrieval.\n","authors":["Kuicai Dong","Yujing Chang","Xin Deik Goh","Dexun Li","Ruiming Tang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2501.08828v1.pdf","comment":"https://huggingface.co/MMDocIR"},{"id":"http://arxiv.org/abs/2501.08814v1","updated":"2025-01-15T14:12:38Z","published":"2025-01-15T14:12:38Z","title":"SAIF: A Comprehensive Framework for Evaluating the Risks of Generative\n  AI in the Public Sector","summary":"  The rapid adoption of generative AI in the public sector, encompassing\ndiverse applications ranging from automated public assistance to welfare\nservices and immigration processes, highlights its transformative potential\nwhile underscoring the pressing need for thorough risk assessments. Despite its\ngrowing presence, evaluations of risks associated with AI-driven systems in the\npublic sector remain insufficiently explored. Building upon an established\ntaxonomy of AI risks derived from diverse government policies and corporate\nguidelines, we investigate the critical risks posed by generative AI in the\npublic sector while extending the scope to account for its multimodal\ncapabilities. In addition, we propose a Systematic dAta generatIon Framework\nfor evaluating the risks of generative AI (SAIF). SAIF involves four key\nstages: breaking down risks, designing scenarios, applying jailbreak methods,\nand exploring prompt types. It ensures the systematic and consistent generation\nof prompt data, facilitating a comprehensive evaluation while providing a solid\nfoundation for mitigating the risks. Furthermore, SAIF is designed to\naccommodate emerging jailbreak methods and evolving prompt types, thereby\nenabling effective responses to unforeseen risk scenarios. We believe that this\nstudy can play a crucial role in fostering the safe and responsible integration\nof generative AI into the public sector.\n","authors":["Kyeongryul Lee","Heehyeon Kim","Joyce Jiyoung Whang"],"pdf_url":"https://arxiv.org/pdf/2501.08814v1.pdf","comment":"6 pages, 2 figures, 1 tables. AI for Public Missions (AIPM) Workshop\n  at the 39th AAAI Conference on Artificial Intelligence (AAAI 2025)"},{"id":"http://arxiv.org/abs/2501.05816v2","updated":"2025-01-15T14:10:01Z","published":"2025-01-10T09:41:46Z","title":"IndoNLP 2025: Shared Task on Real-Time Reverse Transliteration for\n  Romanized Indo-Aryan languages","summary":"  The paper overviews the shared task on Real-Time Reverse Transliteration for\nRomanized Indo-Aryan languages. It focuses on the reverse transliteration of\nlow-resourced languages in the Indo-Aryan family to their native scripts.\nTyping Romanized Indo-Aryan languages using ad-hoc transliterals and achieving\naccurate native scripts are complex and often inaccurate processes with the\ncurrent keyboard systems. This task aims to introduce and evaluate a real-time\nreverse transliterator that converts Romanized Indo-Aryan languages to their\nnative scripts, improving the typing experience for users. Out of 11 registered\nteams, four teams participated in the final evaluation phase with\ntransliteration models for Sinhala, Hindi and Malayalam. These proposed\nsolutions not only solve the issue of ad-hoc transliteration but also empower\nlow-resource language usability in the digital arena.\n","authors":["Deshan Sumanathilaka","Isuri Anuradha","Ruvan Weerasinghe","Nicholas Micallef","Julian Hough"],"pdf_url":"https://arxiv.org/pdf/2501.05816v2.pdf","comment":"7 Pages, 1 Figure, 3 Tables"}],"Software Engineering":[{"id":"http://arxiv.org/abs/2501.09191v1","updated":"2025-01-15T22:39:50Z","published":"2025-01-15T22:39:50Z","title":"Detecting Vulnerabilities in Encrypted Software Code while Ensuring Code\n  Privacy","summary":"  Software vulnerabilities continue to be the main cause of occurrence for\ncyber attacks. In an attempt to reduce them and improve software quality,\nsoftware code analysis has emerged as a service offered by companies\nspecialising in software testing. However, this service requires software\ncompanies to provide access to their software's code, which raises concerns\nabout code privacy and intellectual property theft. This paper presents a novel\napproach to Software Quality and Privacy, in which testing companies can\nperform code analysis tasks on encrypted software code provided by software\ncompanies while code privacy is preserved. The approach combines Static Code\nAnalysis and Searchable Symmetric Encryption in order to process the source\ncode and build an encrypted inverted index that represents its data and control\nflows. The index is then used to discover vulnerabilities by carrying out\nstatic analysis tasks in a confidential way. With this approach, this paper\nalso defines a new research field -- Confidential Code Analysis --, from which\nother types of code analysis tasks and approaches can be derived. We\nimplemented the approach in a new tool called CoCoA and evaluated it\nexperimentally with synthetic and real PHP web applications. The results show\nthat the tool has similar precision as standard (non-confidential) static\nanalysis tools and a modest average performance overhead of 42.7%.\n","authors":["Jorge Martins","David Dantas","Rafael Ramires","Bernardo Ferreira","Ibéria Medeiros"],"pdf_url":"https://arxiv.org/pdf/2501.09191v1.pdf","comment":"18 pages, 3 figures, 13 pages without refs, 4 appendixes"},{"id":"http://arxiv.org/abs/2501.09182v1","updated":"2025-01-15T22:19:34Z","published":"2025-01-15T22:19:34Z","title":"A Blockchain-Enabled Approach to Cross-Border Compliance and Trust","summary":"  As artificial intelligence (AI) systems become increasingly integral to\ncritical infrastructure and global operations, the need for a unified,\ntrustworthy governance framework is more urgent that ever. This paper proposes\na novel approach to AI governance, utilizing blockchain and distributed ledger\ntechnologies (DLT) to establish a decentralized, globally recognized framework\nthat ensures security, privacy, and trustworthiness of AI systems across\nborders. The paper presents specific implementation scenarios within the\nfinancial sector, outlines a phased deployment timeline over the next decade,\nand addresses potential challenges with solutions grounded in current research.\nBy synthesizing advancements in blockchain, AI ethics, and cybersecurity, this\npaper offers a comprehensive roadmap for a decentralized AI governance\nframework capable of adapting to the complex and evolving landscape of global\nAI regulation.\n","authors":["Vikram Kulothungan"],"pdf_url":"https://arxiv.org/pdf/2501.09182v1.pdf","comment":"This is a preprint of paper that has been accepted for Publication at\n  2024 IEEE International Conference on Trust, Privacy and Security in\n  Intelligent Systems, and Applications"},{"id":"http://arxiv.org/abs/2501.09135v1","updated":"2025-01-15T20:39:32Z","published":"2025-01-15T20:39:32Z","title":"HAFix: History-Augmented Large Language Models for Bug Fixing","summary":"  Recent studies have explored the performance of Large Language Models (LLMs)\non various Software Engineering (SE) tasks, such as code generation and bug\nfixing. However, these approaches typically rely on the context data from the\ncurrent snapshot of the project, overlooking the potential of rich historical\ndata from real-world software repositories. Additionally, the impact of prompt\nstyles on LLM performance within a historical context remains underexplored. To\naddress these gaps, we propose HAFix, which stands for History-Augmented LLMs\non Bug Fixing, a novel approach that leverages individual historical heuristics\nassociated with bugs and aggregates the results of these heuristics (HAFix-Agg)\nto enhance LLMs' bug-fixing capabilities. To empirically evaluate HAFix, we\nemploy Code Llama on a dataset of 51 single-line bugs, sourced from 11\nopen-source projects, by mining the historical context data of bugs and\noperationalizing this context in the form of seven heuristics. Our evaluation\ndemonstrates that historical heuristics significantly enhance bug-fixing\nperformance. For example, the FLN-all heuristic achieves a 10% improvement in\nperformance compared to a non-historical baseline inspired by GitHub Copilot.\nFurthermore, HAFix-Agg fixes 45% more bugs than the baseline, outperforming\nFLN-all and demonstrating the best performance overall. Moreover, within the\ncontext of historical heuristics, we identify the Instruction style prompt as\nthe most effective template for LLMs in bug fixing. Finally, we provide a\npragmatic trade-off analysis of bug-fixing performance, cost, and time\nefficiency, offering valuable insights for the practical deployment of our\napproach in real-world scenarios.\n","authors":["Yu Shi","Abdul Ali Bangash","Emad Fallahzadeh","Bram Adams","Ahmed E. Hassan"],"pdf_url":"https://arxiv.org/pdf/2501.09135v1.pdf","comment":"55 pages, 18 figures"},{"id":"http://arxiv.org/abs/2501.09014v1","updated":"2025-01-15T18:57:17Z","published":"2025-01-15T18:57:17Z","title":"How Do Generative Models Draw a Software Engineer? A Case Study on\n  Stable Diffusion Bias","summary":"  Generative models are nowadays widely used to generate graphical content used\nfor multiple purposes, e.g. web, art, advertisement. However, it has been shown\nthat the images generated by these models could reinforce societal biases\nalready existing in specific contexts. In this paper, we focus on understanding\nif this is the case when one generates images related to various software\nengineering tasks. In fact, the Software Engineering (SE) community is not\nimmune from gender and ethnicity disparities, which could be amplified by the\nuse of these models. Hence, if used without consciousness, artificially\ngenerated images could reinforce these biases in the SE domain. Specifically,\nwe perform an extensive empirical evaluation of the gender and ethnicity bias\nexposed by three versions of the Stable Diffusion (SD) model (a very popular\nopen-source text-to-image model) - SD 2, SD XL, and SD 3 - towards SE tasks. We\nobtain 6,720 images by feeding each model with two sets of prompts describing\ndifferent software-related tasks: one set includes the Software Engineer\nkeyword, and one set does not include any specification of the person\nperforming the task. Next, we evaluate the gender and ethnicity disparities in\nthe generated images. Results show how all models are significantly biased\ntowards male figures when representing software engineers. On the contrary,\nwhile SD 2 and SD XL are strongly biased towards White figures, SD 3 is\nslightly more biased towards Asian figures. Nevertheless, all models\nsignificantly under-represent Black and Arab figures, regardless of the prompt\nstyle used. The results of our analysis highlight severe concerns about\nadopting those models to generate content for SE tasks and open the field for\nfuture research on bias mitigation in this context.\n","authors":["Tosin Fadahunsi","Giordano d'Aloisio","Antinisca Di Marco","Federica Sarro"],"pdf_url":"https://arxiv.org/pdf/2501.09014v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08947v1","updated":"2025-01-15T16:49:32Z","published":"2025-01-15T16:49:32Z","title":"Taint Analysis for Graph APIs Focusing on Broken Access Control","summary":"  Graph APIs are capable of flexibly retrieving or manipulating\ngraph-structured data over the web. This rather novel type of APIs presents new\nchallenges when it comes to properly securing the APIs against the usual web\napplication security risks, e.g., broken access control. A prominent security\ntesting approach is taint analysis, which traces tainted, i.e.,\nsecurity-relevant, data from sources (where tainted data is inserted) to sinks\n(where the use of tainted data may lead to a security risk), over the\ninformation flow in an application.\n  We present a first systematic approach to static and dynamic taint analysis\nfor Graph APIs focusing on broken access control. The approach comprises the\nfollowing. We taint nodes in the Graph API if they represent data requiring\nspecific privileges in order to be retrieved or manipulated, and identify API\ncalls which are related to sources and sinks. Then, we statically analyze\nwhether tainted information flow between API source and sink calls occurs. To\nthis end, we model the API calls using graph transformation rules. We\nsubsequently use critical pair analysis to automatically analyze potential\ndependencies between rules representing source calls and rules representing\nsink calls. We distinguish direct from indirect tainted information flow and\nargue under which conditions the CPA is able to detect not only direct, but\nalso indirect tainted flow. The static taint analysis (i) identifies flows that\nneed to be further reviewed, since tainted nodes may be created by an API call\nand used or manipulated by another API call later without having the necessary\nprivileges, and (ii) can be used to systematically design dynamic security\ntests for broken access control. The dynamic taint analysis checks if potential\nbroken access control risks detected during the static taint analysis really\noccur. We apply the approach to a part of the GitHub GraphQL API.\n","authors":["Leen Lambers","Lucas Sakizloglou","Taisiya Khakharova","Fernando Orejas"],"pdf_url":"https://arxiv.org/pdf/2501.08947v1.pdf","comment":"Intermediate preprint for submission to ICGT 24 Special Issue in LMCS"},{"id":"http://arxiv.org/abs/2501.08909v1","updated":"2025-01-15T16:19:12Z","published":"2025-01-15T16:19:12Z","title":"Software Testing for Extended Reality Applications: A Systematic Mapping\n  Study","summary":"  Extended Reality (XR) is an emerging technology spanning diverse application\ndomains and offering immersive user experiences. However, its unique\ncharacteristics, such as six degrees of freedom interactions, present\nsignificant testing challenges distinct from traditional 2D GUI applications,\ndemanding novel testing techniques to build high-quality XR applications. This\npaper presents the first systematic mapping study on software testing for XR\napplications. We selected 34 studies focusing on techniques and empirical\napproaches in XR software testing for detailed examination. The studies are\nclassified and reviewed to address the current research landscape, test facets,\nand evaluation methodologies in the XR testing domain. Additionally, we provide\na repository summarising the mapping study, including datasets and tools\nreferenced in the selected studies, to support future research and practical\napplications. Our study highlights open challenges in XR testing and proposes\nactionable future research directions to address the gaps and advance the field\nof XR software testing.\n","authors":["Ruizhen Gu","José Miguel Rojas","Donghwan Shin"],"pdf_url":"https://arxiv.org/pdf/2501.08909v1.pdf","comment":"50 pages, 10 figures"},{"id":"http://arxiv.org/abs/2501.08908v1","updated":"2025-01-15T16:18:13Z","published":"2025-01-15T16:18:13Z","title":"When Uncertainty Leads to Unsafety: Empirical Insights into the Role of\n  Uncertainty in Unmanned Aerial Vehicle Safety","summary":"  Despite the recent developments in obstacle avoidance and other safety\nfeatures, autonomous Unmanned Aerial Vehicles (UAVs) continue to face safety\nchallenges. No previous work investigated the relationship between the\nbehavioral uncertainty of a UAV and the unsafety of its flight. By quantifying\nuncertainty, it is possible to develop a predictor for unsafety, which acts as\na flight supervisor. We conducted a large-scale empirical investigation of\nsafety violations using PX4-Autopilot, an open-source UAV software platform.\nOur dataset of over 5,000 simulated flights, created to challenge obstacle\navoidance, allowed us to explore the relation between uncertain UAV decisions\nand safety violations: up to 89% of unsafe UAV states exhibit significant\ndecision uncertainty, and up to 74% of uncertain decisions lead to unsafe\nstates. Based on these findings, we implemented Superialist (Supervising\nAutonomous Aerial Vehicles), a runtime uncertainty detector based on\nautoencoders, the state-of-the-art technology for anomaly detection.\nSuperialist achieved high performance in detecting uncertain behaviors with up\nto 96% precision and 93% recall. Despite the observed performance degradation\nwhen using the same approach for predicting unsafety (up to 74% precision and\n87% recall), Superialist enabled early prediction of unsafe states up to 50\nseconds in advance.\n","authors":["Sajad Khatiri","Fatemeh Mohammadi Amin","Sebastiano Panichella","Paolo Tonella"],"pdf_url":"https://arxiv.org/pdf/2501.08908v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2501.08840v1","updated":"2025-01-15T14:50:46Z","published":"2025-01-15T14:50:46Z","title":"CveBinarySheet: A Comprehensive Pre-built Binaries Database for IoT\n  Vulnerability Analysis","summary":"  Binary Static Code Analysis (BSCA) is a pivotal area in software\nvulnerability research, focusing on the precise localization of vulnerabilities\nwithin binary executables. Despite advancements in BSCA techniques, there is a\nnotable scarcity of comprehensive and readily usable vulnerability datasets\ntailored for diverse environments such as IoT, UEFI, and MCU firmware. To\naddress this gap, we present CveBinarySheet, a meticulously curated database\ncontaining 1033 CVE entries spanning from 1999 to 2024. Our dataset encompasses\n16 essential third-party components, including busybox and curl, and supports\nfive CPU architectures: x86-64, i386, MIPS, ARMv7, and RISC-V64. Each\nprecompiled binary is available at two compiler optimization levels (O0 and\nO3), facilitating comprehensive vulnerability analysis under different\ncompilation scenarios. By providing detailed metadata and diverse binary\nsamples, CveBinarySheet aims to accelerate the development of state-of-the-art\nBSCA tools, binary similarity analysis, and vulnerability matching\napplications.\n","authors":["Lingfeng Chen"],"pdf_url":"https://arxiv.org/pdf/2501.08840v1.pdf","comment":"4 pages, dataset for binary SCA training"},{"id":"http://arxiv.org/abs/2501.08834v1","updated":"2025-01-15T14:38:18Z","published":"2025-01-15T14:38:18Z","title":"Smart Contract Fuzzing Towards Profitable Vulnerabilities","summary":"  Billions of dollars are transacted through smart contracts, making\nvulnerabilities a major financial risk. One focus in the security arms race is\non profitable vulnerabilities that attackers can exploit. Fuzzing is a key\nmethod for identifying these vulnerabilities. However, current solutions face\ntwo main limitations: a lack of profit-centric techniques for expediting\ndetection, and insufficient automation in maximizing the profitability of\ndiscovered vulnerabilities, leaving the analysis to human experts. To address\nthese gaps, we have developed VERITE, a profit-centric smart contract fuzzing\nframework that not only effectively detects those profitable vulnerabilities\nbut also maximizes the exploited profits.\n  VERITE has three key features: 1) DeFi action-based mutators for boosting the\nexploration of transactions with different fund flows; 2) potentially\nprofitable candidates identification criteria, which checks whether the input\nhas caused abnormal fund flow properties during testing; 3) a gradient\ndescent-based profit maximization strategy for these identified candidates.\n  VERITE is fully developed from scratch and evaluated on a dataset consisting\nof 61 exploited real-world DeFi projects with an average of over 1.1 million\ndollars loss. The results show that VERITE can automatically extract more than\n18 million dollars in total and is significantly better than state-of-the-art\nfuzzer ITYFUZZ in both detection (29/9) and exploitation (58 times more profits\ngained on average). Remarkbly, in 12 targets, it gains more profits than\nreal-world attacking exploits (1.01 to 11.45 times more). VERITE is also\napplied by auditors in contract auditing, where 6 (5 high severity) zero-day\nvulnerabilities are found with over $2,500 bounty rewards.\n","authors":["Ziqiao Kong","Cen Zhang","Maoyi Xie","Ming Hu","Yue Xue","Ye Liu","Haijun Wang","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2501.08834v1.pdf","comment":"Submission version without revisions requested from peer reviews. The\n  camera-ready version will be available soon"},{"id":"http://arxiv.org/abs/2408.13517v2","updated":"2025-01-15T14:36:05Z","published":"2024-08-24T08:43:03Z","title":"Scalable Similarity-Aware Test Suite Minimization with Reinforcement\n  Learning","summary":"  The Multi-Criteria Test Suite Minimization (MCTSM) problem aims to remove\nredundant test cases, guided by adequacy criteria such as code coverage or\nfault detection capability. However, current techniques either exhibit a high\nloss of fault detection ability or face scalability challenges due to the\nNP-hard nature of the problem, which limits their practical utility. We propose\nTripRL, a novel technique that integrates traditional criteria such as\nstatement coverage and fault detection ability with test coverage similarity\ninto an Integer Linear Program (ILP), to produce a diverse reduced test suite\nwith high test effectiveness. TripRL leverages bipartite graph representation\nand its embedding for concise ILP formulation and combines ILP with effective\nreinforcement learning (RL) training. This combination renders large-scale test\nsuite minimization more scalable and enhances test effectiveness. Our empirical\nevaluations demonstrate that TripRL's runtime scales linearly with the\nmagnitude of the MCTSM problem. Notably, for large test suites from the\nDefects4j dataset where existing approaches fail to provide solutions within a\nreasonable time frame, our technique consistently delivers solutions in less\nthan 47 minutes. The reduced test suites produced by TripRL also maintain the\noriginal statement coverage and fault detection ability while having a higher\npotential to detect unknown faults.\n","authors":["Sijia Gu","Ali Mesbah"],"pdf_url":"https://arxiv.org/pdf/2408.13517v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03093v3","updated":"2025-01-15T13:46:19Z","published":"2024-09-04T21:46:18Z","title":"ASTER: Natural and Multi-language Unit Test Generation with LLMs","summary":"  Implementing automated unit tests is an important but time-consuming activity\nin software development. To assist developers in this task, many techniques for\nautomating unit test generation have been developed. However, despite this\neffort, usable tools exist for very few programming languages. Moreover,\nstudies have found that automatically generated tests suffer poor readability\nand do not resemble developer-written tests. In this work, we present a\nrigorous investigation of how large language models (LLMs) can help bridge the\ngap. We describe a generic pipeline that incorporates static analysis to guide\nLLMs in generating compilable and high-coverage test cases. We illustrate how\nthe pipeline can be applied to different programming languages, specifically\nJava and Python, and to complex software requiring environment mocking. We\nconducted an empirical study to assess the quality of the generated tests in\nterms of code coverage and test naturalness -- evaluating them on standard as\nwell as enterprise Java applications and a large Python benchmark. Our results\ndemonstrate that LLM-based test generation, when guided by static analysis, can\nbe competitive with, and even outperform, state-of-the-art test-generation\ntechniques in coverage achieved while also producing considerably more natural\ntest cases that developers find easy to understand. We also present the results\nof a user study, conducted with 161 professional developers, that highlights\nthe naturalness characteristics of the tests generated by our approach.\n","authors":["Rangeet Pan","Myeongsoo Kim","Rahul Krishna","Raju Pavuluri","Saurabh Sinha"],"pdf_url":"https://arxiv.org/pdf/2409.03093v3.pdf","comment":"Accepted at ICSE-SEIP, 2025"},{"id":"http://arxiv.org/abs/2501.08774v1","updated":"2025-01-15T12:53:49Z","published":"2025-01-15T12:53:49Z","title":"How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in\n  Software Engineering","summary":"  Artificial intelligence (AI), including large language models and generative\nAI, is emerging as a significant force in software development, offering\ndevelopers powerful tools that span the entire development lifecycle. Although\nsoftware engineering research has extensively studied AI tools in software\ndevelopment, the specific types of interactions between developers and these\nAI-powered tools have only recently begun to receive attention. Understanding\nand improving these interactions has the potential to improve productivity,\ntrust, and efficiency in AI-driven workflows. In this paper, we propose a\ntaxonomy of interaction types between developers and AI tools, identifying\neleven distinct interaction types, such as auto-complete code suggestions,\ncommand-driven actions, and conversational assistance. Building on this\ntaxonomy, we outline a research agenda focused on optimizing AI interactions,\nimproving developer control, and addressing trust and usability challenges in\nAI-assisted development. By establishing a structured foundation for studying\ndeveloper-AI interactions, this paper aims to stimulate research on creating\nmore effective, adaptive AI tools for software development.\n","authors":["Christoph Treude","Marco A. Gerosa"],"pdf_url":"https://arxiv.org/pdf/2501.08774v1.pdf","comment":"Accepted at 2nd ACM International Conference on AI Foundation Models\n  and Software Engineering (FORGE 2025)"},{"id":"http://arxiv.org/abs/2501.08760v1","updated":"2025-01-15T12:25:56Z","published":"2025-01-15T12:25:56Z","title":"Leveraging LLM Agents for Translating Network Configurations","summary":"  Configuration translation is a critical and frequent task in network\noperations. When a network device is damaged or outdated, administrators need\nto replace it to maintain service continuity. The replacement devices may\noriginate from different vendors, necessitating configuration translation to\nensure seamless network operation. However, translating configurations manually\nis a labor-intensive and error-prone process. In this paper, we propose an\nintent-based framework for translating network configuration with Large\nLanguage Model (LLM) Agents. The core of our approach is an Intent-based\nRetrieval Augmented Generation (IRAG) module that systematically splits a\nconfiguration file into fragments, extracts intents, and generates accurate\ntranslations. We also design a two-stage verification method to validate the\nsyntax and semantics correctness of the translated configurations. We implement\nand evaluate the proposed method on real-world network configurations.\nExperimental results show that our method achieves 97.74% syntax correctness,\noutperforming state-of-the-art methods in translation accuracy.\n","authors":["Yunze Wei","Xiaohui Xie","Yiwei Zuo","Tianshuo Hu","Xinyi Chen","Kaiwen Chi","Yong Cui"],"pdf_url":"https://arxiv.org/pdf/2501.08760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08109v2","updated":"2025-01-15T11:57:34Z","published":"2024-12-11T05:31:39Z","title":"Unseen Horizons: Unveiling the Real Capability of LLM Code Generation\n  Beyond the Familiar","summary":"  Recently, large language models (LLMs) have shown strong potential in code\ngeneration tasks. However, there are still gaps before they can be fully\napplied in actual software development processes. Accurately assessing the code\ngeneration capabilities of large language models has become an important basis\nfor evaluating and improving the models. Some existing works have constructed\ndatasets to evaluate the capabilities of these models. However, the current\nevaluation process may encounter the illusion of \"Specialist in Familiarity\",\nprimarily due to three gaps: the exposure of target code, case timeliness, and\ndependency availability. The fundamental reason for these gaps is that the code\nin current datasets may have been extensively exposed and exercised during the\ntraining phase, and due to the continuous training and development of LLM,\ntheir timeliness has been severely compromised. The key to solve the problem is\nto, as much as possible, evaluate the LLMs using code that they have not\nencountered before. Thus, the fundamental idea in this paper is to draw on the\nconcept of code obfuscation, changing code at different levels while ensuring\nthe functionality and output. To this end, we build a code-obfuscation based\nbenchmark OBFUSEVAL. We first collect 1,354 raw cases from five real-world\nprojects, including function description and code. Then we use three-level\nstrategy (symbol, structure and semantic) to obfuscate descriptions, code and\ncontext dependencies. We evaluate four LLMs on OBFU- SEVAL and compared the\neffectiveness of different obfuscation strategy. We use official test suites of\nthese projects to evaluate the generated code. The results show that after\nobfuscation, the average decrease ratio of test pass rate can up to 62.5%.\n","authors":["Yuanliang Zhang","Yifan Xie","Shanshan Li","Ke Liu","Chong Wang","Zhouyang Jia","Xiangbing Huang","Jie Song","Chaopeng Luo","Zhizheng Zheng","Rulin Xu","Yitong Liu","Si Zheng","Xiangke Liao"],"pdf_url":"https://arxiv.org/pdf/2412.08109v2.pdf","comment":"Accepted by the 47th International Conference on Software Engineering\n  (ICSE 2025)"},{"id":"http://arxiv.org/abs/2501.08670v1","updated":"2025-01-15T09:04:30Z","published":"2025-01-15T09:04:30Z","title":"Augmenting Smart Contract Decompiler Output through Fine-grained\n  Dependency Analysis and LLM-facilitated Semantic Recovery","summary":"  Decompiler is a specialized type of reverse engineering tool extensively\nemployed in program analysis tasks, particularly in program comprehension and\nvulnerability detection. However, current Solidity smart contract decompilers\nface significant limitations in reconstructing the original source code. In\nparticular, the bottleneck of SOTA decompilers lies in inaccurate method\nidentification, incorrect variable type recovery, and missing contract\nattributes. These deficiencies hinder downstream tasks and understanding of the\nprogram logic. To address these challenges, we propose SmartHalo, a new\nframework that enhances decompiler output by combining static analysis (SA) and\nlarge language models (LLM). SmartHalo leverages the complementary strengths of\nSA's accuracy in control and data flow analysis and LLM's capability in\nsemantic prediction. More specifically, \\system{} constructs a new data\nstructure - Dependency Graph (DG), to extract semantic dependencies via static\nanalysis. Then, it takes DG to create prompts for LLM optimization. Finally,\nthe correctness of LLM outputs is validated through symbolic execution and\nformal verification. Evaluation on a dataset consisting of 465 randomly\nselected smart contract methods shows that SmartHalo significantly improves the\nquality of the decompiled code, compared to SOTA decompilers (e.g., Gigahorse).\nNotably, integrating GPT-4o with SmartHalo further enhances its performance,\nachieving precision rates of 87.39% for method boundaries, 90.39% for variable\ntypes, and 80.65% for contract attributes.\n","authors":["Zeqin Liao","Yuhong Nan","Zixu Gao","Henglong Liang","Sicheng Hao","Peifan Reng","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2501.08670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08600v1","updated":"2025-01-15T05:54:33Z","published":"2025-01-15T05:54:33Z","title":"AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL","summary":"  As REST APIs have become widespread in modern web services, comprehensive\ntesting of these APIs has become increasingly crucial. Due to the vast search\nspace consisting of operations, parameters, and parameter values along with\ntheir complex dependencies and constraints, current testing tools suffer from\nlow code coverage, leading to suboptimal fault detection. To address this\nlimitation, we present a novel tool, AutoRestTest, which integrates the\nSemantic Operation Dependency Graph (SODG) with Multi-Agent Reinforcement\nLearning (MARL) and large language models (LLMs) for effective REST API\ntesting. AutoRestTest determines operation-dependent parameters using the SODG\nand employs five specialized agents (operation, parameter, value, dependency,\nand header) to identify dependencies of operations and generate operation\nsequences, parameter combinations, and values. AutoRestTest provides a\ncommand-line interface and continuous telemetry on successful operation count,\nunique server errors detected, and time elapsed. Upon completion, AutoRestTest\ngenerates a detailed report highlighting errors detected and operations\nexercised. In this paper, we introduce our tool and present preliminary\nresults.\n","authors":["Tyler Stennett","Myeongsoo Kim","Saurabh Sinha","Alessandro Orso"],"pdf_url":"https://arxiv.org/pdf/2501.08600v1.pdf","comment":"To be published in the 47th IEEE/ACM International Conference on\n  Software Engineering - Demonstration Track (ICSE-Demo 2025)"},{"id":"http://arxiv.org/abs/2501.08598v1","updated":"2025-01-15T05:51:20Z","published":"2025-01-15T05:51:20Z","title":"LlamaRestTest: Effective REST API Testing with Small Language Models","summary":"  Modern web services rely heavily on REST APIs, typically documented using the\nOpenAPI specification. The widespread adoption of this standard has resulted in\nthe development of many black-box testing tools that generate tests based on\nthese specifications. Recent advancements in Natural Language Processing (NLP),\nparticularly with Large Language Models (LLMs), have enhanced REST API testing\nby extracting actionable rules and generating input values from the\nhuman-readable portions of the specification. However, these advancements\noverlook the potential of continuously refining the identified rules and test\ninputs based on server responses. To address this limitation, we present\nLlamaRestTest, a novel approach that employs two custom LLMs to generate\nrealistic test inputs and uncover parameter dependencies during the testing\nprocess by incorporating server responses. These LLMs are created by\nfine-tuning the Llama3-8b model, using mined datasets of REST API example\nvalues and inter-parameter dependencies. We evaluated LlamaRestTest on 12\nreal-world services (including popular services such as Spotify), comparing it\nagainst RESTGPT, a GPT-powered specification-enhancement tool, as well as\nseveral state-of-the-art REST API testing tools, including RESTler, MoRest,\nEvoMaster, and ARAT-RL. Our results show that fine-tuning enables smaller LLMs\nto outperform larger models in detecting actionable rules and generating inputs\nfor REST API testing. We evaluated configurations from the base Llama3-8B to\nfine-tuned versions and explored 2-bit, 4-bit, and 8-bit quantization for\nefficiency. LlamaRestTest surpasses state-of-the-art tools in code coverage and\nerror detection, even with RESTGPT-enhanced specifications, and an ablation\nstudy highlights the impact of its novel components.\n","authors":["Myeongsoo Kim","Saurabh Sinha","Alessandro Orso"],"pdf_url":"https://arxiv.org/pdf/2501.08598v1.pdf","comment":"To be published in the ACM International Conference on the\n  Foundations of Software Engineering (FSE 2025)"},{"id":"http://arxiv.org/abs/2408.04820v2","updated":"2025-01-15T03:43:22Z","published":"2024-08-09T02:22:51Z","title":"Natural Language Outlines for Code: Literate Programming in the LLM Era","summary":"  We propose using natural language outlines as a novel modality and\ninteraction surface for providing AI assistance to developers throughout the\nsoftware development process. An NL outline for a code function comprises\nmultiple statements written in concise prose, which partition the code and\nsummarize its main ideas in the style of literate programming. Crucially, we\nfind that modern LLMs can generate accurate and high-quality NL outlines in\npractice. Moreover, NL outlines enable a bidirectional sync between code and\nNL, allowing changes in one to be automatically reflected in the other. We\ndiscuss many use cases for NL outlines: they can accelerate understanding and\nnavigation of code and diffs, simplify code maintenance, augment code search,\nsteer code generation, and more. We then propose and compare multiple LLM\nprompting techniques for generating outlines and ask professional developers to\njudge outline quality. Finally, we present two case studies applying NL\noutlines toward code review and malware detection.\n","authors":["Kensen Shi","Deniz Altınbüken","Saswat Anand","Mihai Christodorescu","Katja Grünwedel","Alexa Koenings","Sai Naidu","Anurag Pathak","Marc Rasi","Fredde Ribeiro","Brandon Ruffin","Siddhant Sanyam","Maxim Tabachnyk","Sara Toth","Roy Tu","Tobias Welp","Pengcheng Yin","Manzil Zaheer","Satish Chandra","Charles Sutton"],"pdf_url":"https://arxiv.org/pdf/2408.04820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08553v2","updated":"2025-01-15T03:37:00Z","published":"2024-08-16T06:37:59Z","title":"Improving the Ability of Pre-trained Language Model by Imparting Large\n  Language Model's Experience","summary":"  Large Language Models (LLMs) and pre-trained Language Models (LMs) have\nachieved impressive success on many software engineering tasks (e.g., code\ncompletion and code generation). By leveraging huge existing code corpora\n(e.g., GitHub), these models can understand the patterns in source code and use\nthese patterns to predict code properties. However, LLMs under few-shot\nlearning perform poorly on non-generative tasks (e.g., fault localization and\nvulnerability localization), and fine-tuning LLMs is time-consuming and costly\nfor end users and small organizations. Furthermore, the performance of\nfine-tuning LMs for non-generative tasks is impressive, yet it heavily depends\non the amount and quality of data. As a result, the current lack of data and\nthe high cost of collecting it in real-world scenarios further limit the\napplicability of LMs. In this paper, we leverage the powerful generation\ncapabilities of LLMs to enhance pre-trained LMs. Specifically, we use LLMs to\ngenerate domain-specific data, thereby improving the performance of pre-trained\nLMs on the target tasks. We conduct experiments by combining different LLMs in\nour generation phase and introducing various LMs to learn from the\nLLM-generated data. Then, we compare the performance of these LMs before and\nafter learning the data. We find that LLM-generated data significantly enhances\nthe performance of LMs. The improvement can reach up to 58.36% for fault\nlocalization and up to 6.09% for clone detection.\n","authors":["Xin Yin","Chao Ni","Xiaodan Xu","Xinrui Li","Xiaohu Yang"],"pdf_url":"https://arxiv.org/pdf/2408.08553v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08550v1","updated":"2025-01-15T03:20:13Z","published":"2025-01-15T03:20:13Z","title":"Formal Model Guided Conformance Testing for Blockchains","summary":"  Modern blockchains increasingly consist of multiple clients that implement\nthe blockchain protocol. If there is a semantic mismatch between the protocol\nimplementations, the blockchain can permanently split and introduce new attack\nvectors. Current ad-hoc test suites for client implementations are not\nsufficient to ensure a high degree of protocol conformance. As an alternative,\nwe present a framework that performs protocol conformance testing using a\nformal model of the protocol and an implementation running inside a\ndeterministic blockchain simulator. Our framework consists of two complementary\nworkflows that use the components as trace generators and checkers. Our insight\nis that both workflows are needed to detect all types of violations. We have\napplied and demonstrated the utility of our framework on an industrial strength\nconsensus protocol.\n","authors":["Filip Drobnjakovic","Amir Kashapov","Matija Kupresanin","Bernhard Scholz","Pavle Subotic"],"pdf_url":"https://arxiv.org/pdf/2501.08550v1.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2408.04806v2","updated":"2025-01-15T23:54:02Z","published":"2024-08-09T01:21:52Z","title":"When Refreshable Tactile Displays Meet Conversational Agents:\n  Investigating Accessible Data Presentation and Analysis with Touch and Speech","summary":"  Despite the recent surge of research efforts to make data visualizations\naccessible to people who are blind or have low vision (BLV), how to support BLV\npeople's data analysis remains an important and challenging question. As\nrefreshable tactile displays (RTDs) become cheaper and conversational agents\ncontinue to improve, their combination provides a promising approach to support\nBLV people's interactive data exploration and analysis. To understand how BLV\npeople would use and react to a system combining an RTD with a conversational\nagent, we conducted a Wizard-of-Oz study with 11 BLV participants, where they\ninteracted with line charts, bar charts, and isarithmic maps. Our analysis of\nparticipants' interactions led to the identification of nine distinct patterns.\nWe also learned that the choice of modalities depended on the type of task and\nprior experience with tactile graphics, and that participants strongly\npreferred the combination of RTD and speech to a single modality. In addition,\nparticipants with more tactile experience described how tactile images\nfacilitated a deeper engagement with the data and supported independent\ninterpretation. Our findings will inform the design of interfaces for such\ninteractive mixed-modality systems.\n","authors":["Samuel Reinders","Matthew Butler","Ingrid Zukerman","Bongshin Lee","Lizhen Qu","Kim Marriott"],"pdf_url":"https://arxiv.org/pdf/2408.04806v2.pdf","comment":"Accepted to be presented at IEEE VIS 2024 (Honorable Mention Award)\n  and published in IEEE TVCG; Replacement: typos corrected, external DOI added"},{"id":"http://arxiv.org/abs/2501.09204v1","updated":"2025-01-15T23:44:41Z","published":"2025-01-15T23:44:41Z","title":"3D Printed Maps and Icons for Inclusion: Testing in the Wild by People\n  who are Blind or have Low Vision","summary":"  The difficulty and consequent fear of travel is one of the most disabling\nconsequences of blindness and severe vision impairment, affecting confidence\nand quality of life. Traditional tactile graphics are vital in the Orientation\nand Mobility training process, however 3D printing may have the capacity to\nenable production of more meaningful and inclusive maps. This study explored\nthe use of 3D printed maps on site at a public event to examine their\nsuitability and to identify guidelines for the design of future 3D maps. An\niterative design process was used in the production of the 3D maps, with\nfeedback from visitors who are blind or have low vision informing the\nrecommendations for their design and use. For example, it was found that many\nrepresentational 3D icons could be recognised by touch without the need for a\nkey and that such a map helped form mental models of the event space. Complex\nmaps, however, require time to explore and should be made available before an\nevent or at the entrance in a comfortable position. The maps were found to\nsupport the orientation and mobility process, and importantly to also promote a\npositive message about inclusion and accessibility.\n","authors":["Leona Holloway","Kim Marriott","Matthew Butler","Samuel Reinders"],"pdf_url":"https://arxiv.org/pdf/2501.09204v1.pdf","comment":"Paper presented at ACM ASSETS 2019: Proceedings of the 21st\n  International ACM SIGACCESS Conference on Computers and Accessibility, ACM,\n  New York, October 2019"},{"id":"http://arxiv.org/abs/2412.15473v2","updated":"2025-01-15T23:11:07Z","published":"2024-12-20T01:05:23Z","title":"Predicting Long-Term Student Outcomes from Short-Term EdTech Log Data","summary":"  Educational stakeholders are often particularly interested in sparse, delayed\nstudent outcomes, like end-of-year statewide exams. The rare occurrence of such\nassessments makes it harder to identify students likely to fail such\nassessments, as well as making it slow for researchers and educators to be able\nto assess the effectiveness of particular educational tools. Prior work has\nprimarily focused on using logs from students full usage (e.g. year-long) of an\neducational product to predict outcomes, or considered predictive accuracy\nusing a few minutes to predict outcomes after a short (e.g. 1 hour) session. In\ncontrast, we investigate machine learning predictors using students' logs\nduring their first few hours of usage can provide useful predictive insight\ninto those students' end-of-school year external assessment. We do this on\nthree diverse datasets: from students in Uganda using a literacy game product,\nand from students in the US using two mathematics intelligent tutoring systems.\nWe consider various measures of the accuracy of the resulting predictors,\nincluding its ability to identify students at different parts along the\nassessment performance distribution. Our findings suggest that short-term log\nusage data, from 2-5 hours, can be used to provide valuable signal about\nstudents' long-term external performance.\n","authors":["Ge Gao","Amelia Leon","Andrea Jetten","Jasmine Turner","Husni Almoubayyed","Stephen Fancsali","Emma Brunskill"],"pdf_url":"https://arxiv.org/pdf/2412.15473v2.pdf","comment":"Accepted to the 15th International Learning Analytics and Knowledge\n  Conference (LAK2025)"},{"id":"http://arxiv.org/abs/2501.09165v1","updated":"2025-01-15T21:32:04Z","published":"2025-01-15T21:32:04Z","title":"Breaking Barriers or Building Dependency? Exploring Team-LLM\n  Collaboration in AI-infused Classroom Debate","summary":"  Classroom debates are a unique form of collaborative learning characterized\nby fast-paced, high-intensity interactions that foster critical thinking and\nteamwork. Despite the recognized importance of debates, the role of AI tools,\nparticularly LLM-based systems, in supporting this dynamic learning environment\nhas been under-explored in HCI. This study addresses this opportunity by\ninvestigating the integration of LLM-based AI into real-time classroom debates.\nOver four weeks, 22 students in a Design History course participated in three\nrounds of debates with support from ChatGPT. The findings reveal how learners\nprompted the AI to offer insights, collaboratively processed its outputs, and\ndivided labor in team-AI interactions. The study also surfaces key advantages\nof AI usage, reducing social anxiety, breaking communication barriers, and\nproviding scaffolding for novices, alongside risks, such as information\noverload and cognitive dependency, which could limit learners' autonomy. We\nthereby discuss a set of nuanced implications for future HCI exploration.\n","authors":["Zihan Zhang","Black Sun","Pengcheng An"],"pdf_url":"https://arxiv.org/pdf/2501.09165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09099v1","updated":"2025-01-15T19:32:32Z","published":"2025-01-15T19:32:32Z","title":"Drama Llama: An LLM-Powered Storylets Framework for Authorable\n  Responsiveness in Interactive Narrative","summary":"  In this paper, we present Drama Llama, an LLM-powered storylets framework\nthat supports the authoring of responsive, open-ended interactive stories. DL\ncombines the structural benefits of storylet-based systems with the generative\ncapabilities of large language models, enabling authors to create responsive\ninteractive narratives while maintaining narrative control. Rather than\ncrafting complex logical preconditions in a general-purpose or domain-specific\nprogramming language, authors define triggers in natural language that fire at\nappropriate moments in the story. Through a preliminary authoring study with\nsix content authors, we present initial evidence that DL can generate coherent\nand meaningful narratives with believable character interactions. This work\nsuggests directions for hybrid approaches that enhance authorial control while\nsupporting emergent narrative generation through LLMs.\n","authors":["Yuqian Sun","Phoebe J. Wang","John Joon Young Chung","Melissa Roemmele","Taewook Kim","Max Kreminski"],"pdf_url":"https://arxiv.org/pdf/2501.09099v1.pdf","comment":"10 pages, 5 photos"},{"id":"http://arxiv.org/abs/2501.08102v2","updated":"2025-01-15T18:10:00Z","published":"2025-01-14T13:19:47Z","title":"Consistency of Responses and Continuations Generated by Large Language\n  Models on Social Media","summary":"  Large Language Models (LLMs) demonstrate remarkable capabilities in text\ngeneration, yet their emotional consistency and semantic coherence in social\nmedia contexts remain insufficiently understood. This study investigates how\nLLMs handle emotional content and maintain semantic relationships through\ncontinuation and response tasks using two open-source models: Gemma and Llama.\nBy analyzing climate change discussions from Twitter and Reddit, we examine\nemotional transitions, intensity patterns, and semantic similarity between\nhuman-authored and LLM-generated content. Our findings reveal that while both\nmodels maintain high semantic coherence, they exhibit distinct emotional\npatterns: Gemma shows a tendency toward negative emotion amplification,\nparticularly anger, while maintaining certain positive emotions like optimism.\nLlama demonstrates superior emotional preservation across a broader spectrum of\naffects. Both models systematically generate responses with attenuated\nemotional intensity compared to human-authored content and show a bias toward\npositive emotions in response tasks. Additionally, both models maintain strong\nsemantic similarity with original texts, though performance varies between\ncontinuation and response tasks. These findings provide insights into LLMs'\nemotional and semantic processing capabilities, with implications for their\ndeployment in social media contexts and human-AI interaction design.\n","authors":["Wenlu Fan","Yuqi Zhu","Chenyang Wang","Bin Wang","Wentao Xu"],"pdf_url":"https://arxiv.org/pdf/2501.08102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09838v3","updated":"2025-01-15T17:20:30Z","published":"2024-12-13T04:09:39Z","title":"Cultivating a Supportive Sphere: Designing Technology to Increase Social\n  Support for Foster-Involved Youth","summary":"  Approximately 400,000 youth in the US are living in foster care due to\nexperiences with abuse or neglect at home. For multiple reasons, these youth\noften don't receive adequate social support from those around them. Despite\ntechnology's potential, very little work has explored how these tools can\nprovide more support to foster-involved youth. To begin to fill this gap, we\nworked with current and former foster-involved youth to develop the first\ndigital tool that aims to increase social support for this population, creating\na novel system in which users complete reflective check-ins in an online\ncommunity setting. We then conducted a pilot study with 15 current and former\nfoster-involved youth, comparing the effect of using the app for two weeks to\ntwo weeks of no intervention. We collected qualitative and quantitative data,\nwhich demonstrated that this type of interface can provide youth with types of\nsocial support that are often not provided by foster care services and other\ndigital interventions. The paper details the motivation behind the app, the\ntrauma-informed design process, and insights gained from this initial\nevaluation study. Finally, the paper concludes with recommendations for\ndesigning digital tools that effectively provide social support to\nfoster-involved youth.\n","authors":["Ila Kumar","Craig Ferguson","Jiayi Wu","Rosalind W Picard"],"pdf_url":"https://arxiv.org/pdf/2412.09838v3.pdf","comment":"Accepted for publication in the 28th ACM SIGCHI Conference on\n  Computer-Supported Cooperative Work & Social Computing (CSCW 2025)"},{"id":"http://arxiv.org/abs/2403.00582v2","updated":"2025-01-15T16:47:28Z","published":"2024-03-01T15:02:36Z","title":"To Trust or Distrust Trust Measures: Validating Questionnaires for Trust\n  in AI","summary":"  Despite the importance of trust in human-AI interactions, researchers must\nadopt questionnaires from other disciplines that lack validation in the AI\ncontext. Motivated by the need for reliable and valid measures, we investigated\nthe psychometric quality of two trust questionnaires, the Trust between People\nand Automation scale (TPA) by Jian et al. (2000) and the Trust Scale for the AI\nContext (TAI) by Hoffman et al. (2023). In a pre-registered online experiment\n(N = 1485), participants observed interactions with trustworthy and\nuntrustworthy AI (autonomous vehicle and chatbot). Results support the\npsychometric quality of the TAI while revealing opportunities to improve the\nTPA, which we outline in our recommendations for using the two questionnaires.\nFurthermore, our findings provide additional empirical evidence of trust and\ndistrust as two distinct constructs that may coexist independently. Building on\nour findings, we highlight the opportunities and added value of measuring both\ntrust and distrust in human-AI research and advocate for further work on both\nconstructs.\n","authors":["Nicolas Scharowski","Sebastian A. C. Perrig","Lena Fanya Aeschbach","Nick von Felten","Klaus Opwis","Philipp Wintersberger","Florian Brühlmann"],"pdf_url":"https://arxiv.org/pdf/2403.00582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08868v1","updated":"2025-01-15T15:37:33Z","published":"2025-01-15T15:37:33Z","title":"Processing and Analyzing Real-World Driving Data: Insights on Trips,\n  Scenarios, and Human Driving Behaviors","summary":"  Analyzing large volumes of real-world driving data is essential for providing\nmeaningful and reliable insights into real-world trips, scenarios, and human\ndriving behaviors. To this end, we developed a multi-level data processing\napproach that adds new information, segments data, and extracts desired\nparameters. Leveraging a confidential but extensive dataset (over 1 million\nkm), this approach leads to three levels of in-depth analysis: trip, scenario,\nand driving. The trip-level analysis explains representative properties\nobserved in real-world trips, while the scenario-level analysis focuses on\nscenario conditions resulting from road events that reduce vehicle speed. The\ndriving-level analysis identifies the cause of driving regimes for specific\nsituations and characterizes typical human driving behaviors. Such analyses can\nsupport the design of both trip- and scenario-based tests, the modeling of\nhuman drivers, and the establishment of guidelines for connected and automated\nvehicles.\n","authors":["Jihun Han","Dominik Karbowski","Ayman Moawad","Namdoo Kim","Aymeric Rousseau","Shihong Fan","Jason Hoon Lee","Jinho Ha"],"pdf_url":"https://arxiv.org/pdf/2501.08868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08864v1","updated":"2025-01-15T15:27:03Z","published":"2025-01-15T15:27:03Z","title":"The New Calculator? Practices, Norms, and Implications of Generative AI\n  in Higher Education","summary":"  Generative AI (GenAI) has introduced myriad opportunities and challenges for\nhigher education. Anticipating this potential transformation requires\nunderstanding students' contextualised practices and norms around GenAI. We\nconducted semi-structured interviews with 26 students and 11 educators from\ndiverse departments across two universities. Grounded in Strong Structuration\nTheory, we find diversity in students' uses and motivations for GenAI.\nOccurring in the context of unclear university guidelines, institutional\nfixation on plagiarism, and inconsistent educator communication, students'\npractices are informed by unspoken rules around appropriate use, GenAI\nlimitations and reliance strategies, and consideration of agency and skills.\nPerceived impacts include changes in confidence, and concerns about skill\ndevelopment, relationships with educators, and plagiarism. Both groups envision\nchanges in universities' attitude to GenAI, responsible use training,\nassessments, and integration of GenAI into education. We discuss\nsocio-technical implications in terms of current and anticipated changes in the\nexternal and internal structures that contextualise students' GenAI use.\n","authors":["Auste Simkute","Viktor Kewenig","Abigail Sellen","Sean Rintel","Lev Tankelevitch"],"pdf_url":"https://arxiv.org/pdf/2501.08864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08774v1","updated":"2025-01-15T12:53:49Z","published":"2025-01-15T12:53:49Z","title":"How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in\n  Software Engineering","summary":"  Artificial intelligence (AI), including large language models and generative\nAI, is emerging as a significant force in software development, offering\ndevelopers powerful tools that span the entire development lifecycle. Although\nsoftware engineering research has extensively studied AI tools in software\ndevelopment, the specific types of interactions between developers and these\nAI-powered tools have only recently begun to receive attention. Understanding\nand improving these interactions has the potential to improve productivity,\ntrust, and efficiency in AI-driven workflows. In this paper, we propose a\ntaxonomy of interaction types between developers and AI tools, identifying\neleven distinct interaction types, such as auto-complete code suggestions,\ncommand-driven actions, and conversational assistance. Building on this\ntaxonomy, we outline a research agenda focused on optimizing AI interactions,\nimproving developer control, and addressing trust and usability challenges in\nAI-assisted development. By establishing a structured foundation for studying\ndeveloper-AI interactions, this paper aims to stimulate research on creating\nmore effective, adaptive AI tools for software development.\n","authors":["Christoph Treude","Marco A. Gerosa"],"pdf_url":"https://arxiv.org/pdf/2501.08774v1.pdf","comment":"Accepted at 2nd ACM International Conference on AI Foundation Models\n  and Software Engineering (FORGE 2025)"},{"id":"http://arxiv.org/abs/2410.03268v2","updated":"2025-01-15T11:39:56Z","published":"2024-10-04T09:39:17Z","title":"Narrative Player: Reviving Data Narratives with Visuals","summary":"  Data-rich documents are commonly found across various fields such as\nbusiness, finance, and science. However, a general limitation of these\ndocuments for reading is their reliance on text to convey data and facts.\nVisual representation of text aids in providing a satisfactory reading\nexperience in comprehension and engagement. However, existing work emphasizes\npresenting the insights of local text context, rather than fully conveying data\nstories within the whole paragraphs and engaging readers. To provide readers\nwith satisfactory data stories, this paper presents Narrative Player, a novel\nmethod that automatically revives data narratives with consistent and\ncontextualized visuals. Specifically, it accepts a paragraph and corresponding\ndata table as input and leverages LLMs to characterize the clauses and extract\ncontextualized data facts. Subsequently, the facts are transformed into a\ncoherent visualization sequence with a carefully designed optimization-based\napproach. Animations are also assigned between adjacent visualizations to\nenable seamless transitions. Finally, the visualization sequence, transition\nanimations, and audio narration generated by text-to-speech technologies are\nrendered into a data video. The evaluation results showed that the\nautomatic-generated data videos were well-received by participants and experts\nfor enhancing reading.\n","authors":["Zekai Shao","Leixian Shen","Haotian Li","Yi Shan","Huamin Qu","Yun Wang","Siming Chen"],"pdf_url":"https://arxiv.org/pdf/2410.03268v2.pdf","comment":"Accepted by IEEE TVCG"},{"id":"http://arxiv.org/abs/2501.08693v1","updated":"2025-01-15T10:08:07Z","published":"2025-01-15T10:08:07Z","title":"Subject Disentanglement Neural Network for Speech Envelope\n  Reconstruction from EEG","summary":"  Reconstructing speech envelopes from EEG signals is essential for exploring\nneural mechanisms underlying speech perception. Yet, EEG variability across\nsubjects and physiological artifacts complicate accurate reconstruction. To\naddress this problem, we introduce Subject Disentangling Neural Network\n(SDN-Net), which disentangles subject identity information from reconstructed\nspeech envelopes to enhance cross-subject reconstruction accuracy. SDN-Net\nintegrates three key components: MLA-Codec, MPN-MI, and CTA-MTDNN. The\nMLA-Codec, a fully convolutional neural network, decodes EEG signals into\nspeech envelopes. The CTA-MTDNN module, a multi-scale time-delay neural network\nwith channel and temporal attention, extracts subject identity features from\nEEG signals. Lastly, the MPN-MI module, a mutual information estimator with a\nmulti-layer perceptron, supervises the removal of subject identity information\nfrom the reconstructed speech envelope. Experiments on the Auditory EEG\nDecoding Dataset demonstrate that SDN-Net achieves superior performance in\ninner- and cross-subject speech envelope reconstruction compared to recent\nstate-of-the-art methods.\n","authors":["Li Zhang","Jiyao Liu"],"pdf_url":"https://arxiv.org/pdf/2501.08693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08626v1","updated":"2025-01-15T07:07:48Z","published":"2025-01-15T07:07:48Z","title":"A Learning Algorithm That Attains the Human Optimum in a Repeated\n  Human-Machine Interaction Game","summary":"  When humans interact with learning-based control systems, a common goal is to\nminimize a cost function known only to the human. For instance, an exoskeleton\nmay adapt its assistance in an effort to minimize the human's metabolic\ncost-of-transport. Conventional approaches to synthesizing the learning\nalgorithm solve an inverse problem to infer the human's cost. However, these\nproblems can be ill-posed, hard to solve, or sensitive to problem data. Here we\nshow a game-theoretic learning algorithm that works solely by observing human\nactions to find the cost minimum, avoiding the need to solve an inverse\nproblem. We evaluate the performance of our algorithm in an extensive set of\nhuman subjects experiments, demonstrating consistent convergence to the minimum\nof a prescribed human cost function in scalar and multidimensional\ninstantiations of the game. We conclude by outlining future directions for\ntheoretical and empirical extensions of our results.\n","authors":["Jason T. Isa","Lillian J. Ratliff","Samuel A. Burden"],"pdf_url":"https://arxiv.org/pdf/2501.08626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08561v1","updated":"2025-01-15T04:04:57Z","published":"2025-01-15T04:04:57Z","title":"ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for\n  Digital Twins","summary":"  In this paper, we propose an Adaptive Neuro-Symbolic Learning Framework for\ndigital twin technology called ``ANSR-DT.\" Our approach combines pattern\nrecognition algorithms with reinforcement learning and symbolic reasoning to\nenable real-time learning and adaptive intelligence. This integration enhances\nthe understanding of the environment and promotes continuous learning, leading\nto better and more effective decision-making in real-time for applications that\nrequire human-machine collaboration. We evaluated the \\textit{ANSR-DT}\nframework for its ability to learn and adapt to dynamic patterns, observing\nsignificant improvements in decision accuracy, reliability, and\ninterpretability when compared to existing state-of-the-art methods. However,\nchallenges still exist in extracting and integrating symbolic rules in complex\nenvironments, which limits the full potential of our framework in heterogeneous\nsettings. Moreover, our ongoing research aims to address this issue in the\nfuture by ensuring seamless integration of neural models at large. In addition,\nour open-source implementation promotes reproducibility and encourages future\nresearch to build on our foundational work.\n","authors":["Safayat Bin Hakim","Muhammad Adil","Alvaro Velasquez","Houbing Herbert Song"],"pdf_url":"https://arxiv.org/pdf/2501.08561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08558v1","updated":"2025-01-15T03:49:08Z","published":"2025-01-15T03:49:08Z","title":"LAMS: LLM-Driven Automatic Mode Switching for Assistive Teleoperation","summary":"  Teleoperating high degrees-of-freedom (DoF) robotic manipulators via low-DoF\ncontrollers like joysticks often requires frequent switching between control\nmodes, where each mode maps controller movements to specific robot actions.\nManually performing this frequent switching can make teleoperation cumbersome\nand inefficient. On the other hand, existing automatic mode-switching\nsolutions, such as heuristic-based or learning-based methods, are often\ntask-specific and lack generalizability. In this paper, we introduce LLM-Driven\nAutomatic Mode Switching (LAMS), a novel approach that leverages Large Language\nModels (LLMs) to automatically switch control modes based on task context.\nUnlike existing methods, LAMS requires no prior task demonstrations and\nincrementally improves by integrating user-generated mode-switching examples.\nWe validate LAMS through an ablation study and a user study with 10\nparticipants on complex, long-horizon tasks, demonstrating that LAMS\neffectively reduces manual mode switches, is preferred over alternative\nmethods, and improves performance over time. The project website with\nsupplementary materials is at https://lams-assistance.github.io/.\n","authors":["Yiran Tao","Jehan Yang","Dan Ding","Zackory Erickson"],"pdf_url":"https://arxiv.org/pdf/2501.08558v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04820v2","updated":"2025-01-15T03:43:22Z","published":"2024-08-09T02:22:51Z","title":"Natural Language Outlines for Code: Literate Programming in the LLM Era","summary":"  We propose using natural language outlines as a novel modality and\ninteraction surface for providing AI assistance to developers throughout the\nsoftware development process. An NL outline for a code function comprises\nmultiple statements written in concise prose, which partition the code and\nsummarize its main ideas in the style of literate programming. Crucially, we\nfind that modern LLMs can generate accurate and high-quality NL outlines in\npractice. Moreover, NL outlines enable a bidirectional sync between code and\nNL, allowing changes in one to be automatically reflected in the other. We\ndiscuss many use cases for NL outlines: they can accelerate understanding and\nnavigation of code and diffs, simplify code maintenance, augment code search,\nsteer code generation, and more. We then propose and compare multiple LLM\nprompting techniques for generating outlines and ask professional developers to\njudge outline quality. Finally, we present two case studies applying NL\noutlines toward code review and malware detection.\n","authors":["Kensen Shi","Deniz Altınbüken","Saswat Anand","Mihai Christodorescu","Katja Grünwedel","Alexa Koenings","Sai Naidu","Anurag Pathak","Marc Rasi","Fredde Ribeiro","Brandon Ruffin","Siddhant Sanyam","Maxim Tabachnyk","Sara Toth","Roy Tu","Tobias Welp","Pengcheng Yin","Manzil Zaheer","Satish Chandra","Charles Sutton"],"pdf_url":"https://arxiv.org/pdf/2408.04820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08552v1","updated":"2025-01-15T03:23:06Z","published":"2025-01-15T03:23:06Z","title":"Reinforcement Learning-Enhanced Procedural Generation for Dynamic\n  Narrative-Driven AR Experiences","summary":"  Procedural Content Generation (PCG) is widely used to create scalable and\ndiverse environments in games. However, existing methods, such as the Wave\nFunction Collapse (WFC) algorithm, are often limited to static scenarios and\nlack the adaptability required for dynamic, narrative-driven applications,\nparticularly in augmented reality (AR) games. This paper presents a\nreinforcement learning-enhanced WFC framework designed for mobile AR\nenvironments. By integrating environment-specific rules and dynamic tile weight\nadjustments informed by reinforcement learning (RL), the proposed method\ngenerates maps that are both contextually coherent and responsive to gameplay\nneeds. Comparative evaluations and user studies demonstrate that the framework\nachieves superior map quality and delivers immersive experiences, making it\nwell-suited for narrative-driven AR games. Additionally, the method holds\npromise for broader applications in education, simulation training, and\nimmersive extended reality (XR) experiences, where dynamic and adaptive\nenvironments are critical.\n","authors":["Aniruddha Srinivas Joshi"],"pdf_url":"https://arxiv.org/pdf/2501.08552v1.pdf","comment":"Number of pages: 13, Number of figures: 4. Accepted for presentation\n  at GRAPP 2025 - 20th International Conference on Computer Graphics Theory and\n  Applications (for additional details on the conference visit\n  https://grapp.scitevents.org). Disclaimer: This preprint may differ from the\n  final version published in the conference proceedings"},{"id":"http://arxiv.org/abs/2501.08187v2","updated":"2025-01-15T02:59:32Z","published":"2025-01-14T15:12:19Z","title":"A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction\n  Following","summary":"  Large language models excel at interpreting complex natural language\ninstructions, enabling them to perform a wide range of tasks. In the life\nsciences, single-cell RNA sequencing (scRNA-seq) data serves as the \"language\nof cellular biology\", capturing intricate gene expression patterns at the\nsingle-cell level. However, interacting with this \"language\" through\nconventional tools is often inefficient and unintuitive, posing challenges for\nresearchers. To address these limitations, we present InstructCell, a\nmulti-modal AI copilot that leverages natural language as a medium for more\ndirect and flexible single-cell analysis. We construct a comprehensive\nmulti-modal instruction dataset that pairs text-based instructions with\nscRNA-seq profiles from diverse tissues and species. Building on this, we\ndevelop a multi-modal cell language architecture capable of simultaneously\ninterpreting and processing both modalities. InstructCell empowers researchers\nto accomplish critical tasks-such as cell type annotation, conditional\npseudo-cell generation, and drug sensitivity prediction-using straightforward\nnatural language commands. Extensive evaluations demonstrate that InstructCell\nconsistently meets or exceeds the performance of existing single-cell\nfoundation models, while adapting to diverse experimental conditions. More\nimportantly, InstructCell provides an accessible and intuitive tool for\nexploring complex single-cell data, lowering technical barriers and enabling\ndeeper biological insights.\n","authors":["Yin Fang","Xinle Deng","Kangwei Liu","Ningyu Zhang","Jingyang Qian","Penghui Yang","Xiaohui Fan","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2501.08187v2.pdf","comment":"37 pages; 13 figures; Code: https://github.com/zjunlp/Instructcell,\n  Models: https://huggingface.co/zjunlp/Instructcell-chat,\n  https://huggingface.co/zjunlp/InstructCell-instruct"},{"id":"http://arxiv.org/abs/2501.08518v1","updated":"2025-01-15T02:06:29Z","published":"2025-01-15T02:06:29Z","title":"Easing Seasickness through Attention Redirection with a\n  Mindfulness-Based Brain--Computer Interface","summary":"  Seasickness is a prevalent issue that adversely impacts both passenger\nexperiences and the operational efficiency of maritime crews. While techniques\nthat redirect attention have proven effective in alleviating motion sickness\nsymptoms in terrestrial environments, applying similar strategies to manage\nseasickness poses unique challenges due to the prolonged and intense motion\nenvironment associated with maritime travel. In this study, we propose a\nmindfulness brain-computer interface (BCI), specifically designed to redirect\nattention with the aim of mitigating seasickness symptoms in real-world\nsettings. Our system utilizes a single-channel headband to capture prefrontal\nEEG signals, which are then wirelessly transmitted to computing devices for the\nassessment of mindfulness states. The results are transferred into real-time\nfeedback as mindfulness scores and audiovisual stimuli, facilitating a shift in\nattentional focus from physiological discomfort to mindfulness practices. A\ntotal of 43 individuals participated in a real-world maritime experiment\nconsisted of three sessions: a real-feedback mindfulness session, a resting\nsession, and a pseudofeedback mindfulness session. Notably, 81.39% of\nparticipants reported that the mindfulness BCI intervention was effective, and\nthere was a significant reduction in the severity of seasickness, as measured\nby the Misery Scale (MISC). Furthermore, EEG analysis revealed a decrease in\nthe theta/beta ratio, corresponding with the alleviation of seasickness\nsymptoms. A decrease in overall EEG band power during the real-feedback\nmindfulness session suggests that the mindfulness BCI fosters a more tranquil\nand downregulated state of brain activity. Together, this study presents a\nnovel nonpharmacological, portable, and effective approach for seasickness\nintervention, with the potential to enhance the cruising experience for both\npassengers and crews.\n","authors":["Xiaoyu Bao","Kailin Xu","Jiawei Zhu","Haiyun Huang","Kangning Li","Qiyun Huang","Yuanqing Li"],"pdf_url":"https://arxiv.org/pdf/2501.08518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08507v1","updated":"2025-01-15T01:09:11Z","published":"2025-01-15T01:09:11Z","title":"A Framework for Dynamic Situational Awareness in Human Robot Teams: An\n  Interview Study","summary":"  In human-robot teams, human situational awareness is the operator's conscious\nknowledge of the team's states, actions, plans and their environment.\nAppropriate human situational awareness is critical to successful human-robot\ncollaboration. In human-robot teaming, it is often assumed that the best and\nrequired level of situational awareness is knowing everything at all times.\nThis view is problematic, because what a human needs to know for optimal team\nperformance varies given the dynamic environmental conditions, task context and\nroles and capabilities of team members. We explore this topic by interviewing\n16 participants with active and repeated experience in diverse human-robot\nteaming applications. Based on analysis of these interviews, we derive a\nframework explaining the dynamic nature of required situational awareness in\nhuman-robot teaming. In addition, we identify a range of factors affecting the\ndynamic nature of required and actual levels of situational awareness (i.e.,\ndynamic situational awareness), types of situational awareness inefficiencies\nresulting from gaps between actual and required situational awareness, and\ntheir main consequences. We also reveal various strategies, initiated by humans\nand robots, that assist in maintaining the required situational awareness. Our\nfindings inform the implementation of accurate estimates of dynamic situational\nawareness and the design of user-adaptive human-robot interfaces. Therefore,\nthis work contributes to the future design of more collaborative and effective\nhuman-robot teams.\n","authors":["Hashini Senaratne","Leimin Tian","Pavan Sikka","Jason Williams","David Howard","Dana Kulić","Cécile Paris"],"pdf_url":"https://arxiv.org/pdf/2501.08507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08500v1","updated":"2025-01-15T00:36:53Z","published":"2025-01-15T00:36:53Z","title":"Visual Network Analysis in Immersive Environments: A Survey","summary":"  The increasing complexity and volume of network data demand effective\nanalysis approaches, with visual exploration proving particularly beneficial.\nImmersive technologies, such as augmented reality, virtual reality, and large\ndisplay walls, have enabled the emerging field of immersive analytics, offering\nnew opportunities to enhance user engagement, spatial awareness, and\nproblem-solving. A growing body of work explores immersive environments for\nnetwork visualisation, ranging from design studies to fully integrated\napplications across various domains. Despite these advancements, the field\nremains fragmented, with diverse methodologies, hardware setups, and evaluation\ncriteria, often lacking clear connections to prior work. This fragmentation\ncomplicates the comparability and generalisability of findings. To address\nthis, we present a structured survey of visual network analysis in immersive\nenvironments. We systematically categorise and analyse existing approaches,\nrevealing connections and coverage within the design space. By synthesising\nfindings of experiments and evaluating current applications, we identify key\nachievements, challenges, and research gaps. Additionally, we provide an\ninteractive online resource for exploring and updating results, aiming to guide\nresearchers and practitioners in advancing the field. This work provides a\ncomprehensive overview of the research landscape and proposes actionable\ninsights to foster innovation in immersive network analysis.\n","authors":["Lucas Joos","Maximilian T. Fischer","Julius Rauscher","Daniel A. Keim","Tim Dwyer","Falk Schreiber","Karsten Klein"],"pdf_url":"https://arxiv.org/pdf/2501.08500v1.pdf","comment":null}]},"2025-01-14T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2501.08402v1","updated":"2025-01-14T19:37:08Z","published":"2025-01-14T19:37:08Z","title":"Addressing Quality Challenges in Deep Learning: The Role of MLOps and\n  Domain Knowledge","summary":"  Deep learning (DL) systems present unique challenges in software engineering,\nespecially concerning quality attributes like correctness and resource\nefficiency. While DL models achieve exceptional performance in specific tasks,\nengineering DL-based systems is still essential. The effort, cost, and\npotential diminishing returns of continual improvements must be carefully\nevaluated, as software engineers often face the critical decision of when to\nstop refining a system relative to its quality attributes. This experience\npaper explores the role of MLOps practices -- such as monitoring and experiment\ntracking -- in creating transparent and reproducible experimentation\nenvironments that enable teams to assess and justify the impact of design\ndecisions on quality attributes. Furthermore, we report on experiences\naddressing the quality challenges by embedding domain knowledge into the design\nof a DL model and its integration within a larger system. The findings offer\nactionable insights into not only the benefits of domain knowledge and MLOps\nbut also the strategic consideration of when to limit further optimizations in\nDL projects to maximize overall system quality and reliability.\n","authors":["Santiago del Rey","Adrià Medina","Xavier Franch","Silverio Martínez-Fernández"],"pdf_url":"https://arxiv.org/pdf/2501.08402v1.pdf","comment":"6 pages, 1 figure, accepted to the 4th International Conference on AI\n  Engineering - Software Engineering for AI (CAIN)"},{"id":"http://arxiv.org/abs/2412.13120v2","updated":"2025-01-14T18:55:03Z","published":"2024-12-17T17:42:43Z","title":"Empirical Analysis of Pull Requests for Google Summer of Code","summary":"  Internship and industry-affiliated capstone projects are popular ways to\nexpose students to real world experiences and bridge the gap between academic\ntraining and industry requirements. However, these two approaches often require\nactive industry collaboration, and many students struggle to find industry\nplacements. Open-source contributions are a crucial alternative to gain real\nworld experience, earn publicly verifiable contribution with real-world impact,\nand learn from experienced open-source contributors. The Google Summer of Code\n(GSoC) is a global initiative that matches students or new contributors with\nexperienced mentors to work on open-source projects. The program aims to\nintroduce the students to open-source development, help them gain valuable\nskills under the guidance of mentors, and hopefully encourage them to continue\ncontributing to open-source projects. The realization of the program objectives\nwill provide a continuous pool of talented new contributors necessary for\nmaintaining open-source projects. This study presents an empirical analysis of\npull requests created by interns during the GSoC program. We extracted and\nanalyzed 17,232 pull requests from 2,456 interns across 1,937 open-source\nprojects. The results show most tasks involve both code-intensive activities\nlike adding new features and fixing bugs, as well as non-code tasks like\nupdating documentation and restructuring the codebase. Feedback from reviewers\ncovers code functionality and programming logic, testing coverage, error\nhandling, code readability, and adherence to best practices. Finally, we\ndiscuss the implications of these results for software engineering education.\n","authors":["Saheed Popoola"],"pdf_url":"https://arxiv.org/pdf/2412.13120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08243v1","updated":"2025-01-14T16:30:10Z","published":"2025-01-14T16:30:10Z","title":"Engineering LLM Powered Multi-agent Framework for Autonomous CloudOps","summary":"  Cloud Operations (CloudOps) is a rapidly growing field focused on the\nautomated management and optimization of cloud infrastructure which is\nessential for organizations navigating increasingly complex cloud environments.\nMontyCloud Inc. is one of the major companies in the CloudOps domain that\nleverages autonomous bots to manage cloud compliance, security, and continuous\noperations. To make the platform more accessible and effective to the\ncustomers, we leveraged the use of GenAI.\n  Developing a GenAI-based solution for autonomous CloudOps for the existing\nMontyCloud system presented us with various challenges such as i) diverse data\nsources; ii) orchestration of multiple processes; and iii) handling complex\nworkflows to automate routine tasks. To this end, we developed MOYA, a\nmulti-agent framework that leverages GenAI and balances autonomy with the\nnecessary human control. This framework integrates various internal and\nexternal systems and is optimized for factors like task orchestration,\nsecurity, and error mitigation while producing accurate, reliable, and relevant\ninsights by utilizing Retrieval Augmented Generation (RAG). Evaluations of our\nmulti-agent system with the help of practitioners as well as using automated\nchecks demonstrate enhanced accuracy, responsiveness, and effectiveness over\nnon-agentic approaches across complex workflows.\n","authors":["Kannan Parthasarathy","Karthik Vaidhyanathan","Rudra Dhar","Venkat Krishnamachari","Basil Muhammed","Adyansh Kakran","Sreemaee Akshathala","Shrikara Arun","Sumant Dubey","Mohan Veerubhotla","Amey Karan"],"pdf_url":"https://arxiv.org/pdf/2501.08243v1.pdf","comment":"The paper has been accepted as full paper to CAIN 2025\n  (https://conf.researchr.org/home/cain-2025), co-located with ICSE 2025\n  (https://conf.researchr.org/home/icse-2025). The paper was submitted to CAIN\n  for review on 9 November 2024"},{"id":"http://arxiv.org/abs/2501.08200v1","updated":"2025-01-14T15:27:01Z","published":"2025-01-14T15:27:01Z","title":"CWEval: Outcome-driven Evaluation on Functionality and Security of LLM\n  Code Generation","summary":"  Large Language Models (LLMs) have significantly aided developers by\ngenerating or assisting in code writing, enhancing productivity across various\ntasks. While identifying incorrect code is often straightforward, detecting\nvulnerabilities in functionally correct code is more challenging, especially\nfor developers with limited security knowledge, which poses considerable\nsecurity risks of using LLM-generated code and underscores the need for robust\nevaluation benchmarks that assess both functional correctness and security.\nCurrent benchmarks like CyberSecEval and SecurityEval attempt to solve it but\nare hindered by unclear and impractical specifications, failing to assess both\nfunctionality and security accurately. To tackle these deficiencies, we\nintroduce CWEval, a novel outcome-driven evaluation framework designed to\nenhance the evaluation of secure code generation by LLMs. This framework not\nonly assesses code functionality but also its security simultaneously with\nhigh-quality task specifications and outcome-driven test oracles which provides\nhigh accuracy. Coupled with CWEval-bench, a multilingual, security-critical\ncoding benchmark, CWEval provides a rigorous empirical security evaluation on\nLLM-generated code, overcoming previous benchmarks' shortcomings. Through our\nevaluations, CWEval reveals a notable portion of functional but insecure code\nproduced by LLMs, and shows a serious inaccuracy of previous evaluations,\nultimately contributing significantly to the field of secure code generation.\nWe open-source our artifact at: https://github.com/Co1lin/CWEval .\n","authors":["Jinjun Peng","Leyi Cui","Kele Huang","Junfeng Yang","Baishakhi Ray"],"pdf_url":"https://arxiv.org/pdf/2501.08200v1.pdf","comment":"to be published in LLM4Code 2025"},{"id":"http://arxiv.org/abs/2501.08186v1","updated":"2025-01-14T15:11:41Z","published":"2025-01-14T15:11:41Z","title":"Executable Multi-Layered Software","summary":"  This paper introduces a novel software visualisation and animation method,\nmanifested in a prototype software tool - AnimArch. The introduced method is\nbased on model fusion of static and dynamic models. The static model is\nrepresented by class diagram while the dynamic model is represented by source\ncode written in high-level Object Action Language from xUML (executable UML).\nThe class diagram defines architecture that is animated in response to\nreal-time execution of the source code. Moreover, additional object diagram\nlayer represents all object instances present in runtime. The AnimArch also\nfeatures source code generation to Python, to bridge the gap from design to\nimplementation. This paper provides detailed description of the modelling\nmethod and screenshots of the accompanying software tool.\n","authors":["Lukas Radosky","Ivan Polasek"],"pdf_url":"https://arxiv.org/pdf/2501.08186v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2501.08165v1","updated":"2025-01-14T14:46:19Z","published":"2025-01-14T14:46:19Z","title":"I Can Find You in Seconds! Leveraging Large Language Models for Code\n  Authorship Attribution","summary":"  Source code authorship attribution is important in software forensics,\nplagiarism detection, and protecting software patch integrity. Existing\ntechniques often rely on supervised machine learning, which struggles with\ngeneralization across different programming languages and coding styles due to\nthe need for large labeled datasets. Inspired by recent advances in natural\nlanguage authorship analysis using large language models (LLMs), which have\nshown exceptional performance without task-specific tuning, this paper explores\nthe use of LLMs for source code authorship attribution.\n  We present a comprehensive study demonstrating that state-of-the-art LLMs can\nsuccessfully attribute source code authorship across different languages. LLMs\ncan determine whether two code snippets are written by the same author with\nzero-shot prompting, achieving a Matthews Correlation Coefficient (MCC) of\n0.78, and can attribute code authorship from a small set of reference code\nsnippets via few-shot learning, achieving MCC of 0.77. Additionally, LLMs show\nsome adversarial robustness against misattribution attacks.\n  Despite these capabilities, we found that naive prompting of LLMs does not\nscale well with a large number of authors due to input token limitations. To\naddress this, we propose a tournament-style approach for large-scale\nattribution. Evaluating this approach on datasets of C++ (500 authors, 26,355\nsamples) and Java (686 authors, 55,267 samples) code from GitHub, we achieve\nclassification accuracy of up to 65% for C++ and 68.7% for Java using only one\nreference per author. These results open new possibilities for applying LLMs to\ncode authorship attribution in cybersecurity and software engineering.\n","authors":["Soohyeon Choi","Yong Kiam Tan","Mark Huasong Meng","Mohamed Ragab","Soumik Mondal","David Mohaisen","Khin Mi Mi Aung"],"pdf_url":"https://arxiv.org/pdf/2501.08165v1.pdf","comment":"12 pages, 5 figures,"},{"id":"http://arxiv.org/abs/2501.08087v1","updated":"2025-01-14T12:57:16Z","published":"2025-01-14T12:57:16Z","title":"Automating Explanation Need Management in App Reviews: A Case Study from\n  the Navigation App Industry","summary":"  Providing explanations in response to user reviews is a time-consuming and\nrepetitive task for companies, as many reviews present similar issues requiring\nnearly identical responses. To improve efficiency, this paper proposes a\nsemi-automated approach to managing explanation needs in user reviews. The\napproach leverages taxonomy categories to classify reviews and assign them to\nrelevant internal teams or sources for responses. 2,366 app reviews from the\nGoogle Play Store and Apple App Store were scraped and analyzed using a word\nand phrase filtering system to detect explanation needs. The detected needs\nwere categorized and assigned to specific internal teams at the company\nGraphmasters GmbH, using a hierarchical assignment strategy that prioritizes\nthe most relevant teams. Additionally, external sources, such as existing\nsupport articles and past review responses, were integrated to provide\ncomprehensive explanations. The system was evaluated through interviews and\nsurveys with the Graphmasters support team, which consists of four employees.\nThe results showed that the hierarchical assignment method improved the\naccuracy of team assignments, with correct teams being identified in 79.2% of\ncases. However, challenges in interrater agreement and the need for new\nresponses in certain cases, particularly for Apple App Store reviews, were\nnoted. Future work will focus on refining the taxonomy and enhancing the\nautomation process to reduce manual intervention further.\n","authors":["Martin Obaidi","Nicolas Voß","Jakob Droste","Hannah Deters","Marc Herrmann","Jannik Fischbach","Kurt Schneider"],"pdf_url":"https://arxiv.org/pdf/2501.08087v1.pdf","comment":"This paper has been accepted at the Software Engineering in Practice\n  (SEIP) track of the 47th International Conference on Software Engineering\n  (ICSE 2025)"},{"id":"http://arxiv.org/abs/2501.07992v1","updated":"2025-01-14T10:35:54Z","published":"2025-01-14T10:35:54Z","title":"LLM-Ehnanced Holonic Architecture for Ad-Hoc Scalable SoS","summary":"  As modern system of systems (SoS) become increasingly adaptive and human\ncentred, traditional architectures often struggle to support interoperability,\nreconfigurability, and effective human system interaction. This paper addresses\nthese challenges by advancing the state of the art holonic architecture for\nSoS, offering two main contributions to support these adaptive needs. First, we\npropose a layered architecture for holons, which includes reasoning,\ncommunication, and capabilities layers. This design facilitates seamless\ninteroperability among heterogeneous constituent systems by improving data\nexchange and integration. Second, inspired by principles of intelligent\nmanufacturing, we introduce specialised holons namely, supervisor, planner,\ntask, and resource holons aimed at enhancing the adaptability and\nreconfigurability of SoS. These specialised holons utilise large language\nmodels within their reasoning layers to support decision making and ensure real\ntime adaptability. We demonstrate our approach through a 3D mobility case study\nfocused on smart city transportation, showcasing its potential for managing\ncomplex, multimodal SoS environments. Additionally, we propose evaluation\nmethods to assess the architecture efficiency and scalability,laying the\ngroundwork for future empirical validations through simulations and real world\nimplementations.\n","authors":["Muhammad Ashfaq","Ahmed R. Sadik","Tommi Mikkonen","Muhammad Waseem","Niko Mäkitalo"],"pdf_url":"https://arxiv.org/pdf/2501.07992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06401v2","updated":"2025-01-14T10:16:18Z","published":"2025-01-11T01:30:09Z","title":"A Comparative Study of Full Apps and Lite Apps for Android","summary":"  App developers aim to create apps that cater to the needs of different types\nof users. This development approach, also known as the \"one-size-fits-all\"\nstrategy, involves combining various functionalities into one app. However,\nthis approach has drawbacks, such as lower conversion rates, slower download\nspeed, larger attack surfaces, and lower update rates. To address these issues,\ndevelopers have created \"lite\" versions to attract new users and enhance the\nuser experience. Despite this, there has been no study conducted to examine the\nrelationship between lite and full apps. To address this gap, we present a\ncomparative study of lite apps, exploring the similarities and differences\nbetween lite and full apps from various perspectives. Our findings indicate\nthat most existing lite apps fail to fulfill their intended goals (e.g.,\nsmaller in size, faster to download, and using less data). Our study also\nreveals the potential security risks associated with lite apps.\n","authors":["Yutian Tang","Xiaojiang Du"],"pdf_url":"https://arxiv.org/pdf/2501.06401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07954v1","updated":"2025-01-14T09:18:34Z","published":"2025-01-14T09:18:34Z","title":"Many-Objective Neuroevolution for Testing Games","summary":"  Generating tests for games is challenging due to the high degree of\nrandomisation inherent to games and hard-to-reach program states that require\nsophisticated gameplay. The test generator NEATEST tackles these challenges by\ncombining search-based software testing principles with neuroevolution to\noptimise neural networks that serve as test cases. However, since NEATEST is\ndesigned as a single-objective algorithm, it may require a long time to cover\nfairly simple program states or may even get stuck trying to reach unreachable\nprogram states. In order to resolve these shortcomings of NEATEST, this work\naims to transform the algorithm into a many-objective search algorithm that\ntargets several program states simultaneously. To this end, we combine the\nneuroevolution algorithm NEATEST with the two established search-based software\ntesting algorithms, MIO and MOSA. Moreover, we adapt the existing\nmany-objective neuroevolution algorithm NEWS/D to serve as a test generator.\nOur experiments on a dataset of 20 SCRATCH programs show that extending NEATEST\nto target several objectives simultaneously increases the average branch\ncoverage from 75.88% to 81.33% while reducing the required search time by\n93.28%.\n","authors":["Patric Feldmeier","Katrin Schmelz","Gordon Fraser"],"pdf_url":"https://arxiv.org/pdf/2501.07954v1.pdf","comment":"11 pages, 18th IEEE International Conference on Software Testing,\n  Verification and Validation (ICST) 2025"},{"id":"http://arxiv.org/abs/2410.13874v4","updated":"2025-01-14T08:42:23Z","published":"2024-10-02T13:02:17Z","title":"COOL: Efficient and Reliable Chain-Oriented Objective Logic with Neural\n  Networks Feedback Control for Program Synthesis","summary":"  Program synthesis methods, whether formal or neural-based, lack fine-grained\ncontrol and flexible modularity, which limits their adaptation to complex\nsoftware development. These limitations stem from rigid Domain-Specific\nLanguage (DSL) frameworks and neural network incorrect predictions. To this\nend, we propose the Chain of Logic (CoL), which organizes the synthesis process\ninto an activity flow and provides heuristic control to guide the process.\nFurthermore, by integrating neural networks with libraries and introducing a\nNeural Network Feedback Control (NNFC) mechanism, our approach modularizes\nsynthesis and mitigates the impact of neural network mispredictions.\nExperiments on relational and symbolic synthesis tasks show that CoL\nsignificantly enhances the efficiency and reliability of DSL program synthesis\nacross multiple metrics. Specifically, CoL improves accuracy by 70% while\nreducing tree operations by 91% and time by 95%. Additionally, NNFC further\nboosts accuracy by 6%, with a 64% reduction in tree operations under\nchallenging conditions such as insufficient training data, increased\ndifficulty, and multidomain synthesis. These improvements confirm COOL as a\nhighly efficient and reliable program synthesis framework.\n","authors":["Jipeng Han"],"pdf_url":"https://arxiv.org/pdf/2410.13874v4.pdf","comment":"31 pages, 11 figures"},{"id":"http://arxiv.org/abs/2501.07892v1","updated":"2025-01-14T07:16:43Z","published":"2025-01-14T07:16:43Z","title":"Leveraging Metamemory Mechanisms for Enhanced Data-Free Code Generation\n  in LLMs","summary":"  Automated code generation using large language models (LLMs) has gained\nattention due to its efficiency and adaptability. However, real-world coding\ntasks or benchmarks like HumanEval and StudentEval often lack dedicated\ntraining datasets, challenging existing few-shot prompting approaches that rely\non reference examples. Inspired by human metamemory-a cognitive process\ninvolving recall and evaluation-we present a novel framework (namely M^2WF) for\nimproving LLMs' one-time code generation. This approach enables LLMs to\nautonomously generate, evaluate, and utilize synthetic examples to enhance\nreliability and performance. Unlike prior methods, it minimizes dependency on\ncurated data and adapts flexibly to various coding scenarios. Our experiments\ndemonstrate significant improvements in coding benchmarks, offering a scalable\nand robust solution for data-free environments. The code and framework will be\npublicly available on GitHub and HuggingFace.\n","authors":["Shuai Wang","Liang Ding","Yibing Zhan","Yong Luo","Zheng He","Dapeng Tao"],"pdf_url":"https://arxiv.org/pdf/2501.07892v1.pdf","comment":"11 pages,6 figures"},{"id":"http://arxiv.org/abs/2407.01710v2","updated":"2025-01-14T05:49:10Z","published":"2024-06-27T10:25:37Z","title":"Failure Diagnosis in Microservice Systems: A Comprehensive Survey and\n  Analysis","summary":"  Widely adopted for their scalability and flexibility, modern microservice\nsystems present unique failure diagnosis challenges due to their independent\ndeployment and dynamic interactions. This complexity can lead to cascading\nfailures that negatively impact operational efficiency and user experience.\nRecognizing the critical role of fault diagnosis in improving the stability and\nreliability of microservice systems, researchers have conducted extensive\nstudies and achieved a number of significant results. This survey provides an\nexhaustive review of 98 scientific papers from 2003 to the present, including a\nthorough examination and elucidation of the fundamental concepts, system\narchitecture, and problem statement. It also includes a qualitative analysis of\nthe dimensions, providing an in-depth discussion of current best practices and\nfuture directions, aiming to further its development and application. In\naddition, this survey compiles publicly available datasets, toolkits, and\nevaluation metrics to facilitate the selection and validation of techniques for\npractitioners.\n","authors":["Shenglin Zhang","Sibo Xia","Wenzhao Fan","Binpeng Shi","Xiao Xiong","Zhenyu Zhong","Minghua Ma","Yongqian Sun","Dan Pei"],"pdf_url":"https://arxiv.org/pdf/2407.01710v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07857v1","updated":"2025-01-14T05:48:27Z","published":"2025-01-14T05:48:27Z","title":"Hierarchical Repository-Level Code Summarization for Business\n  Applications Using Local LLMs","summary":"  In large-scale software development, understanding the functionality and\nintent behind complex codebases is critical for effective development and\nmaintenance. While code summarization has been widely studied, existing methods\nprimarily focus on smaller code units, such as functions, and struggle with\nlarger code artifacts like files and packages. Additionally, current\nsummarization models tend to emphasize low-level implementation details, often\noverlooking the domain and business context that are crucial for real-world\napplications. This paper proposes a two-step hierarchical approach for\nrepository-level code summarization, tailored to business applications. First,\nsmaller code units such as functions and variables are identified using syntax\nanalysis and summarized with local LLMs. These summaries are then aggregated to\ngenerate higher-level file and package summaries. To ensure the summaries are\ngrounded in business context, we design custom prompts that capture the\nintended purpose of code artifacts based on the domain and problem context of\nthe business application. We evaluate our approach on a business support system\n(BSS) for the telecommunications domain, showing that syntax analysis-based\nhierarchical summarization improves coverage, while business-context grounding\nenhances the relevance of the generated summaries.\n","authors":["Nilesh Dhulshette","Sapan Shah","Vinay Kulkarni"],"pdf_url":"https://arxiv.org/pdf/2501.07857v1.pdf","comment":"To appear at LLM4Code@ICSE 2025"},{"id":"http://arxiv.org/abs/2501.07849v1","updated":"2025-01-14T05:21:27Z","published":"2025-01-14T05:21:27Z","title":"Unveiling Provider Bias in Large Language Models for Code Generation","summary":"  Large Language Models (LLMs) have emerged as the new recommendation engines,\noutperforming traditional methods in both capability and scope, particularly in\ncode generation applications. Our research reveals a novel provider bias in\nLLMs, namely without explicit input prompts, these models show systematic\npreferences for services from specific providers in their recommendations\n(e.g., favoring Google Cloud over Microsoft Azure). This bias holds significant\nimplications for market dynamics and societal equilibrium, potentially\npromoting digital monopolies. It may also deceive users and violate their\nexpectations, leading to various consequences. This paper presents the first\ncomprehensive empirical study of provider bias in LLM code generation. We\ndevelop a systematic methodology encompassing an automated pipeline for dataset\ngeneration, incorporating 6 distinct coding task categories and 30 real-world\napplication scenarios. Our analysis encompasses over 600,000 LLM-generated\nresponses across seven state-of-the-art models, utilizing approximately 500\nmillion tokens (equivalent to \\$5,000+ in computational costs). The study\nevaluates both the generated code snippets and their embedded service provider\nselections to quantify provider bias. Additionally, we conduct a comparative\nanalysis of seven debiasing prompting techniques to assess their efficacy in\nmitigating these biases. Our findings demonstrate that LLMs exhibit significant\nprovider preferences, predominantly favoring services from Google and Amazon,\nand can autonomously modify input code to incorporate their preferred providers\nwithout users' requests. Notably, we observe discrepancies between providers\nrecommended in conversational contexts versus those implemented in generated\ncode. The complete dataset and analysis results are available in our\nrepository.\n","authors":["Xiaoyu Zhang","Juan Zhai","Shiqing Ma","Qingshuang Bao","Weipeng Jiang","Chao Shen","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2501.07849v1.pdf","comment":"21 pages, 15 figures"},{"id":"http://arxiv.org/abs/2409.12544v2","updated":"2025-01-14T05:20:53Z","published":"2024-09-19T08:04:30Z","title":"Nigerian Software Engineer or American Data Scientist? GitHub Profile\n  Recruitment Bias in Large Language Models","summary":"  Large Language Models (LLMs) have taken the world by storm, demonstrating\ntheir ability not only to automate tedious tasks, but also to show some degree\nof proficiency in completing software engineering tasks. A key concern with\nLLMs is their \"black-box\" nature, which obscures their internal workings and\ncould lead to societal biases in their outputs. In the software engineering\ncontext, in this early results paper, we empirically explore how well LLMs can\nautomate recruitment tasks for a geographically diverse software team. We use\nOpenAI's ChatGPT to conduct an initial set of experiments using GitHub User\nProfiles from four regions to recruit a six-person software development team,\nanalyzing a total of 3,657 profiles over a five-year period (2019-2023).\nResults indicate that ChatGPT shows preference for some regions over others,\neven when swapping the location strings of two profiles (counterfactuals).\nFurthermore, ChatGPT was more likely to assign certain developer roles to users\nfrom a specific country, revealing an implicit bias. Overall, this study\nreveals insights into the inner workings of LLMs and has implications for\nmitigating such societal biases in these models.\n","authors":["Takashi Nakano","Kazumasa Shimari","Raula Gaikovina Kula","Christoph Treude","Marc Cheong","Kenichi Matsumoto"],"pdf_url":"https://arxiv.org/pdf/2409.12544v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07811v1","updated":"2025-01-14T03:21:10Z","published":"2025-01-14T03:21:10Z","title":"CodeCoR: An LLM-Based Self-Reflective Multi-Agent Framework for Code\n  Generation","summary":"  Code generation aims to produce code that fulfills requirements written in\nnatural languages automatically. Large language Models (LLMs) like ChatGPT have\ndemonstrated promising effectiveness in this area. Nonetheless, these LLMs\noften fail to ensure the syntactic and semantic correctness of the generated\ncode. Recently, researchers proposed multi-agent frameworks that guide LLMs\nwith different prompts to analyze programming tasks, generate code, perform\ntesting in a sequential workflow. However, the performance of the workflow is\nnot robust as the code generation depends on the performance of each agent. To\naddress this challenge, we propose CodeCoR, a self-reflective multi-agent\nframework that evaluates the effectiveness of each agent and their\ncollaborations. Specifically, for a given task description, four agents in\nCodeCoR generate prompts, code, test cases, and repair advice, respectively.\nEach agent generates more than one output and prunes away the low-quality ones.\nThe generated code is tested in the local environment: the code that fails to\npass the generated test cases is sent to the repair agent and the coding agent\nre-generates the code based on repair advice. Finally, the code that passes the\nmost number of generated test cases is returned to users. Our experiments on\nfour widely used datasets, HumanEval, HumanEval-ET, MBPP, and MBPP-ET,\ndemonstrate that CodeCoR significantly outperforms existing baselines (e.g.,\nCodeCoT and MapCoder), achieving an average Pass@1 score of 77.8%.\n","authors":["Ruwei Pan","Hongyu Zhang","Chao Liu"],"pdf_url":"https://arxiv.org/pdf/2501.07811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07805v1","updated":"2025-01-14T03:15:31Z","published":"2025-01-14T03:15:31Z","title":"How Far are App Secrets from Being Stolen? A Case Study on Android","summary":"  Android apps can hold secret strings of themselves such as cloud service\ncredentials or encryption keys. Leakage of such secret strings can induce\nunprecedented consequences like monetary losses or leakage of user private\ninformation. In practice, various security issues were reported because many\napps failed to protect their secrets. However, little is known about the types,\nusages, exploitability, and consequences of app secret leakage issues. While a\nlarge body of literature has been devoted to studying user private information\nleakage, there is no systematic study characterizing app secret leakage issues.\nHow far are Android app secrets from being stolen?\n  To bridge this gap, we conducted the first systematic study to characterize\napp secret leakage issues in Android apps based on 575 potential app secrets\nsampled from 14,665 popular Android apps on Google Play. We summarized the\ncommon categories of leaked app secrets, assessed their security impacts and\ndisclosed app bad practices in storing app secrets. We devised a text mining\nstrategy using regular expressions and demonstrated that numerous app secrets\ncan be easily stolen, even from the highly popular Android apps on Google. In a\nfollow-up study, we harvested 3,711 distinct exploitable app secrets through\nautomatic analysis. Our findings highlight the prevalence of this problem and\ncall for greater attention to app secret protection.\n","authors":["Lili Wei","Heqing Huang","Shing-Chi Cheung","Kevin Li"],"pdf_url":"https://arxiv.org/pdf/2501.07805v1.pdf","comment":"A pre-print version of the paper. It is accepted to Empirical\n  Software Engineering (EMSE)"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2411.10463v2","updated":"2025-01-14T22:08:13Z","published":"2024-11-03T01:34:45Z","title":"Unexploited Information Value in Human-AI Collaboration","summary":"  Humans and AIs are often paired on decision tasks with the expectation of\nachieving complementary performance -- where the combination of human and AI\noutperforms either one alone. However, how to improve performance of a human-AI\nteam is often not clear without knowing more about what particular information\nand strategies each agent employs. In this paper, we propose a model based in\nstatistical decision theory to analyze human-AI collaboration from the\nperspective of what information could be used to improve a human or AI\ndecision. We demonstrate our model on a deepfake detection task to investigate\nseven video-level features by their unexploited value of information. We\ncompare the human alone, AI alone and human-AI team and offer insights on how\nthe AI assistance impacts people's usage of the information and what\ninformation that the AI exploits well might be useful for improving human\ndecisions.\n","authors":["Ziyang Guo","Yifan Wu","Jason Hartline","Jessica Hullman"],"pdf_url":"https://arxiv.org/pdf/2411.10463v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02888v2","updated":"2025-01-14T20:39:33Z","published":"2024-10-03T18:19:52Z","title":"Pseudo-Automation: How Labor-Offsetting Technologies Reconfigure Roles\n  and Relationships in Frontline Retail Work","summary":"  Self-service machines are a form of pseudo-automation; rather than actually\nautomate tasks, they offset them to unpaid customers. Typically implemented for\ncustomer convenience and to reduce labor costs, self-service is often\ncriticized for worsening customer service and increasing loss and theft for\nretailers. Though millions of frontline service workers continue to interact\nwith these technologies on a day-to-day basis, little is known about how these\nmachines change the nature of frontline labor. Through interviews with current\nand former cashiers who work with self-checkout technologies, we investigate\nhow technology that offsets labor from an employee to a customer can\nreconfigure frontline work. We find three changes to cashiering tasks as a\nresult of self-checkout: (1) Working at self-checkout involved parallel demands\nfrom multiple customers, (2) self-checkout work was more problem-oriented\n(including monitoring and policing customers), and (3) traditional checkout\nbegan to become more demanding as easier transactions were filtered to\nself-checkout. As their interactions with customers became more focused on\nproblem solving and rule enforcement, cashiers were often positioned as\nadversaries to customers at self-checkout. To cope with perceived\nadversarialism, cashiers engaged in a form of relational patchwork, using\ntechniques like scapegoating the self-checkout machine and providing excessive\ncustomer service in order to maintain positive customer interactions in the\nface of potential conflict. Our findings highlight how even under\npseudo-automation, workers must engage in relational work to manage and mend\nnegative human-to-human interactions so that machines can be properly\nimplemented in context.\n","authors":["Pegah Moradi","Karen Levy","Cristobal Cheyre"],"pdf_url":"https://arxiv.org/pdf/2410.02888v2.pdf","comment":"Pegah Moradi, Karen Levy, and Cristobal Cheyre. 2025.\n  Pseudo-Automation: How Labor-Offsetting Technologies Reconfigure Roles and\n  Relationships in Frontline Retail Work. Proc. ACM Hum.-Comput. Interact. 9,\n  2, Article CSCW153 (April 2025), 21 pages"},{"id":"http://arxiv.org/abs/2501.08406v1","updated":"2025-01-14T19:53:58Z","published":"2025-01-14T19:53:58Z","title":"OptiChat: Bridging Optimization Models and Practitioners with Large\n  Language Models","summary":"  Optimization models have been applied to solve a wide variety of\ndecision-making problems. These models are usually developed by optimization\nexperts but are used by practitioners without optimization expertise in various\napplication domains. As a result, practitioners often struggle to interact with\nand draw useful conclusions from optimization models independently. To fill\nthis gap, we introduce OptiChat, a natural language dialogue system designed to\nhelp practitioners interpret model formulation, diagnose infeasibility, analyze\nsensitivity, retrieve information, evaluate modifications, and provide\ncounterfactual explanations. By augmenting large language models (LLMs) with\nfunctional calls and code generation tailored for optimization models, we\nenable seamless interaction and minimize the risk of hallucinations in\nOptiChat. We develop a new dataset to evaluate OptiChat's performance in\nexplaining optimization models. Experiments demonstrate that OptiChat\neffectively bridges the gap between optimization models and practitioners,\ndelivering autonomous, accurate, and instant responses.\n","authors":["Hao Chen","Gonzalo Esteban Constante-Flores","Krishna Sri Ipsit Mantri","Sai Madhukiran Kompalli","Akshdeep Singh Ahluwalia","Can Li"],"pdf_url":"https://arxiv.org/pdf/2501.08406v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08393v1","updated":"2025-01-14T19:19:37Z","published":"2025-01-14T19:19:37Z","title":"Empathetic Conversational Agents: Utilizing Neural and Physiological\n  Signals for Enhanced Empathetic Interactions","summary":"  Conversational agents (CAs) are revolutionizing human-computer interaction by\nevolving from text-based chatbots to empathetic digital humans (DHs) capable of\nrich emotional expressions. This paper explores the integration of neural and\nphysiological signals into the perception module of CAs to enhance empathetic\ninteractions. By leveraging these cues, the study aims to detect emotions in\nreal-time and generate empathetic responses and expressions. We conducted a\nuser study where participants engaged in conversations with a DH about\nemotional topics. The DH responded and displayed expressions by mirroring\ndetected emotions in real-time using neural and physiological cues. The results\nindicate that participants experienced stronger emotions and greater engagement\nduring interactions with the Empathetic DH, demonstrating the effectiveness of\nincorporating neural and physiological signals for real-time emotion\nrecognition. However, several challenges were identified, including recognition\naccuracy, emotional transition speeds, individual personality effects, and\nlimitations in voice tone modulation. Addressing these challenges is crucial\nfor further refining Empathetic DHs and fostering meaningful connections\nbetween humans and artificial entities. Overall, this research advances\nhuman-agent interaction and highlights the potential of real-time neural and\nphysiological emotion recognition in creating empathetic DHs.\n","authors":["Nastaran Saffaryazdi","Tamil Selvan Gunasekaran","Kate Laveys","Elizabeth Broadbent","Mark Billinghurst"],"pdf_url":"https://arxiv.org/pdf/2501.08393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08389v1","updated":"2025-01-14T19:06:44Z","published":"2025-01-14T19:06:44Z","title":"Toward Zero-Shot User Intent Recognition in Shared Autonomy","summary":"  A fundamental challenge of shared autonomy is to use high-DoF robots to\nassist, rather than hinder, humans by first inferring user intent and then\nempowering the user to achieve their intent. Although successful, prior methods\neither rely heavily on a priori knowledge of all possible human intents or\nrequire many demonstrations and interactions with the human to learn these\nintents before being able to assist the user. We propose and study a zero-shot,\nvision-only shared autonomy (VOSA) framework designed to allow robots to use\nend-effector vision to estimate zero-shot human intents in conjunction with\nblended control to help humans accomplish manipulation tasks with unknown and\ndynamically changing object locations. To demonstrate the effectiveness of our\nVOSA framework, we instantiate a simple version of VOSA on a Kinova Gen3\nmanipulator and evaluate our system by conducting a user study on three\ntabletop manipulation tasks. The performance of VOSA matches that of an oracle\nbaseline model that receives privileged knowledge of possible human intents\nwhile also requiring significantly less effort than unassisted teleoperation.\nIn more realistic settings, where the set of possible human intents is fully or\npartially unknown, we demonstrate that VOSA requires less human effort and time\nthan baseline approaches while being preferred by a majority of the\nparticipants. Our results demonstrate the efficacy and efficiency of using\noff-the-shelf vision algorithms to enable flexible and beneficial shared\ncontrol of a robot manipulator. Code and videos available here:\nhttps://sites.google.com/view/zeroshot-sharedautonomy/home.\n","authors":["Atharv Belsare","Zohre Karimi","Connor Mattson","Daniel S. Brown"],"pdf_url":"https://arxiv.org/pdf/2501.08389v1.pdf","comment":"10 pages, 6 figures, Accepted to IEEE/ACM International Conference on\n  Human-Robot Interaction (HRI), 2025. Equal Contribution from the first three\n  authors"},{"id":"http://arxiv.org/abs/2501.08253v1","updated":"2025-01-14T16:57:43Z","published":"2025-01-14T16:57:43Z","title":"Jigsaw: Authoring Immersive Storytelling Experiences with Augmented\n  Reality and Internet of Things","summary":"  Augmented Reality (AR) presents new opportunities for immersive storytelling.\nHowever, this immersiveness faces two main hurdles. First, AR's immersive\nquality is often confined to visual elements, such as pixels on a screen.\nSecond, crafting immersive narratives is complex and generally beyond the reach\nof amateurs due to the need for advanced technical skills. We introduce Jigsaw,\na system that empowers beginners to both experience and craft immersive\nstories, blending virtual and physical elements. Jigsaw uniquely combines\nmobile AR with readily available Internet-of-things (IoT) devices. We conducted\na qualitative study with 20 participants to assess Jigsaw's effectiveness in\nboth consuming and creating immersive narratives. The results were promising:\nparticipants not only successfully created their own immersive stories but also\nfound the playback of three such stories deeply engaging. However, sensory\noverload emerged as a significant challenge in these experiences. We discuss\ndesign trade-offs and considerations for future endeavors in immersive\nstorytelling involving AR and IoT.\n","authors":["Lei Zhang","Daekun Kim","Youjean Cho","Ava Robinson","Yu Jiang Tham","Rajan Vaish","Andrés Monroy-Hernández"],"pdf_url":"https://arxiv.org/pdf/2501.08253v1.pdf","comment":"In Proceedings of the 2024 CHI Conference on Human Factors in\n  Computing Systems (CHI '24). 14 pages"},{"id":"http://arxiv.org/abs/2501.08237v1","updated":"2025-01-14T16:22:36Z","published":"2025-01-14T16:22:36Z","title":"Cognitive Assessment and Training in Extended Reality: Multimodal\n  Systems, Clinical Utility, and Current Challenges","summary":"  Extended reality (XR) technologies-encompassing virtual reality (VR),\naugmented reality (AR), and mixed reality (MR) are transforming cognitive\nassessment and training by offering immersive, interactive environments that\nsimulate real-world tasks. XR enhances ecological validity while enabling\nreal-time, multimodal data collection through tools such as galvanic skin\nresponse (GSR), electroencephalography (EEG), eye tracking (ET), hand tracking,\nand body tracking. This allows for a more comprehensive understanding of\ncognitive and emotional processes, as well as adaptive, personalized\ninterventions for users. Despite these advancements, current XR applications\noften underutilize the full potential of multimodal integration, relying\nprimarily on visual and auditory inputs. Challenges such as cybersickness,\nusability concerns, and accessibility barriers further limit the widespread\nadoption of XR tools in cognitive science and clinical practice. This review\nexamines XR-based cognitive assessment and training, focusing on its advantages\nover traditional methods, including ecological validity, engagement, and\nadaptability. It also explores unresolved challenges such as system usability,\ncost, and the need for multimodal feedback integration. The review concludes by\nidentifying opportunities for optimizing XR tools to improve cognitive\nevaluation and rehabilitation outcomes, particularly for diverse populations,\nincluding older adults and individuals with cognitive impairments.\n","authors":["Palmira Victoria González-Erena","Sara Fernández-Guinea","Panagiotis Kourtesis"],"pdf_url":"https://arxiv.org/pdf/2501.08237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08182v1","updated":"2025-01-14T15:08:56Z","published":"2025-01-14T15:08:56Z","title":"CG-MER: A Card Game-based Multimodal dataset for Emotion Recognition","summary":"  The field of affective computing has seen significant advancements in\nexploring the relationship between emotions and emerging technologies. This\npaper presents a novel and valuable contribution to this field with the\nintroduction of a comprehensive French multimodal dataset designed specifically\nfor emotion recognition. The dataset encompasses three primary modalities:\nfacial expressions, speech, and gestures, providing a holistic perspective on\nemotions. Moreover, the dataset has the potential to incorporate additional\nmodalities, such as Natural Language Processing (NLP) to expand the scope of\nemotion recognition research. The dataset was curated through engaging\nparticipants in card game sessions, where they were prompted to express a range\nof emotions while responding to diverse questions. The study included 10\nsessions with 20 participants (9 females and 11 males). The dataset serves as a\nvaluable resource for furthering research in emotion recognition and provides\nan avenue for exploring the intricate connections between human emotions and\ndigital technologies.\n","authors":["Nessrine Farhat","Amine Bohi","Leila Ben Letaifa","Rim Slama"],"pdf_url":"https://arxiv.org/pdf/2501.08182v1.pdf","comment":"8 pages, 2 figures and 4 tables. Sixteenth International Conference\n  on Machine Vision (ICMV 2023), Yerevan, Armenia"},{"id":"http://arxiv.org/abs/2501.08070v1","updated":"2025-01-14T12:35:21Z","published":"2025-01-14T12:35:21Z","title":"The Phase Model of Misinformation Interventions","summary":"  Misinformation is a challenging problem. This paper provides the first\nsystematic interdisciplinary investigation of technical and non-technical\ninterventions against misinformation. It combines interviews and a survey to\nunderstand which interventions are accepted across academic disciplines and\napproved by misinformation experts. Four interventions are supported by more\nthan two in three misinformation experts: promoting media literacy, education\nin schools and universities, finding information about claims, and finding\nsources for claims. The most controversial intervention is deleting\nmisinformation. We discuss the potentials and risks of all interventions.\nEducation-based interventions are perceived as the most helpful by\nmisinformation experts. Interventions focused on providing evidence are also\nwidely perceived as helpful. We discuss them as scalable and always available\ninterventions that empower users to independently identify misinformation. We\nalso introduce the Phase Model of Misinformation Interventions that helps\npractitioners make informed decisions about which interventions to focus on and\nhow to best combine interventions.\n","authors":["Hendrik Heuer"],"pdf_url":"https://arxiv.org/pdf/2501.08070v1.pdf","comment":"Accepted at CSCW 2025, April 2025"},{"id":"http://arxiv.org/abs/2403.09471v5","updated":"2025-01-14T11:59:06Z","published":"2024-03-14T15:10:54Z","title":"MambaTalk: Efficient Holistic Gesture Synthesis with Selective State\n  Space Models","summary":"  Gesture synthesis is a vital realm of human-computer interaction, with\nwide-ranging applications across various fields like film, robotics, and\nvirtual reality. Recent advancements have utilized the diffusion model and\nattention mechanisms to improve gesture synthesis. However, due to the high\ncomputational complexity of these techniques, generating long and diverse\nsequences with low latency remains a challenge. We explore the potential of\nstate space models (SSMs) to address the challenge, implementing a two-stage\nmodeling strategy with discrete motion priors to enhance the quality of\ngestures. Leveraging the foundational Mamba block, we introduce MambaTalk,\nenhancing gesture diversity and rhythm through multimodal integration.\nExtensive experiments demonstrate that our method matches or exceeds the\nperformance of state-of-the-art models.\n","authors":["Zunnan Xu","Yukang Lin","Haonan Han","Sicheng Yang","Ronghui Li","Yachao Zhang","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2403.09471v5.pdf","comment":"NeurlPS 2024, Camera Ready"},{"id":"http://arxiv.org/abs/2501.08046v1","updated":"2025-01-14T11:53:10Z","published":"2025-01-14T11:53:10Z","title":"Building Symbiotic AI: Reviewing the AI Act for a Human-Centred,\n  Principle-Based Framework","summary":"  Artificial Intelligence (AI) spreads quickly as new technologies and services\ntake over modern society. The need to regulate AI design, development, and use\nis strictly necessary to avoid unethical and potentially dangerous consequences\nto humans. The European Union (EU) has released a new legal framework, the AI\nAct, to regulate AI by undertaking a risk-based approach to safeguard humans\nduring interaction. At the same time, researchers offer a new perspective on AI\nsystems, commonly known as Human-Centred AI (HCAI), highlighting the need for a\nhuman-centred approach to their design. In this context, Symbiotic AI (a\nsubtype of HCAI) promises to enhance human capabilities through a deeper and\ncontinuous collaboration between human intelligence and AI. This article\npresents the results of a Systematic Literature Review (SLR) that aims to\nidentify principles that characterise the design and development of Symbiotic\nAI systems while considering humans as the core of the process. Through content\nanalysis, four principles emerged from the review that must be applied to\ncreate Human-Centred AI systems that can establish a symbiotic relationship\nwith humans. In addition, current trends and challenges were defined to\nindicate open questions that may guide future research for the development of\nSAI systems that comply with the AI Act.\n","authors":["Miriana Calvano","Antonio Curci","Giuseppe Desolda","Andrea Esposito","Rosa Lanzilotti","Antonio Piccinno"],"pdf_url":"https://arxiv.org/pdf/2501.08046v1.pdf","comment":"First version: 17 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2412.07344v3","updated":"2025-01-14T10:35:19Z","published":"2024-12-10T09:37:25Z","title":"Virtual Reflections on a Dynamic 2D Eye Model Improve Spatial Reference\n  Identification","summary":"  The visible orientation of human eyes creates some transparency about\npeople's spatial attention and other mental states. This leads to a dual role\nfor the eyes as a means of sensing and communication. Accordingly, artificial\neye models are being explored as communication media in human-machine\ninteraction scenarios. One challenge in the use of eye models for communication\nconsists of resolving spatial reference ambiguities, especially for\nscreen-based models. Here, we introduce an approach for overcoming this\nchallenge through the introduction of reflection-like features that are\ncontingent on artificial eye movements. We conducted a user study with 30\nparticipants in which participants had to use spatial references provided by\ndynamic eye models to advance in a fast-paced group interaction task. Compared\nto a non-reflective eye model and a pure reflection mode, their combination in\nthe new approach resulted in a higher identification accuracy and user\nexperience, suggesting a synergistic benefit.\n","authors":["Matti Krüger","Yutaka Oshima","Yu Fang"],"pdf_url":"https://arxiv.org/pdf/2412.07344v3.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2405.02337v2","updated":"2025-01-14T09:38:26Z","published":"2024-04-29T13:47:45Z","title":"Experiencing the Future Mundane: Configuring Design Fiction as Breaching\n  Experiment","summary":"  This paper introduces a novel methodological approach for surfacing the\nacceptability and adoption challenges that confront future and emerging\ntechnologies from the perspective of mundane action, in which they will\nultimately be embedded and used. This novel approach configures design fiction\nas a breaching experiment to surface taken for granted background expectancies\nthat are fateful for acceptability and adoption. We explain the logic of this\nnew interdisciplinary method and present a concrete case to demonstrate its\nviability: a design fiction called Experiencing the Future Mundane (EFM), which\ndepicts a future world in which watching TV is driven by smart adaptive media.\nWe explicate the design of the EFM, how it was configured to breach common\nsense knowledge and surface taken for granted background expectancies\nconcerning how watching TV works and is expected to work, the acceptability and\nadoption challenges that emerge from user engagement with the experience, and\nhow this novel approach may be adopted more broadly.\n","authors":["Andy Crabtree","Tom Lodge","Alan Chamberlain","Neelima Sailaja","Paul Coulton","Matthew Pilling","Ian Forrester"],"pdf_url":"https://arxiv.org/pdf/2405.02337v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07957v1","updated":"2025-01-14T09:21:17Z","published":"2025-01-14T09:21:17Z","title":"AI Guide Dog: Egocentric Path Prediction on Smartphone","summary":"  This paper introduces AI Guide Dog (AIGD), a lightweight egocentric\nnavigation assistance system for visually impaired individuals, designed for\nreal-time deployment on smartphones. AIGD addresses key challenges in blind\nnavigation by employing a vision-only, multi-label classification approach to\npredict directional commands, ensuring safe traversal across diverse\nenvironments. We propose a novel technique to enable goal-based outdoor\nnavigation by integrating GPS signals and high-level directions, while also\naddressing uncertain multi-path predictions for destination-free indoor\nnavigation. Our generalized model is the first navigation assistance system to\nhandle both goal-oriented and exploratory navigation scenarios across indoor\nand outdoor settings, establishing a new state-of-the-art in blind navigation.\nWe present methods, datasets, evaluations, and deployment insights to encourage\nfurther innovations in assistive navigation systems.\n","authors":["Aishwarya Jadhav","Jeffery Cao","Abhishree Shetty","Urvashi Priyam Kumar","Aditi Sharma","Ben Sukboontip","Jayant Sravan Tamarapalli","Jingyi Zhang","Anirudh Koul"],"pdf_url":"https://arxiv.org/pdf/2501.07957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16793v2","updated":"2025-01-14T08:47:17Z","published":"2024-09-25T10:14:01Z","title":"Spacewalker: Traversing Representation Spaces for Fast Interactive\n  Exploration and Annotation of Unstructured Data","summary":"  In industries such as healthcare, finance, and manufacturing, analysis of\nunstructured textual data presents significant challenges for analysis and\ndecision making. Uncovering patterns within large-scale corpora and\nunderstanding their semantic impact is critical, but depends on domain experts\nor resource-intensive manual reviews. In response, we introduce Spacewalker in\nthis system demonstration paper, an interactive tool designed to analyze,\nexplore, and annotate data across multiple modalities. It allows users to\nextract data representations, visualize them in low-dimensional spaces and\ntraverse large datasets either exploratory or by querying regions of interest.\nWe evaluated Spacewalker through extensive experiments and annotation studies,\nassessing its efficacy in improving data integrity verification and annotation.\nWe show that Spacewalker reduces time and effort compared to traditional\nmethods. The code of this work is open-source and can be found at:\nhttps://github.com/code-lukas/Spacewalker\n","authors":["Lukas Heine","Fabian Hörst","Jana Fragemann","Gijs Luijten","Jan Egger","Fin Bahnsen","M. Saquib Sarfraz","Jens Kleesiek","Constantin Seibold"],"pdf_url":"https://arxiv.org/pdf/2409.16793v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07883v1","updated":"2025-01-14T06:49:22Z","published":"2025-01-14T06:49:22Z","title":"Assessment of Personalized Learning in Immersive and Intelligent Virtual\n  Classroom on Student Engagement","summary":"  As trends in education evolve, personalized learning has transformed\nindividuals' engagement with knowledge and skill development. In the digital\nage, state-of-the-art technologies have been increasingly integrated into\nclassrooms to support intelligent education and foster personalized learning\nexperiences. One promising approach is the use of eye-tracking technology to\nevaluate student engagement in intelligent virtual classrooms. This paper\nexplores the assessment of personalized learning in the virtual classroom and\nits impact on student engagement through the eye movement paradigm. The study\naims to provide insights into how personalized learning approaches can enhance\nstudent participation, motivation, and academic performance in the online\nlearning environment. Through a comprehensive literature review, case study,\nand data analysis, the paper examines the key elements of personalized\nlearning, the methods of assessment, and the resulting effects on student\nengagement. The findings suggest that the eye movement paradigm has the\npotential to assess student engagement and promote better educational outcomes.\n","authors":["Ying Weng","Yiming Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.07883v1.pdf","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2501.06698v2","updated":"2025-01-14T06:34:46Z","published":"2025-01-12T03:14:09Z","title":"A comparative study of sensory encoding models for human navigation in\n  virtual reality","summary":"  In virtual reality applications, users often navigate through virtual\nenvironments, but the issue of physiological responses, such as cybersickness,\nfatigue, and cognitive workload, can disrupt or even halt these activities.\nDespite its impact, the underlying mechanisms of how the sensory system encodes\ninformation in VR remain unclear. In this study, we compare three sensory\nencoding models, Bayesian Efficient Coding, Fitness Maximizing Coding, and the\nLinear Nonlinear Poisson model, regarding their ability to simulate human\nnavigation behavior in VR. By incorporating the factor of physiological\nresponses into the models, we find that the Bayesian Efficient Coding model\ngenerally outperforms the others. Furthermore, the Fitness Maximizing Code\nframework provides more accurate estimates when the error penalty is small. Our\nresults suggest that the Bayesian Efficient Coding framework offers superior\npredictions in most scenarios, providing a better understanding of human\nnavigation behavior in VR environments.\n","authors":["Tangyao Li","Qiyuan Zhan","Yitong Zhu","Bojing Hou","Yuyang Wang"],"pdf_url":"https://arxiv.org/pdf/2501.06698v2.pdf","comment":"6 pages, 4 figures, submitted to IEEE"},{"id":"http://arxiv.org/abs/2501.04905v2","updated":"2025-01-14T06:20:59Z","published":"2025-01-09T01:38:34Z","title":"Balancing Exploration and Cybersickness: Investigating Curiosity-Driven\n  Behavior in Virtual Environments","summary":"  During virtual navigation, users exhibit varied interaction and navigation\nbehaviors influenced by several factors. Existing theories and models have been\ndeveloped to explain and predict these diverse patterns. While users often\nexperience uncomfortable sensations, such as cybersickness, during virtual\nreality (VR) use, they do not always make optimal decisions to mitigate these\neffects. Although methods like reinforcement learning have been used to model\ndecision-making processes, they typically rely on random selection to simulate\nactions, failing to capture the complexities of real navigation behavior. In\nthis study, we propose curiosity as a key factor driving irrational\ndecision-making, suggesting that users continuously balance exploration and\ncybersickness according to the free energy principle during virtual navigation.\nOur findings show that VR users generally adopt conservative strategies when\nnavigating, with most participants displaying negative curiosity across trials.\nHowever, curiosity levels tend to rise when the virtual environment changes,\nillustrating the dynamic interplay between exploration and discomfort. This\nstudy provides a quantitative approach to decoding curiosity-driven behavior\nduring virtual navigation, offering insights into how users balance exploration\nand the avoidance of cybersickness. Future research will further refine this\nmodel by incorporating additional psychological and environmental factors to\nimprove the accuracy of navigation pattern predictions.\n","authors":["Tangyao Li","Yuyang Wang"],"pdf_url":"https://arxiv.org/pdf/2501.04905v2.pdf","comment":"12 pages, 9 figures, submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2403.11075v2","updated":"2025-01-14T06:02:50Z","published":"2024-03-17T03:52:52Z","title":"GOMA: Proactive Embodied Cooperative Communication via Goal-Oriented\n  Mental Alignment","summary":"  Verbal communication plays a crucial role in human cooperation, particularly\nwhen the partners only have incomplete information about the task, environment,\nand each other's mental state. In this paper, we propose a novel cooperative\ncommunication framework, Goal-Oriented Mental Alignment (GOMA). GOMA formulates\nverbal communication as a planning problem that minimizes the misalignment\nbetween the parts of agents' mental states that are relevant to the goals. This\napproach enables an embodied assistant to reason about when and how to\nproactively initialize communication with humans verbally using natural\nlanguage to help achieve better cooperation. We evaluate our approach against\nstrong baselines in two challenging environments, Overcooked (a multiplayer\ngame) and VirtualHome (a household simulator). Our experimental results\ndemonstrate that large language models struggle with generating meaningful\ncommunication that is grounded in the social and physical context. In contrast,\nour approach can successfully generate concise verbal communication for the\nembodied assistant to effectively boost the performance of the cooperation as\nwell as human users' perception of the assistant.\n","authors":["Lance Ying","Kunal Jha","Shivam Aarya","Joshua B. Tenenbaum","Antonio Torralba","Tianmin Shu"],"pdf_url":"https://arxiv.org/pdf/2403.11075v2.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.15240v3","updated":"2025-01-14T04:10:46Z","published":"2024-11-22T01:58:35Z","title":"AI Foundation Models for Wearable Movement Data in Mental Health\n  Research","summary":"  Pretrained foundation models and transformer architectures have driven the\nsuccess of large language models (LLMs) and other modern AI breakthroughs.\nHowever, similar advancements in health data modeling remain limited due to the\nneed for innovative adaptations. Wearable movement data offers a valuable\navenue for exploration, as it's a core feature in nearly all commercial\nsmartwatches, well established in clinical and mental health research, and the\nsequential nature of the data shares similarities to language. We introduce the\nPretrained Actigraphy Transformer (PAT), the first open source foundation model\ndesigned for time-series wearable movement data. Leveraging transformer-based\narchitectures and novel techniques, such as patch embeddings, and pretraining\non data from 29,307 participants in a national U.S. sample, PAT achieves\nstate-of-the-art performance in several mental health prediction tasks. PAT is\nalso lightweight and easily interpretable, making it a robust tool for mental\nhealth research.\n  GitHub: https://github.com/njacobsonlab/Pretrained-Actigraphy-Transformer/\n","authors":["Franklin Y. Ruan","Aiwei Zhang","Jenny Y. Oh","SouYoung Jin","Nicholas C. Jacobson"],"pdf_url":"https://arxiv.org/pdf/2411.15240v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23639v2","updated":"2025-01-14T03:36:04Z","published":"2024-10-31T05:21:46Z","title":"Biologically-Inspired Technologies: Integrating Brain-Computer Interface\n  and Neuromorphic Computing for Human Digital Twins","summary":"  The integration of immersive communication into a human-centric ecosystem has\nintensified the demand for sophisticated Human Digital Twins (HDTs) driven by\nmultifaceted human data. However, the effective construction of HDTs faces\nsignificant challenges due to the heterogeneity of data collection devices, the\nhigh energy demands associated with processing intricate data, and concerns\nover the privacy of sensitive information. This work introduces a novel\nbiologically-inspired (bio-inspired) HDT framework that leverages\nBrain-Computer Interface (BCI) sensor technology to capture brain signals as\nthe data source for constructing HDT. By collecting and analyzing these\nsignals, the framework not only minimizes device heterogeneity and enhances\ndata collection efficiency, but also provides richer and more nuanced\nphysiological and psychological data for constructing personalized HDTs. To\nthis end, we further propose a bio-inspired neuromorphic computing learning\nmodel based on the Spiking Neural Network (SNN). This model utilizes discrete\nneural spikes to emulate the way of human brain processes information, thereby\nenhancing the system's ability to process data effectively while reducing\nenergy consumption. Additionally, we integrate a Federated Learning (FL)\nstrategy within the model to strengthen data privacy. We then conduct a case\nstudy to demonstrate the performance of our proposed twofold bio-inspired\nscheme. Finally, we present several challenges and promising directions for\nfuture research of HDTs driven by bio-inspired technologies.\n","authors":["Chen Shang","Jiadong Yu","Dinh Thai Hoang"],"pdf_url":"https://arxiv.org/pdf/2410.23639v2.pdf","comment":"9 pages, 5 figures,"},{"id":"http://arxiv.org/abs/2408.12463v2","updated":"2025-01-14T01:57:04Z","published":"2024-08-22T15:04:59Z","title":"Smartphone-based Eye Tracking System using Edge Intelligence and Model\n  Optimisation","summary":"  A significant limitation of current smartphone-based eye-tracking algorithms\nis their low accuracy when applied to video-type visual stimuli, as they are\ntypically trained on static images. Also, the increasing demand for real-time\ninteractive applications like games, VR, and AR on smartphones requires\novercoming the limitations posed by resource constraints such as limited\ncomputational power, battery life, and network bandwidth. Therefore, we\ndeveloped two new smartphone eye-tracking techniques for video-type visuals by\ncombining Convolutional Neural Networks (CNN) with two different Recurrent\nNeural Networks (RNN), namely Long Short Term Memory (LSTM) and Gated Recurrent\nUnit (GRU). Our CNN+LSTM and CNN+GRU models achieved an average Root Mean\nSquare Error of 0.955 cm and 1.091 cm, respectively. To address the\ncomputational constraints of smartphones, we developed an edge intelligence\narchitecture to enhance the performance of smartphone-based eye tracking. We\napplied various optimisation methods like quantisation and pruning to deep\nlearning models for better energy, CPU, and memory usage on edge devices,\nfocusing on real-time processing. Using model quantisation, the model inference\ntime in the CNN+LSTM and CNN+GRU models was reduced by 21.72% and 19.50%,\nrespectively, on edge devices.\n","authors":["Nishan Gunawardena","Gough Yumu Lui","Jeewani Anupama Ginige","Bahman Javadi"],"pdf_url":"https://arxiv.org/pdf/2408.12463v2.pdf","comment":"I have included the three papers as reference, which are closely\n  related. We have expanded the future work section to provide a more thorough\n  discussion of the concepts of \"varying lighting conditions\" and \"dynamic user\n  environments.\" We have added a note below Table 4 to clarify the\n  abbreviations' meaning. Elaborated the role of the Domain Expert within the\n  presentation layer in Section 4.1"}]},"2025-01-13T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2501.07676v1","updated":"2025-01-13T20:24:10Z","published":"2025-01-13T20:24:10Z","title":"Smells-sus: Sustainability Smells in IaC","summary":"  Practitioners use Infrastructure as Code (IaC) scripts to efficiently\nconfigure IT infrastructures through machine-readable definition files.\nHowever, during the development of these scripts, some code patterns or\ndeployment choices may lead to sustainability issues like inefficient resource\nutilization or redundant provisioning for example. We call this type of\npatterns sustainability smells. These inefficiencies pose significant\nenvironmental and financial challenges, given the growing scale of cloud\ncomputing. This research focuses on Terraform, a widely adopted IaC tool. Our\nstudy involves defining seven sustainability smells and validating them through\na survey with 19 IaC practitioners. We utilized a dataset of 28,327 Terraform\nscripts from 395 open-source repositories. We performed a detailed qualitative\nanalysis of a randomly sampled 1,860 Terraform scripts from the original\ndataset to identify code patterns that correspond to the sustainability smells\nand used the other 26,467 Terraform scripts to study the prevalence of the\ndefined sustainability smells. Our results indicate varying prevalence rates of\nthese smells across the dataset. The most prevalent smell is Monolithic\nInfrastructure, which appears in 9.67\\% of the scripts. Additionally, our\nfindings highlight the complexity of conducting root cause analysis for\nsustainability issues, as these smells often arise from a confluence of script\nstructures, configuration choices, and deployment contexts.\n","authors":["Seif Ashraf","Mohammad Hamdaqa"],"pdf_url":"https://arxiv.org/pdf/2501.07676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07553v1","updated":"2025-01-13T18:37:01Z","published":"2025-01-13T18:37:01Z","title":"Simulink Mutation Testing using CodeBERT","summary":"  We present BERTiMuS, an approach that uses CodeBERT to generate mutants for\nSimulink models. BERTiMuS converts Simulink models into textual\nrepresentations, masks tokens from the derived text, and uses CodeBERT to\npredict the masked tokens. Simulink mutants are obtained by replacing the\nmasked tokens with predictions from CodeBERT. We evaluate BERTiMuS using\nSimulink models from an industrial benchmark, and compare it with FIM -- a\nstate-of-the-art mutation tool for Simulink. We show that, relying exclusively\non CodeBERT, BERTiMuS can generate the block-based Simulink mutation patterns\ndocumented in the literature. Further, our results indicate that: (a) BERTiMuS\nis complementary to FIM, and (b) when one considers a requirements-aware notion\nof mutation testing, BERTiMuS outperforms FIM.\n","authors":["Jingfan Zhang","Delaram Ghobari","Mehrdad Sabetzadeh","Shiva Nejati"],"pdf_url":"https://arxiv.org/pdf/2501.07553v1.pdf","comment":"This paper has been accepted at the 6th ACM/IEEE International\n  Conference on Automation of Software Test (AST 2025)"},{"id":"http://arxiv.org/abs/2501.07531v1","updated":"2025-01-13T18:09:25Z","published":"2025-01-13T18:09:25Z","title":"Evaluating Agent-based Program Repair at Google","summary":"  Agent-based program repair offers to automatically resolve complex bugs\nend-to-end by combining the planning, tool use, and code generation abilities\nof modern LLMs. Recent work has explored the use of agent-based repair\napproaches on the popular open-source SWE-Bench, a collection of bugs from\nhighly-rated GitHub Python projects. In addition, various agentic approaches\nsuch as SWE-Agent have been proposed to solve bugs in this benchmark. This\npaper explores the viability of using an agentic approach to address bugs in an\nenterprise context. To investigate this, we curate an evaluation set of 178\nbugs drawn from Google's issue tracking system. This dataset spans both\nhuman-reported (78) and machine-reported bugs (100).\n  To establish a repair performance baseline on this benchmark, we implement\nPasserine, an agent similar in spirit to SWE-Agent that can work within\nGoogle's development environment. We show that with 20 trajectory samples and\nGemini 1.5 Pro, Passerine can produce a patch that passes bug tests (i.e.,\nplausible) for 73% of machine-reported and 25.6% of human-reported bugs in our\nevaluation set. After manual examination, we found that 43% of machine-reported\nbugs and 17.9% of human-reported bugs have at least one patch that is\nsemantically equivalent to the ground-truth patch.\n  These results establish a baseline on an industrially relevant benchmark,\nwhich as we show, contains bugs drawn from a different distribution -- in terms\nof language diversity, size, and spread of changes, etc. -- compared to those\nin the popular SWE-Bench dataset.\n","authors":["Pat Rondon","Renyao Wei","José Cambronero","Jürgen Cito","Aaron Sun","Siddhant Sanyam","Michele Tufano","Satish Chandra"],"pdf_url":"https://arxiv.org/pdf/2501.07531v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17976v3","updated":"2025-01-13T17:42:09Z","published":"2024-11-27T01:15:36Z","title":"The importance of visual modelling languages in generative software\n  engineering","summary":"  Multimodal GPTs represent a watershed in the interplay between Software\nEngineering and Generative Artificial Intelligence. GPT-4 accepts image and\ntext inputs, rather than simply natural language. We investigate relevant use\ncases stemming from these enhanced capabilities of GPT-4. To the best of our\nknowledge, no other work has investigated similar use cases involving Software\nEngineering tasks carried out via multimodal GPTs prompted with a mix of\ndiagrams and natural language.\n","authors":["Roberto Rossi"],"pdf_url":"https://arxiv.org/pdf/2411.17976v3.pdf","comment":"9 pages, working paper"},{"id":"http://arxiv.org/abs/2501.07472v1","updated":"2025-01-13T16:40:34Z","published":"2025-01-13T16:40:34Z","title":"LitmusKt: Concurrency Stress Testing for Kotlin","summary":"  We present LitmusKt - the first tool for litmus testing concurrent programs\nin Kotlin. The tool's novelty also lies in the fact that Kotlin is a\nmultiplatform language, i.e., it compiles into multiple platforms, which means\nthat the concurrency has to be tested on several of them. Our tool allows\nwriting litmus tests in a single custom DSL, and these tests are then run in\nKotlin/Native and Kotlin/JVM, two main platforms for concurrent programming in\nKotlin. Using LitmusKt, we discovered novel bugs in the Kotlin compiler, which\nwe then fixed and they are no longer present. Moreover, LitmusKt was integrated\ninto the CI pipeline for Kotlin. We believe that our tool is valuable for\nfurther studying concurrency in Kotlin and other multiplatform languages, as\nwell as for further developing the Kotlin memory model.\n  LitmusKt is openly available on GitHub:\nhttps://github.com/Jetbrains-Research/litmuskt. The demonstration video is\navailable on YouTube: https://youtu.be/gXI0aYJDnRw.\n","authors":["Denis Lochmelis","Evgenii Moiseenko","Yaroslav Golubev","Anton Podkopaev"],"pdf_url":"https://arxiv.org/pdf/2501.07472v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2501.07425v1","updated":"2025-01-13T15:43:36Z","published":"2025-01-13T15:43:36Z","title":"Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests\n  Through Precise Contextual Information Injection","summary":"  Though many learning-based approaches have been proposed for unit test\ngeneration and achieved remarkable performance, they still have limitations in\nrelying on task-specific datasets. Recently, Large Language Models (LLMs)\nguided by prompt engineering have gained attention for their ability to handle\na broad range of tasks, including unit test generation. Despite their success,\nLLMs may exhibit hallucinations when generating unit tests for focal methods or\nfunctions due to their lack of awareness regarding the project's global\ncontext. These hallucinations may manifest as calls to non-existent methods, as\nwell as incorrect parameters or return values, such as mismatched parameter\ntypes or numbers. While many studies have explored the role of context, they\noften extract fixed patterns of context for different models and focal methods,\nwhich may not be suitable for all generation processes (e.g., excessive\nirrelevant context could lead to redundancy, preventing the model from focusing\non essential information). To overcome this limitation, we propose RATester,\nwhich enhances the LLM's ability to generate more repository-aware unit tests\nthrough global contextual information injection. To equip LLMs with global\nknowledge similar to that of human testers, we integrate the language server\ngopls, which provides essential features (e.g., definition lookup) to assist\nthe LLM. When RATester encounters an unfamiliar identifier (e.g., an unfamiliar\nstruct name), it first leverages gopls to fetch relevant definitions and\ndocumentation comments, and then uses this global knowledge to guide the LLM.\nBy utilizing gopls, RATester enriches the LLM's knowledge of the project's\nglobal context, thereby reducing hallucinations during unit test generation.\n","authors":["Xin Yin","Chao Ni","Xinrui Li","Liushan Chen","Guojun Ma","Xiaohu Yang"],"pdf_url":"https://arxiv.org/pdf/2501.07425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.09536v2","updated":"2025-01-13T15:25:37Z","published":"2024-08-18T16:44:01Z","title":"Galapagos: Automated N-Version Programming with LLMs","summary":"  N-Version Programming is a well-known methodology for developing\nfault-tolerant systems. It achieves fault detection and correction at runtime\nby adding diverse redundancy into programs, minimizing fault mode overlap\nbetween redundant program variants. In this work, we propose the automated\ngeneration of program variants using large language models. We design, develop\nand evaluate Gal\\'apagos: a tool for generating program variants using LLMs,\nvalidating their correctness and equivalence, and using them to assemble\nN-Version binaries. We evaluate Gal\\'apagos by creating N-Version components of\nreal-world C code. Our original results show that Gal\\'apagos can produce\nprogram variants that are proven to be functionally equivalent, even when the\nvariants are written in a different programming language. Our systematic\ndiversity measurement indicates that functionally equivalent variants produced\nby Gal\\'apagos, are statically different after compilation, and present\ndiverging internal behavior at runtime. We demonstrate that the variants\nproduced by Gal\\'apagos can protect C code against real miscompilation bugs\nwhich affect the Clang compiler. Overall, our paper shows that producing\nN-Version software can be drastically automated by advanced usage of practical\nformal verification and generative language models.\n","authors":["Javier Ron","Diogo Gaspar","Javier Cabrera-Arteaga","Benoit Baudry","Martin Monperrus"],"pdf_url":"https://arxiv.org/pdf/2408.09536v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07344v1","updated":"2025-01-13T14:04:01Z","published":"2025-01-13T14:04:01Z","title":"Affirmative Hackathon for Software Developers with Disabilities: An\n  Industry Initiative","summary":"  People with disabilities (PWD) often encounter several barriers to becoming\nemployed. A growing body of evidence in software development highlights the\nbenefits of diversity and inclusion in the field. However, recruiting, hiring,\nand fostering a supportive environment for PWD remains challenging. These\nchallenges are exacerbated by the lack of skilled professionals with experience\nin inclusive hiring and management, which prevents companies from effectively\nincreasing PWD representation on software development teams. Inspired by the\nstrategy adopted in some technology companies that attract talent through\nhackathons and training courses, this paper reports the experience of Zup\nInnovation, a Brazilian software company, in hosting a fully remote affirmative\nhackathon with 50 participants to attract PWD developers. This event resulted\nin 10 new hires and 146 people added to the company's talent pool. Through\nsurveys with participants, we gathered attendees' perceptions and experiences,\naiming to improve future hackathons and similar initiatives by providing\ninsights on accessibility and collaboration. Our findings offer lessons for\nother companies seeking to address similar challenges and promote greater\ninclusion in tech teams.\n","authors":["Thayssa Rocha","Nicole Davila","Rafaella Vaccari","Nicoly Menezes","Marcelle Mota","Edward Monteiro","Cleidson de Souza","Gustavo Pinto"],"pdf_url":"https://arxiv.org/pdf/2501.07344v1.pdf","comment":"12 pages, accepted for CHASE 2025"},{"id":"http://arxiv.org/abs/2501.07339v1","updated":"2025-01-13T13:51:05Z","published":"2025-01-13T13:51:05Z","title":"Evaluating Pre-Trained Models for Multi-Language Vulnerability Patching","summary":"  Software vulnerabilities pose critical security risks, demanding prompt and\neffective mitigation strategies. While advancements in Automated Program Repair\n(APR) have primarily targeted general software bugs, the domain of\nvulnerability patching, which is a security-critical subset of APR, remains\nunderexplored. This paper investigates the potential of pre-trained language\nmodels, CodeBERT and CodeT5, for automated vulnerability patching across\ndiverse datasets and five programming languages. We evaluate these models on\ntheir accuracy, computational efficiency, and how the length of vulnerable code\npatches impacts performance. Our findings reveal promising accuracy levels,\nparticularly for CodeT5 on datasets with complex vulnerability patterns, while\nCodeBERT demonstrates strengths in handling fragmented or context-limited\ndatasets. CodeT5 further showcases superior efficiency, making it well-suited\nfor large-scale applications. However, both models face challenges in\nmaintaining performance as patch length increases, highlighting the complexity\nof addressing extended in program repair specifically aimed at fixing\nvulnerabilities. This study benchmarks model performance, highlights key\nlimitations, and offers insights to improve automated vulnerability patching\nfor practical security applications.\n","authors":["Zanis Ali Khan","Aayush Garg","Yuejun Guo","Qiang Tang"],"pdf_url":"https://arxiv.org/pdf/2501.07339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07207v1","updated":"2025-01-13T11:01:41Z","published":"2025-01-13T11:01:41Z","title":"Beyond Security-by-design: Securing a compromised system","summary":"  Digital infrastructures are seeing convergence and connectivity at\nunprecedented scale. This is true for both current critical national\ninfrastructures and emerging future systems that are highly cyber-physical in\nnature with complex intersections between humans and technologies, e.g., smart\ncities, intelligent transportation, high-value manufacturing and Industry 4.0.\nDiverse legacy and non-legacy software systems underpinned by heterogeneous\nhardware compose on-the-fly to deliver services to millions of users with\nvarying requirements and unpredictable actions. This complexity is compounded\nby intricate and complicated supply-chains with many digital assets and\nservices outsourced to third parties. The reality is that, at any particular\npoint in time, there will be untrusted, partially-trusted or compromised\nelements across the infrastructure. Given this reality, and the societal scale\nof digital infrastructures, delivering secure and resilient operations is a\nmajor challenge. We argue that this requires us to move beyond the paradigm of\nsecurity-by-design and embrace the challenge of securing-a-compromised-system.\n","authors":["Awais Rashid","Sana Belguith","Matthew Bradbury","Sadie Creese","Ivan Flechais","Neeraj Suri"],"pdf_url":"https://arxiv.org/pdf/2501.07207v1.pdf","comment":"Article for the Rossfest Symposium in memory of Ross Anderson,\n  Cambridge, UK, 25 March 2025"},{"id":"http://arxiv.org/abs/2501.07204v1","updated":"2025-01-13T10:58:57Z","published":"2025-01-13T10:58:57Z","title":"Containers as the Quantum Leap in Software Development","summary":"  The goal of the project QLEAP (2022-24), funded by Business Finland and\nparticipating organizations, was to study using containers as elements of\narchitecture design. Such systems include containerized AI systems, using\ncontainers in a hybrid setup (public/hybrid/private clouds), and related\nsecurity concerns. The consortium consists of four companies that represent\ndifferent concerns over using containers (Bittium, M-Files, Solita/ADE\nInsights, Vaadin) and one research organization (University of Jyv\\\"askyl\\\"a).\nIn addition, it has received support from two Veturi companies - Nokia and\nTietoevry - who have also participated in steering the project. Moreover, the\nSW4E ecosystem has participated in the project. This document gathers the key\nlessons learned from the project.\n","authors":["Iftikhar Ahmad","Teemu Autto","Teerath Das","Joonas Hämäläinen","Pasi Jalonen","Viljami Järvinen","Harri Kallio","Tomi Kankainen","Taija Kolehmainen","Pertti Kontio","Pyry Kotilainen","Matti Kurittu","Tommi Mikkonen","Rahul Mohanani","Niko Mäkitalo","Jari Partanen","Roope Pajasmaa","Jarkko Pellikka","Manu Setälä","Jari Siukonen","Anssi Sorvisto","Maha Sroor","Teppo Suominen","Salla Timonen","Muhammad Waseem","Yuriy Yevstihnyeyev","Verneri Äberg","Leif Åstrand"],"pdf_url":"https://arxiv.org/pdf/2501.07204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07195v1","updated":"2025-01-13T10:42:43Z","published":"2025-01-13T10:42:43Z","title":"Teaching Empirical Research Methods in Software Engineering: An\n  Editorial Introduction","summary":"  Empirical Software Engineering has received much attention in recent years\nand became a de-facto standard for scientific practice in Software Engineering.\nHowever, while extensive guidelines are nowadays available for designing,\nconducting, reporting, and reviewing empirical studies, similar attention has\nnot yet been paid to teaching empirical software engineering. Closing this gap\nis the scope of this edited book. In the following editorial introduction, we,\nthe editors, set the foundation by laying out the larger context of the\ndiscipline for a positioning of the remainder of this book.\n","authors":["Daniel Mendez","Paris Avgeriou","Marcos Kalinowski","Nauman bin Ali"],"pdf_url":"https://arxiv.org/pdf/2501.07195v1.pdf","comment":"Preprint to a chapter for the edited book \"Handbook on Teaching\n  Empirical Software Engineering\", Springer, 2024"},{"id":"http://arxiv.org/abs/2501.07165v1","updated":"2025-01-13T09:51:23Z","published":"2025-01-13T09:51:23Z","title":"Unveiling Code Clone Patterns in Open Source VR Software: An Empirical\n  Study","summary":"  Code cloning is frequently observed in software development, often leading to\na variety of maintenance and security issues. While substantial research has\nbeen conducted on code cloning in traditional software, to the best of my\nknowledge, there is a lack of studies on cloning in VR software that consider\nits unique nature, particularly the presence of numerous serialized files in\nconjunction with the source code. In this paper, we conduct the first\nlarge-scale quantitative empirical analysis of software clones in 345\nopen-source VR projects, using the NiCad detector for source code clone\ndetection and large language models (LLMs) for identifying serialized file\nclones. Our study leads to a number of insights into cloning phenomena in VR\nsoftware, guided by seven carefully formulated research questions. These\nfindings, along with their implications, are anticipated to provide useful\nguidance for both researchers and software developers within the VR field.\n","authors":["Huashan Chen","Zisheng Huang","Yifan Xu","Wenjie Huang","Jinfu Chen","Haotang Li","Kebin Peng","Feng Liu","Sen He"],"pdf_url":"https://arxiv.org/pdf/2501.07165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05798v2","updated":"2025-01-13T06:50:42Z","published":"2025-01-10T09:01:49Z","title":"ArkAnalyzer: The Static Analysis Framework for OpenHarmony","summary":"  ArkTS is a new programming language dedicated to developing apps for the\nemerging OpenHarmony mobile operating system. Like other programming languages\nconstantly suffering from performance-related code smells or vulnerabilities,\nthe ArkTS programming language will likely encounter the same problems. The\nsolution given by our research community is to invent static analyzers, which\nare often implemented on top of a common static analysis framework, to detect\nand subsequently repair those issues automatically. Unfortunately, such an\nessential framework is not available for the OpenHarmony community yet.\nExisting program analysis methods have several problems when handling the ArkTS\ncode. To bridge the gap, we design and implement a framework named ArkAnalyzer\nand make it publicly available as an open-source project. Our ArkAnalyzer\naddresses the aforementioned problems and has already integrated a number of\nfundamental static analysis functions that are ready to be reused by developers\nto implement OpenHarmony\n","authors":["Haonan Chen","Daihang Chen","Yizhuo Yang","Lingyun Xu","Liang Gao","Mingyi Zhou","Chunming Hu","Li Li"],"pdf_url":"https://arxiv.org/pdf/2501.05798v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16185v3","updated":"2025-01-13T06:10:24Z","published":"2024-01-29T14:32:27Z","title":"LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing\n  LLMs' Vulnerability Reasoning","summary":"  Large language models (LLMs) have demonstrated significant potential in\nvarious tasks, including those requiring human-level intelligence, such as\nvulnerability detection. However, recent efforts to use LLMs for vulnerability\ndetection remain preliminary, as they lack a deep understanding of whether a\nsubject LLM's vulnerability reasoning capability stems from the model itself or\nfrom external aids such as knowledge retrieval and tooling support.\n  In this paper, we aim to decouple LLMs' vulnerability reasoning from other\ncapabilities, such as vulnerability knowledge adoption, context information\nretrieval, and advanced prompt schemes. We introduce LLM4Vuln, a unified\nevaluation framework that separates and assesses LLMs' vulnerability reasoning\ncapabilities and examines improvements when combined with other enhancements.\n  We conduct controlled experiments using 147 ground-truth vulnerabilities and\n147 non-vulnerable cases in Solidity, Java and C/C++, testing them in a total\nof 3,528 scenarios across four LLMs (GPT-3.5, GPT-4, Phi-3, and Llama 3). Our\nfindings reveal the varying impacts of knowledge enhancement, context\nsupplementation, and prompt schemes. We also identify 14 zero-day\nvulnerabilities in four pilot bug bounty programs, resulting in $3,576 in\nbounties.\n","authors":["Yuqiang Sun","Daoyuan Wu","Yue Xue","Han Liu","Wei Ma","Lyuye Zhang","Yang Liu","Yingjiu Li"],"pdf_url":"https://arxiv.org/pdf/2401.16185v3.pdf","comment":"This is a technical report by Nanyang Technological University.\n  Updated to support Solidity, Java and C/C++"},{"id":"http://arxiv.org/abs/2408.04735v3","updated":"2025-01-13T04:57:43Z","published":"2024-08-08T19:30:03Z","title":"Toward a Better Understanding of Probabilistic Delta Debugging","summary":"  Given a list L of elements and a property that L exhibits, ddmin is a\nwell-known test input minimization algorithm designed to automatically\neliminate irrelevant elements from L. This algorithm is extensively adopted in\ntest input minimization and software debloating. Recently, ProbDD, an advanced\nvariant of ddmin, has been proposed and achieved state-of-the-art performance.\nEmploying Bayesian optimization, ProbDD predicts the likelihood of each element\nin L being essential, and statistically decides which elements and how many\nshould be removed each time. Despite its impressive results, the theoretical\nprobabilistic model of ProbDD is complex, and the specific factors driving its\nsuperior performance have not been investigated. In this paper, we conduct the\nfirst in-depth theoretical analysis of ProbDD, clarifying trends in probability\nand subset size changes while simplifying the probability model. Complementing\nthis analysis, we perform empirical experiments, including success rate\nanalysis, ablation studies, and analysis on trade-offs and limitations, to\nbetter understand and demystify this state-of-the-art algorithm. Our success\nrate analysis shows how ProbDD addresses bottlenecks of ddmin by skipping\ninefficient queries that attempt to delete complements of subsets and\npreviously tried subsets. The ablation study reveals that randomness in ProbDD\nhas no significant impact on efficiency. Based on these findings, we propose\nCDD, a simplified version of ProbDD, reducing complexity in both theory and\nimplementation. Besides, the performance of CDD validates our key findings.\nComprehensive evaluations across 76 benchmarks in test input minimization and\nsoftware debloating show that CDD can achieve the same performance as ProbDD\ndespite its simplification. These insights provide valuable guidance for future\nresearch and applications of test input minimization algorithms.\n","authors":["Mengxiao Zhang","Zhenyang Xu","Yongqiang Tian","Xinru Cheng","Chengnian Sun"],"pdf_url":"https://arxiv.org/pdf/2408.04735v3.pdf","comment":"accepted by ICSE25"},{"id":"http://arxiv.org/abs/2405.03058v5","updated":"2025-01-13T03:11:28Z","published":"2024-05-05T21:41:43Z","title":"A Unified Framework for Automated Code Transformation and Pragma\n  Insertion","summary":"  High-level synthesis, source-to-source compilers, and various Design Space\nExploration techniques for pragma insertion have significantly improved the\nQuality of Results of generated designs. These tools offer benefits such as\nreduced development time and enhanced performance. However, achieving\nhigh-quality results often requires additional manual code transformations and\ntiling selections, which are typically performed separately or as\npre-processing steps. Although DSE techniques enable code transformation\nupfront, the vastness of the search space often limits the exploration of all\npossible code transformations, making it challenging to determine which\ntransformations are necessary. Additionally, ensuring correctness remains\nchallenging, especially for complex transformations and optimizations.\n  To tackle this obstacle, we first propose a comprehensive framework\nleveraging HLS compilers. Our system streamlines code transformation, pragma\ninsertion, and tiles size selection for on-chip data caching through a unified\noptimization problem, aiming to enhance parallelization, particularly\nbeneficial for computation-bound kernels. Them employing a novel Non-Linear\nProgramming (NLP) approach, we simultaneously ascertain transformations,\npragmas, and tile sizes, focusing on regular loop-based kernels. Our evaluation\ndemonstrates that our framework adeptly identifies the appropriate\ntransformations, including scenarios where no transformation is necessary, and\ninserts pragmas to achieve a favorable Quality of Results.\n","authors":["Stéphane Pouget","Louis-Noël Pouchet","Jason Cong"],"pdf_url":"https://arxiv.org/pdf/2405.03058v5.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2501.07748v1","updated":"2025-01-13T23:30:14Z","published":"2025-01-13T23:30:14Z","title":"Reliable Vertical Ground Reaction Force Estimation with Smart Insole\n  During Walking","summary":"  The vertical ground reaction force (vGRF) and its characteristic weight\nacceptance and push-off peaks measured during walking are important for gait\nand biomechanical analysis. Current wearable vGRF estimation methods suffer\nfrom drifting errors or low generalization performances, limiting their\npractical application. This paper proposes a novel method for reliably\nestimating vGRF and its characteristic peaks using data collected from the\nsmart insole, including inertial measurement unit data and the newly introduced\ncenter of the pressed sensor data. These data were fused with machine learning\nalgorithms including artificial neural networks, random forest regression, and\nbi-directional long-short-term memory. The proposed method outperformed the\nstate-of-the-art methods with the root mean squared error, normalized root mean\nsquared error, and correlation coefficient of 0.024 body weight (BW), 1.79% BW,\nand 0.997 in intra-participant testing, and 0.044 BW, 3.22% BW, and 0.991 in\ninter-participant testing, respectively. The difference between the reference\nand estimated weight acceptance and push-off peak values are 0.022 BW and 0.017\nBW with a delay of 1.4% and 1.8% of the gait cycle for the intra-participant\ntesting and 0.044 BW and 0.025 BW with a delay of 1.5% and 2.3% of the gait\ncycle for the inter-participant testing. The results indicate that the proposed\nvGRF estimation method has the potential to achieve accurate vGRF measurement\nduring walking in free living environments.\n","authors":["Femi Olugbon","Nozhan Ghoreishi","Ming-Chun Huang","Wenyao Xu","Diliang Chen"],"pdf_url":"https://arxiv.org/pdf/2501.07748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07736v1","updated":"2025-01-13T22:58:37Z","published":"2025-01-13T22:58:37Z","title":"Understanding the Practice, Perception, and Challenge of Blind or Low\n  Vision Students Learning through Accessible Technologies in Non-Inclusive\n  'Blind Colleges'","summary":"  In developing and underdeveloped regions, many 'Blind Colleges' exclusively\nenroll individuals with Blindness or Vision Impairment (BLV) for higher\neducation. While advancements in accessible technologies have facilitated BLV\nstudent integration into 'Integrated Colleges,' their implementation in 'Blind\nColleges' remains uneven due to complex economic, social, and policy\nchallenges. This study investigates the practices, perceptions, and challenges\nof BLV students using accessible technologies in a Chinese 'Blind College'\nthrough a two-part empirical approach. Our findings demonstrate that tactile\nand digital technologies enhance access to education but face significant\nintegration barriers. We emphasize the critical role of early education in\naddressing capability gaps, BLV students' aspirations for more inclusive\neducational environments, and the systemic obstacles within existing\nframeworks. We advocate for leveraging accessible technologies to transition\n'Blind Colleges' into 'Integrated Colleges,' offering actionable insights for\npolicymakers, designers, and educators. Finally, we outline future research\ndirections on accessible technology innovation and its implications for BLV\neducation in resource-constrained settings.\n","authors":["Xiuqi Tommy Zhu","Ziyue Qiu","Ye Wei","Jianhao Wang","Yang Jiao"],"pdf_url":"https://arxiv.org/pdf/2501.07736v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14634v3","updated":"2025-01-13T22:45:30Z","published":"2024-09-23T00:09:34Z","title":"Scideator: Human-LLM Scientific Idea Generation Grounded in\n  Research-Paper Facet Recombination","summary":"  The scientific ideation process often involves blending salient aspects of\nexisting papers to create new ideas. To see if large language models (LLMs) can\nassist this process, we contribute Scideator, a novel mixed-initiative tool for\nscientific ideation. Starting from a user-provided set of papers, Scideator\nextracts key facets (purposes, mechanisms, and evaluations) from these and\nrelevant papers, allowing users to explore the idea space by interactively\nrecombining facets to synthesize inventive ideas. Scideator also helps users to\ngauge idea novelty by searching the literature for potential overlaps and\nshowing automated novelty assessments and explanations. To support these tasks,\nScideator introduces four LLM-powered retrieval-augmented generation (RAG)\nmodules: Analogous Paper Facet Finder, Faceted Idea Generator, Idea Novelty\nChecker, and Idea Novelty Iterator. In a within-subjects user study, 19\ncomputer-science researchers identified significantly more interesting ideas\nusing Scideator compared to a strong baseline combining a scientific search\nengine with LLM interaction.\n","authors":["Marissa Radensky","Simra Shahid","Raymond Fok","Pao Siangliulue","Tom Hope","Daniel S. Weld"],"pdf_url":"https://arxiv.org/pdf/2409.14634v3.pdf","comment":"Added supplementary material"},{"id":"http://arxiv.org/abs/2501.07713v1","updated":"2025-01-13T21:52:46Z","published":"2025-01-13T21:52:46Z","title":"Testing Human-Hand Segmentation on In-Distribution and\n  Out-of-Distribution Data in Human-Robot Interactions Using a Deep Ensemble\n  Model","summary":"  Reliable detection and segmentation of human hands are critical for enhancing\nsafety and facilitating advanced interactions in human-robot collaboration.\nCurrent research predominantly evaluates hand segmentation under\nin-distribution (ID) data, which reflects the training data of deep learning\n(DL) models. However, this approach fails to address out-of-distribution (OOD)\nscenarios that often arise in real-world human-robot interactions. In this\nstudy, we present a novel approach by evaluating the performance of pre-trained\nDL models under both ID data and more challenging OOD scenarios. To mimic\nrealistic industrial scenarios, we designed a diverse dataset featuring simple\nand cluttered backgrounds with industrial tools, varying numbers of hands (0 to\n4), and hands with and without gloves. For OOD scenarios, we incorporated\nunique and rare conditions such as finger-crossing gestures and motion blur\nfrom fast-moving hands, addressing both epistemic and aleatoric uncertainties.\nTo ensure multiple point of views (PoVs), we utilized both egocentric cameras,\nmounted on the operator's head, and static cameras to capture RGB images of\nhuman-robot interactions. This approach allowed us to account for multiple\ncamera perspectives while also evaluating the performance of models trained on\nexisting egocentric datasets as well as static-camera datasets. For\nsegmentation, we used a deep ensemble model composed of UNet and RefineNet as\nbase learners. Performance evaluation was conducted using segmentation metrics\nand uncertainty quantification via predictive entropy. Results revealed that\nmodels trained on industrial datasets outperformed those trained on\nnon-industrial datasets, highlighting the importance of context-specific\ntraining. Although all models struggled with OOD scenarios, those trained on\nindustrial datasets demonstrated significantly better generalization.\n","authors":["Reza Jalayer","Yuxin Chen","Masoud Jalayer","Carlotta Orsenigo","Masayoshi Tomizuka"],"pdf_url":"https://arxiv.org/pdf/2501.07713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10999v2","updated":"2025-01-13T21:41:47Z","published":"2024-12-14T23:59:42Z","title":"Cocoa: Co-Planning and Co-Execution with AI Agents","summary":"  We present Cocoa, a system that implements a novel interaction design pattern\n-- interactive plans -- for users to collaborate with an AI agent on complex,\nmulti-step tasks in a document editor. Cocoa harmonizes human and AI efforts\nand enables flexible delegation of agency through two actions: Co-planning\n(where users collaboratively compose a plan of action with the agent) and\nCo-execution (where users collaboratively execute plan steps with the agent).\nUsing scientific research as a sample domain, we motivate the design of Cocoa\nthrough a formative study with 9 researchers while also drawing inspiration\nfrom the design of computational notebooks. We evaluate Cocoa through a user\nstudy with 16 researchers and find that when compared to a strong chat\nbaseline, Cocoa improved agent steerability without sacrificing ease of use. A\ndeeper investigation of the general utility of both systems uncovered insights\ninto usage contexts where interactive plans may be more appropriate than chat,\nand vice versa. Our work surfaces numerous practical implications and paves new\npaths for interactive interfaces that foster more effective collaboration\nbetween humans and agentic AI systems.\n","authors":["K. J. Kevin Feng","Kevin Pu","Matt Latzke","Tal August","Pao Siangliulue","Jonathan Bragg","Daniel S. Weld","Amy X. Zhang","Joseph Chee Chang"],"pdf_url":"https://arxiv.org/pdf/2412.10999v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07690v1","updated":"2025-01-13T21:06:44Z","published":"2025-01-13T21:06:44Z","title":"An Investigation of Experiences Engaging the Margins in Data-Centric\n  Innovation","summary":"  Data-centric technologies provide exciting opportunities, but recent research\nhas shown how lack of representation in datasets, often as a result of systemic\ninequities and socioeconomic disparities, can produce inequitable outcomes that\ncan exclude or harm certain demographics. In this paper, we discuss preliminary\ninsights from an ongoing effort aimed at better understanding barriers to\nequitable data-centric innovation. We report findings from a survey of 261\ntechnologists and researchers who use data in their work regarding their\nexperiences seeking adequate, representative datasets. Our findings suggest\nthat age and identity play a significant role in the seeking and selection of\nrepresentative datasets, warranting further investigation into these aspects of\ndata-centric research and development.\n","authors":["Gabriella Thompson","Ebtesam Al Haque","Paulette Blanc","Meme Styles","Denae Ford","Angela D. R. Smith","Brittany Johnson"],"pdf_url":"https://arxiv.org/pdf/2501.07690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07661v1","updated":"2025-01-13T19:47:44Z","published":"2025-01-13T19:47:44Z","title":"\"Near Data\" and \"Far Data\" for Urban Sustainability: How Do Community\n  Advocates Envision Data Intermediaries?","summary":"  In the densifying data ecosystem of today's cities, data intermediaries are\ncrucial stakeholders in facilitating data access and use. Community advocates\nlive in these sites of social injustices and opportunities for change. Highly\nexperienced in working with data to enact change, they offer distinctive\ninsights on data practices and tools. This paper examines the unique\nperspectives that community advocates offer on data intermediaries. Based on\ninterviews with 17 advocates working with 23 grassroots and nonprofit\norganizations, we propose the quality of \"near\" and \"far\" to be seriously\nconsidered in data intermediaries' works and articulate advocates' vision of\nconnecting \"near data\" and \"far data.\" To pursue this vision, we identified\nthree pathways for data intermediaries: align data exploration with ways of\nstorytelling, communicate context and uncertainties, and decenter artifacts for\nrelationship building. These pathways help data intermediaries to put data\nfeminism into practice, surface design opportunities and tensions, and raise\nkey questions for supporting the pursuit of the Right to the City.\n","authors":["Han Qiao","Siyi Wu","Christoph Becker"],"pdf_url":"https://arxiv.org/pdf/2501.07661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07536v1","updated":"2025-01-13T18:16:13Z","published":"2025-01-13T18:16:13Z","title":"ML Mule: Mobile-Driven Context-Aware Collaborative Learning","summary":"  Artificial intelligence has been integrated into nearly every aspect of daily\nlife, powering applications from object detection with computer vision to large\nlanguage models for writing emails and compact models in smart homes. These\nmachine learning models cater to individual users but are often detached from\nthem, as they are typically stored and processed in centralized data centers.\nThis centralized approach raises privacy concerns, incurs high infrastructure\ncosts, and struggles with personalization. Federated and fully decentralized\nlearning methods have been proposed to address these issues, but they still\ndepend on centralized servers or face slow convergence due to communication\nconstraints. To overcome these challenges, we propose ML Mule, a approach that\nutilizes individual mobile devices as 'Mules' to train and transport model\nsnapshots as they move through physical spaces, sharing these models with the\nphysical 'Spaces' they inhabit. This method implicitly forms affinity groups\namong devices associated with users who share particular spaces, enabling\ncollaborative model evolution, and protecting users' privacy. Our approach\naddresses several major shortcomings of traditional, federated, and fully\ndecentralized learning systems. The proposed framework represents a new class\nof machine learning methods that are more robust, distributed, and\npersonalized, bringing the field closer to realizing the original vision of\nintelligent, adaptive, and genuinely context-aware smart environments. The\nresults show that ML Mule converges faster and achieves higher model accuracy\ncompared to other existing methods.\n","authors":["Haoxiang Yu","Javier Berrocal","Christine Julien"],"pdf_url":"https://arxiv.org/pdf/2501.07536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.01884v2","updated":"2025-01-13T17:58:55Z","published":"2025-01-03T16:31:59Z","title":"Telegram as a Battlefield: Kremlin-related Communications during the\n  Russia-Ukraine Conflict","summary":"  Telegram emerged as a crucial platform for both parties during the conflict\nbetween Russia and Ukraine. Per its minimal policies for content moderation,\nPro-Kremlin narratives and potential misinformation were spread on Telegram,\nwhile anti-Kremlin narratives with related content were also propagated, such\nas war footage, troop movements, maps of bomb shelters, and air raid warnings.\nThis paper presents a dataset of posts from both pro-Kremlin and anti-Kremlin\nTelegram channels, collected over a period spanning a year before and a year\nafter the Russian invasion. The dataset comprises 404 pro-Kremlin channels with\n4,109,645 posts and 114 anti-Kremlin channels with 1,117,768 posts. We provide\ndetails on the data collection process, processing methods, and dataset\ncharacterization. Lastly, we discuss the potential research opportunities this\ndataset may enable researchers across various disciplines.\n","authors":["Apaar Bawa","Ugur Kursuncu","Dilshod Achilov","Valerie L. Shalin","Nitin Agarwal","Esra Akbas"],"pdf_url":"https://arxiv.org/pdf/2501.01884v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08926v3","updated":"2025-01-13T15:19:14Z","published":"2024-10-11T15:50:53Z","title":"Zero-Shot Pupil Segmentation with SAM 2: A Case Study of Over 14 Million\n  Images","summary":"  We explore the transformative potential of SAM 2, a vision foundation model,\nin advancing gaze estimation and eye tracking technologies. By significantly\nreducing annotation time, lowering technical barriers through its ease of\ndeployment, and enhancing segmentation accuracy, SAM 2 addresses critical\nchallenges faced by researchers and practitioners. Utilizing its zero-shot\nsegmentation capabilities with minimal user input-a single click per video-we\ntested SAM 2 on over 14 million eye images from diverse datasets, including\nvirtual reality setups and the world's largest unified dataset recorded using\nwearable eye trackers. Remarkably, in pupil segmentation tasks, SAM 2 matches\nthe performance of domain-specific models trained solely on eye images,\nachieving competitive mean Intersection over Union (mIoU) scores of up to 93%\nwithout fine-tuning. Additionally, we provide our code and segmentation masks\nfor these widely used datasets to promote further research.\n","authors":["Virmarie Maquiling","Sean Anthony Byrne","Diederick C. Niehorster","Marco Carminati","Enkelejda Kasneci"],"pdf_url":"https://arxiv.org/pdf/2410.08926v3.pdf","comment":"Virmarie Maquiling and Sean Anthony Byrne contributed equally to this\n  paper, 8 pages, 3 figures, ETRA 2025, pre-print"},{"id":"http://arxiv.org/abs/2501.07394v1","updated":"2025-01-13T15:09:33Z","published":"2025-01-13T15:09:33Z","title":"Exploring the distribution of connectivity weights in resting-state EEG\n  networks","summary":"  The resting-state brain networks (RSNs) reflects the functional connectivity\npatterns between brain modules, providing essential foundations for decoding\nintrinsic neural information within the brain. It serves as one of the primary\ntools for describing the spatial dynamics of the brain using various\nneuroimaging techniques, such as electroencephalography (EEG) and\nmagnetoencephalography (MEG). However, the distribution rules or potential\nmodes of functional connectivity weights in the resting state remain unclear.\nIn this context, we first start from simulation, using forward solving model to\ngenerate scalp EEG with four channel densities (19, 32, 64, 128). Subsequently,\nwe construct scalp brain networks using five coupling measures, aiming to\nexplore whether different channel density or coupling measures affect the\ndistribution pattern of functional connectivity weights. Next, we quantify the\ndistribution pattern by calculating the skewness, kurtosis, and Shannon entropy\nof the functional connectivity network weights. Finally, the results of the\nsimulation were validated in a normative database. We observed that: 1) The\nfunctional connection weights exhibit a right-skewed distribution, and are not\ninfluenced by channel density or coupling measures; 2) The functional\nconnection weights exhibit a relatively uniform distribution, with the\npotential for volume conduction to affect the degree of uniformity in the\ndistribution; 3) Networks constructed using coupling measures influenced by\nvolume conduction exhibit significant correlations between the average\nconnection weight and measures of skewness, kurtosis, and Shannon entropy. This\nstudy contributes to a deeper understanding of RSNs, providing valuable\ninsights for research in the field of neuroscience, and holds promise for being\nassociated with brain cognition and disease diagnosis.\n","authors":["Xiao Gong","Xiaolong Huang","Jie Ruan"],"pdf_url":"https://arxiv.org/pdf/2501.07394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07320v1","updated":"2025-01-13T13:31:28Z","published":"2025-01-13T13:31:28Z","title":"ChartEditor: A Human-AI Paired Tool for Authoring Pictorial Charts","summary":"  Pictorial charts are favored for their memorability and visual appeal,\noffering a more engaging alternative to basic charts. However, their creation\ncan be complex and time-consuming due to the lack of native support in popular\nvisualization tools like Tableau. While AI-generated content (AIGC) tools have\nlowered the barrier to creating pictorial charts, they often lack precise\ndesign control. To address this issue, we introduce ChartEditor, a human-AI\npaired tool that transforms basic charts into pictorial versions based on user\nintent. ChartEditor decomposes chart images into visual components and\norganizes them within a hierarchical tree. Based on this tree, users can\nexpress their intent in natural language, which is then translated into\nmodifications to the hierarchy. In addition, users can directly interact with\nand modify specific chart components via an intuitive interface to achieve\nfine-grained design control. A user study demonstrates the effectiveness and\nusability of ChartEditor in simplifying the creation of pictorial charts.\n","authors":["Siyu Yan","Tiancheng Liu","Weikai Yang","Nan Tang","Yuyu Luo"],"pdf_url":"https://arxiv.org/pdf/2501.07320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07234v1","updated":"2025-01-13T11:32:24Z","published":"2025-01-13T11:32:24Z","title":"Enhancing Interaction with Augmented Reality through Mid-Air Haptic\n  Feedback: Architecture Design and User Feedback","summary":"  The integration of haptics within Augmented Reality may help to deliver an\nenriched experience, while facilitating the performance of specific actions\n(e.g. repositioning or resizin ) that are still dependent on the user's skills.\nThis paper gathers the description of a flexible architecture designed to\ndeploy haptically-enabled AR applications. The haptic feedback may be generated\nthrough a variety of devices (e.g., wearable, graspable, or mid-air ones), and\nthe architecture facilitates handling the specificity of each. For this reason,\nit is discussed how to generate a haptic representation of a 3D digital object\ndepending on the application and the target device. Additionally, it is\nincluded an analysis of practical, relevant issues that arise when setting up a\nsystem to work with specific devices like Head-Mounted Displays (e.g.,\nHoloLens) and mid-air haptic devices (e.g., Ultrahaptics UHK), such as the\nalignment between the real world and the virtual one. The architecture\napplicability is demonstrated through the implementation of two applications:\nForm Inspector and Simon Game, built for HoloLens and iOS mobile phones for\nvisualization and for UHK for mid-air haptics delivery. These applications have\nbeen used by nine users to explore the efficiency, meaningfulness, and\nusefulness of mid-air haptics for form perception, object resizing, and push\ninteraction tasks. Results show that, although mobile interaction is preferred\nwhen this option is available, haptics turn out to be more meaningful in\nidentifying shapes when compared to what users initially expect and in\ncontributing to the execution of resizing tasks. Moreover, this preliminary\nuser study reveals that users may be expecting a tailored interface metaphor,\nnot necessarily inspired in natural interaction.\n","authors":["Diego Vaquero-Melchor","Ana M. Bernardos"],"pdf_url":"https://arxiv.org/pdf/2501.07234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07213v1","updated":"2025-01-13T11:12:47Z","published":"2025-01-13T11:12:47Z","title":"Multi-face emotion detection for effective Human-Robot Interaction","summary":"  The integration of dialogue interfaces in mobile devices has become\nubiquitous, providing a wide array of services. As technology progresses,\nhumanoid robots designed with human-like features to interact effectively with\npeople are gaining prominence, and the use of advanced human-robot dialogue\ninterfaces is continually expanding. In this context, emotion recognition plays\na crucial role in enhancing human-robot interaction by enabling robots to\nunderstand human intentions. This research proposes a facial emotion detection\ninterface integrated into a mobile humanoid robot, capable of displaying\nreal-time emotions from multiple individuals on a user interface. To this end,\nvarious deep neural network models for facial expression recognition were\ndeveloped and evaluated under consistent computer-based conditions, yielding\npromising results. Afterwards, a trade-off between accuracy and memory\nfootprint was carefully considered to effectively implement this application on\na mobile humanoid robot.\n","authors":["Mohamed Ala Yahyaoui","Mouaad Oujabour","Leila Ben Letaifa","Amine Bohi"],"pdf_url":"https://arxiv.org/pdf/2501.07213v1.pdf","comment":"9 pages, 8 figures and 1 table. Accepted at the 17th International\n  Conference on Agents and Artificial Intelligence (ICAART 2025), Porto,\n  Portugal"},{"id":"http://arxiv.org/abs/2501.07207v1","updated":"2025-01-13T11:01:41Z","published":"2025-01-13T11:01:41Z","title":"Beyond Security-by-design: Securing a compromised system","summary":"  Digital infrastructures are seeing convergence and connectivity at\nunprecedented scale. This is true for both current critical national\ninfrastructures and emerging future systems that are highly cyber-physical in\nnature with complex intersections between humans and technologies, e.g., smart\ncities, intelligent transportation, high-value manufacturing and Industry 4.0.\nDiverse legacy and non-legacy software systems underpinned by heterogeneous\nhardware compose on-the-fly to deliver services to millions of users with\nvarying requirements and unpredictable actions. This complexity is compounded\nby intricate and complicated supply-chains with many digital assets and\nservices outsourced to third parties. The reality is that, at any particular\npoint in time, there will be untrusted, partially-trusted or compromised\nelements across the infrastructure. Given this reality, and the societal scale\nof digital infrastructures, delivering secure and resilient operations is a\nmajor challenge. We argue that this requires us to move beyond the paradigm of\nsecurity-by-design and embrace the challenge of securing-a-compromised-system.\n","authors":["Awais Rashid","Sana Belguith","Matthew Bradbury","Sadie Creese","Ivan Flechais","Neeraj Suri"],"pdf_url":"https://arxiv.org/pdf/2501.07207v1.pdf","comment":"Article for the Rossfest Symposium in memory of Ross Anderson,\n  Cambridge, UK, 25 March 2025"},{"id":"http://arxiv.org/abs/2501.07196v1","updated":"2025-01-13T10:42:55Z","published":"2025-01-13T10:42:55Z","title":"Crowdsourced human-based computational approach for tagging peripheral\n  blood smear sample images from Sickle Cell Disease patients using non-expert\n  users","summary":"  In this paper, we present a human-based computation approach for the analysis\nof peripheral blood smear (PBS) images images in patients with Sickle Cell\nDisease (SCD). We used the Mechanical Turk microtask market to crowdsource the\nlabeling of PBS images. We then use the expert-tagged erythrocytesIDB dataset\nto assess the accuracy and reliability of our proposal. Our results showed that\nwhen a robust consensus is achieved among the Mechanical Turk workers,\nprobability of error is very low, based on comparison with expert analysis.\nThis suggests that our proposed approach can be used to annotate datasets of\nPBS images, which can then be used to train automated methods for the diagnosis\nof SCD. In future work, we plan to explore the potential integration of our\nfindings with outcomes obtained through automated methodologies. This could\nlead to the development of more accurate and reliable methods for the diagnosis\nof SCD\n","authors":["José María Buades Rubio","Gabriel Moyà-Alcover","Antoni Jaume-i-Capó","Nataša Petrović"],"pdf_url":"https://arxiv.org/pdf/2501.07196v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07182v1","updated":"2025-01-13T10:25:58Z","published":"2025-01-13T10:25:58Z","title":"Unveiling Voices: A Co-Hashtag Analysis of TikTok Discourse on the 2023\n  Israel-Palestine Crisis","summary":"  TikTok has gradually become one of the most pervasive social media platforms\nin our daily lives. In this research article, I explore how users on TikTok\ndiscussed the crisis in Palestine that worsened in 2023. Using network\nanalysis, I situate keywords representing the conflict and categorize them\nthematically based on a coding schema derived from politically and\nideologically differentiable stances. I conclude that that activism and\npropaganda are contending amongst themselves in the thriving space afforded by\nTikTok today.\n","authors":["Rozin Hasin"],"pdf_url":"https://arxiv.org/pdf/2501.07182v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07180v1","updated":"2025-01-13T10:19:30Z","published":"2025-01-13T10:19:30Z","title":"Evaluating Robotic Approach Techniques for the Insertion of a Straight\n  Instrument into a Vitreoretinal Surgery Trocar","summary":"  Advances in vitreoretinal robotic surgery enable precise techniques for gene\ntherapies. This study evaluates three robotic approaches using the 7-DoF\nrobotic arm for docking a micro-precise tool to a trocar: fully co-manipulated,\nhybrid co-manipulated/teleoperated, and hybrid with camera assistance. The\nfully co-manipulated approach was the fastest but had a 42% success rate.\nHybrid methods showed higher success rates (91.6% and 100%) and completed tasks\nwithin 2 minutes. NASA Task Load Index (TLX) assessments indicated lower\nphysical demand and effort for hybrid approaches.\n","authors":["Ross Henry","Martin Huber","Anestis Mablekos-Alexiou","Carlo Seneci","Mohamed Abdelaziz","Hans Natalius","Lyndon da Cruz","Christos Bergeles"],"pdf_url":"https://arxiv.org/pdf/2501.07180v1.pdf","comment":"2 Pages, 2 Figures, 1 Table"},{"id":"http://arxiv.org/abs/2407.11218v3","updated":"2025-01-13T09:23:41Z","published":"2024-07-15T20:07:33Z","title":"Walk along: An Experiment on Controlling the Mobile Robot 'Spot' with\n  Voice and Gestures","summary":"  Robots are becoming more capable and can autonomously perform tasks such as\nnavigating between locations. However, human oversight remains crucial. This\nstudy compared two touchless methods for directing mobile robots: voice control\nand gesture control, to investigate the efficiency of the methods and the\npreference of users. We tested these methods in two conditions: one in which\nparticipants remained stationary and one in which they walked freely alongside\nthe robot. We hypothesized that walking alongside the robot would result in\nhigher intuitiveness ratings and improved task performance, based on the idea\nthat walking promotes spatial alignment and reduces the effort required for\nmental rotation. In a 2x2 within-subject design, 218 participants guided the\nquadruped robot Spot along a circuitous route with multiple 90-degree turns\nusing rotate left, rotate right, and walk forward commands. After each trial,\nparticipants rated the intuitiveness of the command mapping, while\npost-experiment interviews were used to gather the participants' preferences.\nResults showed that voice control combined with walking with Spot was the most\nfavored and intuitive, whereas gesture control while standing caused confusion\nfor left/right commands. Nevertheless, 29% of participants preferred gesture\ncontrol, citing increased task engagement and visual congruence as reasons. An\nodometry-based analysis revealed that participants often followed behind Spot,\nparticularly in the gesture control condition, when they were allowed to walk.\nIn conclusion, voice control with walking produced the best outcomes. Improving\nphysical ergonomics and adjusting gesture types could make gesture control more\neffective.\n","authors":["Renchi Zhang","Jesse van der Linden","Dimitra Dodou","Harleigh Seyffert","Yke Bauke Eisma","Joost C. F. de Winter"],"pdf_url":"https://arxiv.org/pdf/2407.11218v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07051v1","updated":"2025-01-13T04:18:52Z","published":"2025-01-13T04:18:52Z","title":"ROSAnnotator: A Web Application for ROSBag Data Analysis in Human-Robot\n  Interaction","summary":"  Human-robot interaction (HRI) is an interdisciplinary field that utilises\nboth quantitative and qualitative methods. While ROSBags, a file format within\nthe Robot Operating System (ROS), offer an efficient means of collecting\ntemporally synched multimodal data in empirical studies with real robots, there\nis a lack of tools specifically designed to integrate qualitative coding and\nanalysis functions with ROSBags. To address this gap, we developed\nROSAnnotator, a web-based application that incorporates a multimodal Large\nLanguage Model (LLM) to support both manual and automated annotation of ROSBag\ndata. ROSAnnotator currently facilitates video, audio, and transcription\nannotations and provides an open interface for custom ROS messages and tools.\nBy using ROSAnnotator, researchers can streamline the qualitative analysis\nprocess, create a more cohesive analysis pipeline, and quickly access\nstatistical summaries of annotations, thereby enhancing the overall efficiency\nof HRI data analysis. https://github.com/CHRI-Lab/ROSAnnotator\n","authors":["Yan Zhang","Haoqi Li","Ramtin Tabatabaei","Wafa Johal"],"pdf_url":"https://arxiv.org/pdf/2501.07051v1.pdf","comment":"Accepted to HRI 2025"},{"id":"http://arxiv.org/abs/2501.05723v2","updated":"2025-01-13T02:58:58Z","published":"2025-01-10T05:43:34Z","title":"Robot Error Awareness Through Human Reactions: Implementation,\n  Evaluation, and Recommendations","summary":"  Effective error detection is crucial to prevent task disruption and maintain\nuser trust. Traditional methods often rely on task-specific models or user\nreporting, which can be inflexible or slow. Recent research suggests social\nsignals, naturally exhibited by users in response to robot errors, can enable\nmore flexible, timely error detection. However, most studies rely on post hoc\nanalysis, leaving their real-time effectiveness uncertain and lacking\nuser-centric evaluation. In this work, we developed a proactive error detection\nsystem that combines user behavioral signals (facial action units and speech),\nuser feedback, and error context for automatic error detection. In a study (N =\n28), we compared our proactive system to a status quo reactive approach.\nResults show our system 1) reliably and flexibly detects error, 2) detects\nerrors faster than the reactive approach, and 3) is perceived more favorably by\nusers than the reactive one. We discuss recommendations for enabling robot\nerror awareness in future HRI systems.\n","authors":["Maia Stiber","Russell Taylor","Chien-Ming Huang"],"pdf_url":"https://arxiv.org/pdf/2501.05723v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.15748v3","updated":"2025-01-13T02:40:24Z","published":"2022-03-29T16:58:09Z","title":"An Adaptive Benchmark for Modeling User Exploration of Large Datasets","summary":"  In this paper, we present a new DBMS performance benchmark that can simulate\nuser exploration with any specified dashboard design made of standard\nvisualization and interaction components. The distinguishing feature of our\nSImulation-BAsed (or SIMBA) benchmark is its ability to model user analysis\ngoals as a set of SQL queries to be generated through a valid sequence of user\ninteractions, as well as measure the completion of analysis goals by testing\nfor equivalence between the user's previous queries and their goal queries. In\nthis way, the SIMBA benchmark can simulate how an analyst opportunistically\nsearches for interesting insights at the beginning of an exploration session\nand eventually hones in on specific goals towards the end. To demonstrate the\nversatility of the SIMBA benchmark, we use it to test the performance of four\nDBMSs with six different dashboard specifications and compare our results with\nIDEBench. Our results show how goal-driven simulation can reveal gaps in DBMS\nperformance missed by existing benchmarking methods and across a range of data\nexploration scenarios.\n","authors":["Joanna Purich","Anthony Wise","Leilani Battle"],"pdf_url":"https://arxiv.org/pdf/2203.15748v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06981v1","updated":"2025-01-13T00:11:47Z","published":"2025-01-13T00:11:47Z","title":"Data Enrichment Work and AI Labor in Latin America and the Caribbean","summary":"  The global AI surge demands crowdworkers from diverse languages and cultures.\nThey are pivotal in labeling data for enabling global AI systems. Despite\nglobal significance, research has primarily focused on understanding the\nperspectives and experiences of US and India crowdworkers, leaving a notable\ngap. To bridge this, we conducted a survey with 100 crowdworkers across 16\nLatin American and Caribbean countries. We discovered that these workers\nexhibited pride and respect for their digital labor, with strong support and\nadmiration from their families. Notably, crowd work was also seen as a stepping\nstone to financial and professional independence. Surprisingly, despite wanting\nmore connection, these workers also felt isolated from peers and doubtful of\nothers' labor quality. They resisted collaboration and gender-based tools,\nvaluing gender-neutrality. Our work advances HCI understanding of Latin\nAmerican and Caribbean crowdwork, offering insights for digital resistance\ntools for the region.\n","authors":["Gianna Williams","Maya De Los Santos","Alexandra To","Saiph Savage"],"pdf_url":"https://arxiv.org/pdf/2501.06981v1.pdf","comment":"17 pages of content with 2 figures"}]},"2025-01-12T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2501.06976v1","updated":"2025-01-12T23:27:08Z","published":"2025-01-12T23:27:08Z","title":"TensorConvolutionPlus: A python package for distribution system\n  flexibility area estimation","summary":"  Power system operators need new, efficient operational tools to use the\nflexibility of distributed resources and deal with the challenges of highly\nuncertain and variable power systems. Transmission system operators can\nconsider the available flexibility in distribution systems (DSs) without\nbreaching the DS constraints through flexibility areas. However, there is an\nabsence of open-source packages for flexibility area estimation. This paper\nintroduces TensorConvolutionPlus, a user-friendly Python-based package for\nflexibility area estimation. The main features of TensorConvolutionPlus include\nestimating flexibility areas using the TensorConvolution+ algorithm, the power\nflow-based algorithm, an exhaustive PF-based algorithm, and an optimal power\nflow-based algorithm. Additional features include adapting flexibility area\nestimations from different operating conditions and including flexibility\nservice providers offering discrete setpoints of flexibility. The\nTensorConvolutionPlus package facilitates a broader adaptation of flexibility\nestimation algorithms by system operators and power system researchers.\n","authors":["Demetris Chrysostomou","Jose Luis Rueda Torres","Jochen Lorenz Cremer"],"pdf_url":"https://arxiv.org/pdf/2501.06976v1.pdf","comment":"9 pages, 10 figures,"},{"id":"http://arxiv.org/abs/2501.06972v1","updated":"2025-01-12T23:06:25Z","published":"2025-01-12T23:06:25Z","title":"How is Google using AI for internal code migrations?","summary":"  In recent years, there has been a tremendous interest in using generative AI,\nand particularly large language models (LLMs) in software engineering; indeed\nthere are now several commercially available tools, and many large companies\nalso have created proprietary ML-based tools for their own software engineers.\nWhile the use of ML for common tasks such as code completion is available in\ncommodity tools, there is a growing interest in application of LLMs for more\nbespoke purposes. One such purpose is code migration.\n  This article is an experience report on using LLMs for code migrations at\nGoogle. It is not a research study, in the sense that we do not carry out\ncomparisons against other approaches or evaluate research questions/hypotheses.\nRather, we share our experiences in applying LLM-based code migration in an\nenterprise context across a range of migration cases, in the hope that other\nindustry practitioners will find our insights useful. Many of these learnings\napply to any application of ML in software engineering. We see evidence that\nthe use of LLMs can reduce the time needed for migrations significantly, and\ncan reduce barriers to get started and complete migration programs.\n","authors":["Stoyan Nikolov","Daniele Codecasa","Anna Sjovall","Maxim Tabachnyk","Satish Chandra","Siddharth Taneja","Celal Ziftci"],"pdf_url":"https://arxiv.org/pdf/2501.06972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.17298v2","updated":"2025-01-12T20:13:35Z","published":"2024-12-23T05:41:01Z","title":"Prompting in the Wild: An Empirical Study of Prompt Evolution in\n  Software Repositories","summary":"  The adoption of Large Language Models (LLMs) is reshaping software\ndevelopment as developers integrate these LLMs into their applications. In such\napplications, prompts serve as the primary means of interacting with LLMs.\nDespite the widespread use of LLM-integrated applications, there is limited\nunderstanding of how developers manage and evolve prompts. This study presents\nthe first empirical analysis of prompt evolution in LLM-integrated software\ndevelopment. We analyzed 1,262 prompt changes across 243 GitHub repositories to\ninvestigate the patterns and frequencies of prompt changes, their relationship\nwith code changes, documentation practices, and their impact on system\nbehavior. Our findings show that developers primarily evolve prompts through\nadditions and modifications, with most changes occurring during feature\ndevelopment. We identified key challenges in prompt engineering: only 21.9% of\nprompt changes are documented in commit messages, changes can introduce logical\ninconsistencies, and misalignment often occurs between prompt changes and LLM\nresponses. These insights emphasize the need for specialized testing\nframeworks, automated validation tools, and improved documentation practices to\nenhance the reliability of LLM-integrated applications.\n","authors":["Mahan Tafreshipour","Aaron Imani","Eric Huang","Eduardo Almeida","Thomas Zimmermann","Iftekhar Ahmed"],"pdf_url":"https://arxiv.org/pdf/2412.17298v2.pdf","comment":"Accepted at MSR 2025"},{"id":"http://arxiv.org/abs/2501.02875v2","updated":"2025-01-12T19:20:15Z","published":"2025-01-06T09:36:57Z","title":"METFORD -- Mutation tEsTing Framework fOR anDroid","summary":"  Mutation testing may be used to guide test case generation and as a technique\nto assess the quality of test suites. Despite being used frequently, mutation\ntesting is not so commonly applied in the mobile world. One critical challenge\nin mutation testing is dealing with its computational cost. Generating mutants,\nrunning test cases over each mutant, and analyzing the results may require\nsignificant time and resources. This research aims to contribute to reducing\nAndroid mutation testing costs. It implements mutation testing operators\n(traditional and Android-specific) according to mutant schemata (implementing\nmultiple mutants into a single code file). It also describes an Android\nmutation testing framework developed to execute test cases and determine\nmutation scores. Additional mutation operators can be implemented in JavaScript\nand easily integrated into the framework. The overall approach is validated\nthrough case studies showing that mutant schemata have advantages over the\ntraditional mutation strategy (one file per mutant). The results show mutant\nschemata overcome traditional mutation in all evaluated aspects with no\nadditional cost: it takes 8.50% less time for mutant generation, requires\n99.78% less disk space, and runs, on average, 6.45% faster than traditional\nmutation. Moreover, considering sustainability metrics, mutant schemata have\n8,18% less carbon footprint than traditional strategy.\n","authors":["Auri M. R. Vincenzi","Pedro H. Kuroishi","João C. M. Bispo","Ana R. C. da Veiga","David R. C. da Mata","Francisco B. Azevedo","Ana C. R. Paiva"],"pdf_url":"https://arxiv.org/pdf/2501.02875v2.pdf","comment":"Accept for publication in the Journal of System and Software - JSS.\n  This work is partially supported by Brazilian Funding Agencies FAPESP (Grant\n  n. 2019/23160-0 and 2023/00001-9), CAPES, and CNPq"},{"id":"http://arxiv.org/abs/2501.06894v1","updated":"2025-01-12T18:05:08Z","published":"2025-01-12T18:05:08Z","title":"Analyzing the Evolution and Maintenance of Quantum Computing\n  Repositories","summary":"  Quantum computing is an emerging field with significant potential, yet\nsoftware development and maintenance challenges limit its accessibility and\nmaturity. This work investigates the current state, evolution, and maintenance\npractices in the quantum computing community by conducting a large-scale mining\nanalysis of over 21,000 quantum software repositories on GitHub, containing\nmore than 1.2 million commits contributed by over 10,000 unique developers.\nSpecifically, the focus of this paper is to: (i) assess the community's status\nand growth by examining the popularity of quantum computing, trends in\nprogramming languages and framework usage, growth of contributors, and insights\nfrom repository documentation; and (ii) analyze maintenance practices through\ncommit patterns, issue classification, and maintenance levels. Our findings\nindicate rapid growth in the quantum computing community, with a 200% increase\nin the number of repositories and a 150% rise in contributors since 2017. Our\nanalysis of commits shows a strong focus on perfective updates, while the\nrelatively low number of corrective commits highlights potential gaps in bug\nresolution. Furthermore, one-third of the quantum computing issues highlight\nthe need for specialized tools in addition to general software infrastructure.\nIn summary, this work provides a foundation for targeted improvements in\nquantum software to support sustained growth and technical advancement. Based\non our analysis of development activity, community structure, and maintenance\npractices, this study offers actionable recommendations to enhance quantum\nprogramming tools, documentation, and resources. We are also open-sourcing our\ndataset to support further analysis by the community and to guide future\nresearch and tool development for quantum computing.\n","authors":["Krishna Upadhyay","Vinaik Chhetri","A. B. Siddique","Umar Farooq"],"pdf_url":"https://arxiv.org/pdf/2501.06894v1.pdf","comment":"12 pages, 12 figures, 6 tables,"},{"id":"http://arxiv.org/abs/2501.06837v1","updated":"2025-01-12T15:10:57Z","published":"2025-01-12T15:10:57Z","title":"An efficient approach to represent enterprise web application structure\n  using Large Language Model in the service of Intelligent Quality Engineering","summary":"  This paper presents a novel approach to represent enterprise web application\nstructures using Large Language Models (LLMs) to enable intelligent quality\nengineering at scale. We introduce a hierarchical representation methodology\nthat optimizes the few-shot learning capabilities of LLMs while preserving the\ncomplex relationships and interactions within web applications. The approach\nencompasses five key phases: comprehensive DOM analysis, multi-page synthesis,\ntest suite generation, execution, and result analysis. Our methodology\naddresses existing challenges around usage of Generative AI techniques in\nautomated software testing by developing a structured format that enables LLMs\nto understand web application architecture through in-context learning. We\nevaluated our approach using two distinct web applications: an e-commerce\nplatform (Swag Labs) and a healthcare application (MediBox) which is deployed\nwithin Atalgo engineering environment. The results demonstrate success rates of\n90\\% and 70\\%, respectively, in achieving automated testing, with high\nrelevance scores for test cases across multiple evaluation criteria. The\nfindings suggest that our representation approach significantly enhances LLMs'\nability to generate contextually relevant test cases and provide better quality\nassurance overall, while reducing the time and effort required for testing.\n","authors":["Zaber Al Hassan Ayon","Gulam Husain","Roshankumar Bisoi","Waliur Rahman","Dr Tom Osborn"],"pdf_url":"https://arxiv.org/pdf/2501.06837v1.pdf","comment":"16 pages, 1 figure and 4 tables, relevant for Gen AI and enterprise\n  AI use cases"},{"id":"http://arxiv.org/abs/2501.06788v1","updated":"2025-01-12T12:02:26Z","published":"2025-01-12T12:02:26Z","title":"How Low Can We Go? Minimizing Interaction Samples for Configurable\n  Systems","summary":"  Modern software systems are typically configurable, a fundamental\nprerequisite for wide applicability and reusability. This flexibility poses an\nextraordinary challenge for quality assurance, as the enormous number of\npossible configurations makes it impractical to test each of them separately.\nThis is where t-wise interaction sampling can be used to systematically cover\nthe configuration space and detect unknown feature interactions. Over the last\ntwo decades, numerous algorithms for computing small interaction samples have\nbeen studied, providing improvements for a range of heuristic results;\nnevertheless, it has remained unclear how much these results can still be\nimproved.\n  We present a significant breakthrough: a fundamental framework, based on the\nmathematical principle of duality, for combining near-optimal solutions with\nprovable lower bounds on the required sample size. This implies that we no\nlonger need to work on heuristics with marginal or no improvement, but can\ncertify the solution quality by establishing a limit on the remaining gap; in\nmany cases, we can even prove optimality of achieved solutions. This\ntheoretical contribution also provides extensive practical improvements: Our\nalgorithm SampLNS was tested on 47 small and medium-sized configurable systems\nfrom the existing literature. SampLNS can reliably find samples of smaller size\nthan previous methods in 85% of the cases; moreover, we can achieve and prove\noptimality of solutions for 63% of all instances. This makes it possible to\navoid cumbersome efforts of minimizing samples by researchers as well as\npractitioners, and substantially save testing resources for most configurable\nsystems.\n","authors":["Dominik Krupke","Ahmad Moradi","Michael Perk","Phillip Keldenich","Gabriel Gehrke","Sebastian Krieter","Thomas Thüm","Sándor P. Fekete"],"pdf_url":"https://arxiv.org/pdf/2501.06788v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06738v1","updated":"2025-01-12T07:22:13Z","published":"2025-01-12T07:22:13Z","title":"Hold On! Is My Feedback Useful? Evaluating the Usefulness of Code Review\n  Comments","summary":"  Context: In collaborative software development, the peer code review process\nproves beneficial only when the reviewers provide useful comments. Objective:\nThis paper investigates the usefulness of Code Review Comments (CR comments)\nthrough textual feature-based and featureless approaches. Method: We select\nthree available datasets from both open-source and commercial projects.\nAdditionally, we introduce new features from software and non-software domains.\nMoreover, we experiment with the presence of jargon, voice, and codes in CR\ncomments and classify the usefulness of CR comments through featurization,\nbag-of-words, and transfer learning techniques. Results: Our models outperform\nthe baseline by achieving state-of-the-art performance. Furthermore, the result\ndemonstrates that the commercial gigantic LLM, GPT-4o, or non-commercial naive\nfeatureless approach, Bag-of-Word with TF-IDF, is more effective for predicting\nthe usefulness of CR comments. Conclusion: The significant improvement in\npredicting usefulness solely from CR comments escalates research on this task.\nOur analyses portray the similarities and differences of domains, projects,\ndatasets, models, and features for predicting the usefulness of CR comments.\n","authors":["Sharif Ahmed","Nasir U. Eisty"],"pdf_url":"https://arxiv.org/pdf/2501.06738v1.pdf","comment":"Accepted for publication in Empirical Software Engineering (EMSE)\n  Journal"},{"id":"http://arxiv.org/abs/2501.06716v1","updated":"2025-01-12T04:50:47Z","published":"2025-01-12T04:50:47Z","title":"Symbol Resolution MatRs: Make it Fast and Observable with Stable Linking","summary":"  Dynamic linking is the standard mechanism for using external dependencies\nsince it enables code reuse, streamlines software updates, and reduces\ndisk/network use. Dynamic linking waits until runtime to calculate an\napplication's relocation mapping, i.e., the mapping between each externally\nreferenced symbol in the application to the dependency that provides the\nsymbol. Unfortunately, it comes with two downsides. First, dynamic linking\nlimits the performance of current systems since it can take seconds to\ncalculate a relocation mapping for a large program. Second, dynamic linking\nlimits the dependency management of applications since it prevents a developer\nfrom accurately observing a relocation mapping except at runtime.\n  This paper makes the key insight that the benefits conventionally attributed\nto dynamic linking: code reuse, streamlined software updates, and reduced\ndisk/network use are actually benefits of shared libraries. Thus, we present\nstable linking, a new mechanism for using dependencies that uses shared\nlibraries to retain their benefits but eliminates the downsides of dynamic\nlinking. Stable linking separates a system's state into management times; when\nthe system can be modified, and epochs when it cannot. Stable linking\ncalculates each application's relocation mapping at the beginning of each\nepoch, allows developers to inspect the relocation mapping during the epoch,\nand reuses the mapping for subsequent executions in the epoch. We design and\nbuild MatR, the first stable linker. We use MatR in three workloads and show\nthat it improves upon dynamic linking performance by a factor of 2.19 on\naverage. Additionally, we use the system in three vignettes, or case-studies,\nthat illustrate the system's improvements to dependency management.\n","authors":["Farid Zakaria","Andrew Quinn","Thomas R. W. Scogland"],"pdf_url":"https://arxiv.org/pdf/2501.06716v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2501.06706v1","updated":"2025-01-12T04:17:39Z","published":"2025-01-12T04:17:39Z","title":"AIOpsLab: A Holistic Framework to Evaluate AI Agents for Enabling\n  Autonomous Clouds","summary":"  AI for IT Operations (AIOps) aims to automate complex operational tasks, such\nas fault localization and root cause analysis, to reduce human workload and\nminimize customer impact. While traditional DevOps tools and AIOps algorithms\noften focus on addressing isolated operational tasks, recent advances in Large\nLanguage Models (LLMs) and AI agents are revolutionizing AIOps by enabling\nend-to-end and multitask automation. This paper envisions a future where AI\nagents autonomously manage operational tasks throughout the entire incident\nlifecycle, leading to self-healing cloud systems, a paradigm we term AgentOps.\nRealizing this vision requires a comprehensive framework to guide the design,\ndevelopment, and evaluation of these agents. To this end, we present AIOPSLAB,\na framework that not only deploys microservice cloud environments, injects\nfaults, generates workloads, and exports telemetry data but also orchestrates\nthese components and provides interfaces for interacting with and evaluating\nagents. We discuss the key requirements for such a holistic framework and\ndemonstrate how AIOPSLAB can facilitate the evaluation of next-generation AIOps\nagents. Through evaluations of state-of-the-art LLM agents within the benchmark\ncreated by AIOPSLAB, we provide insights into their capabilities and\nlimitations in handling complex operational tasks in cloud environments.\n","authors":["Yinfang Chen","Manish Shetty","Gagan Somashekar","Minghua Ma","Yogesh Simmhan","Jonathan Mace","Chetan Bansal","Rujia Wang","Saravan Rajmohan"],"pdf_url":"https://arxiv.org/pdf/2501.06706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14843v3","updated":"2025-01-12T01:32:45Z","published":"2023-12-22T17:15:58Z","title":"SusDevOps: Promoting Sustainability to a First Principle in Software\n  Delivery","summary":"  Sustainability is becoming a key property of modern software systems. While\nthere is a substantial and growing body of knowledge on engineering sustainable\nsoftware, end-to-end frameworks that situate sustainability-related activities\nwithin the software delivery lifecycle are missing. In this article, we propose\nthe SusDevOps framework that promotes sustainability to a first principle\nwithin a DevOps context. We demonstrate the lifecycle phases and techniques of\nSusDevOps through the case of a software development startup company.\n","authors":["Istvan David"],"pdf_url":"https://arxiv.org/pdf/2312.14843v3.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2501.06977v1","updated":"2025-01-12T23:29:53Z","published":"2025-01-12T23:29:53Z","title":"Combining Automation and Expertise: A Semi-automated Approach to\n  Correcting Eye Tracking Data in Reading Tasks","summary":"  In reading tasks drift can move fixations from one word to another or even\nanother line, invalidating the eye tracking recording. Manual correction is\ntime-consuming and subjective, while automated correction is fast yet limited\nin accuracy. In this paper we present Fix8 (Fixate), an open-source GUI tool\nthat offers a novel semi-automated correction approach for eye tracking data in\nreading tasks. The proposed approach allows the user to collaborate with an\nalgorithm to produce accurate corrections faster without sacrificing accuracy.\nThrough a usability study (N=14) we assess the time benefits of the proposed\ntechnique, and measure the correction accuracy in comparison to manual\ncorrection. In addition, we assess subjective workload through NASA Task Load\nIndex, and user opinions through Likert-scale questions. Our results show that\non average the proposed technique was 44% faster than manual correction without\nany sacrifice in accuracy. In addition, users reported a preference for the\nproposed technique, lower workload, and higher perceived performance compared\nto manual correction. Fix8 is a valuable tool that offers useful features for\ngenerating synthetic eye tracking data, visualization, filters, data\nconverters, and eye movement analysis in addition to the main contribution in\ndata correction.\n","authors":["Naser Al Madi","Brett Torra","Yixin Li","Najam Tariq"],"pdf_url":"https://arxiv.org/pdf/2501.06977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06964v1","updated":"2025-01-12T22:49:32Z","published":"2025-01-12T22:49:32Z","title":"Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate\n  Patient Perspectives","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in\nrole-playing scenarios, particularly in simulating domain-specific experts\nusing tailored prompts. This ability enables LLMs to adopt the persona of\nindividuals with specific backgrounds, offering a cost-effective and efficient\nalternative to traditional, resource-intensive user studies. By mimicking human\nbehavior, LLMs can anticipate responses based on concrete demographic or\nprofessional profiles. In this paper, we evaluate the effectiveness of LLMs in\nsimulating individuals with diverse backgrounds and analyze the consistency of\nthese simulated behaviors compared to real-world outcomes. In particular, we\nexplore the potential of LLMs to interpret and respond to discharge summaries\nprovided to patients leaving the Intensive Care Unit (ICU). We evaluate and\ncompare with human responses the comprehensibility of discharge summaries among\nindividuals with varying educational backgrounds, using this analysis to assess\nthe strengths and limitations of LLM-driven simulations. Notably, when LLMs are\nprimed with educational background information, they deliver accurate and\nactionable medical guidance 88% of the time. However, when other information is\nprovided, performance significantly drops, falling below random chance levels.\nThis preliminary study shows the potential benefits and pitfalls of\nautomatically generating patient-specific health information from diverse\npopulations. While LLMs show promise in simulating health personas, our results\nhighlight critical gaps that must be addressed before they can be reliably used\nin clinical settings. Our findings suggest that a straightforward\nquery-response model could outperform a more tailored approach in delivering\nhealth information. This is a crucial first step in understanding how LLMs can\nbe optimized for personalized health communication while maintaining accuracy.\n","authors":["Xinyao Ma","Rui Zhu","Zihao Wang","Jingwei Xiong","Qingyu Chen","Haixu Tang","L. Jean Camp","Lucila Ohno-Machado"],"pdf_url":"https://arxiv.org/pdf/2501.06964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.20758v2","updated":"2025-01-12T21:57:58Z","published":"2024-12-30T07:03:54Z","title":"High-Sensitivity Vision-Based Tactile Sensing Enhanced by\n  Microstructures and Lightweight CNN","summary":"  Tactile sensing is critical in advanced interactive systems by emulating the\nhuman sense of touch to detect stimuli. Vision-based tactile sensors (VBTSs)\nare promising for their ability to provide rich information, robustness,\nadaptability, low cost, and multimodal capabilities. However, current\ntechnologies still have limitations in sensitivity, spatial resolution, and the\nhigh computational demands of deep learning-based image processing. This paper\npresents a comprehensive approach combining a novel sensor structure with\nmicromachined structures and an efficient image processing method, and\ndemonstrates that carefully engineered microstructures within the sensor\nhardware can significantly enhance sensitivity while reducing computational\nload. Unlike traditional designs with tracking markers, our sensor incorporates\nan interface surface with micromachined trenches, as an example of\nmicrostructures, which modulate light transmission and amplify the variation in\nresponse to applied force. By capturing variations in brightness, wire width,\nand cross pattern locations with a camera, the sensor accurately infers the\ncontact location, the magnitude of displacement and applied force with a\nlightweight convolutional neural network (CNN). Theoretical and experimental\nresults demonstrated that the microstructures significantly enhance sensitivity\nby amplifying the visual effects of shape distortion. The sensor system\neffectively detected forces below 10 mN, and achieved a millimetre-level\nsingle-point spatial resolution. Using a model with only one convolutional\nlayer, a mean absolute error (MAE) below 0.05 mm have been achieved. Its soft\nsensor body ensures compatibility with soft robots and wearable electronics,\nwhile its immunity to electrical crosstalk and interference guarantees\nreliability in complex human-machine environments.\n","authors":["Mayue Shi","Yongqi Zhang","Xiaotong Guo","Eric M. Yeatman"],"pdf_url":"https://arxiv.org/pdf/2412.20758v2.pdf","comment":"27 pages, 13 figures, 2 tables; rearranged figures; corrected typos"},{"id":"http://arxiv.org/abs/2501.06901v1","updated":"2025-01-12T18:55:57Z","published":"2025-01-12T18:55:57Z","title":"Games! What are they good for? The Struggle of Serious Game Adoption for\n  Rehabilitation","summary":"  The field of serious games for health has grown significantly, demonstrating\neffectiveness in various clinical contexts such as stroke, spinal cord injury,\nand degenerative neurological diseases. Despite their potential benefits,\ntherapists face barriers to adopting serious games in rehabilitation, including\nlimited training and game literacy, concerns about cost and equipment\navailability, and a lack of evidence-based research on game effectiveness.\nSerious games for rehabilitation often involve repetitive exercises, which can\nbe tedious and reduce motivation for continued rehabilitation, treating clients\nas passive recipients of clinical outcomes rather than players. This study\nidentifies gaps and provides essential insights for advancing serious games in\nrehabilitation, aiming to enhance their engagement for clients and\neffectiveness as a therapeutic tool. Addressing these challenges requires a\nparadigm shift towards developing and co-creating serious games for\nrehabilitation with therapists, researchers, and stakeholders. Furthermore,\nfuture research is crucial to advance the development of serious games,\nensuring they adhere to evidence-based principles and engage both clients and\ntherapists. This endeavor will identify gaps in the field, inspire new\ndirections, and support the creation of practical guidelines for serious games\nresearch.\n","authors":["Maria Micaela Fonseca","Nuno Fachada","Micael Sousa","Jorge Oliveira","Pedro Rodrigues","Sara Sousa","Claudia Quaresma","Phil Lopes"],"pdf_url":"https://arxiv.org/pdf/2501.06901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06899v1","updated":"2025-01-12T18:52:53Z","published":"2025-01-12T18:52:53Z","title":"Virtual Reality-Based Telerehabilitation for Upper Limb Recovery\n  Post-Stroke: A Systematic Review of Design Principles, Monitoring, Safety,\n  and Engagement Strategies","summary":"  Stroke rehabilitation continues to face challenges in accessibility and\npatient engagement, where traditional approaches often fall short. Virtual\nreality (VR)-based telerehabilitation offers a promising avenue, by enabling\nhome-based recovery through immersive environments and gamification. This\nsystematic review evaluates current VR solutions for upper-limb post-stroke\nrecovery, focusing on design principles, safety measures, patient-therapist\ncommunication, and strategies to promote motivation and adherence. Following\nPRISMA 2020 guidelines, a comprehensive search was conducted across PubMed,\nIEEE Xplore, and ScienceDirect. The review reveals a scarcity of studies\nmeeting the inclusion criteria, possibly reflecting the challenges inherent in\nthe current paradigm of VR telerehabilitation systems. Although these systems\nhave potential to enhance accessibility and patient autonomy, they often lack\nstandardized safety protocols and reliable real-time monitoring. Human-centered\ndesign principles are evident in some solutions, but inconsistent patient\ninvolvement during the development process limits their usability and clinical\nrelevance. Furthermore, communication between patients and therapists remains\nconstrained by technological barriers, although advancements in real-time\nfeedback and adaptive systems offer promising solutions. This review\nunderscores the potential of VR telerehabilitation to address critical needs in\nupper-limb stroke recovery while highlighting the importance of addressing\nexisting limitations to ensure broader clinical implementation and improved\npatient outcomes.\n","authors":["Pedro Rodrigues","Claudia Quaresma","Maria Costa","Filipe Luz","Maria Micaela Fonseca"],"pdf_url":"https://arxiv.org/pdf/2501.06899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06869v1","updated":"2025-01-12T16:39:13Z","published":"2025-01-12T16:39:13Z","title":"A Foundational Generative Model for Breast Ultrasound Image Analysis","summary":"  Foundational models have emerged as powerful tools for addressing various\ntasks in clinical settings. However, their potential development to breast\nultrasound analysis remains untapped. In this paper, we present BUSGen, the\nfirst foundational generative model specifically designed for breast ultrasound\nimage analysis. Pretrained on over 3.5 million breast ultrasound images, BUSGen\nhas acquired extensive knowledge of breast structures, pathological features,\nand clinical variations. With few-shot adaptation, BUSGen can generate\nrepositories of realistic and informative task-specific data, facilitating the\ndevelopment of models for a wide range of downstream tasks. Extensive\nexperiments highlight BUSGen's exceptional adaptability, significantly\nexceeding real-data-trained foundational models in breast cancer screening,\ndiagnosis, and prognosis. In breast cancer early diagnosis, our approach\noutperformed all board-certified radiologists (n=9), achieving an average\nsensitivity improvement of 16.5% (P-value<0.0001). Additionally, we\ncharacterized the scaling effect of using generated data which was as effective\nas the collected real-world data for training diagnostic models. Moreover,\nextensive experiments demonstrated that our approach improved the\ngeneralization ability of downstream models. Importantly, BUSGen protected\npatient privacy by enabling fully de-identified data sharing, making progress\nforward in secure medical data utilization. An online demo of BUSGen is\navailable at https://aibus.bio.\n","authors":["Haojun Yu","Youcheng Li","Nan Zhang","Zihan Niu","Xuantong Gong","Yanwen Luo","Haotian Ye","Siyu He","Quanlin Wu","Wangyan Qin","Mengyuan Zhou","Jie Han","Jia Tao","Ziwei Zhao","Di Dai","Di He","Dong Wang","Binghui Tang","Ling Huo","James Zou","Qingli Zhu","Yong Wang","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2501.06869v1.pdf","comment":"Peking University; Stanford University; Peking University Cancer\n  Hospital & Institute; Peking Union Medical College Hospital; Cancer Hospital,\n  Chinese Academy of Medical Sciences"},{"id":"http://arxiv.org/abs/2501.06867v1","updated":"2025-01-12T16:31:53Z","published":"2025-01-12T16:31:53Z","title":"Toward a Universal Concept of Artificial Personality: Implementing\n  Robotic Personality in a Kinova Arm","summary":"  The fundamental role of personality in shaping interactions is increasingly\nbeing exploited in robotics. A carefully designed robotic personality has been\nshown to improve several key aspects of Human-Robot Interaction (HRI). However,\nthe fragmentation and rigidity of existing approaches reveal even greater\nchallenges when applied to non-humanoid robots. On one hand, the state of the\nart is very dispersed; on the other hand, Industry 4.0 is moving towards a\nfuture where humans and industrial robots are going to coexist. In this\ncontext, the proper design of a robotic personality can lead to more successful\ninteractions. This research takes a first step in that direction by integrating\na comprehensive cognitive architecture built upon the definition of robotic\npersonality - validated on humanoid robots - into a robotic Kinova Jaco2 arm.\nThe robot personality is defined through the cognitive architecture as a vector\nin the three-dimensional space encompassing Conscientiousness, Extroversion,\nand Agreeableness, affecting how actions are executed, the action selection\nprocess, and the internal reaction to environmental stimuli. Our main objective\nis to determine whether users perceive distinct personalities in the robot,\nregardless of its shape, and to understand the role language plays in shaping\nthese perceptions. To achieve this, we conducted a user study comprising 144\nsessions of a collaborative game between a Kinova Jaco2 arm and participants,\nwhere the robot's behavior was influenced by its assigned personality.\nFurthermore, we compared two conditions: in the first, the robot communicated\nsolely through gestures and action choices, while in the second, it also\nutilized verbal interaction.\n","authors":["Alice Nardelli","Lorenzo Landolfi","Dario Pasquali","Antonio Sgorbissa","Francesco Rea","Carmine Recchiuto"],"pdf_url":"https://arxiv.org/pdf/2501.06867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09763v3","updated":"2025-01-12T15:56:53Z","published":"2024-10-13T07:41:37Z","title":"EEG-based AI-BCI Wheelchair Advancement: A Brain-Computer Interfacing\n  Wheelchair System Using Deep Learning Approach","summary":"  This study offers a revolutionary strategy to developing wheelchairs based on\nthe Brain-Computer Interface (BCI) that incorporates Artificial Intelligence\n(AI) using a The device uses electroencephalogram (EEG) data to mimic\nwheelchair navigation. Five different models were trained on a pre-filtered\ndataset that was divided into fixed-length windows using a sliding window\ntechnique. Each window contained statistical measurements, FFT coefficients for\ndifferent frequency bands, and a label identifying the activity carried out\nduring that window that was taken from an open-source Kaggle repository. The\nXGBoost model outperformed the other models, CatBoost, GRU, SVC, and XGBoost,\nwith an accuracy of 60%. The CatBoost model with a major difference between\ntraining and testing accuracy shows overfitting, and similarly, the\nbest-performing model, with SVC, was implemented in a tkinter GUI. The\nwheelchair movement could be simulated in various directions, and a Raspberry\nPi-powered wheelchair system for brain-computer interface is proposed here.\n","authors":["Biplov Paneru","Bishwash Paneru","Bipul Thapa","Khem Narayan Poudyal"],"pdf_url":"https://arxiv.org/pdf/2410.09763v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06757v1","updated":"2025-01-12T09:25:10Z","published":"2025-01-12T09:25:10Z","title":"OptiCarVis: Improving Automated Vehicle Functionality Visualizations\n  Using Bayesian Optimization to Enhance User Experience","summary":"  Automated vehicle (AV) acceptance relies on their understanding via feedback.\nWhile visualizations aim to enhance user understanding of AV's detection,\nprediction, and planning functionalities, establishing an optimal design is\nchallenging. Traditional \"one-size-fits-all\" designs might be unsuitable,\nstemming from resource-intensive empirical evaluations. This paper introduces\nOptiCarVis, a set of Human-in-the-Loop (HITL) approaches using Multi-Objective\nBayesian Optimization (MOBO) to optimize AV feedback visualizations. We compare\nconditions using eight expert and user-customized designs for a Warm-Start HITL\nMOBO. An online study (N=117) demonstrates OptiCarVis's efficacy in\nsignificantly improving trust, acceptance, perceived safety, and predictability\nwithout increasing cognitive load. OptiCarVis facilitates a comprehensive\ndesign space exploration, enhancing in-vehicle interfaces for optimal passenger\nexperiences and broader applicability.\n","authors":["Pascal Jansen","Mark Colley","Svenja Krauß","Daniel Hirschle","Enrico Rukzio"],"pdf_url":"https://arxiv.org/pdf/2501.06757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05322v2","updated":"2025-01-12T08:44:36Z","published":"2025-01-09T15:45:28Z","title":"\"What's Happening\"- A Human-centered Multimodal Interpreter Explaining\n  the Actions of Autonomous Vehicles","summary":"  Public distrust of self-driving cars is growing. Studies emphasize the need\nfor interpreting the behavior of these vehicles to passengers to promote trust\nin autonomous systems. Interpreters can enhance trust by improving transparency\nand reducing perceived risk. However, current solutions often lack a\nhuman-centric approach to integrating multimodal interpretations. This paper\nintroduces a novel Human-centered Multimodal Interpreter (HMI) system that\nleverages human preferences to provide visual, textual, and auditory feedback.\nThe system combines a visual interface with Bird's Eye View (BEV), map, and\ntext display, along with voice interaction using a fine-tuned large language\nmodel (LLM). Our user study, involving diverse participants, demonstrated that\nthe HMI system significantly boosts passenger trust in AVs, increasing average\ntrust levels by over 8%, with trust in ordinary environments rising by up to\n30%. These results underscore the potential of the HMI system to improve the\nacceptance and reliability of autonomous vehicles by providing clear,\nreal-time, and context-sensitive explanations of vehicle actions.\n","authors":["Xuewen Luo","Fan Ding","Ruiqi Chen","Rishikesh Panda","Junnyong Loo","Shuyun Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.05322v2.pdf","comment":"This paper has been accepted for presentation at WACV Workshop HAVI\n  2025"},{"id":"http://arxiv.org/abs/2501.06744v1","updated":"2025-01-12T08:01:57Z","published":"2025-01-12T08:01:57Z","title":"Enabling Cardiac Monitoring using In-ear Ballistocardiogram on COTS\n  Wireless Earbuds","summary":"  The human ear offers a unique opportunity for cardiac monitoring due to its\nphysiological and practical advantages. However, existing earable solutions\nrequire additional hardware and complex processing, posing challenges for\ncommercial True Wireless Stereo (TWS) earbuds which are limited by their form\nfactor and resources. In this paper, we propose TWSCardio, a novel system that\nrepurposes the IMU sensors in TWS earbuds for cardiac monitoring. Our key\nfinding is that these sensors can capture in-ear ballistocardiogram (BCG)\nsignals. TWSCardio reuses the unstable Bluetooth channel to stream the IMU data\nto a smartphone for BCG processing. It incorporates a signal enhancement\nframework to address issues related to missing data and low sampling rate,\nwhile mitigating motion artifacts by fusing multi-axis information.\nFurthermore, it employs a region-focused signal reconstruction method to\ntranslate the multi-axis in-ear BCG signals into fine-grained seismocardiogram\n(SCG) signals. We have implemented TWSCardio as an efficient real-time app. Our\nexperiments on 100 subjects verify that TWSCardio can accurately reconstruct\ncardiac signals while showing resilience to motion artifacts, missing data, and\nlow sampling rates. Our case studies further demonstrate that TWSCardio can\nsupport diverse cardiac monitoring applications.\n","authors":["Yongjian Fu","Ke Sun","Ruyao Wang","Xinyi Li","Ju Ren","Yaoxue Zhang","Xinyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.06744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.08222v4","updated":"2025-01-12T00:43:58Z","published":"2023-03-14T20:32:06Z","title":"Disconnected from Reality: Do the core concepts of the metaverse exclude\n  disabled individuals?","summary":"  Commercially-driven metaverse development has been driven by philosophical\nand science fiction concepts. Through translating these concepts into products,\nthe developers may have inadvertently excluded individuals with disabilities\nfrom this new expanded reality. This ideologically-driven development is\npresented in this paper through a brief background of what we see as the most\ninfluential of these concepts, and explain how these might affect disabled\nindividuals wishing to engage with said products. It is our hope that these\nideas prompt conversation on future inclusivity access from the concept stage\nof future metaverse development.\n","authors":["Mark Quinlan"],"pdf_url":"https://arxiv.org/pdf/2303.08222v4.pdf","comment":"TIAM23 Workshop at ACM CHI 23, Hamburg, Germany"}]},"2025-01-11T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2501.05129v2","updated":"2025-01-11T21:52:45Z","published":"2025-01-09T10:32:41Z","title":"A Framework for Devising, Evaluating and Fine-tuning Indoor Tracking\n  Algorithms","summary":"  In recent years, we have observed a growing interest in Indoor Tracking\nSystems (ITS) for providing location-based services indoors. This is due to the\nlimitations of Global Navigation and Satellite Systems, which do not operate in\nnon-line-of-sight environments. Depending on their architecture, ITS can rely\non expensive infrastructure, accumulate errors, or be challenging to evaluate\nin real-life environments. Building an ITS is a complex process that involves\ndevising, evaluating and fine-tuning tracking algorithms. This process is not\nyet standard, as researchers use different types of equipment, deployment\nenvironments, and evaluation metrics. Therefore, it is challenging for\nresearchers to build novel tracking algorithms and for the research community\nto reproduce the experiments.\n  To address these challenges, we propose MobiXIM, a framework that provides a\nset of tools for devising, evaluating and fine-tuning tracking algorithms in a\nstructured manner. For devising tracking algorithms, MobiXIM introduces a novel\nplugin architecture, allowing researchers to collaborate and extend existing\nalgorithms. We assess our framework by building an ITS encompassing the key\nelements of wireless, inertial, and collaborative ITS. The proposed ITS\nachieves a positioning accuracy of 4 m, which is an improvement of up to 33%\ncompared to a baseline Pedestrian Dead Reckoning algorithm.\n","authors":["Alpha Diallo","Benoit Garbinato"],"pdf_url":"https://arxiv.org/pdf/2501.05129v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12605v4","updated":"2025-01-11T15:09:13Z","published":"2024-03-19T10:14:48Z","title":"Online Marketplace: A Benchmark for Data Management in Microservices","summary":"  Microservice architectures have become a popular approach for designing\nscalable distributed applications. Despite their extensive use in industrial\nsettings for over a decade, there is limited understanding of the data\nmanagement challenges that arise in these applications. Consequently, it has\nbeen difficult to advance data system technologies that effectively support\nmicroservice applications. To fill this gap, we present Online Marketplace, a\nmicroservice benchmark that highlights core data management challenges that\nexisting benchmarks fail to address. These challenges include transaction\nprocessing, query processing, event processing, constraint enforcement, and\ndata replication. We have defined criteria for various data management issues\nto enable proper comparison across data systems and platforms.\n  Through case studies with state-of-the-art data platforms, we discuss the\nissues encountered while implementing and meeting Online Marketplace's\ncriteria. By capturing the overhead of meeting the key data management\nrequirements that are overlooked by existing benchmarks, we gain actionable\ninsights into the experimental platforms. This highlights the significance of\nOnline Marketplace in advancing future data systems to meet the needs of\nmicroservice practitioners.\n","authors":["Rodrigo Laigner","Zhexiang Zhang","Yijian Liu","Leonardo Freitas Gomes","Yongluan Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.12605v4.pdf","comment":"Version accepted at SIGMOD'25"},{"id":"http://arxiv.org/abs/2312.12933v3","updated":"2025-01-11T12:41:00Z","published":"2023-12-20T11:19:23Z","title":"ACTesting: Automated Cross-modal Testing Method of Text-to-Image\n  Software","summary":"  Recently, creative generative artificial intelligence software has emerged as\na pivotal assistant, enabling users to generate content and seek inspiration\nrapidly. Text-to-Image (T2I) software, one of the most widely used, synthesizes\nimages with text input by engaging in a cross-modal process. However, despite\nsubstantial advancements in the T2I engine, T2I software still encounters\nerrors when generating complex or non-realistic scenes, including omitting\nfocal entities, low image realism, and mismatched text-image information. The\ncross-modal nature of T2I software complicates error detection for traditional\ntesting methods, and the absence of test oracles further exacerbates the\ncomplexity of the testing process. To fill this gap, we propose ACTesting, an\nAutomated Cross-modal Testing Method of Text-to-Image Software, the first\ntesting method explicitly designed for T2I software. ACTesting utilizes the\nmetamorphic testing principle to address the oracle problem and identifies\ncross-modal semantic consistency as its fundamental Metamorphic relation (MR)\nby employing the Entity-relationship (ER) triples. We design three kinds of\nmutation operators under the guidance of MR and the adaptability density\nconstraint to construct the new input text. After generating the images based\non the text, ACTesting verifies whether MR is satisfied by detecting the ER\ntriples across two modalities to detect the errors of T2I software. In our\nexperiments across five popular T2I software, ACTesting effectively generates\nerror-revealing tests, resulting in a decrease in text-image consistency by up\nto 20% when compared to the baseline. Additionally, an ablation study\ndemonstrates the efficacy of the proposed mutation operators. The experimental\nresults validate that ACTesting can reliably identify errors within T2I\nsoftware.\n","authors":["Siqi Gu","Chunrong Fang","Quanjun Zhang","Zhenyu Chen"],"pdf_url":"https://arxiv.org/pdf/2312.12933v3.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2501.06523v1","updated":"2025-01-11T12:18:46Z","published":"2025-01-11T12:18:46Z","title":"Not real or too soft? On the challenges of publishing interdisciplinary\n  software engineering research","summary":"  The discipline of software engineering (SE) combines social and technological\ndimensions. It is an interdisciplinary research field. However,\ninterdisciplinary research submitted to software engineering venues may not\nreceive the same level of recognition as more traditional or technical topics\nsuch as software testing. For this paper, we conducted an online survey of 73\nSE researchers and used a mixed-method data analysis approach to investigate\ntheir challenges and recommendations when publishing interdisciplinary research\nin SE. We found that the challenges of publishing interdisciplinary research in\nSE can be divided into topic-related and reviewing-related challenges.\nFurthermore, while our initial focus was on publishing interdisciplinary\nresearch, the impact of current reviewing practices on marginalized groups\nemerged from our data, as we found that marginalized groups are more likely to\nreceive negative feedback. In addition, we found that experienced researchers\nare less likely to change their research direction due to feedback they\nreceive. To address the identified challenges, our participants emphasize the\nimportance of highlighting the impact and value of interdisciplinary work for\nSE, collaborating with experienced researchers, and establishing clearer\nsubmission guidelines and new interdisciplinary SE publication venues. Our\nfindings contribute to the understanding of the current state of the SE\nresearch community and how we could better support interdisciplinary research\nin our field.\n","authors":["Sonja M. Hyrynsalmi","Grischa Liebel","Ronnie de Souza Santos","Sebastian Baltes"],"pdf_url":"https://arxiv.org/pdf/2501.06523v1.pdf","comment":"12 pages, 1 figure, 4 tables, 47th International Conference on\n  Software Engineering: Software Engineering in Society (ICSE-SEIS 2025)"},{"id":"http://arxiv.org/abs/2501.06491v1","updated":"2025-01-11T09:36:14Z","published":"2025-01-11T09:36:14Z","title":"Improving Requirements Classification with SMOTE-Tomek Preprocessing","summary":"  This study emphasizes the domain of requirements engineering by applying the\nSMOTE-Tomek preprocessing technique, combined with stratified K-fold\ncross-validation, to address class imbalance in the PROMISE dataset. This\ndataset comprises 969 categorized requirements, classified into functional and\nnon-functional types. The proposed approach enhances the representation of\nminority classes while maintaining the integrity of validation folds, leading\nto a notable improvement in classification accuracy. Logistic regression\nachieved 76.16\\%, significantly surpassing the baseline of 58.31\\%. These\nresults highlight the applicability and efficiency of machine learning models\nas scalable and interpretable solutions.\n","authors":["Barak Or"],"pdf_url":"https://arxiv.org/pdf/2501.06491v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.06459v1","updated":"2025-01-11T07:17:11Z","published":"2025-01-11T07:17:11Z","title":"Enhancing The Open Network: Definition and Automated Detection of Smart\n  Contract Defects","summary":"  The Open Network (TON), designed to support Telegram's extensive user base of\nhundreds of millions, has garnered considerable attention since its launch in\n2022. FunC is the most popular programming language for writing smart contracts\non TON. It is distinguished by a unique syntax compared to other smart contract\nlanguages. Despite growing interest, research on the practical defects of TON\nsmart contracts is still in its early stages. In this paper, we summarize eight\nsmart contract defects identified from TON's official blogs and audit reports,\neach with detailed definitions and code examples. Furthermore, we propose a\nstatic analysis framework called TONScanner to facilitate the detection of\nthese defects. Specifically, TONScanner reuses FunC compiler's frontend code to\ntransform the FunC source code into FunC intermediate representation (IR) in\nthe form of a directed acyclic graph (DAG). Based on this IR, TONScanner\nconstructs a control flow graph (CFG), then transforms it into a static single\nassignment (SSA) form to simplify further analysis. TONScanner also integrates\nData Dependency, Call Graph, Taint Analysis, and Cell Construct, which are\nspecifically tailored for TON blockchain's unique data structures. These\ncomponents finally facilitate the identification of the eight defects. We\nevaluate the effectiveness of TONScanner by applying it to 1,640 smart\ncontracts and find a total of 14,995 defects. Through random sampling and\nmanual labeling, we find that TONScanner achieves an overall precision of\n97.49%. The results reveal that current TON contracts contain numerous defects,\nindicating that developers are prone to making errors. TONScanner has proven\nits ability to accurately identify these defects, thereby aiding in their\ncorrection.\n","authors":["Hao Song","Teng Li","Jiachi Chen","Ting Chen","Beibei Li","Zhangyan Lin","Yi Lu","Pan Li","Xihan Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.06459v1.pdf","comment":"The paper has been accepted for presentation at the 47th IEEE/ACM\n  International Conference on Software Engineering (ICSE 2025)"},{"id":"http://arxiv.org/abs/2501.06443v1","updated":"2025-01-11T05:52:41Z","published":"2025-01-11T05:52:41Z","title":"Quantum Testing in the Wild: A Case Study with Qiskit Algorithms","summary":"  Although classical computing has excelled in a wide range of applications,\nthere remain problems that push the limits of its capabilities, especially in\nfields like cryptography, optimization, and materials science. Quantum\ncomputing introduces a new computational paradigm, based on principles of\nsuperposition and entanglement to explore solutions beyond the capabilities of\nclassical computation. With the increasing interest in the field, there are\nchallenges and opportunities for academics and practitioners in terms of\nsoftware engineering practices, particularly in testing quantum programs. This\npaper presents an empirical study of testing patterns in quantum algorithms. We\nanalyzed all the tests handling quantum aspects of the implementations in the\nQiskit Algorithms library and identified seven distinct patterns that make use\nof (1) fixed seeds for algorithms based on random elements; (2) deterministic\noracles; (3) precise and approximate assertions; (4) Data-Driven Testing (DDT);\n(5) functional testing; (6) testing for intermediate parts of the algorithms\nbeing tested; and (7) equivalence checking for quantum circuits. Our results\nshow a prevalence of classical testing techniques to test the quantum-related\nelements of the library, while recent advances from the research community have\nyet to achieve wide adoption among practitioners.\n","authors":["Neilson Carlos Leite Ramalho","Erico Augusto da Silva","Higor Amario de Souza","Marcos Lordello Chaim"],"pdf_url":"https://arxiv.org/pdf/2501.06443v1.pdf","comment":"This paper has been accepted for presentation in the ERA track at the\n  2025 IEEE International Conference on Software Analysis, Evolution and\n  Reengineering (SANER 2025)"},{"id":"http://arxiv.org/abs/2501.06437v1","updated":"2025-01-11T04:47:20Z","published":"2025-01-11T04:47:20Z","title":"Uncovering Non-native Speakers' Experiences in Global Software\n  Development Teams -- A Bourdieusian Perspective","summary":"  Globally distributed software development has been a mainstream paradigm in\ndeveloping modern software systems. We have witnessed a fast-growing population\nof software developers from areas where English is not a native language in the\nlast several decades. Given that English is still the de facto working language\nin most global software engineering teams, we need to gain more knowledge about\nthe experiences of developers who are non-native English speakers. We conducted\nan empirical study to fill this research gap. In this study, we interviewed 27\nChinese developers in commercial software development and open source global\nsoftware development teams and applied Bourdieu's capital-field-habitus\nframework in an abductive data analysis process. Our study reveals four types\nof capital (language, social, symbolic, and economic) involved in their\nexperiences and examines the interrelations among them. We found that\nnon-native speakers' insufficient language capital played an essential role in\nprohibiting them from accessing and accumulating other capital, thus\nreproducing the sustained and systematic disadvantaged positions of non-native\nEnglish speakers in GSD teams. We further discussed the theoretical and\npractical implications of the study.\n","authors":["Yi Wang","Yang Yue","Wei Wang","Gaowei Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.06437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06428v1","updated":"2025-01-11T03:47:04Z","published":"2025-01-11T03:47:04Z","title":"Optimizing digital experiences with content delivery networks:\n  Architectures, performance strategies, and future trends","summary":"  This research investigates how CDNs (Content Delivery Networks) can improve\nthe digital experience, as consumers increasingly expect fast, efficient, and\neffortless access to online resources. CDNs play a crucial role in reducing\nlatency, enhancing scalability, and optimizing delivery mechanisms, which is\nevident across various platforms and regions. The study focuses on key CDN\nconcerns, such as foundational and modern CDN architectures, edge computing,\nhybrid CDNs, and multi-CDN strategies. It also explores performance-enhancing\ntopics, including caching, load balancing, and the novel features of HTTP/3 and\nQUIC.\n  Current trends, such as integrating CDNs with 5G networks, serverless\narchitectures, and AI-driven traffic management, are examined to demonstrate\nhow CDN technology is likely to evolve. The study also addresses challenges\nrelated to security, cost, and global regulations. Practical examples from the\ne-commerce, streaming, and gaming industries highlight how enhanced CDNs are\ntransforming these sectors.\n  The conclusions emphasize the need to evolve CDN strategies to meet growing\nuser expectations and adapt to the rapidly changing digital landscape.\nAdditionally, the research identifies future research opportunities,\nparticularly in exploring the impact of QC, the enhancement of AI services, and\nthe sustainability of CDN solutions. Overall, the study situates architectural\ndesign, performance strategies, and emerging trends to address gaps and create\na more efficient and secure approach for improving digital experiences.\n","authors":["Anuj Tyagi"],"pdf_url":"https://arxiv.org/pdf/2501.06428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06424v1","updated":"2025-01-11T03:33:20Z","published":"2025-01-11T03:33:20Z","title":"Towards User-Focused Cross-Domain Testing: Disentangling Accessibility,\n  Usability, and Fairness","summary":"  Fairness testing is increasingly recognized as fundamental in software\nengineering, especially in the domain of data-driven systems powered by\nartificial intelligence. However, its practical integration into software\ndevelopment may pose challenges, given its overlapping boundaries with\nusability and accessibility testing. In this tertiary study, we explore these\ncomplexities using insights from 12 systematic reviews published in the past\ndecade, shedding light on the nuanced interactions among fairness, usability,\nand accessibility testing and how they intersect within contemporary software\ndevelopment practices.\n","authors":["Matheus de Morais Leça","Ronnie de Souza Santos"],"pdf_url":"https://arxiv.org/pdf/2501.06424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04309v2","updated":"2025-01-11T03:29:49Z","published":"2023-05-07T15:32:16Z","title":"Unveiling Overlooked Performance Variance in Serverless Computing","summary":"  Serverless computing is an emerging cloud computing paradigm for developing\napplications at the function level, known as serverless functions. Due to the\nhighly dynamic execution environment, multiple identical runs of the same\nserverless function can yield different performance, specifically in terms of\nend-to-end response latency. However, surprisingly, our analysis of serverless\ncomputing-related papers published in top-tier conferences highlights that the\nresearch community lacks awareness of the performance variance problem, with\nonly 38.38% of these papers employing multiple runs for quantifying it. To\nfurther investigate, we analyze the performance of 72 serverless functions\ncollected from these papers. Our findings reveal that the performance of these\nserverless functions can differ by up to 338.76% (44.28% on average) across\ndifferent runs. Moreover, 61.11% of these functions produce unreliable\nperformance results, with a low number of repetitions commonly employed in the\nserverless computing literature. Our study highlights a lack of awareness in\nthe serverless computing community regarding the well-known performance\nvariance problem in software engineering. The empirical results illustrate the\nsubstantial magnitude of this variance, emphasizing that ignoring the variance\ncan affect research reproducibility and result reliability.\n","authors":["Jinfeng Wen","Zhenpeng Chen","Federica Sarro","Shangguang Wang"],"pdf_url":"https://arxiv.org/pdf/2305.04309v2.pdf","comment":"This work has been accepted for publication in Empirical Software\n  Engineering!"},{"id":"http://arxiv.org/abs/2501.06420v1","updated":"2025-01-11T03:19:51Z","published":"2025-01-11T03:19:51Z","title":"Unveiling Code Clones in Quantum Programming: An Empirical Study with\n  Qiskit","summary":"  Code clones, referring to identical or similar code fragments, have long\nposed challenges in classical programming, impacting software quality,\nmaintainability, and scalability. However, their presence and characteristics\nin quantum programming remain unexplored. This paper presents an empirical\nstudy of code clones in quantum programs, specifically focusing on software\ndeveloped using the Qiskit framework. We examine the existence, distribution,\ndensity, and size of code clones in quantum software, revealing a high density\nof Type-2 and Type-3 clones involving minor modifications. Our findings suggest\nthat these clones are more frequent in quantum software, likely due to the\ncomplexity of quantum algorithms and their integration with classical logic.\nThis highlights the need for advanced clone detection and refactoring tools\nspecifically designed for the quantum domain to improve software\nmaintainability and scalability.\n","authors":["Kenta Manoku","Jianjun Zhao"],"pdf_url":"https://arxiv.org/pdf/2501.06420v1.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2501.06658v1","updated":"2025-01-11T22:59:37Z","published":"2025-01-11T22:59:37Z","title":"Comparing Few-Shot Prompting of GPT-4 LLMs with BERT Classifiers for\n  Open-Response Assessment in Tutor Equity Training","summary":"  Assessing learners in ill-defined domains, such as scenario-based human\ntutoring training, is an area of limited research. Equity training requires a\nnuanced understanding of context, but do contemporary large language models\n(LLMs) have a knowledge base that can navigate these nuances? Legacy\ntransformer models like BERT, in contrast, have less real-world knowledge but\ncan be more easily fine-tuned than commercial LLMs. Here, we study whether\nfine-tuning BERT on human annotations outperforms state-of-the-art LLMs (GPT-4o\nand GPT-4-Turbo) with few-shot prompting and instruction. We evaluate\nperformance on four prediction tasks involving generating and explaining\nopen-ended responses in advocacy-focused training lessons in a higher education\nstudent population learning to become middle school tutors. Leveraging a\ndataset of 243 human-annotated open responses from tutor training lessons, we\nfind that BERT demonstrates superior performance using an offline fine-tuning\napproach, which is more resource-efficient than commercial GPT models. We\nconclude that contemporary GPT models may not adequately capture nuanced\nresponse patterns, especially in complex tasks requiring explanation. This work\nadvances the understanding of AI-driven learner evaluation under the lens of\nfine-tuning versus few-shot prompting on the nuanced task of equity training,\ncontributing to more effective training solutions and assisting practitioners\nin choosing adequate assessment methods.\n","authors":["Sanjit Kakarla","Conrad Borchers","Danielle Thomas","Shambhavi Bhushan","Kenneth R. Koedinger"],"pdf_url":"https://arxiv.org/pdf/2501.06658v1.pdf","comment":"8 Page Workshop Paper, AAAI2025 Workshop on Innovation and\n  Responsibility in AI-Supported Education (iRAISE) - Open-response Grading,\n  Feedback, Equity Training, LLMs, BERT, GPT-4"},{"id":"http://arxiv.org/abs/2501.06607v1","updated":"2025-01-11T18:12:36Z","published":"2025-01-11T18:12:36Z","title":"AI Drawing Partner: Co-Creative Drawing Agent and Research Platform to\n  Model Co-Creation","summary":"  This paper describes the AI Drawing Partner, which is a co-creative drawing\nagent that also serves as a research platform to model co-creation. The AI\nDrawing Partner is an early example of a quantified co-creative AI system that\nautomatically models the co-creation that happens on the system. The method the\nsystem uses to capture this data is based on a new cognitive science framework\ncalled co-creative sense-making (CCSM). The CCSM is based on the cognitive\ntheory of enaction, which describes how meaning emerges through interaction\nwith the environment and other people in that environment in a process of\nsense-making. The CCSM quantifies elements of interaction dynamics to identify\nsense-making patterns and interaction trends. This paper describes a new\ntechnique for modeling the interaction and collaboration dynamics of\nco-creative AI systems with the co-creative sense-making (CCSM) framework. A\ncase study is conducted of ten co-creative drawing sessions between a human\nuser and the co-creative agent. The analysis includes showing the artworks\nproduced, the quantified data from the AI Drawing Partner, the curves\ndescribing interaction dynamics, and a visualization of interaction trend\nsequences. The primary contribution of this paper is presenting the AI Drawing\nPartner, which is a unique co-creative AI system and research platform that\ncollaborates with the user in addition to quantifying, modeling, and\nvisualizing the co-creative process using the CCSM framework.\n","authors":["Nicholas Davis","Janet Rafner"],"pdf_url":"https://arxiv.org/pdf/2501.06607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06597v1","updated":"2025-01-11T17:45:13Z","published":"2025-01-11T17:45:13Z","title":"EmoXpt: Analyzing Emotional Variances in Human Comments and\n  LLM-Generated Responses","summary":"  The widespread adoption of generative AI has generated diverse opinions, with\nindividuals expressing both support and criticism of its applications. This\nstudy investigates the emotional dynamics surrounding generative AI by\nanalyzing human tweets referencing terms such as ChatGPT, OpenAI, Copilot, and\nLLMs. To further understand the emotional intelligence of ChatGPT, we examine\nits responses to selected tweets, highlighting differences in sentiment between\nhuman comments and LLM-generated responses. We introduce EmoXpt, a sentiment\nanalysis framework designed to assess both human perspectives on generative AI\nand the sentiment embedded in ChatGPT's responses. Unlike prior studies that\nfocus exclusively on human sentiment, EmoXpt uniquely evaluates the emotional\nexpression of ChatGPT. Experimental results demonstrate that LLM-generated\nresponses are notably more efficient, cohesive, and consistently positive than\nhuman responses.\n","authors":["Shireesh Reddy Pyreddy","Tarannum Shaila Zaman"],"pdf_url":"https://arxiv.org/pdf/2501.06597v1.pdf","comment":"7 pages, 10 figures, 5 tables. This paper has been accepted and\n  presented at the 2025 IEEE 15th Annual Computing and Communication Workshop\n  and Conference (CCWC)"},{"id":"http://arxiv.org/abs/2501.06527v1","updated":"2025-01-11T12:31:10Z","published":"2025-01-11T12:31:10Z","title":"Scaffolding Creativity: Integrating Generative AI Tools and Real-world\n  Experiences in Business Education","summary":"  This case study explores the integration of Generative AI tools and\nreal-world experiences in business education. Through a study of an innovative\nundergraduate course, we investigate how AI-assisted learning, combined with\nexperiential components, impacts students' creative processes and learning\noutcomes. Our findings reveal that this integrated approach accelerates\nknowledge acquisition, enables students to overcome traditional creative\nbarriers, and facilitates a dynamic interplay between AI-generated insights and\nreal-world observations. The study also highlights challenges, including the\nneed for instructors with high AI literacy and the rapid evolution of AI tools\ncreating a moving target for curriculum design. These insights contribute to\nthe growing body of literature on AI in education and provide actionable\nrecommendations for educators preparing students for the complexities of modern\nbusiness environments.\n","authors":["Nicole C. Wang"],"pdf_url":"https://arxiv.org/pdf/2501.06527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06488v1","updated":"2025-01-11T09:12:43Z","published":"2025-01-11T09:12:43Z","title":"NVS-SQA: Exploring Self-Supervised Quality Representation Learning for\n  Neurally Synthesized Scenes without References","summary":"  Neural View Synthesis (NVS), such as NeRF and 3D Gaussian Splatting,\neffectively creates photorealistic scenes from sparse viewpoints, typically\nevaluated by quality assessment methods like PSNR, SSIM, and LPIPS. However,\nthese full-reference methods, which compare synthesized views to reference\nviews, may not fully capture the perceptual quality of neurally synthesized\nscenes (NSS), particularly due to the limited availability of dense reference\nviews. Furthermore, the challenges in acquiring human perceptual labels hinder\nthe creation of extensive labeled datasets, risking model overfitting and\nreduced generalizability. To address these issues, we propose NVS-SQA, a NSS\nquality assessment method to learn no-reference quality representations through\nself-supervision without reliance on human labels. Traditional self-supervised\nlearning predominantly relies on the \"same instance, similar representation\"\nassumption and extensive datasets. However, given that these conditions do not\napply in NSS quality assessment, we employ heuristic cues and quality scores as\nlearning objectives, along with a specialized contrastive pair preparation\nprocess to improve the effectiveness and efficiency of learning. The results\nshow that NVS-SQA outperforms 17 no-reference methods by a large margin (i.e.,\non average 109.5% in SRCC, 98.6% in PLCC, and 91.5% in KRCC over the second\nbest) and even exceeds 16 full-reference methods across all evaluation metrics\n(i.e., 22.9% in SRCC, 19.1% in PLCC, and 18.6% in KRCC over the second best).\n","authors":["Qiang Qu","Yiran Shen","Xiaoming Chen","Yuk Ying Chung","Weidong Cai","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2501.06488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06416v1","updated":"2025-01-11T03:12:53Z","published":"2025-01-11T03:12:53Z","title":"Influencing Humans to Conform to Preference Models for RLHF","summary":"  Designing a reinforcement learning from human feedback (RLHF) algorithm to\napproximate a human's unobservable reward function requires assuming,\nimplicitly or explicitly, a model of human preferences. A preference model that\npoorly describes how humans generate preferences risks learning a poor\napproximation of the human's reward function. In this paper, we conduct three\nhuman studies to asses whether one can influence the expression of real human\npreferences to more closely conform to a desired preference model. Importantly,\nour approach does not seek to alter the human's unobserved reward function.\nRather, we change how humans use this reward function to generate preferences,\nsuch that they better match whatever preference model is assumed by a\nparticular RLHF algorithm. We introduce three interventions: showing humans the\nquantities that underlie a preference model, which is normally unobservable\ninformation derived from the reward function; training people to follow a\nspecific preference model; and modifying the preference elicitation question.\nAll intervention types show significant effects, providing practical tools to\nimprove preference data quality and the resultant alignment of the learned\nreward functions. Overall we establish a novel research direction in model\nalignment: designing interfaces and training interventions to increase human\nconformance with the modeling assumptions of the algorithm that will learn from\ntheir input.\n","authors":["Stephane Hatgis-Kessell","W. Bradley Knox","Serena Booth","Scott Niekum","Peter Stone"],"pdf_url":"https://arxiv.org/pdf/2501.06416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00521v2","updated":"2025-01-11T02:30:56Z","published":"2024-06-29T19:50:06Z","title":"A Medical Low-Back Pain Physical Rehabilitation Dataset for Human Body\n  Movement Analysis","summary":"  While automatic monitoring and coaching of exercises are showing encouraging\nresults in non-medical applications, they still have limitations such as errors\nand limited use contexts. To allow the development and assessment of physical\nrehabilitation by an intelligent tutoring system, we identify in this article\nfour challenges to address and propose a medical dataset of clinical patients\ncarrying out low back-pain rehabilitation exercises. The dataset includes 3D\nKinect skeleton positions and orientations, RGB videos, 2D skeleton data, and\nmedical annotations to assess the correctness, and error classification and\nlocalisation of body part and timespan. Along this dataset, we perform a\ncomplete research path, from data collection to processing, and finally a small\nbenchmark. We evaluated on the dataset two baseline movement recognition\nalgorithms, pertaining to two different approaches: the probabilistic approach\nwith a Gaussian Mixture Model (GMM), and the deep learning approach with a\nLong-Short Term Memory (LSTM).\n  This dataset is valuable because it includes rehabilitation relevant motions\nin a clinical setting with patients in their rehabilitation program, using a\ncost-effective, portable, and convenient sensor, and because it shows the\npotential for improvement on these challenges.\n","authors":["Sao Mai Nguyen","Maxime Devanne","Olivier Remy-Neris","Mathieu Lempereur","André Thepaut"],"pdf_url":"https://arxiv.org/pdf/2407.00521v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05452v2","updated":"2025-01-11T01:08:46Z","published":"2024-10-07T19:35:15Z","title":"WearableMil: An End-to-End Framework for Military Activity Recognition\n  and Performance Monitoring","summary":"  Musculoskeletal injuries during military training significantly impact\nreadiness, making prevention through activity monitoring crucial. While Human\nActivity Recognition (HAR) using wearable devices offers promising solutions,\nit faces challenges in processing continuous data streams and recognizing\ndiverse activities without predefined sessions. This paper introduces an\nend-to-end framework for preprocessing, analyzing, and recognizing activities\nfrom wearable data in military training contexts. Using data from 135 soldiers\nwearing \\textit{Garmin--55} smartwatches over six months with over 15 million\nminutes. We develop a hierarchical deep learning approach that achieves 93.8%\naccuracy in temporal splits and 83.8% in cross-user evaluation. Our framework\naddresses missing data through physiologically-informed methods, reducing\nunknown sleep states from 40.38% to 3.66%. We demonstrate that while longer\ntime windows (45-60 minutes) improve basic state classification, they present\ntrade-offs in detecting fine-grained activities. Additionally, we introduce an\nintuitive visualization system that enables real-time comparison of individual\nperformance against group metrics across multiple physiological indicators.\nThis approach to activity recognition and performance monitoring provides\nmilitary trainers with actionable insights for optimizing training programs and\npreventing injuries.\n","authors":["Barak Gahtan","Shany Funk","Einat Kodesh","Itay Ketko","Tsvi Kuflik","Alex M. Bronstein"],"pdf_url":"https://arxiv.org/pdf/2410.05452v2.pdf","comment":null}]},"2025-01-10T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2501.06370v1","updated":"2025-01-10T22:42:06Z","published":"2025-01-10T22:42:06Z","title":"Towards a Probabilistic Framework for Analyzing and Improving\n  LLM-Enabled Software","summary":"  Ensuring the reliability and verifiability of large language model\n(LLM)-enabled systems remains a significant challenge in software engineering.\nWe propose a probabilistic framework for systematically analyzing and improving\nthese systems by modeling and refining distributions over clusters of\nsemantically equivalent outputs. This framework facilitates the evaluation and\niterative improvement of Transference Models -- key software components that\nutilize LLMs to transform inputs into outputs for downstream tasks. To\nillustrate its utility, we apply the framework to the autoformalization\nproblem, where natural language documentation is transformed into formal\nprogram specifications. Our case illustrates how probabilistic analysis enables\nthe identification of weaknesses and guides focused alignment improvements,\nresulting in more reliable and interpretable outputs. This principled approach\noffers a foundation for addressing critical challenges in the development of\nrobust LLM-enabled systems.\n","authors":["Juan Manuel Baldonado","Flavia Bonomo-Braberman","Víctor Adrián Braberman"],"pdf_url":"https://arxiv.org/pdf/2501.06370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06305v1","updated":"2025-01-10T19:04:55Z","published":"2025-01-10T19:04:55Z","title":"Reinforcement Learning-Driven Adaptation Chains: A Robust Framework for\n  Multi-Cloud Workflow Security","summary":"  Cloud computing has emerged as a crucial solution for managing data- and\ncompute-intensive workflows, offering scalability to address dynamic demands.\nHowever, security concerns persist, especially for workflows involving\nsensitive data and tasks. One of the main gaps in the literature is the lack of\nrobust and flexible measures for reacting to these security violations. To\naddress this, we propose an innovative approach leveraging Reinforcement\nLearning (RL) to formulate adaptation chains, responding effectively to\nsecurity violations within cloud-based workflows. These chains consist of\nsequences of adaptation actions tailored to attack characteristics, workflow\ndependencies, and user-defined requirements. Unlike conventional single-task\nadaptations, adaptation chains provide a comprehensive mitigation strategy by\ntaking into account both control and data dependencies between tasks, thereby\naccommodating conflicting objectives effectively. Moreover, our RL-based\napproach uses insights from past responses to mitigate uncertainties associated\nwith adaptation costs. We evaluate the method using our jBPM and Cloudsim Plus\nbased implementation and compare the impact of selected adaptation chains on\nworkflows with the single adaptation approach. Results demonstrate that the\nadaptation chain approach outperforms in terms of total adaptation cost,\noffering resilience and adaptability against security threats.\n","authors":["Nafiseh Soveizi","Dimka Karastoyanova"],"pdf_url":"https://arxiv.org/pdf/2501.06305v1.pdf","comment":"17 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2501.06283v1","updated":"2025-01-10T17:23:14Z","published":"2025-01-10T17:23:14Z","title":"Dafny as Verification-Aware Intermediate Language for Code Generation","summary":"  Using large language models (LLMs) to generate source code from natural\nlanguage prompts is a popular and promising idea with a wide range of\napplications. One of its limitations is that the generated code can be faulty\nat times, often in a subtle way, despite being presented to the user as\ncorrect. In this paper, we explore ways in which formal methods can assist with\nincreasing the quality of code generated by an LLM. Instead of emitting code in\na target language directly, we propose that the user guides the LLM to first\ngenerate an opaque intermediate representation, in the verification-aware\nlanguage Dafny, that can be automatically validated for correctness against\nagreed on specifications. The correct Dafny program is then compiled to the\ntarget language and returned to the user. All user-system interactions\nthroughout the procedure occur via natural language; Dafny code is never\nexposed. We describe our current prototype and report on its performance on the\nHumanEval Python code generation benchmarks.\n","authors":["Yue Chen Li","Stefan Zetzsche","Siva Somayyajula"],"pdf_url":"https://arxiv.org/pdf/2501.06283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.06765v3","updated":"2025-01-10T17:02:33Z","published":"2024-01-12T18:56:57Z","title":"Automated Test Case Repair Using Language Models","summary":"  Ensuring the quality of software systems through testing is essential, yet\nmaintaining test cases poses significant challenges and costs. The need for\nfrequent updates to align with the evolving system under test often entails\nhigh complexity and cost for maintaining these test cases. Further, unrepaired\nbroken test cases can degrade test suite quality and disrupt the software\ndevelopment process, wasting developers' time. To address this challenge, we\npresent TaRGet (Test Repair GEneraTor), a novel approach leveraging pre-trained\ncode language models for automated test case repair. TaRGet treats test repair\nas a language translation task, employing a two-step process to fine-tune a\nlanguage model based on essential context data characterizing the test\nbreakage. To evaluate our approach, we introduce TaRBench, a comprehensive\nbenchmark we developed covering 45,373 broken test repairs across 59\nopen-source projects. Our results demonstrate TaRGet's effectiveness, achieving\na 66.1% exact match accuracy. Furthermore, our study examines the effectiveness\nof TaRGet across different test repair scenarios. We provide a practical guide\nto predict situations where the generated test repairs might be less reliable.\nWe also explore whether project-specific data is always necessary for\nfine-tuning and if our approach can be effective on new projects.\n","authors":["Ahmadreza Saboor Yaraghi","Darren Holden","Nafiseh Kahani","Lionel Briand"],"pdf_url":"https://arxiv.org/pdf/2401.06765v3.pdf","comment":"40 pages, 18 figures"},{"id":"http://arxiv.org/abs/2412.14306v2","updated":"2025-01-10T17:00:34Z","published":"2024-12-18T20:19:56Z","title":"Closing the Gap: A User Study on the Real-world Usefulness of AI-powered\n  Vulnerability Detection & Repair in the IDE","summary":"  This paper presents the first empirical study of a vulnerability detection\nand fix tool with professional software developers on real projects that they\nown. We implemented DeepVulGuard, an IDE-integrated tool based on\nstate-of-the-art detection and fix models, and show that it has promising\nperformance on benchmarks of historic vulnerability data. DeepVulGuard scans\ncode for vulnerabilities (including identifying the vulnerability type and\nvulnerable region of code), suggests fixes, provides natural-language\nexplanations for alerts and fixes, leveraging chat interfaces. We recruited 17\nprofessional software developers at Microsoft, observed their usage of the tool\non their code, and conducted interviews to assess the tool's usefulness, speed,\ntrust, relevance, and workflow integration. We also gathered detailed\nqualitative feedback on users' perceptions and their desired features. Study\nparticipants scanned a total of 24 projects, 6.9k files, and over 1.7 million\nlines of source code, and generated 170 alerts and 50 fix suggestions. We find\nthat although state-of-the-art AI-powered detection and fix tools show promise,\nthey are not yet practical for real-world use due to a high rate of false\npositives and non-applicable fixes. User feedback reveals several actionable\npain points, ranging from incomplete context to lack of customization for the\nuser's codebase. Additionally, we explore how AI features, including confidence\nscores, explanations, and chat interaction, can apply to vulnerability\ndetection and fixing. Based on these insights, we offer practical\nrecommendations for evaluating and deploying AI detection and fix models. Our\ncode and data are available at https://doi.org/10.6084/m9.figshare.26367139.\n","authors":["Benjamin Steenhoek","Kalpathy Sivaraman","Renata Saldivar Gonzalez","Yevhen Mohylevskyy","Roshanak Zilouchian Moghaddam","Wei Le"],"pdf_url":"https://arxiv.org/pdf/2412.14306v2.pdf","comment":"Accepted to ICSE 2025 research track. Camera-ready version with\n  updated acknowledgments"},{"id":"http://arxiv.org/abs/2401.06889v2","updated":"2025-01-10T16:06:21Z","published":"2024-01-12T20:52:56Z","title":"Invisible Labor in Open Source Software Ecosystems","summary":"  Invisible labor is work that is either not fully visible or not appropriately\ncompensated. In open source software (OSS) ecosystems, essential tasks that do\nnot involve code (like content moderation) often become invisible to the\ndetriment of individuals and organizations. However, invisible labor is\nsufficiently difficult to measure that we do not know how much of OSS\nactivities are invisible. Our study addresses this challenge, demonstrating\nthat roughly half of OSS work is invisible. We do this by developing a\ncognitive anchoring survey technique that measures OSS developer\nself-assessments of labor visibility and attribution. Survey respondents\n(n=142) reported that their work is more likely to be invisible (2 in 3 tasks)\nthan visible, and that half (50.1%) is uncompensated. Priming participants with\nthe idea of visibility caused participants to think their work was more\nvisible, and that visibility was less important, than those primed with\ninvisibility. We also found evidence that tensions between attribution\nmotivations probably increase how common invisible labor is. This suggests that\nadvertising OSS activities as \"open\" may lead contributors to overestimate how\nvisible their labor actually is. Our findings suggest benefits to working with\nvaried stakeholders to make select, collectively valued activities visible, and\nincreasing compensation in valued forms (like attribution, opportunities, or\npay) when possible. This could improve fairness in software development while\nproviding greater transparency into work designs that help organizations and\ncommunities achieve their goals.\n","authors":["John Meluso","Amanda Casari","Katie McLaughlin","Milo Z. Trujillo"],"pdf_url":"https://arxiv.org/pdf/2401.06889v2.pdf","comment":"31 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2412.11698v2","updated":"2025-01-10T13:35:37Z","published":"2024-12-16T12:21:05Z","title":"On Large Language Models in Mission-Critical IT Governance: Are We Ready\n  Yet?","summary":"  Context. The security of critical infrastructure has been a pressing concern\nsince the advent of computers and has become even more critical in today's era\nof cyber warfare. Protecting mission-critical systems (MCSs), essential for\nnational security, requires swift and robust governance, yet recent events\nreveal the increasing difficulty of meeting these challenges. Aim. Building on\nprior research showcasing the potential of Generative AI (GAI), such as Large\nLanguage Models, in enhancing risk analysis, we aim to explore practitioners'\nviews on integrating GAI into the governance of IT MCSs. Our goal is to provide\nactionable insights and recommendations for stakeholders, including\nresearchers, practitioners, and policymakers. Method. We designed a survey to\ncollect practical experiences, concerns, and expectations of practitioners who\ndevelop and implement security solutions in the context of MCSs. Conclusions\nand Future Works. Our findings highlight that the safe use of LLMs in MCS\ngovernance requires interdisciplinary collaboration. Researchers should focus\non designing regulation-oriented models and focus on accountability;\npractitioners emphasize data protection and transparency, while policymakers\nmust establish a unified AI framework with global benchmarks to ensure ethical\nand secure LLMs-based MCS governance.\n","authors":["Matteo Esposito","Francesco Palagiano","Valentina Lenarduzzi","Davide Taibi"],"pdf_url":"https://arxiv.org/pdf/2412.11698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05899v1","updated":"2025-01-10T11:49:31Z","published":"2025-01-10T11:49:31Z","title":"Prompt engineering and its implications on the energy consumption of\n  Large Language Models","summary":"  Reducing the environmental impact of AI-based software systems has become\ncritical. The intensive use of large language models (LLMs) in software\nengineering poses severe challenges regarding computational resources, data\ncenters, and carbon emissions. In this paper, we investigate how prompt\nengineering techniques (PETs) can impact the carbon emission of the Llama 3\nmodel for the code generation task. We experimented with the CodeXGLUE\nbenchmark to evaluate both energy consumption and the accuracy of the generated\ncode using an isolated testing environment. Our initial results show that the\nenergy consumption of LLMs can be reduced by using specific tags that\ndistinguish different prompt parts. Even though a more in-depth evaluation is\nneeded to confirm our findings, this work suggests that prompt engineering can\nreduce LLMs' energy consumption during the inference phase without compromising\nperformance, paving the way for further investigations.\n","authors":["Riccardo Rubei","Aicha Moussaid","Claudio di Sipio","Davide di Ruscio"],"pdf_url":"https://arxiv.org/pdf/2501.05899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05811v1","updated":"2025-01-10T09:27:15Z","published":"2025-01-10T09:27:15Z","title":"MLKAPS: Machine Learning and Adaptive Sampling for HPC Kernel\n  Auto-tuning","summary":"  Many High-Performance Computing (HPC) libraries rely on decision trees to\nselect the best kernel hyperparameters at runtime,depending on the input and\nenvironment. However, finding optimized configurations for each input and\nenvironment is challengingand requires significant manual effort and\ncomputational resources. This paper presents MLKAPS, a tool that automates this\ntask usingmachine learning and adaptive sampling techniques. MLKAPS generates\ndecision trees that tune HPC kernels' design parameters toachieve efficient\nperformance for any user input. MLKAPS scales to large input and design spaces,\noutperforming similar state-of-the-artauto-tuning tools in tuning time and mean\nspeedup. We demonstrate the benefits of MLKAPS on the highly optimized Intel\nMKLdgetrf LU kernel and show that MLKAPS finds blindspots in the manual tuning\nof HPC experts. It improves over 85% of the inputswith a geomean speedup of\nx1.30. On the Intel MKL dgeqrf QR kernel, MLKAPS improves performance on 85% of\nthe inputs with ageomean speedup of x1.18.\n","authors":["Mathys Jam","Eric Petit","Pablo de Oliveira Castro","David Defour","Greg Henry","William Jalby"],"pdf_url":"https://arxiv.org/pdf/2501.05811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05792v1","updated":"2025-01-10T08:53:42Z","published":"2025-01-10T08:53:42Z","title":"Test Case Generation for Simulink Models: An Experience from the E-Bike\n  Domain","summary":"  Cyber-physical systems development often requires engineers to search for\ndefects in their Simulink models. Search-based software testing (SBST) is a\nstandard technology that supports this activity. To increase practical\nadaption, industries need empirical evidence of the effectiveness and\nefficiency of (existing) SBST techniques on benchmarks from different domains\nand of varying complexity. To address this industrial need, this paper presents\nour experience assessing the effectiveness and efficiency of SBST in generating\nfailure-revealing test cases for cyber-physical systems requirements. Our study\nsubject is within the electric bike (e-Bike) domain and concerns the software\ncontroller of an e-Bike motor, particularly its functional, regulatory, and\nsafety requirements. We assessed the effectiveness and efficiency of HECATE, an\nSBST framework for Simulink models, to analyze two software controllers. HECATE\nsuccessfully identified failure-revealing test cases for 83% (30 out of 36) of\nour experiments. It required, on average, 1 h 17 min 26 s (min = 11 min 56 s,\nmax = 8 h 16 min 22 s, std = 1 h 50 min 34 s) to compute the failure-revealing\ntest cases. The developer of the e-Bike model confirmed the failures identified\nby HECATE. We present the lessons learned and discuss the relevance of our\nresults for industrial applications, the state of practice improvement, and the\nresults' generalizability.\n","authors":["Michael Marzella","Andrea Bombarda","Marcello Minervini","Nunzio Marco Bisceglia","Angelo Gargantini","Claudio Menghi"],"pdf_url":"https://arxiv.org/pdf/2501.05792v1.pdf","comment":"10 pages, 2 pages for references"},{"id":"http://arxiv.org/abs/2501.05724v1","updated":"2025-01-10T05:43:36Z","published":"2025-01-10T05:43:36Z","title":"I Can't Share Code, but I need Translation -- An Empirical Study on Code\n  Translation through Federated LLM","summary":"  Owing to the rapid evolution of technologies and project requirements,\norganizations need to upgrade the code base in their software projects to a new\nversion of the programming language or even translating to an entirely new one.\nHowever, code translation is resource-intensive and requires expertise in both\nthe source and target languages. While researchers have made progress in\nautomating translations between legacy and modern languages, recent work has\nincreasingly turned to pre-trained Large Language Models (LLMs) to translate\nefficiently.\n  Given the proprietary nature of code, organizations prefer fine-tuning LLMs\nlocally rather than relying on external APIs. This is one of the first\nempirical studies that proposes a Federated LLM-based approach for code\ntranslation. The proposed approach enables clients to jointly train a code\ntranslator without sharing sensitive data. This study demonstrates that\nparticipants can collaboratively develop a FedLLM for efficient code\ntranslation (particularly C\\# to Java and vice-versa) with superior results\n(more than 40\\% improvement in CodeLLaMA's CodeBLEU score) compared to\nindividual client models. Our findings indicate that FedLLM offers a\ncollaborative approach to code translation and could serve as a promising\ndirection for future research in this field.\n","authors":["Jahnavi Kumar","Venkata Lakshmana Sasaank Janapati","Mokshith Reddy Tanguturi","Sridhar Chimalakonda"],"pdf_url":"https://arxiv.org/pdf/2501.05724v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2501.05706v1","updated":"2025-01-10T04:32:19Z","published":"2025-01-10T04:32:19Z","title":"Debugging Without Error Messages: How LLM Prompting Strategy Affects\n  Programming Error Explanation Effectiveness","summary":"  Making errors is part of the programming process -- even for the most\nseasoned professionals. Novices in particular are bound to make many errors\nwhile learning. It is well known that traditional (compiler/interpreter)\nprogramming error messages have been less than helpful for many novices and can\nhave effects such as being frustrating, containing confusing jargon, and being\ndownright misleading. Recent work has found that large language models (LLMs)\ncan generate excellent error explanations, but that the effectiveness of these\nerror messages heavily depends on whether the LLM has been provided with\ncontext -- typically the original source code where the problem occurred.\nKnowing that programming error messages can be misleading and/or contain that\nserves little-to-no use (particularly for novices) we explore the reverse: what\nhappens when GPT-3.5 is prompted for error explanations on just the erroneous\nsource code itself -- original compiler/interpreter produced error message\nexcluded. We utilized various strategies to make more effective error\nexplanations, including one-shot prompting and fine-tuning. We report the\nbaseline results of how effective the error explanations are at providing\nfeedback, as well as how various prompting strategies might improve the\nexplanations' effectiveness. Our results can help educators by understanding\nhow LLMs respond to such prompts that novices are bound to make, and hopefully\nlead to more effective use of Generative AI in the classroom.\n","authors":["Audrey Salmon","Katie Hammer","Eddie Antonio Santos","Brett A. Becker"],"pdf_url":"https://arxiv.org/pdf/2501.05706v1.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2411.12924v2","updated":"2025-01-10T03:55:57Z","published":"2024-11-19T23:22:33Z","title":"Human-In-the-Loop Software Development Agents","summary":"  Recently, Large Language Models (LLMs)-based multi-agent paradigms for\nsoftware engineering are introduced to automatically resolve software\ndevelopment tasks (e.g., from a given issue to source code). However, existing\nwork is evaluated based on historical benchmark datasets, rarely considers\nhuman feedback at each stage of the automated software development process, and\nhas not been deployed in practice. In this paper, we introduce a\nHuman-in-the-loop LLM-based Agents framework (HULA) for software development\nthat allows software engineers to refine and guide LLMs when generating coding\nplans and source code for a given task. We design, implement, and deploy the\nHULA framework into Atlassian JIRA for internal uses. Through a multi-stage\nevaluation of the HULA framework, Atlassian software engineers perceive that\nHULA can minimize the overall development time and effort, especially in\ninitiating a coding plan and writing code for straightforward tasks. On the\nother hand, challenges around code quality remain a concern in some cases. We\ndraw lessons learned and discuss opportunities for future work, which will pave\nthe way for the advancement of LLM-based agents in software development.\n","authors":["Wannita Takerngsaksiri","Jirat Pasuksmit","Patanamon Thongtanunam","Chakkrit Tantithamthavorn","Ruixiong Zhang","Fan Jiang","Jing Li","Evan Cook","Kun Chen","Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2411.12924v2.pdf","comment":"10 pages, 9 figures, ICSE SEIP 2025"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2501.06348v1","updated":"2025-01-10T21:20:11Z","published":"2025-01-10T21:20:11Z","title":"Why Automate This? Exploring the Connection between Time Use, Well-being\n  and Robot Automation Across Social Groups","summary":"  Understanding the motivations underlying the human inclination to automate\ntasks is vital to developing truly helpful robots integrated into daily life.\nAccordingly, we ask: are individuals more inclined to automate chores based on\nthe time they consume or the feelings experienced while performing them? This\nstudy explores these preferences and whether they vary across different social\ngroups (i.e., gender category and income level). Leveraging data from the\nBEHAVIOR-1K dataset, the American Time-Use Survey, and the American Time-Use\nSurvey Well-Being Module, we investigate the relationship between the desire\nfor automation, time spent on daily activities, and their associated feelings -\nHappiness, Meaningfulness, Sadness, Painfulness, Stressfulness, or Tiredness.\nOur key findings show that, despite common assumptions, time spent does not\nstrongly relate to the desire for automation for the general population. For\nthe feelings analyzed, only happiness and pain are key indicators. Significant\ndifferences by gender and economic level also emerged: Women prefer to automate\nstressful activities, whereas men prefer to automate those that make them\nunhappy; mid-income individuals prioritize automating less enjoyable and\nmeaningful activities, while low and high-income show no significant\ncorrelations. We hope our research helps motivate technologies to develop\nrobots that match the priorities of potential users, moving domestic robotics\ntoward more socially relevant solutions. We open-source all the data, including\nan online tool that enables the community to replicate our analysis and explore\nadditional trends at https://hri1260.github.io/why-automate-this.\n","authors":["Ruchira Ray","Leona Pang","Sanjana Srivastava","Li Fei-Fei","Samantha Shorey","Roberto Martín-Martín"],"pdf_url":"https://arxiv.org/pdf/2501.06348v1.pdf","comment":"20 pages, 14 figures"},{"id":"http://arxiv.org/abs/2501.06317v1","updated":"2025-01-10T19:39:06Z","published":"2025-01-10T19:39:06Z","title":"Understanding How Paper Writers Use AI-Generated Captions in Figure\n  Caption Writing","summary":"  Figures and their captions play a key role in scientific publications.\nHowever, despite their importance, many captions in published papers are poorly\ncrafted, largely due to a lack of attention by paper authors. While prior AI\nresearch has explored caption generation, it has mainly focused on\nreader-centered use cases, where users evaluate generated captions rather than\nactively integrating them into their writing. This paper addresses this gap by\ninvestigating how paper authors incorporate AI-generated captions into their\nwriting process through a user study involving 18 participants. Each\nparticipant rewrote captions for two figures from their own recently published\nwork, using captions generated by state-of-the-art AI models as a resource. By\nanalyzing video recordings of the writing process through interaction analysis,\nwe observed that participants often began by copying and refining AI-generated\ncaptions. Paper writers favored longer, detail-rich captions that integrated\ntextual and visual elements but found current AI models less effective for\ncomplex figures. These findings highlight the nuanced and diverse nature of\nfigure caption composition, revealing design opportunities for AI systems to\nbetter support the challenges of academic writing.\n","authors":["Ho Yin"," Ng","Ting-Yao Hsu","Jiyoo Min","Sungchul Kim","Ryan A. Rossi","Tong Yu","Hyunggu Jung","Ting-Hao 'Kenneth' Huang"],"pdf_url":"https://arxiv.org/pdf/2501.06317v1.pdf","comment":"This paper will appear at AAAI 2025 Workshop (2nd AI4Research\n  Workshop: Towards a Knowledge-grounded Scientific Research Lifecycle)"},{"id":"http://arxiv.org/abs/2412.06989v3","updated":"2025-01-10T19:05:56Z","published":"2024-12-09T20:55:54Z","title":"Learning About Algorithm Auditing in Five Steps: Scaffolding How High\n  School Youth Can Systematically and Critically Evaluate Machine Learning\n  Applications","summary":"  While there is widespread interest in supporting young people to critically\nevaluate machine learning-powered systems, there is little research on how we\ncan support them in inquiring about how these systems work and what their\nlimitations and implications may be. Outside of K-12 education, an effective\nstrategy in evaluating black-boxed systems is algorithm auditing-a method for\nunderstanding algorithmic systems' opaque inner workings and external impacts\nfrom the outside in. In this paper, we review how expert researchers conduct\nalgorithm audits and how end users engage in auditing practices to propose five\nsteps that, when incorporated into learning activities, can support young\npeople in auditing algorithms. We present a case study of a team of teenagers\nengaging with each step during an out-of-school workshop in which they audited\npeer-designed generative AI TikTok filters. We discuss the kind of scaffolds we\nprovided to support youth in algorithm auditing and directions and challenges\nfor integrating algorithm auditing into classroom activities. This paper\ncontributes: (a) a conceptualization of five steps to scaffold algorithm\nauditing learning activities, and (b) examples of how youth engaged with each\nstep during our pilot study.\n","authors":["Luis Morales-Navarro","Yasmin B. Kafai","Lauren Vogelstein","Evelyn Yu","Danaë Metaxa"],"pdf_url":"https://arxiv.org/pdf/2412.06989v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06177v1","updated":"2025-01-10T18:58:14Z","published":"2025-01-10T18:58:14Z","title":"ScooterLab: A Programmable and Participatory Sensing Research Testbed\n  using Micromobility Vehicles","summary":"  Micromobility vehicles, such as e-scooters, are increasingly popular in urban\ncommunities but present significant challenges in terms of road safety, user\nprivacy, infrastructure planning, and civil engineering. Addressing these\ncritical issues requires a large-scale and easily accessible research\ninfrastructure to collect diverse mobility and contextual data from\nmicromobility users in realistic settings. To this end, we present ScooterLab,\na community research testbed comprising a fleet of customizable battery-powered\nmicromobility vehicles retrofitted with advanced sensing, communication, and\ncontrol capabilities. ScooterLab enables interdisciplinary research at the\nintersection of computing, mobility, and urban planning by providing\nresearchers with tools to design and deploy customized sensing experiments and\naccess curated datasets. The testbed will enable advances in machine learning,\nprivacy, and urban transportation research while promoting sustainable\nmobility.\n","authors":["Ubaidullah Khan","Raveen Wijewickrama","Buddhi Ashan M. K.","A. H. M. Nazmus Sakib","Khoi Trinh","Christina Duthie","Nima Najafian","Ahmer Patel","R. N. Molina","Anindya Maiti","Sushil K. Prasad","Greg P. Griffin","Murtuza Jadliwala"],"pdf_url":"https://arxiv.org/pdf/2501.06177v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06073v1","updated":"2025-01-10T16:11:12Z","published":"2025-01-10T16:11:12Z","title":"The interplay of user preference and precision in different gaze-based\n  interaction methods","summary":"  In this study, we investigated gaze-based interaction methods within a\nvirtual reality game with a visual search task with 52 participants. We\ncompared four different interaction techniques: Selection by dwell time or\nconfirmation of selection by head orientation, nodding or smooth pursuit eye\nmovements. We evaluated both subjective and objective performance metrics,\nincluding NASA-TLX for subjective task load as well as time to find the correct\ntargets and points achieved for objective analysis. The results showed\nsignificant differences between the interaction methods in terms of NASA TLX\ndimensions, time to find the right targets, and overall performance scores,\nsuggesting differential effectiveness of gaze-based approaches in improving\nintuitive system communication. Interestingly, the results revealed\ngender-specific differences, suggesting interesting implications for the design\nof gaze-based interaction paradigms that are optimized for different user needs\nand preferences. These findings could help to develop more customized and\neffective gaze interaction systems that can improve accessibility and user\nsatisfaction.\n","authors":["Björn Rene Severitt","Yannick Sauer","Alexander Neugebauer","Rajat Agarwala","Nora Castner","Siegfried Wahl"],"pdf_url":"https://arxiv.org/pdf/2501.06073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06282v1","updated":"2025-01-10T15:55:27Z","published":"2025-01-10T15:55:27Z","title":"MinMo: A Multimodal Large Language Model for Seamless Voice Interaction","summary":"  Recent advancements in large language models (LLMs) and multimodal\nspeech-text models have laid the groundwork for seamless voice interactions,\nenabling real-time, natural, and human-like conversations. Previous models for\nvoice interactions are categorized as native and aligned. Native models\nintegrate speech and text processing in one framework but struggle with issues\nlike differing sequence lengths and insufficient pre-training. Aligned models\nmaintain text LLM capabilities but are often limited by small datasets and a\nnarrow focus on speech tasks. In this work, we introduce MinMo, a Multimodal\nLarge Language Model with approximately 8B parameters for seamless voice\ninteraction. We address the main limitations of prior aligned multimodal\nmodels. We train MinMo through multiple stages of speech-to-text alignment,\ntext-to-speech alignment, speech-to-speech alignment, and duplex interaction\nalignment, on 1.4 million hours of diverse speech data and a broad range of\nspeech tasks. After the multi-stage training, MinMo achieves state-of-the-art\nperformance across various benchmarks for voice comprehension and generation\nwhile maintaining the capabilities of text LLMs, and also facilitates\nfull-duplex conversation, that is, simultaneous two-way communication between\nthe user and the system. Moreover, we propose a novel and simple voice decoder\nthat outperforms prior models in voice generation. The enhanced\ninstruction-following capabilities of MinMo supports controlling speech\ngeneration based on user instructions, with various nuances including emotions,\ndialects, and speaking rates, and mimicking specific voices. For MinMo, the\nspeech-to-text latency is approximately 100ms, full-duplex latency is\napproximately 600ms in theory and 800ms in practice. The MinMo project web page\nis https://funaudiollm.github.io/minmo, and the code and models will be\nreleased soon.\n","authors":["Qian Chen","Yafeng Chen","Yanni Chen","Mengzhe Chen","Yingda Chen","Chong Deng","Zhihao Du","Ruize Gao","Changfeng Gao","Zhifu Gao","Yabin Li","Xiang Lv","Jiaqing Liu","Haoneng Luo","Bin Ma","Chongjia Ni","Xian Shi","Jialong Tang","Hui Wang","Hao Wang","Wen Wang","Yuxuan Wang","Yunlan Xu","Fan Yu","Zhijie Yan","Yexin Yang","Baosong Yang","Xian Yang","Guanrou Yang","Tianyu Zhao","Qinglin Zhang","Shiliang Zhang","Nan Zhao","Pei Zhang","Chong Zhang","Jinren Zhou"],"pdf_url":"https://arxiv.org/pdf/2501.06282v1.pdf","comment":"Work in progress. Authors are listed in alphabetical order by family\n  name"},{"id":"http://arxiv.org/abs/2406.11136v2","updated":"2025-01-10T15:53:00Z","published":"2024-06-17T01:47:11Z","title":"Robots in Family Routines: Development of and Initial Insights from the\n  Family-Robot Routines Inventory","summary":"  Despite advances in areas such as the personalization of robots, sustaining\nadoption of robots for long-term use in families remains a challenge. Recent\nstudies have identified integrating robots into families' routines and rituals\nas a promising approach to support long-term adoption. However, few studies\nexplored the integration of robots into family routines and there is a gap in\nsystematic measures to capture family preferences for robot integration.\nBuilding upon existing routine inventories, we developed Family-Robot Routines\nInventory (FRRI), with 24 family routines and 24 child routine items, to\ncapture parents' attitudes toward and expectations from the integration of\nrobotic technology into their family routines. Using this inventory, we\ncollected data from 150 parents through an online survey. Our analysis\nindicates that parents had varying perceptions for the utility of integrating\nrobots into their routines. For example, parents found robot integration to be\nmore helpful in children's individual routines, than to the collective routines\nof their families. We discuss the design implications of these preliminary\nfindings, and how they may serve as a first step toward understanding the\ndiverse challenges and demands of designing and integrating household robots\nfor families.\n","authors":["Michael F. Xu","Bengisu Cagiltay","Joseph Michaelis","Sarah Sebo","Bilge Mutlu"],"pdf_url":"https://arxiv.org/pdf/2406.11136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04860v2","updated":"2025-01-10T15:47:19Z","published":"2025-01-08T22:22:15Z","title":"Exploring the Use of Robots for Diary Studies","summary":"  As interest in studying in-the-wild human-robot interaction grows, there is a\nneed for methods to collect data over time and in naturalistic or potentially\nprivate environments. HRI researchers have increasingly used the diary method\nfor these studies, asking study participants to self-administer a structured\ndata collection instrument, i.e., a diary, over a period of time. Although the\ndiary method offers a unique window into settings that researchers may not have\naccess to, they also lack the interactivity and probing that interview-based\nmethods offer. In this paper, we explore a novel data collection method in\nwhich a robot plays the role of an interactive diary. We developed the Diary\nRobot system and performed in-home deployments for a week to evaluate the\nfeasibility and effectiveness of this approach. Using traditional text-based\nand audio-based diaries as benchmarks, we found that robots are able to\neffectively elicit the intended information. We reflect on our findings, and\ndescribe scenarios where the utilization of robots in diary studies as a data\ncollection instrument may be especially applicable.\n","authors":["Michael F. Xu","Bilge Mutlu"],"pdf_url":"https://arxiv.org/pdf/2501.04860v2.pdf","comment":"Proceedings of the 20th ACM/IEEE International Conference on Human\n  Robot Interaction (HRI 2025)"},{"id":"http://arxiv.org/abs/2501.05985v1","updated":"2025-01-10T14:17:48Z","published":"2025-01-10T14:17:48Z","title":"Exploring LLMs for Automated Pre-Testing of Cross-Cultural Surveys","summary":"  Designing culturally relevant questionnaires for ICTD research is\nchallenging, particularly when adapting surveys for populations to non-western\ncontexts. Prior work adapted questionnaires through expert reviews and pilot\nstudies, which are resource-intensive and time-consuming. To address these\nchallenges, we propose using large language models (LLMs) to automate the\nquestionnaire pretesting process in cross-cultural settings. Our study used\nLLMs to adapt a U.S.-focused climate opinion survey for a South African\naudience. We then tested the adapted questionnaire with 116 South African\nparticipants via Prolific, asking them to provide feedback on both versions.\nParticipants perceived the LLM-adapted questions as slightly more favorable\nthan the traditional version. Our note opens discussions on the potential role\nof LLMs in adapting surveys and facilitating cross-cultural questionnaire\ndesign.\n","authors":["Divya Mani Adhikari","Vikram Kamath Cannanure","Alexander Hartland","Ingmar Weber"],"pdf_url":"https://arxiv.org/pdf/2501.05985v1.pdf","comment":"Accepted to ICTD 2024 (Notes)"},{"id":"http://arxiv.org/abs/2412.14776v2","updated":"2025-01-10T12:39:47Z","published":"2024-12-19T12:02:47Z","title":"Collaborative Problem Solving in Mixed Reality: A Study on Visual Graph\n  Analysis","summary":"  Problem solving is a composite cognitive process, invoking a number of\nsystems and subsystems, such as perception and memory. Individuals may form\ncollectives to solve a given problem together, in collaboration, especially\nwhen complexity is thought to be high. To determine if and when collaborative\nproblem solving is desired, we must quantify collaboration first. For this, we\ninvestigate the practical virtue of collaborative problem solving. Using visual\ngraph analysis, we perform a study with 72 participants in two countries and\nthree languages. We compare ad hoc pairs to individuals and nominal pairs,\nsolving two different tasks on graphs in visuospatial mixed reality. The\naverage collaborating pair does not outdo its nominal counterpart, but it does\nhave a significant trade-off against the individual: an ad hoc pair uses 1.46\nmore time to achieve 4.6 higher accuracy. We also use the concept of task\ninstance complexity to quantify differences in complexity. As task instance\ncomplexity increases, these differences largely scale, though with two notable\nexceptions. With this study we show the importance of using nominal groups as\nbenchmark in collaborative virtual environments research. We conclude that a\nmixed reality environment does not automatically imply superior collaboration.\n","authors":["Dimitar Garkov","Tommaso Piselli","Emilio Di Giacomo","Karsten Klein","Giuseppe Liotta","Fabrizio Montecchiani","Falk Schreiber"],"pdf_url":"https://arxiv.org/pdf/2412.14776v2.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2501.03968v2","updated":"2025-01-10T10:38:49Z","published":"2025-01-07T18:06:27Z","title":"VLM-driven Behavior Tree for Context-aware Task Planning","summary":"  The use of Large Language Models (LLMs) for generating Behavior Trees (BTs)\nhas recently gained attention in the robotics community, yet remains in its\nearly stages of development. In this paper, we propose a novel framework that\nleverages Vision-Language Models (VLMs) to interactively generate and edit BTs\nthat address visual conditions, enabling context-aware robot operations in\nvisually complex environments. A key feature of our approach lies in the\nconditional control through self-prompted visual conditions. Specifically, the\nVLM generates BTs with visual condition nodes, where conditions are expressed\nas free-form text. Another VLM process integrates the text into its prompt and\nevaluates the conditions against real-world images during robot execution. We\nvalidated our framework in a real-world cafe scenario, demonstrating both its\nfeasibility and limitations.\n","authors":["Naoki Wake","Atsushi Kanehira","Jun Takamatsu","Kazuhiro Sasabuchi","Katsushi Ikeuchi"],"pdf_url":"https://arxiv.org/pdf/2501.03968v2.pdf","comment":"10 pages, 11 figures, 5 tables. Last updated on January 9th, 2024"},{"id":"http://arxiv.org/abs/2501.05840v1","updated":"2025-01-10T10:29:27Z","published":"2025-01-10T10:29:27Z","title":"Applying Think-Aloud in ICTD: A Case Study of a Chatbot Use by Teachers\n  in Rural Côte d'Ivoire","summary":"  Think-alouds are a common HCI usability method where participants verbalize\ntheir thoughts while using interfaces. However, their utility in cross-cultural\nsettings, particularly in the Global South, is unclear, where cultural\ndifferences impact user interactions. This paper investigates the usability\nchallenges teachers in rural C\\^ote d'Ivoire faced when using a chatbot\ndesigned to support an educational program. We conducted think-aloud sessions\nwith 20 teachers two weeks after a chatbot deployment, analyzing their\nnavigation, errors, and time spent on tasks. We discuss our approach and\nfindings that helped us identify usability issues and challenging features for\nimproving the chatbot designs. Our note summarizes our reflections on using\nthink-aloud and contributes to discussions on its culturally sensitive\nadaptation in the Global South.\n","authors":["Vikram Kamath Cannanure","Sharon Wolf","Kaja Jasińska","Timothy X Brown","Amy Ogan"],"pdf_url":"https://arxiv.org/pdf/2501.05840v1.pdf","comment":"ICTD 24, Notes track. International Conference on Information &\n  Communication Technologies and Development 2024"},{"id":"http://arxiv.org/abs/2501.05790v1","updated":"2025-01-10T08:50:38Z","published":"2025-01-10T08:50:38Z","title":"Understanding Impact of Human Feedback via Influence Functions","summary":"  In Reinforcement Learning from Human Feedback (RLHF), it is crucial to learn\nsuitable reward models from human feedback to align large language models\n(LLMs) with human intentions. However, human feedback can often be noisy,\ninconsistent, or biased, especially when evaluating complex responses. Such\nfeedback can lead to misaligned reward signals, potentially causing unintended\nside effects during the RLHF process. To address these challenges, we explore\nthe use of influence functions to measure the impact of human feedback on the\nperformance of reward models. We propose a compute-efficient approximation\nmethod that enables the application of influence functions to LLM-based reward\nmodels and large-scale preference datasets. In our experiments, we demonstrate\ntwo key applications of influence functions: (1) detecting common forms of\nlabeler bias in human feedback datasets and (2) guiding labelers to refine\ntheir strategies to align more closely with expert feedback. By quantifying the\nimpact of human feedback on reward models, we believe that influence functions\ncan enhance feedback interpretability and contribute to scalable oversight in\nRLHF, helping labelers provide more accurate and consistent feedback. Source\ncode is available at https://github.com/mintaywon/IF_RLHF\n","authors":["Taywon Min","Haeone Lee","Hanho Ryu","Yongchan Kwon","Kimin Lee"],"pdf_url":"https://arxiv.org/pdf/2501.05790v1.pdf","comment":"Source code: https://github.com/mintaywon/IF_RLHF"},{"id":"http://arxiv.org/abs/2501.05714v1","updated":"2025-01-10T05:15:14Z","published":"2025-01-10T05:15:14Z","title":"How to Enable Effective Cooperation Between Humans and NLP Models: A\n  Survey of Principles, Formalizations, and Beyond","summary":"  With the advancement of large language models (LLMs), intelligent models have\nevolved from mere tools to autonomous agents with their own goals and\nstrategies for cooperating with humans. This evolution has birthed a novel\nparadigm in NLP, i.e., human-model cooperation, that has yielded remarkable\nprogress in numerous NLP tasks in recent years. In this paper, we take the\nfirst step to present a thorough review of human-model cooperation, exploring\nits principles, formalizations, and open challenges. In particular, we\nintroduce a new taxonomy that provides a unified perspective to summarize\nexisting approaches. Also, we discuss potential frontier areas and their\ncorresponding challenges. We regard our work as an entry point, paving the way\nfor more breakthrough research in this regard.\n","authors":["Chen Huang","Yang Deng","Wenqiang Lei","Jiancheng Lv","Tat-Seng Chua","Jimmy Xiangji Huang"],"pdf_url":"https://arxiv.org/pdf/2501.05714v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2501.05706v1","updated":"2025-01-10T04:32:19Z","published":"2025-01-10T04:32:19Z","title":"Debugging Without Error Messages: How LLM Prompting Strategy Affects\n  Programming Error Explanation Effectiveness","summary":"  Making errors is part of the programming process -- even for the most\nseasoned professionals. Novices in particular are bound to make many errors\nwhile learning. It is well known that traditional (compiler/interpreter)\nprogramming error messages have been less than helpful for many novices and can\nhave effects such as being frustrating, containing confusing jargon, and being\ndownright misleading. Recent work has found that large language models (LLMs)\ncan generate excellent error explanations, but that the effectiveness of these\nerror messages heavily depends on whether the LLM has been provided with\ncontext -- typically the original source code where the problem occurred.\nKnowing that programming error messages can be misleading and/or contain that\nserves little-to-no use (particularly for novices) we explore the reverse: what\nhappens when GPT-3.5 is prompted for error explanations on just the erroneous\nsource code itself -- original compiler/interpreter produced error message\nexcluded. We utilized various strategies to make more effective error\nexplanations, including one-shot prompting and fine-tuning. We report the\nbaseline results of how effective the error explanations are at providing\nfeedback, as well as how various prompting strategies might improve the\nexplanations' effectiveness. Our results can help educators by understanding\nhow LLMs respond to such prompts that novices are bound to make, and hopefully\nlead to more effective use of Generative AI in the classroom.\n","authors":["Audrey Salmon","Katie Hammer","Eddie Antonio Santos","Brett A. Becker"],"pdf_url":"https://arxiv.org/pdf/2501.05706v1.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2501.05703v1","updated":"2025-01-10T04:22:31Z","published":"2025-01-10T04:22:31Z","title":"Visualization Tool: Exploring COVID-19 Data","summary":"  The ability to effectively visualize data is crucial in the contemporary\nworld where information is often voluminous and complex. Visualizations, such\nas charts, graphs, and maps, provide an intuitive and easily understandable\nmeans to interpret, analyze, and communicate patterns, trends, and insights\nhidden within large datasets. These graphical representations can help\nresearchers, policymakers, and the public to better comprehend and respond to a\nmultitude of issues. In this study, we explore a visualization tool to\ninterpret and understand various data of COVID-19 pandemic. While others have\nshown COVID-19 visualization methods/tools, our tool provides a mean to analyze\nCOVID-19 data in a more comprehensive way. We have used the public data from NY\nTimes and CDC, and various COVID-19 data (e.g., core places, patterns, foot\ntraffic) from Safegraph. Figure 1 shows the basic view of our visualization\nview. In addition to providing visualizations of these data, our visualization\nalso considered the Surprising Map. The Surprising Map is a type of choropleth\nmap that can avoid misleading of producing visual prominence to known base\nrates or to artifacts of sample size and normalization in visualizing the\ndensity of events in spatial data. It is based on Bayesian surprise-it creates\na space of equi-plausible models and uses Bayesian updating to re-estimate\ntheir plausibility based on individual events.\n","authors":["Dong Hyun Jeon","Jong Kwan Lee","Prabal Dhaubhadel","Aaron Kuhlman"],"pdf_url":"https://arxiv.org/pdf/2501.05703v1.pdf","comment":"Published in ISIITA 2024"},{"id":"http://arxiv.org/abs/2411.12924v2","updated":"2025-01-10T03:55:57Z","published":"2024-11-19T23:22:33Z","title":"Human-In-the-Loop Software Development Agents","summary":"  Recently, Large Language Models (LLMs)-based multi-agent paradigms for\nsoftware engineering are introduced to automatically resolve software\ndevelopment tasks (e.g., from a given issue to source code). However, existing\nwork is evaluated based on historical benchmark datasets, rarely considers\nhuman feedback at each stage of the automated software development process, and\nhas not been deployed in practice. In this paper, we introduce a\nHuman-in-the-loop LLM-based Agents framework (HULA) for software development\nthat allows software engineers to refine and guide LLMs when generating coding\nplans and source code for a given task. We design, implement, and deploy the\nHULA framework into Atlassian JIRA for internal uses. Through a multi-stage\nevaluation of the HULA framework, Atlassian software engineers perceive that\nHULA can minimize the overall development time and effort, especially in\ninitiating a coding plan and writing code for straightforward tasks. On the\nother hand, challenges around code quality remain a concern in some cases. We\ndraw lessons learned and discuss opportunities for future work, which will pave\nthe way for the advancement of LLM-based agents in software development.\n","authors":["Wannita Takerngsaksiri","Jirat Pasuksmit","Patanamon Thongtanunam","Chakkrit Tantithamthavorn","Ruixiong Zhang","Fan Jiang","Jing Li","Evan Cook","Kun Chen","Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2411.12924v2.pdf","comment":"10 pages, 9 figures, ICSE SEIP 2025"},{"id":"http://arxiv.org/abs/2501.05674v1","updated":"2025-01-10T02:53:24Z","published":"2025-01-10T02:53:24Z","title":"Balancing Sleep and Study: Cultural Contexts in Family Informatics for\n  Taiwanese Parents and Children","summary":"  This study examines the intersection of academic pressure and sleep within\nTaiwanese families, revealing how cultural norms and expectations shape sleep\npractices. Through interviews and two-week diaries from eleven families, we\nfound that academic demands significantly influence children's sleep patterns,\nleading to reduced sleep duration and varied sleep schedules. Our research\nhighlights the importance of integrating care and attuning into the design of\nsleep-tracking technologies, advocating for a family informatics approach that\nconsiders both health needs and social expectations. By exploring these\ndynamics, we contribute to a broader understanding of family contexts in\ndiverse cultural settings and offer insights for more inclusive technology\ndesign.\n","authors":["Yang Hong","Ru-Yun Tseng","Ying-Yu Chen"],"pdf_url":"https://arxiv.org/pdf/2501.05674v1.pdf","comment":"20 pages, 2 figures, ACM GROUP 2025"},{"id":"http://arxiv.org/abs/2501.05664v1","updated":"2025-01-10T02:31:09Z","published":"2025-01-10T02:31:09Z","title":"ExoFabric: A Re-moldable Textile System for Creating Customizable Soft\n  Goods and Wearable Applications","summary":"  Fabric has been a fundamental part of human life for thousands of years,\nproviding comfort, protection, and aesthetic expression. While modern\nadvancements have enhanced fabric's functionality, it remains static and\nunchangeable, failing to adapt to our evolving body shapes and preferences.\nThis lack of adaptability can lead to unsustainable practices, as consumers\noften buy more items to meet their changing needs. In this paper, we propose\nExoFabric, a re-moldable fabric system for customized soft goods applications.\nWe created ExoFabric by embedding thermoplastic threads into fabric through\ncomputerized embroidery to allow for tunability between rigid plastic and\nconformable fabric. We defined a library of design primitives to enable\ngeometric formability, stiffness, and stretchability by identifying suitable\nfabrics, threads, embroidery parameters, and machine limitations. To facilitate\npractical applications, we demonstrated practical methods for linking\nparameters to application requirements, showcasing form-fitting wearables,\nstructural support, and shape-changeable furniture for repeatable or one-time\ncustomization.\n","authors":["Rosalie Lin","Aditi Maheshwari","Jung Wook Park","Andreea Danielescu"],"pdf_url":"https://arxiv.org/pdf/2501.05664v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2501.05628v1","updated":"2025-01-10T00:08:37Z","published":"2025-01-10T00:08:37Z","title":"Concerns and Values in Human-Robot Interactions: A Focus on Social\n  Robotics","summary":"  Robots, as AI with physical instantiation, inhabit our social and physical\nworld, where their actions have both social and physical consequences, posing\nchallenges for researchers when designing social robots. This study starts with\na scoping review to identify discussions and potential concerns arising from\ninteractions with robotic systems. Two focus groups of technology ethics\nexperts then validated a comprehensive list of key topics and values in\nhuman-robot interaction (HRI) literature. These insights were integrated into\nthe HRI Value Compass web tool, to help HRI researchers identify ethical values\nin robot design. The tool was evaluated in a pilot study. This work benefits\nthe HRI community by highlighting key concerns in human-robot interactions and\nproviding an instrument to help researchers design robots that align with human\nvalues, ensuring future robotic systems adhere to these values in social\napplications.\n","authors":["Giulio Antonio Abbo","Tony Belpaeme","Micol Spitale"],"pdf_url":"https://arxiv.org/pdf/2501.05628v1.pdf","comment":"52 pages, 10 figures, 5 appendices"}]},"2025-01-09T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2501.05625v1","updated":"2025-01-09T23:48:03Z","published":"2025-01-09T23:48:03Z","title":"Harnessing Large Language Model for Virtual Reality Exploration Testing:\n  A Case Study","summary":"  As the Virtual Reality (VR) industry expands, the need for automated GUI\ntesting is growing rapidly. Large Language Models (LLMs), capable of retaining\ninformation long-term and analyzing both visual and textual data, are emerging\nas a potential key to deciphering the complexities of VR's evolving user\ninterfaces. In this paper, we conduct a case study to investigate the\ncapability of using LLMs, particularly GPT-4o, for field of view (FOV) analysis\nin VR exploration testing. Specifically, we validate that LLMs can identify\ntest entities in FOVs and that prompt engineering can effectively enhance the\naccuracy of test entity identification from 41.67% to 71.30%. Our study also\nshows that LLMs can accurately describe identified entities' features with at\nleast a 90% correction rate. We further find out that the core features that\neffectively represent an entity are color, placement, and shape. Furthermore,\nthe combination of the three features can especially be used to improve the\naccuracy of determining identical entities in multiple FOVs with the highest\nF1-score of 0.70. Additionally, our study demonstrates that LLMs are capable of\nscene recognition and spatial understanding in VR with precisely designed\nstructured prompts. Finally, we find that LLMs fail to label the identified\ntest entities, and we discuss potential solutions as future research\ndirections.\n","authors":["Zhenyu Qi","Haotang Li","Hao Qin","Kebin Peng","Sen He","Xue Qin"],"pdf_url":"https://arxiv.org/pdf/2501.05625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.05239v3","updated":"2025-01-09T19:12:14Z","published":"2023-08-09T21:54:34Z","title":"Enhancing Architecture Frameworks by Including Modern Stakeholders and\n  their Views/Viewpoints","summary":"  Various architecture frameworks for software, systems, and enterprises have\nbeen proposed in the literature. They identified several stakeholders and\ndefined modeling perspectives, architecture viewpoints, and views to frame and\naddress stakeholder concerns. However, the stakeholders with data science and\nMachine Learning (ML) related concerns, such as data scientists and data\nengineers, are yet to be included in existing architecture frameworks. Only\nthis way can we envision a holistic system architecture description of an\nML-enabled system. Note that the ML component behavior and functionalities are\nspecial and should be distinguished from traditional software system behavior\nand functionalities. The main reason is that the actual functionality should be\ninferred from data instead of being specified at design time. Additionally, the\nstructural models of ML components, such as ML model architectures, are\ntypically specified using different notations and formalisms from what the\nSoftware Engineering (SE) community uses for software structural models. Yet,\nthese two aspects, namely ML and non-ML, are becoming so intertwined that it\nnecessitates an extension of software architecture frameworks and modeling\npractices toward supporting ML-enabled system architectures. In this paper, we\naddress this gap through an empirical study using an online survey instrument.\nWe surveyed 61 subject matter experts from over 25 organizations in 10\ncountries.\n","authors":["Armin Moin","Atta Badii","Stephan Günnemann","Moharram Challenger"],"pdf_url":"https://arxiv.org/pdf/2308.05239v3.pdf","comment":"ICICT 2025"},{"id":"http://arxiv.org/abs/2501.05412v1","updated":"2025-01-09T18:13:22Z","published":"2025-01-09T18:13:22Z","title":"Search-based Testing of Simulink Models with Requirements Tables","summary":"  Search-based software testing (SBST) of Simulink models helps find scenarios\nthat demonstrate that the system can reach a state that violates one of its\nrequirements. However, many SBST techniques for Simulink models rely on\nrequirements being expressed in logical languages, limiting their adoption in\nindustry. To help with the adoption, SBST methods and tools for Simulink models\nneed to be integrated with tools used by engineers to specify requirements.\nThis work presents the first black-box testing approach for Simulink models\nthat supports Requirements Table (RT), a tool from Simulink Requirements\nToolbox used by practitioners to express software requirements.\n  We evaluated our solution by considering 60 model-RT combinations each made\nby a model and an RT. Our SBST framework returned a failure-revealing test case\nfor 70% of the model-RT combinations. Remarkably, it identified a\nfailure-revealing test case for three model-RT combinations for a cruise\ncontroller of an industrial simulator that other previously used tools were not\nable to find. The efficiency of our SBST solution is acceptable for practical\napplications and comparable with existing SBST tools that are not based on RT.\n","authors":["Federico Formica","Chris George","Shayda Rahmatyan","Vera Pantelic","Mark Lawford","Angelo Gargantini","Claudio Menghi"],"pdf_url":"https://arxiv.org/pdf/2501.05412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05396v1","updated":"2025-01-09T17:42:23Z","published":"2025-01-09T17:42:23Z","title":"FairCode: Evaluating Social Bias of LLMs in Code Generation","summary":"  Large language models (LLMs) have demonstrated significant capability in code\ngeneration, drawing increasing attention to the evaluation of the quality and\nsafety of their outputs. However, research on bias in code generation remains\nlimited. Existing studies typically assess bias by applying malicious prompts\nor reapply tasks and dataset for discriminative models. Given that LLMs are\noften aligned with human values and that prior datasets are not fully optimized\nfor code-related tasks, there is a pressing need for benchmarks specifically\ndesigned for evaluating code models. In this study, we introduce FairCode, a\nnovel benchmark for evaluating bias in code generation. FairCode comprises two\ntasks: function implementation and test case generation, each evaluating social\nbias through diverse scenarios. Additionally, we propose a new metric,\nFairScore, to assess model performance on this benchmark. We conduct\nexperiments on widely used LLMs and provide a comprehensive analysis of the\nresults. The findings reveal that all tested LLMs exhibit bias. The code is\navailable at https://github.com/YongkDu/FairCode.\n","authors":["Yongkang Du","Jen-tse Huang","Jieyu Zhao","Lu Lin"],"pdf_url":"https://arxiv.org/pdf/2501.05396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02490v3","updated":"2025-01-09T17:09:18Z","published":"2024-05-03T21:45:48Z","title":"Software Fairness Debt","summary":"  As software systems continue to play a significant role in modern society,\nensuring their fairness has become a critical concern in software engineering.\nMotivated by this scenario, this paper focused on exploring the multifaceted\nnature of bias in software systems, aiming to provide a comprehensive\nunderstanding of its origins, manifestations, and impacts. Through a scoping\nstudy, we identified the primary causes of fairness deficiency in software\ndevelopment and highlighted their adverse effects on individuals and\ncommunities, including instances of discrimination and the perpetuation of\ninequalities. Our investigation culminated in the introduction of the concept\nof software fairness debt, which complements the notions of technical and\nsocial debt, encapsulating the accumulation of biases in software engineering\npractices while emphasizing the societal ramifications of bias embedded within\nsoftware systems. Our study contributes to a deeper understanding of fairness\nin software engineering and paves the way for the development of more equitable\nand socially responsible software systems.\n","authors":["Ronnie de Souza Santos","Felipe Fronchetti","Savio Freire","Rodrigo Spinola"],"pdf_url":"https://arxiv.org/pdf/2405.02490v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19528v3","updated":"2025-01-09T15:12:04Z","published":"2024-10-25T12:53:33Z","title":"AgentForge: A Flexible Low-Code Platform for Reinforcement Learning\n  Agent Design","summary":"  Developing a reinforcement learning (RL) agent often involves identifying\nvalues for numerous parameters, covering the policy, reward function,\nenvironment, and agent-internal architecture. Since these parameters are\ninterrelated in complex ways, optimizing them is a black-box problem that\nproves especially challenging for nonexperts. Although existing\noptimization-as-a-service platforms (e.g., Vizier and Optuna) can handle such\nproblems, they are impractical for RL systems, since the need for manual user\nmapping of each parameter to distinct components makes the effort cumbersome.\nIt also requires understanding of the optimization process, limiting the\nsystems' application beyond the machine learning field and restricting access\nin areas such as cognitive science, which models human decision-making. To\ntackle these challenges, the paper presents AgentForge, a flexible low-code\nplatform to optimize any parameter set across an RL system. Available at\nhttps://github.com/feferna/AgentForge, it allows an optimization problem to be\ndefined in a few lines of code and handed to any of the interfaced optimizers.\nWith AgentForge, the user can optimize the parameters either individually or\njointly. The paper presents an evaluation of its performance for a challenging\nvision-based RL problem.\n","authors":["Francisco Erivaldo Fernandes Junior","Antti Oulasvirta"],"pdf_url":"https://arxiv.org/pdf/2410.19528v3.pdf","comment":"This paper has been accepted at the 17th International Conference on\n  Agents and Artificial Intelligence (ICAART 2025)"},{"id":"http://arxiv.org/abs/2501.05258v1","updated":"2025-01-09T14:13:39Z","published":"2025-01-09T14:13:39Z","title":"Automating the Detection of Code Vulnerabilities by Analyzing GitHub\n  Issues","summary":"  In today's digital landscape, the importance of timely and accurate\nvulnerability detection has significantly increased. This paper presents a\nnovel approach that leverages transformer-based models and machine learning\ntechniques to automate the identification of software vulnerabilities by\nanalyzing GitHub issues. We introduce a new dataset specifically designed for\nclassifying GitHub issues relevant to vulnerability detection. We then examine\nvarious classification techniques to determine their effectiveness. The results\ndemonstrate the potential of this approach for real-world application in early\nvulnerability detection, which could substantially reduce the window of\nexploitation for software vulnerabilities. This research makes a key\ncontribution to the field by providing a scalable and computationally efficient\nframework for automated detection, enabling the prevention of compromised\nsoftware usage before official notifications. This work has the potential to\nenhance the security of open-source software ecosystems.\n","authors":["Daniele Cipollone","Changjie Wang","Mariano Scazzariello","Simone Ferlin","Maliheh Izadi","Dejan Kostic","Marco Chiesa"],"pdf_url":"https://arxiv.org/pdf/2501.05258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05255v1","updated":"2025-01-09T14:12:43Z","published":"2025-01-09T14:12:43Z","title":"CallNavi: A Study and Challenge on Function Calling Routing and\n  Invocation in Large Language Models","summary":"  Interacting with a software system via a chatbot can be challenging,\nespecially when the chatbot needs to generate API calls, in the right order and\nwith the right parameters, to communicate with the system. API calling in\nchatbot systems poses significant challenges, particularly in complex,\nmulti-step tasks requiring accurate API selection and execution. We contribute\nto this domain in three ways: first, by introducing a novel dataset designed to\nassess models on API function selection, parameter generation, and nested API\ncalls; second, by benchmarking state-of-the-art language models across varying\nlevels of complexity to evaluate their performance in API function generation\nand parameter accuracy; and third, by proposing an enhanced API routing method\nthat combines general-purpose large language models for API selection with\nfine-tuned models for parameter generation and some prompt engineering\napproach. These approaches lead to substantial improvements in handling complex\nAPI tasks, offering practical advancements for real-world API-driven chatbot\nsystems.\n","authors":["Yewei Song","Cedric Lothritz","Xunzhu Tang","Saad Ezzini","Jacques Klein","Tegawendé F. Bissyandé","Andrey Boytsov","Ulrick Ble","Anne Goujon"],"pdf_url":"https://arxiv.org/pdf/2501.05255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05252v1","updated":"2025-01-09T14:03:35Z","published":"2025-01-09T14:03:35Z","title":"From Scientific Texts to Verifiable Code: Automating the Process with\n  Transformers","summary":"  Despite the vast body of research literature proposing algorithms with formal\nguarantees, the amount of verifiable code in today's systems remains minimal.\nThis discrepancy stems from the inherent difficulty of verifying code,\nparticularly due to the time-consuming nature and strict formalism of proof\ndetails that formal verification tools require. However, the emergence of\ntransformers in Large Language Models presents a promising solution to this\nchallenge. In this position paper, we believe that transformers have the\npotential to read research papers that propose algorithms with formal proofs\nand translate these proofs into verifiable code. We leverage transformers to\nfirst build a formal structure of the proof using the original text from the\npaper, and then to handle the tedious, low-level aspects of proofs that are\noften omitted by humans. We argue that this approach can significantly reduce\nthe barrier to formal verification. The above idea of reading papers to write\nverifiable code opens new avenues for automating the verification of complex\nsystems, enabling a future where formally verified algorithms from academic\nresearch can more seamlessly transition into real-world software systems,\nthereby improving code reliability and security.\n","authors":["Changjie Wang","Mariano Scazzariello","Marco Chiesa"],"pdf_url":"https://arxiv.org/pdf/2501.05252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05248v1","updated":"2025-01-09T14:00:01Z","published":"2025-01-09T14:00:01Z","title":"Deriving Coding-Specific Sub-Models from LLMs using Resource-Efficient\n  Pruning","summary":"  Large Language Models (LLMs) have demonstrated their exceptional performance\nin various complex code generation tasks. However, their broader adoption is\nlimited by significant computational demands and high resource requirements,\nparticularly memory and processing power. To mitigate such requirements, model\npruning techniques are used to create more compact models with significantly\nfewer parameters. However, current approaches do not focus on the efficient\nextraction of programming-language-specific sub-models. In this work, we\nexplore the idea of efficiently deriving coding-specific sub-models through\nunstructured pruning (i.e., Wanda). We investigate the impact of different\ndomain-specific calibration datasets on pruning outcomes across three distinct\ndomains and extend our analysis to extracting four language-specific\nsub-models: Python, Java, C++, and JavaScript. We are the first to efficiently\nextract programming-language-specific sub-models using appropriate calibration\ndatasets while maintaining acceptable accuracy w.r.t. full models. We are also\nthe first to provide analytical evidence that domain-specific tasks activate\ndistinct regions within LLMs, supporting the creation of specialized sub-models\nthrough unstructured pruning. We believe that this work has significant\npotential to enhance LLM accessibility for coding by reducing computational\nrequirements to enable local execution on consumer-grade hardware, and\nsupporting faster inference times critical for real-time development feedback.\n","authors":["Laura Puccioni","Alireza Farshin","Mariano Scazzariello","Changjie Wang","Marco Chiesa","Dejan Kostic"],"pdf_url":"https://arxiv.org/pdf/2501.05248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05247v1","updated":"2025-01-09T13:57:09Z","published":"2025-01-09T13:57:09Z","title":"Online Prompt and Solver Selection for Program Synthesis","summary":"  Large Language Models (LLMs) demonstrate impressive capabilities in the\ndomain of program synthesis. This level of performance is not, however,\nuniversal across all tasks, all LLMs and all prompting styles. There are many\nareas where one LLM dominates, one prompting style dominates, or where calling\na symbolic solver is a better choice than an LLM. A key challenge for the user\nthen, is to identify not only when an LLM is the right choice of solver, and\nthe appropriate LLM to call for a given synthesis task, but also the right way\nto call it. A non-expert user who makes the wrong choice, incurs a cost both in\nterms of results (number of tasks solved, and the time it takes to solve them)\nand financial cost, if using a closed-source language model via a commercial\nAPI. We frame this choice as an online learning problem. We use a multi-armed\nbandit algorithm to select which symbolic solver, or LLM and prompt combination\nto deploy in order to maximize a given reward function (which may prioritize\nsolving time, number of synthesis tasks solved, or financial cost of solving).\nWe implement an instance of this approach, called CYANEA, and evaluate it on\nsynthesis queries from the literature in ranking function synthesis, from the\nsyntax-guided synthesis competition, and fresh, unseen queries generated from\nSMT problems. CYANEA solves 37.2\\% more queries than the best single solver and\nachieves results within 4\\% of the virtual best solver.\n","authors":["Yixuan Li","Lewis Frampton","Federico Mora","Elizabeth Polgreen"],"pdf_url":"https://arxiv.org/pdf/2501.05247v1.pdf","comment":"Accepted at the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25) Main Track"},{"id":"http://arxiv.org/abs/2501.04600v2","updated":"2025-01-09T13:44:15Z","published":"2025-01-08T16:31:59Z","title":"Do Automated Fixes Truly Mitigate Smart Contract Exploits?","summary":"  Automated Program Repair (APR) for smart contract security promises to\nautomatically mitigate smart contract vulnerabilities responsible for billions\nin financial losses. However, the true effectiveness of this research in\naddressing smart contract exploits remains uncharted territory. This paper\nbridges this critical gap by introducing a novel and systematic experimental\nframework for evaluating exploit mitigation of program repair tools for smart\ncontracts. We qualitatively and quantitatively analyze 20 state-of-the-art APR\ntools using a dataset of 143 vulnerable smart contracts, for which we manually\ncraft 91 executable exploits. We are the very first to define and measure the\nessential \"exploit mitigation rate\", giving researchers and practitioners and\nreal sense of effectiveness of cutting edge techniques. Our findings reveal\nsubstantial disparities in the state of the art, with an exploit mitigation\nrate ranging from a low of 27% to a high of 73%, a result that nobody would\nguess from reading the original papers. Our study identifies systemic\nlimitations, such as inconsistent functionality preservation, that must be\naddressed in future research on program repair for smart contracts.\n","authors":["Sofia Bobadilla","Monica Jin","Martin Monperrus"],"pdf_url":"https://arxiv.org/pdf/2501.04600v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05176v1","updated":"2025-01-09T11:52:32Z","published":"2025-01-09T11:52:32Z","title":"Deep Assessment of Code Review Generation Approaches: Beyond Lexical\n  Similarity","summary":"  Code review is a standard practice for ensuring the quality of software\nprojects, and recent research has focused extensively on automated code review.\nWhile significant advancements have been made in generating code reviews, the\nautomated assessment of these reviews remains less explored, with existing\napproaches and metrics often proving inaccurate. Current metrics, such as BLEU,\nprimarily rely on lexical similarity between generated and reference reviews.\nHowever, such metrics tend to underestimate reviews that articulate the\nexpected issues in ways different from the references. In this paper, we\nexplore how semantic similarity between generated and reference reviews can\nenhance the automated assessment of code reviews. We first present a benchmark\ncalled \\textit{GradedReviews}, which is constructed by collecting real-world\ncode reviews from open-source projects, generating reviews using\nstate-of-the-art approaches, and manually assessing their quality. We then\nevaluate existing metrics for code review assessment using this benchmark,\nrevealing their limitations. To address these limitations, we propose two novel\nsemantic-based approaches for assessing code reviews. The first approach\ninvolves converting both the generated review and its reference into digital\nvectors using a deep learning model and then measuring their semantic\nsimilarity through Cosine similarity. The second approach generates a prompt\nbased on the generated review and its reference, submits this prompt to\nChatGPT, and requests ChatGPT to rate the generated review according to\nexplicitly defined criteria. Our evaluation on the \\textit{GradedReviews}\nbenchmark indicates that the proposed semantic-based approaches significantly\noutperform existing state-of-the-art metrics in assessing generated code\nreview, improving the correlation coefficient between the resulting scores and\nhuman scores from 0.22 to 0.47.\n","authors":["Yanjie Jiang","Hui Liu","Tianyi Chen","Fu Fan","Chunhao Dong","Kui Liu","Lu Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.05176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05165v1","updated":"2025-01-09T11:38:58Z","published":"2025-01-09T11:38:58Z","title":"Bringing Order Amidst Chaos: On the Role of Artificial Intelligence in\n  Secure Software Engineering","summary":"  Context. Developing secure and reliable software remains a key challenge in\nsoftware engineering (SE). The ever-evolving technological landscape offers\nboth opportunities and threats, creating a dynamic space where chaos and order\ncompete. Secure software engineering (SSE) must continuously address\nvulnerabilities that endanger software systems and carry broader socio-economic\nrisks, such as compromising critical national infrastructure and causing\nsignificant financial losses. Researchers and practitioners have explored\nmethodologies like Static Application Security Testing Tools (SASTTs) and\nartificial intelligence (AI) approaches, including machine learning (ML) and\nlarge language models (LLMs), to detect and mitigate these vulnerabilities.\nEach method has unique strengths and limitations.\n  Aim. This thesis seeks to bring order to the chaos in SSE by addressing\ndomain-specific differences that impact AI accuracy.\n  Methodology. The research employs a mix of empirical strategies, such as\nevaluating effort-aware metrics, analyzing SASTTs, conducting method-level\nanalysis, and leveraging evidence-based techniques like systematic dataset\nreviews. These approaches help characterize vulnerability prediction datasets.\n  Results. Key findings include limitations in static analysis tools for\nidentifying vulnerabilities, gaps in SASTT coverage of vulnerability types,\nweak relationships among vulnerability severity scores, improved defect\nprediction accuracy using just-in-time modeling, and threats posed by untouched\nmethods.\n  Conclusions. This thesis highlights the complexity of SSE and the importance\nof contextual knowledge in improving AI-driven vulnerability and defect\nprediction. The comprehensive analysis advances effective prediction models,\nbenefiting both researchers and practitioners.\n","authors":["Matteo Esposito"],"pdf_url":"https://arxiv.org/pdf/2501.05165v1.pdf","comment":"PhD thesis"},{"id":"http://arxiv.org/abs/2410.09352v2","updated":"2025-01-09T09:24:40Z","published":"2024-10-12T03:36:52Z","title":"LogLM: From Task-based to Instruction-based Automated Log Analysis","summary":"  Automatic log analysis is essential for the efficient Operation and\nMaintenance (O&M) of software systems, providing critical insights into system\nbehaviors. However, existing approaches mostly treat log analysis as training a\nmodel to perform an isolated task ( e.g., anomaly detection, log parsing, etc.)\nusing task-specific log-label pairs. These task-based approaches are inflexible\nin generalizing to complex scenarios, depend on task-specific training data,\nand cost significantly when deploying multiple models. In this paper, we\npropose an instruction-based training approach that transforms log-label pairs\nfrom multiple tasks and domains into a unified format of instruction-response\npairs. Our trained model, LogLM, can follow complex user instructions and\ngeneralize better across different tasks, thereby increasing flexibility and\nreducing the dependence on task-specific training data. By integrating major\nlog analysis tasks into a single model, our approach also relieves model\ndeployment burden. Experimentally, LogLM outperforms existing approaches across\nfive log analysis capabilities, and exhibits strong generalization abilities on\ncomplex instructions and unseen tasks.\n","authors":["Yilun Liu","Yuhe Ji","Shimin Tao","Minggui He","Weibin Meng","Shenglin Zhang","Yongqian Sun","Yuming Xie","Boxing Chen","Hao Yang"],"pdf_url":"https://arxiv.org/pdf/2410.09352v2.pdf","comment":"Accepted by ICSE 2025 (SEIP Track)"},{"id":"http://arxiv.org/abs/2411.14503v2","updated":"2025-01-09T08:55:07Z","published":"2024-11-21T08:31:06Z","title":"Planning-Driven Programming: A Large Language Model Programming Workflow","summary":"  The strong performance of large language models (LLMs) raises extensive\ndiscussion on their application to code generation. Recent research suggests\ncontinuous program refinements through visible tests to improve code generation\naccuracy in LLMs. However, these methods suffer from LLMs' inefficiency and\nlimited reasoning capacity. In this work, we propose an LLM programming\nworkflow (LPW) designed to improve both initial code generation and subsequent\nrefinements within a structured two-phase workflow. Specifically, the solution\ngeneration phase formulates a solution plan, which is then verified through\nvisible tests to specify the intended natural language solution. Subsequently,\nthe code implementation phase drafts an initial code according to the solution\nplan and its verification. If the generated code fails the visible tests, the\nplan verification serves as the intended solution to consistently inform the\nrefinement process for correcting bugs. Compared to state-of-the-art methods\nacross various existing LLMs, LPW significantly improves the Pass@1 accuracy by\nup to 16.4% on well-established text-to-code generation benchmarks. LPW also\nsets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8%\non MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContest, using\nGPT-4o as the backbone.\n","authors":["Chao Lei","Yanchuan Chang","Nir Lipovetzky","Krista A. Ehinger"],"pdf_url":"https://arxiv.org/pdf/2411.14503v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05062v1","updated":"2025-01-09T08:34:34Z","published":"2025-01-09T08:34:34Z","title":"Deep Learning-based Code Completion: On the Impact on Performance of\n  Contextual Information","summary":"  Code completion aims at speeding up code writing by recommending to\ndevelopers the next tokens they are likely to type. Deep Learning (DL) models\npushed the boundaries of code completion by redefining what these coding\nassistants can do: We moved from predicting few code tokens to automatically\ngenerating entire functions. One important factor impacting the performance of\nDL-based code completion techniques is the context provided as input. With\n\"context\" we refer to what the model knows about the code to complete. In a\nsimple scenario, the DL model might be fed with a partially implemented\nfunction to complete. In this case, the context is represented by the\nincomplete function and, based on it, the model must generate a prediction. It\nis however possible to expand such a context to include additional information,\nlike the whole source code file containing the function to complete, which\ncould be useful to boost the prediction performance. In this work, we present\nan empirical study investigating how the performance of a DL-based code\ncompletion technique is affected by different contexts. We experiment with 8\ntypes of contexts and their combinations. These contexts include: (i) coding\ncontexts, featuring information extracted from the code base in which the code\ncompletion is invoked (e.g., code components structurally related to the one to\n\"complete\"); (ii) process context, with information aimed at depicting the\ncurrent status of the project in which a code completion task is triggered\n(e.g., a textual representation of open issues relevant for the code to\ncomplete); and (iii) developer contexts, capturing information about the\ndeveloper invoking the code completion (e.g., the APIs frequently used). Our\nresults show that additional contextual information can benefit the performance\nof DL-based code completion, with relative improvements up to +22% in terms of\ncorrect predictions.\n","authors":["Matteo Ciniselli","Luca Pascarella","Gabriele Bavota"],"pdf_url":"https://arxiv.org/pdf/2501.05062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05051v1","updated":"2025-01-09T08:20:42Z","published":"2025-01-09T08:20:42Z","title":"On the Generalizability of Transformer Models to Code Completions of\n  Different Lengths","summary":"  The programming landscape is nowadays being reshaped by the advent of Large\nLanguage Models (LLMs) able to automate code-related tasks related to code\nimplementation (e.g., code completion) and comprehension (e.g., code\nsummarization). Such a paradigm shift comes with a number of implications\nrelated to how software will be written, maintained, and evolved. Also, these\nLLMs are extremely expensive to train, posing questions on their sustainability\nover time. Given their training cost, their ability to generalize, namely their\nability to work on task instances different from those on which they have been\ntrained, is an aspect worth being investigated. Previous work already showed\nthat transformer models can successfully support code completion in a\ncross-project setting. However, it is unclear whether LLM are able to\ngeneralize to inputs having lengths not seen during training. For example, it\nis known that training a model on short instances allows to substantially\nreduce the training cost. However, the extent to which such a model would\nprovide good performance on sequences having lengths not seen during training\nis not known. Many recent works in Natural Language Processing (NLP) tackled\nthis problem in the context of decoder-only LLMs, i.e., xPOS and ALiBi. To\nassess if these solutions extend to encoder-decoder LLMs usually adopted in the\ncode-related tasks, we present a large empirical study evaluating this\ngeneralization property of these and other encoding schemes proposed in the\nliterature, namely Sinusoidal, xPOS, ALiBi, and T5. We found that none of these\nsolutions successfully generalize to unseen lengths and that the only safe\nsolution is to ensure the representativeness in the training set of all lengths\nlikely to be encountered at inference time.\n","authors":["Nathan Cooper","Rosalia Tufano","Gabriele Bavota","Denys Poshyvanyk"],"pdf_url":"https://arxiv.org/pdf/2501.05051v1.pdf","comment":"Accepted for publication at ICSME 2024"},{"id":"http://arxiv.org/abs/2501.04976v1","updated":"2025-01-09T05:15:55Z","published":"2025-01-09T05:15:55Z","title":"On the Diagnosis of Flaky Job Failures: Understanding and Prioritizing\n  Failure Categories","summary":"  The continuous delivery of modern software requires the execution of many\nautomated pipeline jobs. These jobs ensure the frequent release of new software\nversions while detecting code problems at an early stage. For TELUS, our\nindustrial partner in the telecommunications field, reliable job execution is\ncrucial to minimize wasted time and streamline Continuous Deployment (CD). In\nthis context, flaky job failures are one of the main issues hindering CD. Prior\nstudies proposed techniques based on machine learning to automate the detection\nof flaky jobs. While valuable, these solutions are insufficient to address the\nwaste associated with the diagnosis of flaky failures, which remain largely\nunexplored due to the wide range of underlying causes. This study examines\n4,511 flaky job failures at TELUS to identify the different categories of flaky\nfailures that we prioritize based on Recency, Frequency, and Monetary (RFM)\nmeasures. We identified 46 flaky failure categories that we analyzed using\nclustering and RFM measures to determine 14 priority categories for future\nautomated diagnosis and repair research. Our findings also provide valuable\ninsights into the evolution and impact of these categories. The identification\nand prioritization of flaky failure categories using RFM analysis introduce a\nnovel approach that can be used in other contexts.\n","authors":["Henri Aïdasso","Francis Bordeleau","Ali Tizghadam"],"pdf_url":"https://arxiv.org/pdf/2501.04976v1.pdf","comment":"This paper has been accepted at the 47th International Conference on\n  Software Engineering: Software Engineering in Practice 2025"},{"id":"http://arxiv.org/abs/2310.08275v4","updated":"2025-01-09T02:31:37Z","published":"2023-10-12T12:24:52Z","title":"Harnessing the Power of LLM to Support Binary Taint Analysis","summary":"  This paper proposes LATTE, the first static binary taint analysis that is\npowered by a large language model (LLM). LATTE is superior to the state of the\nart (e.g., Emtaint, Arbiter, Karonte) in three aspects. First, LATTE is fully\nautomated while prior static binary taint analyzers need rely on human\nexpertise to manually customize taint propagation rules and vulnerability\ninspection rules. Second, LATTE is significantly effective in vulnerability\ndetection, demonstrated by our comprehensive evaluations. For example, LATTE\nhas found 37 new bugs in real-world firmware which the baselines failed to\nfind, and 7 of them have been assigned CVE numbers. Lastly, LATTE incurs\nremarkably low engineering cost, making it a cost-efficient and scalable\nsolution for security researchers and practitioners. We strongly believe that\nLATTE opens up a new direction to harness the recent advance in LLMs to improve\nvulnerability analysis for binary programs.\n","authors":["Puzhuo Liu","Chengnian Sun","Yaowen Zheng","Xuan Feng","Chuan Qin","Yuncheng Wang","Zhenyang Xu","Zhi Li","Peng Di","Yu Jiang","Limin Sun"],"pdf_url":"https://arxiv.org/pdf/2310.08275v4.pdf","comment":"36 pages,16 figures"},{"id":"http://arxiv.org/abs/2306.17077v4","updated":"2025-01-09T01:29:00Z","published":"2023-06-29T16:28:34Z","title":"RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot","summary":"  Performance bugs are non-functional bugs that can even manifest in\nwell-tested commercial products. Fixing these performance bugs is an important\nyet challenging problem. In this work, we address this challenge and present a\nnew approach called Retrieval-Augmented Prompt Generation (RAPGen). Given a\ncode snippet with a performance issue, RAPGen first retrieves a prompt\ninstruction from a pre-constructed knowledge-base of previous performance bug\nfixes and then generates a prompt using the retrieved instruction. It then uses\nthis prompt on a Large Language Model (such as Codex) in zero-shot to generate\na fix. We compare our approach with the various prompt variations and state of\nthe art methods in the task of performance bug fixing. Our evaluation shows\nthat RAPGen can generate performance improvement suggestions equivalent or\nbetter than a developer in ~60% of the cases, getting ~42% of them verbatim, in\nan expert-verified dataset of past performance changes made by C# developers.\n","authors":["Spandan Garg","Roshanak Zilouchian Moghaddam","Neel Sundaresan"],"pdf_url":"https://arxiv.org/pdf/2306.17077v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04890v1","updated":"2025-01-09T00:10:59Z","published":"2025-01-09T00:10:59Z","title":"Evaluating Developer-written Unit Test Case Reduction for Java -- A\n  Replication Study","summary":"  Abstract: Failing test case reduction can promote efficient debugging because\na developer may not need to observe components that are not relevant to\ninducing failure. Failing test case reduction can also improve the efficiency\nof fault localization. These considerations have prompted researchers to study\nthe reduction process, the reduction output, and the removed entities. Christi\net al. studied test reduction using a tool called ReduSharptor for C# tests.\nThey considered the test to be an Abstract Syntax Tree (AST). Based on that,\nthey studied the reduction outcome and removed entities in terms of Leaf nodes\nand Non-Leaf nodes of the AST. They claimed that (1) leaf nodes are removed in\nlarge numbers, and (2) the probability of removal is slightly higher than\nnon-leaf nodes. We replicate their results using a different test case\nreduction tool, ReduJavator, for Java unit tests. We evaluate test reduction\nusing 30 randomly chosen bugs from the Defects4J database and 30 mutants for 6\nopen-source projects. Our results confirm their first claim: leaf nodes are\nremoved in large numbers. Our results are inconclusive regarding their second\nclaim; we cannot confirm that the probability of removal is higher for non-leaf\nnodes.\n","authors":["Tuan D Le","Brandon Wilber","Arpit Christi"],"pdf_url":"https://arxiv.org/pdf/2501.04890v1.pdf","comment":"5 pages and 4 figures"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2501.05621v1","updated":"2025-01-09T23:41:24Z","published":"2025-01-09T23:41:24Z","title":"Employing Social Media to Improve Mental Health Outcomes","summary":"  As social media platforms are increasingly adopted, the data the data people\nleave behind is shining new light into our understanding of phenomena, ranging\nfrom socio-economic-political events to the spread of infectious diseases. This\nchapter presents research conducted in the past decade that has harnessed\nsocial media data in the service of mental health and well-being. The\ndiscussion is organized along three thrusts: a first that highlights how social\nmedia data has been utilized to detect and predict risk to varied mental health\nconcerns; a second thrust that focuses on translation paradigms that can enable\nto use of such social media based algorithms in the real-world; and the final\nthrust that brings to the fore the ethical considerations and challenges that\nengender the conduct of this research as well as its translation. The chapter\nconcludes by noting open questions and problems in this emergent area,\nemphasizing the need for deeper interdisciplinary collaborations and\nparticipatory research design, incorporating and centering on human agency, and\nattention to societal inequities and harms that may result from or be\nexacerbated in this line of computational social science research.\n","authors":["Munmun De Choudhury"],"pdf_url":"https://arxiv.org/pdf/2501.05621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05610v1","updated":"2025-01-09T23:18:38Z","published":"2025-01-09T23:18:38Z","title":"Towards Probabilistic Inference of Human Motor Intentions by Assistive\n  Mobile Robots Controlled via a Brain-Computer Interface","summary":"  Assistive mobile robots are a transformative technology that helps persons\nwith disabilities regain the ability to move freely. Although autonomous\nwheelchairs significantly reduce user effort, they still require human input to\nallow users to maintain control and adapt to changing environments. Brain\nComputer Interface (BCI) stands out as a highly user-friendly option that does\nnot require physical movement. Current BCI systems can understand whether users\nwant to accelerate or decelerate, but they implement these changes in discrete\nspeed steps rather than allowing for smooth, continuous velocity adjustments.\nThis limitation prevents the systems from mimicking the natural, fluid speed\nchanges seen in human self-paced motion. The authors aim to address this\nlimitation by redesigning the perception-action cycle in a BCI controlled\nrobotic system: improving how the robotic agent interprets the user's motion\nintentions (world state) and implementing these actions in a way that better\nreflects natural physical properties of motion, such as inertia and damping.\nThe scope of this paper focuses on the perception aspect. We asked and answered\na normative question \"what computation should the robotic agent carry out to\noptimally perceive incomplete or noisy sensory observations?\" Empirical EEG\ndata were collected, and probabilistic representation that served as world\nstate distributions were learned and evaluated in a Generative Adversarial\nNetwork framework. The ROS framework was established that connected with a\nGazebo environment containing a digital twin of an indoor space and a virtual\nmodel of a robotic wheelchair. Signal processing and statistical analyses were\nimplemented to identity the most discriminative features in the\nspatial-spectral-temporal dimensions, which are then used to construct the\nworld model for the robotic agent to interpret user motion intentions as a\nBayesian observer.\n","authors":["Xiaoshan Zhou","Carol M. Menassa","Vineet R. Kamat"],"pdf_url":"https://arxiv.org/pdf/2501.05610v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.02095v2","updated":"2025-01-09T22:38:13Z","published":"2024-11-04T13:59:01Z","title":"The evolution of volumetric video: A survey of smart transcoding and\n  compression approaches","summary":"  Volumetric video, the capture and display of three-dimensional (3D) imagery,\nhas emerged as a revolutionary technology poised to transform the media\nlandscape, enabling immersive experiences that transcend the limitations of\ntraditional 2D video. One of the key challenges in this domain is the efficient\ndelivery of these high-bandwidth, data-intensive volumetric video streams,\nwhich requires innovative transcoding and compression techniques. This research\npaper explores the state-of-the-art in volumetric video compression and\ndelivery, with a focus on the potential of AI-driven solutions to address the\nunique challenges posed by this emerging medium.\n","authors":["Preetish Kakkar","Hariharan Ragothaman"],"pdf_url":"https://arxiv.org/pdf/2411.02095v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05600v1","updated":"2025-01-09T22:17:23Z","published":"2025-01-09T22:17:23Z","title":"The Multifaceted Nature of Mentoring in OSS: Strategies, Qualities, and\n  Ideal Outcomes","summary":"  Mentorship in open source software (OSS) is a vital, multifaceted process\nthat includes onboarding newcomers, fostering skill development, and enhancing\ncommunity building. This study examines task-focused mentoring strategies that\nhelp mentees complete their tasks and the ideal personal qualities and outcomes\nof good mentorship in OSS communities. We conducted two surveys to gather\ncontributor perceptions: the first survey, with 70 mentors, mapped 17 mentoring\nchallenges to 21 strategies that help support mentees. The second survey, with\n85 contributors, assessed the importance of personal qualities and ideal\nmentorship outcomes. Our findings not only provide actionable strategies to\nhelp mentees overcome challenges and become successful contributors but also\nguide current and future mentors and OSS communities in understanding the\npersonal qualities that are the cornerstone of good mentorship and the outcomes\nthat mentor-mentee pairs should aspire to achieve.\n","authors":["Zixuan Feng","Igor Steinmacher","Marco Gerosa","Tyler Menezes","Alexander Serebrenik","Reed Milewicz","Anita Sarma"],"pdf_url":"https://arxiv.org/pdf/2501.05600v1.pdf","comment":"10 pages, the 18th International Conference on Cooperative and Human\n  Aspects of Software Engineering (CHASE 2025)"},{"id":"http://arxiv.org/abs/2501.05595v1","updated":"2025-01-09T21:56:51Z","published":"2025-01-09T21:56:51Z","title":"Human-centered Geospatial Data Science","summary":"  This entry provides an overview of Human-centered Geospatial Data Science,\nhighlighting the gaps it aims to bridge, its significance, and its key topics\nand research. Geospatial Data Science, which derives geographic knowledge and\ninsights from large volumes of geospatial big data using advanced Geospatial\nArtificial Intelligence (GeoAI), has been widely used to tackle a wide range of\ngeographic problems. However, it often overlooks the subjective human\nexperiences that fundamentally influence human-environment interactions, and\nfew strategies have been developed to ensure that these technologies follow\nethical guidelines and prioritize human values. Human-centered Geospatial Data\nScience advocates for two primary focuses. First, it advances our understanding\nof human-environment interactions by leveraging Geospatial Data Science to\nmeasure and analyze human subjective experiences at place including emotion,\nperception, cognition, and creativity. Second, it advocates for the development\nof responsible and ethical Geospatial Data Science methods that protect\ngeoprivacy, enhance fairness and reduce bias, and improve the explainability\nand transparency of geospatial technologies. With these two missions,\nHuman-centered Geospatial Data Sciences brings a fresh perspective to develop\nand utilize geospatial technologies that positively impact society and benefit\nhuman well-being and the humanities.\n","authors":["Yuhao Kang"],"pdf_url":"https://arxiv.org/pdf/2501.05595v1.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2501.05589v1","updated":"2025-01-09T21:51:45Z","published":"2025-01-09T21:51:45Z","title":"LGL-BCI: A Motor-Imagery-Based Brain-Computer Interface with Geometric\n  Learning","summary":"  Brain--computer interfaces are groundbreaking technology whereby brain\nsignals are used to control external devices. Despite some advances in recent\nyears, electroencephalogram (EEG)-based motor-imagery tasks face challenges,\nsuch as amplitude and phase variability and complex spatial correlations, with\na need for smaller models and faster inference. In this study, we develop a\nprototype, called the Lightweight Geometric Learning Brain--Computer Interface\n(LGL-BCI), which uses our customized geometric deep learning architecture for\nswift model inference without sacrificing accuracy. LGL-BCI contains an EEG\nchannel selection module via a feature decomposition algorithm to reduce the\ndimensionality of a symmetric positive definite matrix, providing adaptiveness\namong the continuously changing EEG signal. Meanwhile, a built-in lossless\ntransformation helps boost the inference speed. The performance of our solution\nwas evaluated using two real-world EEG devices and two public EEG datasets.\nLGL-BCI demonstrated significant improvements, achieving an accuracy of 82.54%\ncompared to 62.22% for the state-of-the-art approach. Furthermore, LGL-BCI uses\nfewer parameters (64.9K vs. 183.7K), highlighting its computational efficiency.\nThese findings underscore both the superior accuracy and computational\nefficiency of LGL-BCI, demonstrating the feasibility and robustness of\ngeometric deep learning in motor-imagery brain--computer interface\napplications.\n","authors":["Jianchao Lu","Yuzhe Tian","Yang Zhang","Quan Z. Sheng","Xi Zheng"],"pdf_url":"https://arxiv.org/pdf/2501.05589v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2310.08051"}]},"2025-01-08T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2501.04835v1","updated":"2025-01-08T20:39:45Z","published":"2025-01-08T20:39:45Z","title":"Do Code LLMs Understand Design Patterns?","summary":"  Code Large Language Models (LLMs) demonstrate great versatility in adapting\nto various downstream tasks, including code generation and completion, as well\nas bug detection and fixing. However, Code LLMs often fail to capture existing\ncoding standards, leading to the generation of code that conflicts with the\nrequired design patterns for a given project. As a result, developers must\npost-process to adapt the generated code to the project's design norms. In this\nwork, we empirically investigate the biases of Code LLMs in software\ndevelopment. Through carefully designed experiments, we assess the models'\nunderstanding of design patterns across recognition, comprehension, and\ngeneration. Our findings reveal that biases in Code LLMs significantly affect\nthe reliability of downstream tasks.\n","authors":["Zhenyu Pan","Xuefeng Song","Yunkun Wang","Rongyu Cao","Binhua Li","Yongbin Li","Han Liu"],"pdf_url":"https://arxiv.org/pdf/2501.04835v1.pdf","comment":"accpeted by llm4code workshop in ICSE 2025"},{"id":"http://arxiv.org/abs/2310.14548v2","updated":"2025-01-08T20:01:28Z","published":"2023-10-23T04:03:56Z","title":"Test Smell: A Parasitic Energy Consumer in Software Testing","summary":"  Traditionally, energy efficiency research has focused on reducing energy\nconsumption at the hardware level and, more recently, in the design and coding\nphases of the software development life cycle. However, software testing's\nimpact on energy consumption did not receive attention from the research\ncommunity. Specifically, how test code design quality and test smell (e.g.,\nsub-optimal design and bad practices in test code) impact energy consumption\nhas not been investigated yet. This study examined 12 Apache projects to\nanalyze the association between test smell and its effects on energy\nconsumption in software testing. We conducted a mixed-method empirical analysis\nfrom two dimensions; software (data mining in Apache projects) and developers'\nviews (a survey of 62 software practitioners). Our findings show that: 1) test\nsmell is associated with energy consumption in software testing. Specifically\nsmelly part of a test case consumes 10.92\\% more energy compared to the\nnon-smelly part. 2) certain test smells are more energy-hungry than others, 3)\nrefactored test cases tend to consume less energy than their smelly\ncounterparts, and 4) most developers lack knowledge about test smells' impact\non energy consumption. We conclude the paper with several observations that can\ndirect future research and developments.\n","authors":["Md Rakib Hossain Misu","Jiawei Li","Adithya Bhattiprolu","Yang Liu","Eduardo Almeida","Iftekhar Ahmed"],"pdf_url":"https://arxiv.org/pdf/2310.14548v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04811v1","updated":"2025-01-08T19:59:48Z","published":"2025-01-08T19:59:48Z","title":"Fast, Fine-Grained Equivalence Checking for Neural Decompilers","summary":"  Neural decompilers are machine learning models that reconstruct the source\ncode from an executable program. Critical to the lifecycle of any machine\nlearning model is an evaluation of its effectiveness. However, existing\ntechniques for evaluating neural decompilation models have substantial\nweaknesses, especially when it comes to showing the correctness of the neural\ndecompiler's predictions. To address this, we introduce codealign, a novel\ninstruction-level code equivalence technique designed for neural decompilers.\nWe provide a formal definition of a relation between equivalent instructions,\nwhich we term an equivalence alignment. We show how codealign generates\nequivalence alignments, then evaluate codealign by comparing it with symbolic\nexecution. Finally, we show how the information codealign provides-which parts\nof the functions are equivalent and how well the variable names match-is\nsubstantially more detailed than existing state-of-the-art evaluation metrics,\nwhich report unitless numbers measuring similarity.\n","authors":["Luke Dramko","Claire Le Goues","Edward J. Schwartz"],"pdf_url":"https://arxiv.org/pdf/2501.04811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04810v1","updated":"2025-01-08T19:54:31Z","published":"2025-01-08T19:54:31Z","title":"On the Impact of Requirements Smells in Prompts: The Case of Automated\n  Traceability","summary":"  Large language models (LLMs) are increasingly used to generate software\nartifacts, such as source code, tests, and trace links. Requirements play a\ncentral role in shaping the input prompts that guide LLMs, as they are often\nused as part of the prompts to synthesize the artifacts. However, the impact of\nrequirements formulation on LLM performance remains unclear. In this paper, we\ninvestigate the role of requirements smells-indicators of potential issues like\nambiguity and inconsistency-when used in prompts for LLMs. We conducted\nexperiments using two LLMs focusing on automated trace link generation between\nrequirements and code. Our results show mixed outcomes: while requirements\nsmells had a small but significant effect when predicting whether a requirement\nwas implemented in a piece of code (i.e., a trace link exists), no significant\neffect was observed when tracing the requirements with the associated lines of\ncode. These findings suggest that requirements smells can affect LLM\nperformance in certain SE tasks but may not uniformly impact all tasks. We\nhighlight the need for further research to understand these nuances and propose\nfuture work toward developing guidelines for mitigating the negative effects of\nrequirements smells in AI-driven SE processes.\n","authors":["Andreas Vogelsang","Alexander Korn","Giovanna Broccia","Alessio Ferrari","Jannik Fischbach","Chetan Arora"],"pdf_url":"https://arxiv.org/pdf/2501.04810v1.pdf","comment":"Accepted at 2025 IEEE/ACM 47th International Conference on Software\n  Engineering: New Ideas and Emerging Results (ICSE-NIER)"},{"id":"http://arxiv.org/abs/2501.04798v1","updated":"2025-01-08T19:24:05Z","published":"2025-01-08T19:24:05Z","title":"Teaching Simulation as a Research Method in Empirical Software\n  Engineering","summary":"  The chapter supports educators and postgraduate students in understanding the\nrole of simulation in software engineering research based on the authors'\nexperience. This way, it includes a background positioning simulation-based\nstudies in software engineering research, the proposition of learning\nobjectives for teaching simulation as a research method, and presents our\nexperience when teaching simulation concepts and practice. For educators, it\nfurther provides learning objectives when teaching simulation, considering the\ncurrent state of the art in software engineering research and the necessary\nguidance and recommended learning activities to achieve these objectives. For\nstudents, it drives the learning path for those interested in learning this\nmethod but had no opportunity to engage in an entire course on simulation in\nthe context of empirical research.\n","authors":["Breno Bernard Nicolau de França","Dietmar Pfahl","Valdemar Vicente Graciano Neto","Nauman bin Ali"],"pdf_url":"https://arxiv.org/pdf/2501.04798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01176v3","updated":"2025-01-08T19:00:09Z","published":"2024-05-02T11:02:23Z","title":"SOPA: A Framework for Sustainability-Oriented Process Analysis and\n  Re-design in Business Process Management","summary":"  Given the continuous global degradation of the Earth's ecosystem due to\nunsustainable human activity, it is increasingly important for enterprises to\nevaluate the effects they have on the environment. Consequently, assessing the\nimpact of business processes on sustainability is becoming an important\nconsideration in the discipline of Business Process Management (BPM). However,\nexisting practical approaches that aim at a sustainability-oriented analysis of\nbusiness processes provide only a limited perspective on the environmental\nimpact caused. Further, they provide no clear and practically applicable\nmechanism for sustainability-driven process analysis and re-design. Following a\ndesign science methodology, we here propose and study SOPA, a framework for\nsustainability-oriented process analysis and re-design. SOPA extends the BPM\nlife cycle by use of Life Cycle Assessment (LCA) for sustainability analysis in\ncombination with Activity-based Costing (ABC). We evaluate SOPA and its\nusefulness with a case study, by means of an implementation to support the\napproach, thereby also illustrating the practical applicability of this work.\n","authors":["Finn Klessascheck","Ingo Weber","Luise Pufahl"],"pdf_url":"https://arxiv.org/pdf/2405.01176v3.pdf","comment":null}]}}